2024-01-15 11:36:40,741 - Log file for this run: /Users/francescocenciarelli/Desktop/Cambridge/PMLS/coursework/ai8x-training/logs/2024.01.15-113640/2024.01.15-113640.log
2024-01-15 11:36:40,759 - Optimizer Type: <class 'torch.optim.sgd.SGD'>
2024-01-15 11:36:40,759 - Optimizer Args: {'lr': 0.1, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False}
2024-01-15 11:36:40,828 - Dataset sizes:
	training=54000
	validation=6000
	test=10000
2024-01-15 11:36:40,828 - Reading compression schedule from: policies/schedule.yaml
2024-01-15 11:36:40,831 - 

2024-01-15 11:36:40,831 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:36:50,870 - Epoch: [0][   10/  211]    Overall Loss 2.298568    Objective Loss 2.298568                                        LR 0.100000    Time 1.003764    
2024-01-15 11:36:56,465 - Epoch: [0][   20/  211]    Overall Loss 2.263910    Objective Loss 2.263910                                        LR 0.100000    Time 0.781605    
2024-01-15 11:37:02,439 - Epoch: [0][   30/  211]    Overall Loss 2.198977    Objective Loss 2.198977                                        LR 0.100000    Time 0.720127    
2024-01-15 11:37:08,037 - Epoch: [0][   40/  211]    Overall Loss 2.087190    Objective Loss 2.087190                                        LR 0.100000    Time 0.680023    
2024-01-15 11:37:14,894 - Epoch: [0][   50/  211]    Overall Loss 1.950644    Objective Loss 1.950644                                        LR 0.100000    Time 0.681131    
2024-01-15 11:37:20,949 - Epoch: [0][   60/  211]    Overall Loss 1.819505    Objective Loss 1.819505                                        LR 0.100000    Time 0.668496    
2024-01-15 11:37:28,126 - Epoch: [0][   70/  211]    Overall Loss 1.688277    Objective Loss 1.688277                                        LR 0.100000    Time 0.675492    
2024-01-15 11:37:34,717 - Epoch: [0][   80/  211]    Overall Loss 1.578313    Objective Loss 1.578313                                        LR 0.100000    Time 0.673427    
2024-01-15 11:37:40,823 - Epoch: [0][   90/  211]    Overall Loss 1.479738    Objective Loss 1.479738                                        LR 0.100000    Time 0.666432    
2024-01-15 11:37:47,481 - Epoch: [0][  100/  211]    Overall Loss 1.391312    Objective Loss 1.391312                                        LR 0.100000    Time 0.666358    
2024-01-15 11:37:53,616 - Epoch: [0][  110/  211]    Overall Loss 1.321136    Objective Loss 1.321136                                        LR 0.100000    Time 0.661537    
2024-01-15 11:37:59,356 - Epoch: [0][  120/  211]    Overall Loss 1.259472    Objective Loss 1.259472                                        LR 0.100000    Time 0.654234    
2024-01-15 11:38:04,993 - Epoch: [0][  130/  211]    Overall Loss 1.198456    Objective Loss 1.198456                                        LR 0.100000    Time 0.647265    
2024-01-15 11:38:10,713 - Epoch: [0][  140/  211]    Overall Loss 1.140286    Objective Loss 1.140286                                        LR 0.100000    Time 0.641881    
2024-01-15 11:38:16,482 - Epoch: [0][  150/  211]    Overall Loss 1.089527    Objective Loss 1.089527                                        LR 0.100000    Time 0.637539    
2024-01-15 11:38:22,012 - Epoch: [0][  160/  211]    Overall Loss 1.043740    Objective Loss 1.043740                                        LR 0.100000    Time 0.632248    
2024-01-15 11:38:28,118 - Epoch: [0][  170/  211]    Overall Loss 1.002781    Objective Loss 1.002781                                        LR 0.100000    Time 0.630971    
2024-01-15 11:38:33,988 - Epoch: [0][  180/  211]    Overall Loss 0.963927    Objective Loss 0.963927                                        LR 0.100000    Time 0.628518    
2024-01-15 11:38:39,635 - Epoch: [0][  190/  211]    Overall Loss 0.929257    Objective Loss 0.929257                                        LR 0.100000    Time 0.625152    
2024-01-15 11:38:45,474 - Epoch: [0][  200/  211]    Overall Loss 0.898059    Objective Loss 0.898059                                        LR 0.100000    Time 0.623087    
2024-01-15 11:38:52,002 - Epoch: [0][  210/  211]    Overall Loss 0.867864    Objective Loss 0.867864    Top1 91.406250    Top5 99.609375    LR 0.100000    Time 0.624496    
2024-01-15 11:38:52,864 - Epoch: [0][  211/  211]    Overall Loss 0.865231    Objective Loss 0.865231    Top1 91.330645    Top5 99.193548    LR 0.100000    Time 0.625614    
2024-01-15 11:38:54,043 - --- validate (epoch=0)-----------
2024-01-15 11:38:54,045 - 6000 samples (256 per mini-batch)
2024-01-15 11:39:02,583 - Epoch: [0][   10/   24]    Loss 0.271766    Top1 91.992188    Top5 99.882812    
2024-01-15 11:39:04,555 - Epoch: [0][   20/   24]    Loss 0.275838    Top1 91.699219    Top5 99.746094    
2024-01-15 11:39:05,482 - Epoch: [0][   24/   24]    Loss 0.280030    Top1 91.533333    Top5 99.733333    
2024-01-15 11:39:06,430 - ==> Top1: 91.533    Top5: 99.733    Loss: 0.280

2024-01-15 11:39:06,432 - ==> Confusion:
[[547   0  12   2   3   7   6   3  19   6]
 [  0 672   7   2   1   0   2   3   1   0]
 [  0   2 520  22   4   6   1   8  18   5]
 [  0   1  10 558   0   4   0   4   4   2]
 [  1   7  14   2 490   3   8  10   2  28]
 [  0   3   4  14   2 469   4   3  13   6]
 [  4   3   6   0   5  11 578   0  20   4]
 [  0   6  18  22   2   4   0 566   0   7]
 [  1   2   3   7   2   7   7   1 539  15]
 [  0   5   7  12   6  13   1   7  11 553]]

2024-01-15 11:39:06,440 - ==> Best [Top1: 91.533   Top5: 99.733   Sparsity:0.00   Params: 71148 on epoch: 0]
2024-01-15 11:39:06,441 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:39:06,457 - 

2024-01-15 11:39:06,457 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:39:19,418 - Epoch: [1][   10/  211]    Overall Loss 0.288201    Objective Loss 0.288201                                        LR 0.100000    Time 1.295830    
2024-01-15 11:39:25,781 - Epoch: [1][   20/  211]    Overall Loss 0.281175    Objective Loss 0.281175                                        LR 0.100000    Time 0.965979    
2024-01-15 11:39:32,104 - Epoch: [1][   30/  211]    Overall Loss 0.276306    Objective Loss 0.276306                                        LR 0.100000    Time 0.854667    
2024-01-15 11:39:37,842 - Epoch: [1][   40/  211]    Overall Loss 0.276597    Objective Loss 0.276597                                        LR 0.100000    Time 0.784402    
2024-01-15 11:39:45,225 - Epoch: [1][   50/  211]    Overall Loss 0.285840    Objective Loss 0.285840                                        LR 0.100000    Time 0.775169    
2024-01-15 11:39:51,150 - Epoch: [1][   60/  211]    Overall Loss 0.281606    Objective Loss 0.281606                                        LR 0.100000    Time 0.744710    
2024-01-15 11:39:56,996 - Epoch: [1][   70/  211]    Overall Loss 0.275800    Objective Loss 0.275800                                        LR 0.100000    Time 0.721819    
2024-01-15 11:40:02,978 - Epoch: [1][   80/  211]    Overall Loss 0.271541    Objective Loss 0.271541                                        LR 0.100000    Time 0.706352    
2024-01-15 11:40:08,597 - Epoch: [1][   90/  211]    Overall Loss 0.264132    Objective Loss 0.264132                                        LR 0.100000    Time 0.690282    
2024-01-15 11:40:14,301 - Epoch: [1][  100/  211]    Overall Loss 0.257185    Objective Loss 0.257185                                        LR 0.100000    Time 0.678286    
2024-01-15 11:40:20,102 - Epoch: [1][  110/  211]    Overall Loss 0.253792    Objective Loss 0.253792                                        LR 0.100000    Time 0.669345    
2024-01-15 11:40:26,171 - Epoch: [1][  120/  211]    Overall Loss 0.250256    Objective Loss 0.250256                                        LR 0.100000    Time 0.664139    
2024-01-15 11:40:31,821 - Epoch: [1][  130/  211]    Overall Loss 0.247523    Objective Loss 0.247523                                        LR 0.100000    Time 0.656503    
2024-01-15 11:40:37,487 - Epoch: [1][  140/  211]    Overall Loss 0.244059    Objective Loss 0.244059                                        LR 0.100000    Time 0.650076    
2024-01-15 11:40:44,058 - Epoch: [1][  150/  211]    Overall Loss 0.240470    Objective Loss 0.240470                                        LR 0.100000    Time 0.650533    
2024-01-15 11:40:51,834 - Epoch: [1][  160/  211]    Overall Loss 0.237425    Objective Loss 0.237425                                        LR 0.100000    Time 0.658467    
2024-01-15 11:40:57,615 - Epoch: [1][  170/  211]    Overall Loss 0.232825    Objective Loss 0.232825                                        LR 0.100000    Time 0.653732    
2024-01-15 11:41:05,211 - Epoch: [1][  180/  211]    Overall Loss 0.230850    Objective Loss 0.230850                                        LR 0.100000    Time 0.659602    
2024-01-15 11:41:12,775 - Epoch: [1][  190/  211]    Overall Loss 0.228900    Objective Loss 0.228900                                        LR 0.100000    Time 0.664686    
2024-01-15 11:41:18,425 - Epoch: [1][  200/  211]    Overall Loss 0.227657    Objective Loss 0.227657                                        LR 0.100000    Time 0.659692    
2024-01-15 11:41:24,821 - Epoch: [1][  210/  211]    Overall Loss 0.226213    Objective Loss 0.226213    Top1 92.187500    Top5 100.000000    LR 0.100000    Time 0.658718    
2024-01-15 11:41:25,442 - Epoch: [1][  211/  211]    Overall Loss 0.226029    Objective Loss 0.226029    Top1 93.145161    Top5 99.798387    LR 0.100000    Time 0.658536    
2024-01-15 11:41:26,887 - --- validate (epoch=1)-----------
2024-01-15 11:41:26,892 - 6000 samples (256 per mini-batch)
2024-01-15 11:41:33,838 - Epoch: [1][   10/   24]    Loss 0.171036    Top1 95.000000    Top5 99.726562    
2024-01-15 11:41:35,861 - Epoch: [1][   20/   24]    Loss 0.165529    Top1 95.156250    Top5 99.765625    
2024-01-15 11:41:36,615 - Epoch: [1][   24/   24]    Loss 0.166594    Top1 95.066667    Top5 99.800000    
2024-01-15 11:41:37,452 - ==> Top1: 95.067    Top5: 99.800    Loss: 0.167

2024-01-15 11:41:37,455 - ==> Confusion:
[[599   0   2   0   1   0   2   0   1   0]
 [  2 671   5   0   4   0   2   3   0   1]
 [  9   0 547   1   3   2   1  11  11   1]
 [  4   0  16 539   0   8   1   6   6   3]
 [  1   0   3   1 539   1   6   1   1  12]
 [ 10   3   0   3   1 482   3   0   9   7]
 [  8   1   0   0   3   0 610   0   9   0]
 [  0   3   9   0   4   0   0 605   1   3]
 [  9   0   1   0   7   3  14   1 544   5]
 [  9   1   1   1  15   4   1   7   8 568]]

2024-01-15 11:41:37,461 - ==> Best [Top1: 95.067   Top5: 99.800   Sparsity:0.00   Params: 71148 on epoch: 1]
2024-01-15 11:41:37,462 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:41:37,477 - 

2024-01-15 11:41:37,478 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:41:48,870 - Epoch: [2][   10/  211]    Overall Loss 0.163351    Objective Loss 0.163351                                        LR 0.100000    Time 1.138984    
2024-01-15 11:41:54,441 - Epoch: [2][   20/  211]    Overall Loss 0.170151    Objective Loss 0.170151                                        LR 0.100000    Time 0.847981    
2024-01-15 11:42:00,163 - Epoch: [2][   30/  211]    Overall Loss 0.174996    Objective Loss 0.174996                                        LR 0.100000    Time 0.756026    
2024-01-15 11:42:05,690 - Epoch: [2][   40/  211]    Overall Loss 0.180964    Objective Loss 0.180964                                        LR 0.100000    Time 0.705091    
2024-01-15 11:42:11,423 - Epoch: [2][   50/  211]    Overall Loss 0.177394    Objective Loss 0.177394                                        LR 0.100000    Time 0.678693    
2024-01-15 11:42:17,479 - Epoch: [2][   60/  211]    Overall Loss 0.174972    Objective Loss 0.174972                                        LR 0.100000    Time 0.666492    
2024-01-15 11:42:23,334 - Epoch: [2][   70/  211]    Overall Loss 0.169306    Objective Loss 0.169306                                        LR 0.100000    Time 0.654909    
2024-01-15 11:42:29,277 - Epoch: [2][   80/  211]    Overall Loss 0.165252    Objective Loss 0.165252                                        LR 0.100000    Time 0.647319    
2024-01-15 11:42:35,623 - Epoch: [2][   90/  211]    Overall Loss 0.167322    Objective Loss 0.167322                                        LR 0.100000    Time 0.645884    
2024-01-15 11:42:41,583 - Epoch: [2][  100/  211]    Overall Loss 0.167319    Objective Loss 0.167319                                        LR 0.100000    Time 0.640883    
2024-01-15 11:42:47,415 - Epoch: [2][  110/  211]    Overall Loss 0.166372    Objective Loss 0.166372                                        LR 0.100000    Time 0.635634    
2024-01-15 11:42:53,869 - Epoch: [2][  120/  211]    Overall Loss 0.165071    Objective Loss 0.165071                                        LR 0.100000    Time 0.636430    
2024-01-15 11:42:59,533 - Epoch: [2][  130/  211]    Overall Loss 0.163975    Objective Loss 0.163975                                        LR 0.100000    Time 0.631033    
2024-01-15 11:43:05,235 - Epoch: [2][  140/  211]    Overall Loss 0.163425    Objective Loss 0.163425                                        LR 0.100000    Time 0.626681    
2024-01-15 11:43:10,926 - Epoch: [2][  150/  211]    Overall Loss 0.163306    Objective Loss 0.163306                                        LR 0.100000    Time 0.622835    
2024-01-15 11:43:17,008 - Epoch: [2][  160/  211]    Overall Loss 0.163632    Objective Loss 0.163632                                        LR 0.100000    Time 0.621914    
2024-01-15 11:43:22,638 - Epoch: [2][  170/  211]    Overall Loss 0.163725    Objective Loss 0.163725                                        LR 0.100000    Time 0.618440    
2024-01-15 11:43:28,722 - Epoch: [2][  180/  211]    Overall Loss 0.161918    Objective Loss 0.161918                                        LR 0.100000    Time 0.617870    
2024-01-15 11:43:35,293 - Epoch: [2][  190/  211]    Overall Loss 0.160058    Objective Loss 0.160058                                        LR 0.100000    Time 0.619930    
2024-01-15 11:43:41,598 - Epoch: [2][  200/  211]    Overall Loss 0.159064    Objective Loss 0.159064                                        LR 0.100000    Time 0.620452    
2024-01-15 11:43:48,705 - Epoch: [2][  210/  211]    Overall Loss 0.157940    Objective Loss 0.157940    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.624744    
2024-01-15 11:43:49,555 - Epoch: [2][  211/  211]    Overall Loss 0.157877    Objective Loss 0.157877    Top1 96.774194    Top5 99.798387    LR 0.100000    Time 0.625806    
2024-01-15 11:43:50,748 - --- validate (epoch=2)-----------
2024-01-15 11:43:50,750 - 6000 samples (256 per mini-batch)
2024-01-15 11:43:57,399 - Epoch: [2][   10/   24]    Loss 0.136275    Top1 96.093750    Top5 99.765625    
2024-01-15 11:43:59,373 - Epoch: [2][   20/   24]    Loss 0.136171    Top1 95.976562    Top5 99.785156    
2024-01-15 11:44:00,114 - Epoch: [2][   24/   24]    Loss 0.136150    Top1 95.966667    Top5 99.800000    
2024-01-15 11:44:00,882 - ==> Top1: 95.967    Top5: 99.800    Loss: 0.136

2024-01-15 11:44:00,884 - ==> Confusion:
[[598   0   2   0   0   0   4   0   0   1]
 [  0 684   1   0   1   0   0   2   0   0]
 [  1   4 556   4   2   1   0  10   2   6]
 [  2   2   5 560   0   5   0   8   1   0]
 [  0   0   4   0 551   0   0   2   0   8]
 [  3   1   5   1   3 499   3   0   2   1]
 [  7   6   0   0  11   6 597   0   4   0]
 [  0   0   7   1   5   1   0 608   0   3]
 [  8   1   7   3  10   5   6   3 535   6]
 [  2   3   1   3  18   5   0   9   4 570]]

2024-01-15 11:44:00,889 - ==> Best [Top1: 95.967   Top5: 99.800   Sparsity:0.00   Params: 71148 on epoch: 2]
2024-01-15 11:44:00,890 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:44:00,901 - 

2024-01-15 11:44:00,901 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:44:10,750 - Epoch: [3][   10/  211]    Overall Loss 0.136391    Objective Loss 0.136391                                        LR 0.100000    Time 0.984788    
2024-01-15 11:44:17,042 - Epoch: [3][   20/  211]    Overall Loss 0.133365    Objective Loss 0.133365                                        LR 0.100000    Time 0.806794    
2024-01-15 11:44:22,599 - Epoch: [3][   30/  211]    Overall Loss 0.138153    Objective Loss 0.138153                                        LR 0.100000    Time 0.723034    
2024-01-15 11:44:28,679 - Epoch: [3][   40/  211]    Overall Loss 0.137093    Objective Loss 0.137093                                        LR 0.100000    Time 0.694242    
2024-01-15 11:44:34,669 - Epoch: [3][   50/  211]    Overall Loss 0.136899    Objective Loss 0.136899                                        LR 0.100000    Time 0.675171    
2024-01-15 11:44:41,168 - Epoch: [3][   60/  211]    Overall Loss 0.138178    Objective Loss 0.138178                                        LR 0.100000    Time 0.670929    
2024-01-15 11:44:46,911 - Epoch: [3][   70/  211]    Overall Loss 0.139560    Objective Loss 0.139560                                        LR 0.100000    Time 0.657110    
2024-01-15 11:44:53,191 - Epoch: [3][   80/  211]    Overall Loss 0.139164    Objective Loss 0.139164                                        LR 0.100000    Time 0.653457    
2024-01-15 11:44:58,815 - Epoch: [3][   90/  211]    Overall Loss 0.138333    Objective Loss 0.138333                                        LR 0.100000    Time 0.643327    
2024-01-15 11:45:04,375 - Epoch: [3][  100/  211]    Overall Loss 0.137912    Objective Loss 0.137912                                        LR 0.100000    Time 0.634587    
2024-01-15 11:45:10,182 - Epoch: [3][  110/  211]    Overall Loss 0.140201    Objective Loss 0.140201                                        LR 0.100000    Time 0.629679    
2024-01-15 11:45:15,793 - Epoch: [3][  120/  211]    Overall Loss 0.139005    Objective Loss 0.139005                                        LR 0.100000    Time 0.623957    
2024-01-15 11:45:21,297 - Epoch: [3][  130/  211]    Overall Loss 0.139427    Objective Loss 0.139427                                        LR 0.100000    Time 0.618295    
2024-01-15 11:45:26,879 - Epoch: [3][  140/  211]    Overall Loss 0.139306    Objective Loss 0.139306                                        LR 0.100000    Time 0.613997    
2024-01-15 11:45:32,471 - Epoch: [3][  150/  211]    Overall Loss 0.137874    Objective Loss 0.137874                                        LR 0.100000    Time 0.610341    
2024-01-15 11:45:38,068 - Epoch: [3][  160/  211]    Overall Loss 0.136409    Objective Loss 0.136409                                        LR 0.100000    Time 0.607151    
2024-01-15 11:45:43,731 - Epoch: [3][  170/  211]    Overall Loss 0.135042    Objective Loss 0.135042                                        LR 0.100000    Time 0.604736    
2024-01-15 11:45:49,479 - Epoch: [3][  180/  211]    Overall Loss 0.133524    Objective Loss 0.133524                                        LR 0.100000    Time 0.603060    
2024-01-15 11:45:55,322 - Epoch: [3][  190/  211]    Overall Loss 0.132112    Objective Loss 0.132112                                        LR 0.100000    Time 0.602064    
2024-01-15 11:46:00,846 - Epoch: [3][  200/  211]    Overall Loss 0.132038    Objective Loss 0.132038                                        LR 0.100000    Time 0.599580    
2024-01-15 11:46:06,415 - Epoch: [3][  210/  211]    Overall Loss 0.131153    Objective Loss 0.131153    Top1 96.875000    Top5 99.609375    LR 0.100000    Time 0.597544    
2024-01-15 11:46:06,964 - Epoch: [3][  211/  211]    Overall Loss 0.131326    Objective Loss 0.131326    Top1 95.967742    Top5 99.798387    LR 0.100000    Time 0.597310    
2024-01-15 11:46:07,846 - --- validate (epoch=3)-----------
2024-01-15 11:46:07,848 - 6000 samples (256 per mini-batch)
2024-01-15 11:46:14,598 - Epoch: [3][   10/   24]    Loss 0.122397    Top1 96.484375    Top5 99.765625    
2024-01-15 11:46:16,958 - Epoch: [3][   20/   24]    Loss 0.122161    Top1 96.289062    Top5 99.824219    
2024-01-15 11:46:17,655 - Epoch: [3][   24/   24]    Loss 0.121778    Top1 96.300000    Top5 99.833333    
2024-01-15 11:46:18,505 - ==> Top1: 96.300    Top5: 99.833    Loss: 0.122

2024-01-15 11:46:18,506 - ==> Confusion:
[[597   0   1   0   0   1   2   0   0   4]
 [  1 677   2   3   0   0   0   4   0   1]
 [  3   1 552  13   0   0   0  14   1   2]
 [  0   0   1 570   1   2   0   7   1   1]
 [  0   1   3   0 537   1   1   5   1  16]
 [  1   0   1   6   2 501   1   0   3   3]
 [  6   5   2   0   5  10 600   0   2   1]
 [  0   2   1   3   0   0   0 618   0   1]
 [  3   2   2   8   6   5   3   3 542  10]
 [  1   1   0   6   9   3   0   9   2 584]]

2024-01-15 11:46:18,509 - ==> Best [Top1: 96.300   Top5: 99.833   Sparsity:0.00   Params: 71148 on epoch: 3]
2024-01-15 11:46:18,509 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:46:18,517 - 

2024-01-15 11:46:18,517 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:46:27,448 - Epoch: [4][   10/  211]    Overall Loss 0.108333    Objective Loss 0.108333                                        LR 0.100000    Time 0.892970    
2024-01-15 11:46:32,986 - Epoch: [4][   20/  211]    Overall Loss 0.111957    Objective Loss 0.111957                                        LR 0.100000    Time 0.723367    
2024-01-15 11:46:38,652 - Epoch: [4][   30/  211]    Overall Loss 0.117106    Objective Loss 0.117106                                        LR 0.100000    Time 0.671049    
2024-01-15 11:46:44,228 - Epoch: [4][   40/  211]    Overall Loss 0.116831    Objective Loss 0.116831                                        LR 0.100000    Time 0.642679    
2024-01-15 11:46:49,821 - Epoch: [4][   50/  211]    Overall Loss 0.115145    Objective Loss 0.115145                                        LR 0.100000    Time 0.625980    
2024-01-15 11:46:55,408 - Epoch: [4][   60/  211]    Overall Loss 0.117762    Objective Loss 0.117762                                        LR 0.100000    Time 0.614753    
2024-01-15 11:47:00,963 - Epoch: [4][   70/  211]    Overall Loss 0.118838    Objective Loss 0.118838                                        LR 0.100000    Time 0.606269    
2024-01-15 11:47:06,541 - Epoch: [4][   80/  211]    Overall Loss 0.120737    Objective Loss 0.120737                                        LR 0.100000    Time 0.600188    
2024-01-15 11:47:12,066 - Epoch: [4][   90/  211]    Overall Loss 0.119847    Objective Loss 0.119847                                        LR 0.100000    Time 0.594876    
2024-01-15 11:47:17,525 - Epoch: [4][  100/  211]    Overall Loss 0.119790    Objective Loss 0.119790                                        LR 0.100000    Time 0.589974    
2024-01-15 11:47:22,986 - Epoch: [4][  110/  211]    Overall Loss 0.119514    Objective Loss 0.119514                                        LR 0.100000    Time 0.585969    
2024-01-15 11:47:28,674 - Epoch: [4][  120/  211]    Overall Loss 0.118037    Objective Loss 0.118037                                        LR 0.100000    Time 0.584530    
2024-01-15 11:47:34,224 - Epoch: [4][  130/  211]    Overall Loss 0.117784    Objective Loss 0.117784                                        LR 0.100000    Time 0.582259    
2024-01-15 11:47:39,753 - Epoch: [4][  140/  211]    Overall Loss 0.118521    Objective Loss 0.118521                                        LR 0.100000    Time 0.580151    
2024-01-15 11:47:45,197 - Epoch: [4][  150/  211]    Overall Loss 0.117579    Objective Loss 0.117579                                        LR 0.100000    Time 0.577764    
2024-01-15 11:47:50,632 - Epoch: [4][  160/  211]    Overall Loss 0.118073    Objective Loss 0.118073                                        LR 0.100000    Time 0.575615    
2024-01-15 11:47:56,183 - Epoch: [4][  170/  211]    Overall Loss 0.118545    Objective Loss 0.118545                                        LR 0.100000    Time 0.574401    
2024-01-15 11:48:01,678 - Epoch: [4][  180/  211]    Overall Loss 0.117474    Objective Loss 0.117474                                        LR 0.100000    Time 0.573015    
2024-01-15 11:48:07,148 - Epoch: [4][  190/  211]    Overall Loss 0.117175    Objective Loss 0.117175                                        LR 0.100000    Time 0.571642    
2024-01-15 11:48:12,590 - Epoch: [4][  200/  211]    Overall Loss 0.117542    Objective Loss 0.117542                                        LR 0.100000    Time 0.570264    
2024-01-15 11:48:18,019 - Epoch: [4][  210/  211]    Overall Loss 0.117298    Objective Loss 0.117298    Top1 94.531250    Top5 99.609375    LR 0.100000    Time 0.568958    
2024-01-15 11:48:18,546 - Epoch: [4][  211/  211]    Overall Loss 0.117290    Objective Loss 0.117290    Top1 95.564516    Top5 99.798387    LR 0.100000    Time 0.568757    
2024-01-15 11:48:19,330 - --- validate (epoch=4)-----------
2024-01-15 11:48:19,330 - 6000 samples (256 per mini-batch)
2024-01-15 11:48:24,642 - Epoch: [4][   10/   24]    Loss 0.096662    Top1 96.875000    Top5 99.921875    
2024-01-15 11:48:26,547 - Epoch: [4][   20/   24]    Loss 0.093953    Top1 97.070312    Top5 99.941406    
2024-01-15 11:48:27,509 - Epoch: [4][   24/   24]    Loss 0.094872    Top1 97.016667    Top5 99.933333    
2024-01-15 11:48:28,082 - ==> Top1: 97.017    Top5: 99.933    Loss: 0.095

2024-01-15 11:48:28,083 - ==> Confusion:
[[592   0   2   1   0   1   4   0   3   2]
 [  0 677   6   0   0   0   1   3   0   1]
 [  0   2 570   1   0   0   1   6   4   2]
 [  0   0   7 556   1   2   0   8   5   4]
 [  0   1   4   0 547   0   0   6   0   7]
 [  1   2   2   0   0 504   4   0   5   0]
 [  6   0   0   0   5   0 619   0   1   0]
 [  0   1   5   0   3   0   0 614   0   2]
 [  1   0   3   1   6   1   8   1 562   1]
 [  2   0   2   0  14   4   1   5   7 580]]

2024-01-15 11:48:28,086 - ==> Best [Top1: 97.017   Top5: 99.933   Sparsity:0.00   Params: 71148 on epoch: 4]
2024-01-15 11:48:28,087 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:48:28,097 - 

2024-01-15 11:48:28,097 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:48:40,811 - Epoch: [5][   10/  211]    Overall Loss 0.119095    Objective Loss 0.119095                                        LR 0.100000    Time 1.271301    
2024-01-15 11:48:46,559 - Epoch: [5][   20/  211]    Overall Loss 0.124114    Objective Loss 0.124114                                        LR 0.100000    Time 0.922957    
2024-01-15 11:48:53,324 - Epoch: [5][   30/  211]    Overall Loss 0.118371    Objective Loss 0.118371                                        LR 0.100000    Time 0.840733    
2024-01-15 11:48:59,062 - Epoch: [5][   40/  211]    Overall Loss 0.116322    Objective Loss 0.116322                                        LR 0.100000    Time 0.773957    
2024-01-15 11:49:04,914 - Epoch: [5][   50/  211]    Overall Loss 0.111705    Objective Loss 0.111705                                        LR 0.100000    Time 0.736197    
2024-01-15 11:49:11,073 - Epoch: [5][   60/  211]    Overall Loss 0.113199    Objective Loss 0.113199                                        LR 0.100000    Time 0.716088    
2024-01-15 11:49:16,592 - Epoch: [5][   70/  211]    Overall Loss 0.116341    Objective Loss 0.116341                                        LR 0.100000    Time 0.692629    
2024-01-15 11:49:22,421 - Epoch: [5][   80/  211]    Overall Loss 0.114833    Objective Loss 0.114833                                        LR 0.100000    Time 0.678893    
2024-01-15 11:49:28,034 - Epoch: [5][   90/  211]    Overall Loss 0.112763    Objective Loss 0.112763                                        LR 0.100000    Time 0.665809    
2024-01-15 11:49:33,540 - Epoch: [5][  100/  211]    Overall Loss 0.113232    Objective Loss 0.113232                                        LR 0.100000    Time 0.654276    
2024-01-15 11:49:39,272 - Epoch: [5][  110/  211]    Overall Loss 0.111993    Objective Loss 0.111993                                        LR 0.100000    Time 0.646899    
2024-01-15 11:49:44,733 - Epoch: [5][  120/  211]    Overall Loss 0.111866    Objective Loss 0.111866                                        LR 0.100000    Time 0.638490    
2024-01-15 11:49:50,179 - Epoch: [5][  130/  211]    Overall Loss 0.111545    Objective Loss 0.111545                                        LR 0.100000    Time 0.631262    
2024-01-15 11:49:55,913 - Epoch: [5][  140/  211]    Overall Loss 0.109220    Objective Loss 0.109220                                        LR 0.100000    Time 0.627124    
2024-01-15 11:50:01,846 - Epoch: [5][  150/  211]    Overall Loss 0.107976    Objective Loss 0.107976                                        LR 0.100000    Time 0.624859    
2024-01-15 11:50:07,438 - Epoch: [5][  160/  211]    Overall Loss 0.106406    Objective Loss 0.106406                                        LR 0.100000    Time 0.620751    
2024-01-15 11:50:13,118 - Epoch: [5][  170/  211]    Overall Loss 0.105816    Objective Loss 0.105816                                        LR 0.100000    Time 0.617640    
2024-01-15 11:50:18,742 - Epoch: [5][  180/  211]    Overall Loss 0.106139    Objective Loss 0.106139                                        LR 0.100000    Time 0.614560    
2024-01-15 11:50:24,526 - Epoch: [5][  190/  211]    Overall Loss 0.105523    Objective Loss 0.105523                                        LR 0.100000    Time 0.612654    
2024-01-15 11:50:30,202 - Epoch: [5][  200/  211]    Overall Loss 0.105141    Objective Loss 0.105141                                        LR 0.100000    Time 0.610391    
2024-01-15 11:50:35,830 - Epoch: [5][  210/  211]    Overall Loss 0.104888    Objective Loss 0.104888    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.608121    
2024-01-15 11:50:36,376 - Epoch: [5][  211/  211]    Overall Loss 0.104852    Objective Loss 0.104852    Top1 96.774194    Top5 100.000000    LR 0.100000    Time 0.607826    
2024-01-15 11:50:37,399 - --- validate (epoch=5)-----------
2024-01-15 11:50:37,400 - 6000 samples (256 per mini-batch)
2024-01-15 11:50:44,163 - Epoch: [5][   10/   24]    Loss 0.102979    Top1 96.796875    Top5 99.960938    
2024-01-15 11:50:46,118 - Epoch: [5][   20/   24]    Loss 0.103031    Top1 96.914062    Top5 99.960938    
2024-01-15 11:50:46,911 - Epoch: [5][   24/   24]    Loss 0.102881    Top1 96.983333    Top5 99.966667    
2024-01-15 11:50:47,509 - ==> Top1: 96.983    Top5: 99.967    Loss: 0.103

2024-01-15 11:50:47,510 - ==> Confusion:
[[599   0   0   0   0   0   2   0   0   4]
 [  1 677   3   0   1   1   1   4   0   0]
 [  0   0 550  11   1   1   0   8   8   7]
 [  1   0   0 574   0   5   0   0   2   1]
 [  2   1   2   0 532   1   0   3   1  23]
 [  1   0   0   1   0 510   3   0   2   1]
 [  2   2   0   0   2  10 604   0   9   2]
 [  0   2   2   7   1   1   0 604   0   8]
 [  2   0   1   5   0   6   1   0 566   3]
 [  0   1   2   1   3   1   0   2   2 603]]

2024-01-15 11:50:47,514 - ==> Best [Top1: 97.017   Top5: 99.933   Sparsity:0.00   Params: 71148 on epoch: 4]
2024-01-15 11:50:47,514 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:50:47,520 - 

2024-01-15 11:50:47,521 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:50:56,028 - Epoch: [6][   10/  211]    Overall Loss 0.119087    Objective Loss 0.119087                                        LR 0.100000    Time 0.850624    
2024-01-15 11:51:01,550 - Epoch: [6][   20/  211]    Overall Loss 0.109763    Objective Loss 0.109763                                        LR 0.100000    Time 0.701336    
2024-01-15 11:51:07,066 - Epoch: [6][   30/  211]    Overall Loss 0.112935    Objective Loss 0.112935                                        LR 0.100000    Time 0.651403    
2024-01-15 11:51:12,557 - Epoch: [6][   40/  211]    Overall Loss 0.111435    Objective Loss 0.111435                                        LR 0.100000    Time 0.625788    
2024-01-15 11:51:18,079 - Epoch: [6][   50/  211]    Overall Loss 0.108004    Objective Loss 0.108004                                        LR 0.100000    Time 0.611058    
2024-01-15 11:51:23,524 - Epoch: [6][   60/  211]    Overall Loss 0.105534    Objective Loss 0.105534                                        LR 0.100000    Time 0.599940    
2024-01-15 11:51:29,157 - Epoch: [6][   70/  211]    Overall Loss 0.104017    Objective Loss 0.104017                                        LR 0.100000    Time 0.594688    
2024-01-15 11:51:34,658 - Epoch: [6][   80/  211]    Overall Loss 0.103408    Objective Loss 0.103408                                        LR 0.100000    Time 0.589098    
2024-01-15 11:51:40,257 - Epoch: [6][   90/  211]    Overall Loss 0.103205    Objective Loss 0.103205                                        LR 0.100000    Time 0.585848    
2024-01-15 11:51:45,833 - Epoch: [6][  100/  211]    Overall Loss 0.104003    Objective Loss 0.104003                                        LR 0.100000    Time 0.583010    
2024-01-15 11:51:51,526 - Epoch: [6][  110/  211]    Overall Loss 0.105005    Objective Loss 0.105005                                        LR 0.100000    Time 0.581747    
2024-01-15 11:51:57,361 - Epoch: [6][  120/  211]    Overall Loss 0.105027    Objective Loss 0.105027                                        LR 0.100000    Time 0.581888    
2024-01-15 11:52:02,925 - Epoch: [6][  130/  211]    Overall Loss 0.105748    Objective Loss 0.105748                                        LR 0.100000    Time 0.579917    
2024-01-15 11:52:08,446 - Epoch: [6][  140/  211]    Overall Loss 0.104705    Objective Loss 0.104705                                        LR 0.100000    Time 0.577923    
2024-01-15 11:52:13,924 - Epoch: [6][  150/  211]    Overall Loss 0.105682    Objective Loss 0.105682                                        LR 0.100000    Time 0.575914    
2024-01-15 11:52:19,424 - Epoch: [6][  160/  211]    Overall Loss 0.108267    Objective Loss 0.108267                                        LR 0.100000    Time 0.574288    
2024-01-15 11:52:25,113 - Epoch: [6][  170/  211]    Overall Loss 0.110006    Objective Loss 0.110006                                        LR 0.100000    Time 0.573965    
2024-01-15 11:52:30,576 - Epoch: [6][  180/  211]    Overall Loss 0.110488    Objective Loss 0.110488                                        LR 0.100000    Time 0.572424    
2024-01-15 11:52:36,052 - Epoch: [6][  190/  211]    Overall Loss 0.110268    Objective Loss 0.110268                                        LR 0.100000    Time 0.571113    
2024-01-15 11:52:41,488 - Epoch: [6][  200/  211]    Overall Loss 0.108631    Objective Loss 0.108631                                        LR 0.100000    Time 0.569735    
2024-01-15 11:52:46,940 - Epoch: [6][  210/  211]    Overall Loss 0.108262    Objective Loss 0.108262    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.568564    
2024-01-15 11:52:47,488 - Epoch: [6][  211/  211]    Overall Loss 0.108029    Objective Loss 0.108029    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.568458    
2024-01-15 11:52:48,314 - --- validate (epoch=6)-----------
2024-01-15 11:52:48,316 - 6000 samples (256 per mini-batch)
2024-01-15 11:52:54,160 - Epoch: [6][   10/   24]    Loss 0.100812    Top1 96.718750    Top5 99.960938    
2024-01-15 11:52:56,249 - Epoch: [6][   20/   24]    Loss 0.091307    Top1 96.972656    Top5 99.941406    
2024-01-15 11:52:56,930 - Epoch: [6][   24/   24]    Loss 0.094763    Top1 97.016667    Top5 99.916667    
2024-01-15 11:52:57,754 - ==> Top1: 97.017    Top5: 99.917    Loss: 0.095

2024-01-15 11:52:57,756 - ==> Confusion:
[[598   0   3   0   0   0   0   0   4   0]
 [  1 684   2   0   0   0   1   0   0   0]
 [  1   1 570   3   0   0   0   7   3   1]
 [  0   1  11 557   0   6   0   4   3   1]
 [  1   3   4   0 541   0   1   4   3   8]
 [  1   0   1   2   0 498   3   1  10   2]
 [  1   3   0   0   2   2 617   0   6   0]
 [  1   5   6   1   0   0   0 610   0   2]
 [  3   1   1   0   3   2   6   1 565   2]
 [  1   2   1   1   8   2   0  10   9 581]]

2024-01-15 11:52:57,760 - ==> Best [Top1: 97.017   Top5: 99.933   Sparsity:0.00   Params: 71148 on epoch: 4]
2024-01-15 11:52:57,760 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:52:57,766 - 

2024-01-15 11:52:57,767 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:53:08,034 - Epoch: [7][   10/  211]    Overall Loss 0.078308    Objective Loss 0.078308                                        LR 0.100000    Time 1.026631    
2024-01-15 11:53:13,776 - Epoch: [7][   20/  211]    Overall Loss 0.084362    Objective Loss 0.084362                                        LR 0.100000    Time 0.800316    
2024-01-15 11:53:19,252 - Epoch: [7][   30/  211]    Overall Loss 0.088548    Objective Loss 0.088548                                        LR 0.100000    Time 0.716047    
2024-01-15 11:53:24,906 - Epoch: [7][   40/  211]    Overall Loss 0.093830    Objective Loss 0.093830                                        LR 0.100000    Time 0.678376    
2024-01-15 11:53:30,544 - Epoch: [7][   50/  211]    Overall Loss 0.092716    Objective Loss 0.092716                                        LR 0.100000    Time 0.655438    
2024-01-15 11:53:35,990 - Epoch: [7][   60/  211]    Overall Loss 0.095095    Objective Loss 0.095095                                        LR 0.100000    Time 0.636950    
2024-01-15 11:53:41,610 - Epoch: [7][   70/  211]    Overall Loss 0.094923    Objective Loss 0.094923                                        LR 0.100000    Time 0.626209    
2024-01-15 11:53:47,059 - Epoch: [7][   80/  211]    Overall Loss 0.094854    Objective Loss 0.094854                                        LR 0.100000    Time 0.616033    
2024-01-15 11:53:52,748 - Epoch: [7][   90/  211]    Overall Loss 0.092864    Objective Loss 0.092864                                        LR 0.100000    Time 0.610788    
2024-01-15 11:53:58,188 - Epoch: [7][  100/  211]    Overall Loss 0.092488    Objective Loss 0.092488                                        LR 0.100000    Time 0.604099    
2024-01-15 11:54:03,833 - Epoch: [7][  110/  211]    Overall Loss 0.093168    Objective Loss 0.093168                                        LR 0.100000    Time 0.600498    
2024-01-15 11:54:10,286 - Epoch: [7][  120/  211]    Overall Loss 0.093244    Objective Loss 0.093244                                        LR 0.100000    Time 0.604213    
2024-01-15 11:54:16,118 - Epoch: [7][  130/  211]    Overall Loss 0.093330    Objective Loss 0.093330                                        LR 0.100000    Time 0.602585    
2024-01-15 11:54:21,696 - Epoch: [7][  140/  211]    Overall Loss 0.092679    Objective Loss 0.092679                                        LR 0.100000    Time 0.599377    
2024-01-15 11:54:27,308 - Epoch: [7][  150/  211]    Overall Loss 0.092493    Objective Loss 0.092493                                        LR 0.100000    Time 0.596826    
2024-01-15 11:54:32,823 - Epoch: [7][  160/  211]    Overall Loss 0.091598    Objective Loss 0.091598                                        LR 0.100000    Time 0.593988    
2024-01-15 11:54:38,308 - Epoch: [7][  170/  211]    Overall Loss 0.090616    Objective Loss 0.090616                                        LR 0.100000    Time 0.591307    
2024-01-15 11:54:44,470 - Epoch: [7][  180/  211]    Overall Loss 0.090864    Objective Loss 0.090864                                        LR 0.100000    Time 0.592681    
2024-01-15 11:54:50,905 - Epoch: [7][  190/  211]    Overall Loss 0.090998    Objective Loss 0.090998                                        LR 0.100000    Time 0.595353    
2024-01-15 11:54:56,457 - Epoch: [7][  200/  211]    Overall Loss 0.090810    Objective Loss 0.090810                                        LR 0.100000    Time 0.593339    
2024-01-15 11:55:02,076 - Epoch: [7][  210/  211]    Overall Loss 0.090818    Objective Loss 0.090818    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.591836    
2024-01-15 11:55:02,643 - Epoch: [7][  211/  211]    Overall Loss 0.090807    Objective Loss 0.090807    Top1 96.975806    Top5 100.000000    LR 0.100000    Time 0.591717    
2024-01-15 11:55:03,672 - --- validate (epoch=7)-----------
2024-01-15 11:55:03,674 - 6000 samples (256 per mini-batch)
2024-01-15 11:55:10,597 - Epoch: [7][   10/   24]    Loss 0.087937    Top1 97.578125    Top5 100.000000    
2024-01-15 11:55:12,525 - Epoch: [7][   20/   24]    Loss 0.092578    Top1 97.343750    Top5 99.980469    
2024-01-15 11:55:13,277 - Epoch: [7][   24/   24]    Loss 0.088307    Top1 97.400000    Top5 99.983333    
2024-01-15 11:55:14,107 - ==> Top1: 97.400    Top5: 99.983    Loss: 0.088

2024-01-15 11:55:14,108 - ==> Confusion:
[[596   0   2   0   0   0   5   0   1   1]
 [  0 685   1   0   0   1   0   1   0   0]
 [  0   0 577   1   0   0   2   3   2   1]
 [  0   0   7 563   0   4   1   6   1   1]
 [  2   1   4   0 539   1   3   4   0  11]
 [  4   0   1   0   0 507   4   0   0   2]
 [  3   1   0   0   0   2 623   0   2   0]
 [  2   6   5   2   2   0   0 608   0   0]
 [  4   1   5   1   1   3  10   0 557   2]
 [  3   1   1   0   4   8   0   6   3 589]]

2024-01-15 11:55:14,111 - ==> Best [Top1: 97.400   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 7]
2024-01-15 11:55:14,112 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:55:14,118 - 

2024-01-15 11:55:14,118 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:55:23,156 - Epoch: [8][   10/  211]    Overall Loss 0.096214    Objective Loss 0.096214                                        LR 0.100000    Time 0.903714    
2024-01-15 11:55:28,814 - Epoch: [8][   20/  211]    Overall Loss 0.087801    Objective Loss 0.087801                                        LR 0.100000    Time 0.734678    
2024-01-15 11:55:34,276 - Epoch: [8][   30/  211]    Overall Loss 0.089134    Objective Loss 0.089134                                        LR 0.100000    Time 0.671828    
2024-01-15 11:55:39,971 - Epoch: [8][   40/  211]    Overall Loss 0.090727    Objective Loss 0.090727                                        LR 0.100000    Time 0.646213    
2024-01-15 11:55:45,493 - Epoch: [8][   50/  211]    Overall Loss 0.090039    Objective Loss 0.090039                                        LR 0.100000    Time 0.627374    
2024-01-15 11:55:51,105 - Epoch: [8][   60/  211]    Overall Loss 0.090391    Objective Loss 0.090391                                        LR 0.100000    Time 0.616330    
2024-01-15 11:55:56,758 - Epoch: [8][   70/  211]    Overall Loss 0.087232    Objective Loss 0.087232                                        LR 0.100000    Time 0.609011    
2024-01-15 11:56:02,295 - Epoch: [8][   80/  211]    Overall Loss 0.087679    Objective Loss 0.087679                                        LR 0.100000    Time 0.602084    
2024-01-15 11:56:07,924 - Epoch: [8][   90/  211]    Overall Loss 0.088591    Objective Loss 0.088591                                        LR 0.100000    Time 0.597722    
2024-01-15 11:56:13,815 - Epoch: [8][  100/  211]    Overall Loss 0.088972    Objective Loss 0.088972                                        LR 0.100000    Time 0.596846    
2024-01-15 11:56:19,400 - Epoch: [8][  110/  211]    Overall Loss 0.089040    Objective Loss 0.089040                                        LR 0.100000    Time 0.593349    
2024-01-15 11:56:25,204 - Epoch: [8][  120/  211]    Overall Loss 0.087530    Objective Loss 0.087530                                        LR 0.100000    Time 0.592253    
2024-01-15 11:56:30,788 - Epoch: [8][  130/  211]    Overall Loss 0.087732    Objective Loss 0.087732                                        LR 0.100000    Time 0.589643    
2024-01-15 11:56:36,408 - Epoch: [8][  140/  211]    Overall Loss 0.087470    Objective Loss 0.087470                                        LR 0.100000    Time 0.587657    
2024-01-15 11:56:41,994 - Epoch: [8][  150/  211]    Overall Loss 0.087278    Objective Loss 0.087278                                        LR 0.100000    Time 0.585713    
2024-01-15 11:56:47,641 - Epoch: [8][  160/  211]    Overall Loss 0.087535    Objective Loss 0.087535                                        LR 0.100000    Time 0.584390    
2024-01-15 11:56:53,288 - Epoch: [8][  170/  211]    Overall Loss 0.087729    Objective Loss 0.087729                                        LR 0.100000    Time 0.583229    
2024-01-15 11:56:58,771 - Epoch: [8][  180/  211]    Overall Loss 0.086640    Objective Loss 0.086640                                        LR 0.100000    Time 0.581273    
2024-01-15 11:57:04,210 - Epoch: [8][  190/  211]    Overall Loss 0.086466    Objective Loss 0.086466                                        LR 0.100000    Time 0.579303    
2024-01-15 11:57:09,753 - Epoch: [8][  200/  211]    Overall Loss 0.085705    Objective Loss 0.085705                                        LR 0.100000    Time 0.578053    
2024-01-15 11:57:15,204 - Epoch: [8][  210/  211]    Overall Loss 0.086336    Objective Loss 0.086336    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.576480    
2024-01-15 11:57:15,721 - Epoch: [8][  211/  211]    Overall Loss 0.086195    Objective Loss 0.086195    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.576194    
2024-01-15 11:57:16,329 - --- validate (epoch=8)-----------
2024-01-15 11:57:16,330 - 6000 samples (256 per mini-batch)
2024-01-15 11:57:21,447 - Epoch: [8][   10/   24]    Loss 0.099938    Top1 97.500000    Top5 99.882812    
2024-01-15 11:57:23,393 - Epoch: [8][   20/   24]    Loss 0.094236    Top1 97.246094    Top5 99.902344    
2024-01-15 11:57:24,212 - Epoch: [8][   24/   24]    Loss 0.091260    Top1 97.283333    Top5 99.916667    
2024-01-15 11:57:24,782 - ==> Top1: 97.283    Top5: 99.917    Loss: 0.091

2024-01-15 11:57:24,783 - ==> Confusion:
[[598   0   1   0   1   0   2   0   3   0]
 [  0 680   2   1   1   0   0   3   1   0]
 [  1   0 569   3   0   1   0   4   7   1]
 [  0   0   0 573   1   1   0   3   4   1]
 [  0   0   2   0 558   0   0   0   1   4]
 [  0   0   2   7   0 494   5   1   8   1]
 [  1   0   0   0   3   4 610   0  13   0]
 [  0   0   8   2   2   1   0 610   1   1]
 [  1   0   2   2   4   2   2   0 571   0]
 [  1   2   2   2  15   0   0  11   8 574]]

2024-01-15 11:57:24,784 - ==> Best [Top1: 97.400   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 7]
2024-01-15 11:57:24,784 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:57:24,788 - 

2024-01-15 11:57:24,788 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:57:32,910 - Epoch: [9][   10/  211]    Overall Loss 0.085736    Objective Loss 0.085736                                        LR 0.100000    Time 0.812184    
2024-01-15 11:57:38,448 - Epoch: [9][   20/  211]    Overall Loss 0.086836    Objective Loss 0.086836                                        LR 0.100000    Time 0.682923    
2024-01-15 11:57:44,002 - Epoch: [9][   30/  211]    Overall Loss 0.087556    Objective Loss 0.087556                                        LR 0.100000    Time 0.640363    
2024-01-15 11:57:49,522 - Epoch: [9][   40/  211]    Overall Loss 0.091888    Objective Loss 0.091888                                        LR 0.100000    Time 0.618258    
2024-01-15 11:57:55,036 - Epoch: [9][   50/  211]    Overall Loss 0.090898    Objective Loss 0.090898                                        LR 0.100000    Time 0.604860    
2024-01-15 11:58:00,530 - Epoch: [9][   60/  211]    Overall Loss 0.091319    Objective Loss 0.091319                                        LR 0.100000    Time 0.595617    
2024-01-15 11:58:06,428 - Epoch: [9][   70/  211]    Overall Loss 0.089970    Objective Loss 0.089970                                        LR 0.100000    Time 0.594758    
2024-01-15 11:58:12,032 - Epoch: [9][   80/  211]    Overall Loss 0.088425    Objective Loss 0.088425                                        LR 0.100000    Time 0.590448    
2024-01-15 11:58:17,770 - Epoch: [9][   90/  211]    Overall Loss 0.087391    Objective Loss 0.087391                                        LR 0.100000    Time 0.588588    
2024-01-15 11:58:24,034 - Epoch: [9][  100/  211]    Overall Loss 0.086899    Objective Loss 0.086899                                        LR 0.100000    Time 0.592335    
2024-01-15 11:58:31,966 - Epoch: [9][  110/  211]    Overall Loss 0.085371    Objective Loss 0.085371                                        LR 0.100000    Time 0.610577    
2024-01-15 11:58:37,734 - Epoch: [9][  120/  211]    Overall Loss 0.084819    Objective Loss 0.084819                                        LR 0.100000    Time 0.607747    
2024-01-15 11:58:43,198 - Epoch: [9][  130/  211]    Overall Loss 0.084630    Objective Loss 0.084630                                        LR 0.100000    Time 0.603014    
2024-01-15 11:58:48,649 - Epoch: [9][  140/  211]    Overall Loss 0.084822    Objective Loss 0.084822                                        LR 0.100000    Time 0.598874    
2024-01-15 11:58:54,102 - Epoch: [9][  150/  211]    Overall Loss 0.085176    Objective Loss 0.085176                                        LR 0.100000    Time 0.595298    
2024-01-15 11:58:59,543 - Epoch: [9][  160/  211]    Overall Loss 0.084832    Objective Loss 0.084832                                        LR 0.100000    Time 0.592097    
2024-01-15 11:59:05,066 - Epoch: [9][  170/  211]    Overall Loss 0.083966    Objective Loss 0.083966                                        LR 0.100000    Time 0.589752    
2024-01-15 11:59:10,534 - Epoch: [9][  180/  211]    Overall Loss 0.084572    Objective Loss 0.084572                                        LR 0.100000    Time 0.587356    
2024-01-15 11:59:15,998 - Epoch: [9][  190/  211]    Overall Loss 0.084198    Objective Loss 0.084198                                        LR 0.100000    Time 0.585196    
2024-01-15 11:59:21,462 - Epoch: [9][  200/  211]    Overall Loss 0.084110    Objective Loss 0.084110                                        LR 0.100000    Time 0.583255    
2024-01-15 11:59:27,047 - Epoch: [9][  210/  211]    Overall Loss 0.084052    Objective Loss 0.084052    Top1 96.093750    Top5 99.609375    LR 0.100000    Time 0.582067    
2024-01-15 11:59:27,579 - Epoch: [9][  211/  211]    Overall Loss 0.084055    Objective Loss 0.084055    Top1 96.774194    Top5 99.798387    LR 0.100000    Time 0.581832    
2024-01-15 11:59:28,417 - --- validate (epoch=9)-----------
2024-01-15 11:59:28,419 - 6000 samples (256 per mini-batch)
2024-01-15 11:59:35,061 - Epoch: [9][   10/   24]    Loss 0.080328    Top1 97.695312    Top5 99.960938    
2024-01-15 11:59:36,967 - Epoch: [9][   20/   24]    Loss 0.077038    Top1 97.695312    Top5 99.921875    
2024-01-15 11:59:37,659 - Epoch: [9][   24/   24]    Loss 0.074873    Top1 97.783333    Top5 99.933333    
2024-01-15 11:59:38,228 - ==> Top1: 97.783    Top5: 99.933    Loss: 0.075

2024-01-15 11:59:38,229 - ==> Confusion:
[[589   0   8   0   1   0   3   0   2   2]
 [  0 683   2   0   0   1   0   2   0   0]
 [  0   2 576   1   1   0   0   2   1   3]
 [  1   0   1 576   0   2   0   3   0   0]
 [  1   0   0   0 554   0   1   2   0   7]
 [  0   0   1   3   0 511   1   2   0   0]
 [  3   2   1   0   1  14 609   0   1   0]
 [  0   2   2   0   0   1   0 620   0   0]
 [  0   0   3   6   3   6   2   0 563   1]
 [  2   1   3   1   9   3   0   8   2 586]]

2024-01-15 11:59:38,233 - ==> Best [Top1: 97.783   Top5: 99.933   Sparsity:0.00   Params: 71148 on epoch: 9]
2024-01-15 11:59:38,233 - Saving checkpoint to: logs/2024.01.15-113640/checkpoint.pth.tar
2024-01-15 11:59:38,240 - 

2024-01-15 11:59:38,240 - Initiating quantization aware training (QAT)...
2024-01-15 11:59:38,252 - 

2024-01-15 11:59:38,252 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 11:59:46,683 - Epoch: [10][   10/  211]    Overall Loss 0.159886    Objective Loss 0.159886                                        LR 0.100000    Time 0.843020    
2024-01-15 11:59:53,109 - Epoch: [10][   20/  211]    Overall Loss 0.148509    Objective Loss 0.148509                                        LR 0.100000    Time 0.742748    
2024-01-15 11:59:58,796 - Epoch: [10][   30/  211]    Overall Loss 0.139183    Objective Loss 0.139183                                        LR 0.100000    Time 0.684697    
2024-01-15 12:00:04,476 - Epoch: [10][   40/  211]    Overall Loss 0.130252    Objective Loss 0.130252                                        LR 0.100000    Time 0.655509    
2024-01-15 12:00:10,111 - Epoch: [10][   50/  211]    Overall Loss 0.124790    Objective Loss 0.124790                                        LR 0.100000    Time 0.637082    
2024-01-15 12:00:15,750 - Epoch: [10][   60/  211]    Overall Loss 0.120063    Objective Loss 0.120063                                        LR 0.100000    Time 0.624864    
2024-01-15 12:00:21,383 - Epoch: [10][   70/  211]    Overall Loss 0.115695    Objective Loss 0.115695                                        LR 0.100000    Time 0.616058    
2024-01-15 12:00:27,101 - Epoch: [10][   80/  211]    Overall Loss 0.113487    Objective Loss 0.113487                                        LR 0.100000    Time 0.610505    
2024-01-15 12:00:32,741 - Epoch: [10][   90/  211]    Overall Loss 0.111227    Objective Loss 0.111227                                        LR 0.100000    Time 0.605342    
2024-01-15 12:00:38,470 - Epoch: [10][  100/  211]    Overall Loss 0.110093    Objective Loss 0.110093                                        LR 0.100000    Time 0.602087    
2024-01-15 12:00:44,155 - Epoch: [10][  110/  211]    Overall Loss 0.107561    Objective Loss 0.107561                                        LR 0.100000    Time 0.599020    
2024-01-15 12:00:49,793 - Epoch: [10][  120/  211]    Overall Loss 0.106215    Objective Loss 0.106215                                        LR 0.100000    Time 0.596087    
2024-01-15 12:00:55,711 - Epoch: [10][  130/  211]    Overall Loss 0.104951    Objective Loss 0.104951                                        LR 0.100000    Time 0.595741    
2024-01-15 12:01:01,493 - Epoch: [10][  140/  211]    Overall Loss 0.103838    Objective Loss 0.103838                                        LR 0.100000    Time 0.594485    
2024-01-15 12:01:07,135 - Epoch: [10][  150/  211]    Overall Loss 0.102600    Objective Loss 0.102600                                        LR 0.100000    Time 0.592459    
2024-01-15 12:01:13,260 - Epoch: [10][  160/  211]    Overall Loss 0.101204    Objective Loss 0.101204                                        LR 0.100000    Time 0.593706    
2024-01-15 12:01:18,959 - Epoch: [10][  170/  211]    Overall Loss 0.100747    Objective Loss 0.100747                                        LR 0.100000    Time 0.592296    
2024-01-15 12:01:24,724 - Epoch: [10][  180/  211]    Overall Loss 0.099874    Objective Loss 0.099874                                        LR 0.100000    Time 0.591412    
2024-01-15 12:01:30,373 - Epoch: [10][  190/  211]    Overall Loss 0.099006    Objective Loss 0.099006                                        LR 0.100000    Time 0.590012    
2024-01-15 12:01:36,071 - Epoch: [10][  200/  211]    Overall Loss 0.098163    Objective Loss 0.098163                                        LR 0.100000    Time 0.588997    
2024-01-15 12:01:41,736 - Epoch: [10][  210/  211]    Overall Loss 0.097142    Objective Loss 0.097142    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.587916    
2024-01-15 12:01:42,297 - Epoch: [10][  211/  211]    Overall Loss 0.097020    Objective Loss 0.097020    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.587788    
2024-01-15 12:01:43,070 - --- validate (epoch=10)-----------
2024-01-15 12:01:43,071 - 6000 samples (256 per mini-batch)
2024-01-15 12:01:49,315 - Epoch: [10][   10/   24]    Loss 0.080911    Top1 97.656250    Top5 100.000000    
2024-01-15 12:01:51,435 - Epoch: [10][   20/   24]    Loss 0.083958    Top1 97.656250    Top5 99.960938    
2024-01-15 12:01:52,183 - Epoch: [10][   24/   24]    Loss 0.080183    Top1 97.800000    Top5 99.966667    
2024-01-15 12:01:52,726 - ==> Top1: 97.800    Top5: 99.967    Loss: 0.080

2024-01-15 12:01:52,727 - ==> Confusion:
[[594   0   3   0   0   0   5   0   0   3]
 [  1 680   3   0   0   0   0   4   0   0]
 [  2   0 567   1   1   1   0  11   0   3]
 [  1   0   2 575   0   0   0   3   1   1]
 [  0   0   2   0 543   0   3   2   1  14]
 [  1   0   0   4   0 506   4   0   2   1]
 [  2   2   0   1   2   2 621   0   1   0]
 [  0   1   1   0   1   1   0 621   0   0]
 [  0   0   1   5   2   1   5   1 567   2]
 [  1   1   0   2   7   1   2   5   2 594]]

2024-01-15 12:01:52,729 - ==> Best [Top1: 97.800   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 10]
2024-01-15 12:01:52,729 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:01:52,735 - 

2024-01-15 12:01:52,735 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:02:01,633 - Epoch: [11][   10/  211]    Overall Loss 0.084188    Objective Loss 0.084188                                        LR 0.100000    Time 0.889714    
2024-01-15 12:02:07,391 - Epoch: [11][   20/  211]    Overall Loss 0.083539    Objective Loss 0.083539                                        LR 0.100000    Time 0.732673    
2024-01-15 12:02:13,024 - Epoch: [11][   30/  211]    Overall Loss 0.084470    Objective Loss 0.084470                                        LR 0.100000    Time 0.676206    
2024-01-15 12:02:18,675 - Epoch: [11][   40/  211]    Overall Loss 0.082282    Objective Loss 0.082282                                        LR 0.100000    Time 0.648400    
2024-01-15 12:02:24,360 - Epoch: [11][   50/  211]    Overall Loss 0.081171    Objective Loss 0.081171                                        LR 0.100000    Time 0.632419    
2024-01-15 12:02:30,025 - Epoch: [11][   60/  211]    Overall Loss 0.080468    Objective Loss 0.080468                                        LR 0.100000    Time 0.621417    
2024-01-15 12:02:35,661 - Epoch: [11][   70/  211]    Overall Loss 0.082855    Objective Loss 0.082855                                        LR 0.100000    Time 0.613156    
2024-01-15 12:02:41,500 - Epoch: [11][   80/  211]    Overall Loss 0.080988    Objective Loss 0.080988                                        LR 0.100000    Time 0.609473    
2024-01-15 12:02:47,122 - Epoch: [11][   90/  211]    Overall Loss 0.080528    Objective Loss 0.080528                                        LR 0.100000    Time 0.604214    
2024-01-15 12:02:52,979 - Epoch: [11][  100/  211]    Overall Loss 0.080159    Objective Loss 0.080159                                        LR 0.100000    Time 0.602353    
2024-01-15 12:02:58,639 - Epoch: [11][  110/  211]    Overall Loss 0.079342    Objective Loss 0.079342                                        LR 0.100000    Time 0.599038    
2024-01-15 12:03:04,287 - Epoch: [11][  120/  211]    Overall Loss 0.079021    Objective Loss 0.079021                                        LR 0.100000    Time 0.596181    
2024-01-15 12:03:09,930 - Epoch: [11][  130/  211]    Overall Loss 0.078243    Objective Loss 0.078243                                        LR 0.100000    Time 0.593720    
2024-01-15 12:03:15,560 - Epoch: [11][  140/  211]    Overall Loss 0.078183    Objective Loss 0.078183                                        LR 0.100000    Time 0.591519    
2024-01-15 12:03:21,183 - Epoch: [11][  150/  211]    Overall Loss 0.078630    Objective Loss 0.078630                                        LR 0.100000    Time 0.589560    
2024-01-15 12:03:26,863 - Epoch: [11][  160/  211]    Overall Loss 0.078817    Objective Loss 0.078817                                        LR 0.100000    Time 0.588205    
2024-01-15 12:03:32,492 - Epoch: [11][  170/  211]    Overall Loss 0.079158    Objective Loss 0.079158                                        LR 0.100000    Time 0.586712    
2024-01-15 12:03:38,118 - Epoch: [11][  180/  211]    Overall Loss 0.079131    Objective Loss 0.079131                                        LR 0.100000    Time 0.585373    
2024-01-15 12:03:43,767 - Epoch: [11][  190/  211]    Overall Loss 0.079482    Objective Loss 0.079482                                        LR 0.100000    Time 0.584290    
2024-01-15 12:03:49,383 - Epoch: [11][  200/  211]    Overall Loss 0.080468    Objective Loss 0.080468                                        LR 0.100000    Time 0.583151    
2024-01-15 12:03:55,001 - Epoch: [11][  210/  211]    Overall Loss 0.080511    Objective Loss 0.080511    Top1 96.484375    Top5 100.000000    LR 0.100000    Time 0.582129    
2024-01-15 12:03:55,579 - Epoch: [11][  211/  211]    Overall Loss 0.080474    Objective Loss 0.080474    Top1 97.177419    Top5 100.000000    LR 0.100000    Time 0.582109    
2024-01-15 12:03:56,410 - --- validate (epoch=11)-----------
2024-01-15 12:03:56,412 - 6000 samples (256 per mini-batch)
2024-01-15 12:04:03,102 - Epoch: [11][   10/   24]    Loss 0.086571    Top1 97.539062    Top5 99.960938    
2024-01-15 12:04:05,201 - Epoch: [11][   20/   24]    Loss 0.086216    Top1 97.500000    Top5 99.960938    
2024-01-15 12:04:05,941 - Epoch: [11][   24/   24]    Loss 0.087045    Top1 97.566667    Top5 99.966667    
2024-01-15 12:04:06,485 - ==> Top1: 97.567    Top5: 99.967    Loss: 0.087

2024-01-15 12:04:06,486 - ==> Confusion:
[[591   0   1   0   0   1   3   2   3   4]
 [  0 681   2   0   0   0   1   4   0   0]
 [  0   0 565   8   0   1   2   3   4   3]
 [  0   0   0 578   0   2   0   2   1   0]
 [  0   0   4   0 534   1   2   1   0  23]
 [  0   1   0   6   0 506   2   1   0   2]
 [  0   2   0   0   2   7 619   0   1   0]
 [  0   0   5   2   1   0   0 615   0   2]
 [  1   0   0   5   2   3   5   0 562   6]
 [  0   1   0   1   4   1   0   1   4 603]]

2024-01-15 12:04:06,487 - ==> Best [Top1: 97.800   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 10]
2024-01-15 12:04:06,488 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:04:06,492 - 

2024-01-15 12:04:06,492 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:04:14,787 - Epoch: [12][   10/  211]    Overall Loss 0.086546    Objective Loss 0.086546                                        LR 0.100000    Time 0.829492    
2024-01-15 12:04:20,415 - Epoch: [12][   20/  211]    Overall Loss 0.087834    Objective Loss 0.087834                                        LR 0.100000    Time 0.696051    
2024-01-15 12:04:26,177 - Epoch: [12][   30/  211]    Overall Loss 0.084906    Objective Loss 0.084906                                        LR 0.100000    Time 0.656087    
2024-01-15 12:04:31,813 - Epoch: [12][   40/  211]    Overall Loss 0.085800    Objective Loss 0.085800                                        LR 0.100000    Time 0.632932    
2024-01-15 12:04:37,433 - Epoch: [12][   50/  211]    Overall Loss 0.085180    Objective Loss 0.085180                                        LR 0.100000    Time 0.618740    
2024-01-15 12:04:43,073 - Epoch: [12][   60/  211]    Overall Loss 0.082341    Objective Loss 0.082341                                        LR 0.100000    Time 0.609581    
2024-01-15 12:04:48,702 - Epoch: [12][   70/  211]    Overall Loss 0.082054    Objective Loss 0.082054                                        LR 0.100000    Time 0.602901    
2024-01-15 12:04:54,326 - Epoch: [12][   80/  211]    Overall Loss 0.082435    Objective Loss 0.082435                                        LR 0.100000    Time 0.597821    
2024-01-15 12:04:59,943 - Epoch: [12][   90/  211]    Overall Loss 0.081501    Objective Loss 0.081501                                        LR 0.100000    Time 0.593796    
2024-01-15 12:05:05,631 - Epoch: [12][  100/  211]    Overall Loss 0.082610    Objective Loss 0.082610                                        LR 0.100000    Time 0.591285    
2024-01-15 12:05:11,496 - Epoch: [12][  110/  211]    Overall Loss 0.082015    Objective Loss 0.082015                                        LR 0.100000    Time 0.590843    
2024-01-15 12:05:17,131 - Epoch: [12][  120/  211]    Overall Loss 0.082616    Objective Loss 0.082616                                        LR 0.100000    Time 0.588559    
2024-01-15 12:05:22,754 - Epoch: [12][  130/  211]    Overall Loss 0.081908    Objective Loss 0.081908                                        LR 0.100000    Time 0.586527    
2024-01-15 12:05:28,490 - Epoch: [12][  140/  211]    Overall Loss 0.081705    Objective Loss 0.081705                                        LR 0.100000    Time 0.585604    
2024-01-15 12:05:34,114 - Epoch: [12][  150/  211]    Overall Loss 0.081437    Objective Loss 0.081437                                        LR 0.100000    Time 0.584041    
2024-01-15 12:05:39,757 - Epoch: [12][  160/  211]    Overall Loss 0.080510    Objective Loss 0.080510                                        LR 0.100000    Time 0.582805    
2024-01-15 12:05:45,535 - Epoch: [12][  170/  211]    Overall Loss 0.080418    Objective Loss 0.080418                                        LR 0.100000    Time 0.582508    
2024-01-15 12:05:51,160 - Epoch: [12][  180/  211]    Overall Loss 0.080650    Objective Loss 0.080650                                        LR 0.100000    Time 0.581384    
2024-01-15 12:05:56,781 - Epoch: [12][  190/  211]    Overall Loss 0.080712    Objective Loss 0.080712                                        LR 0.100000    Time 0.580366    
2024-01-15 12:06:02,422 - Epoch: [12][  200/  211]    Overall Loss 0.080534    Objective Loss 0.080534                                        LR 0.100000    Time 0.579541    
2024-01-15 12:06:08,072 - Epoch: [12][  210/  211]    Overall Loss 0.080013    Objective Loss 0.080013    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.578847    
2024-01-15 12:06:08,648 - Epoch: [12][  211/  211]    Overall Loss 0.079902    Objective Loss 0.079902    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.578830    
2024-01-15 12:06:09,229 - --- validate (epoch=12)-----------
2024-01-15 12:06:09,229 - 6000 samples (256 per mini-batch)
2024-01-15 12:06:14,285 - Epoch: [12][   10/   24]    Loss 0.080603    Top1 97.695312    Top5 99.960938    
2024-01-15 12:06:16,383 - Epoch: [12][   20/   24]    Loss 0.085231    Top1 97.480469    Top5 99.980469    
2024-01-15 12:06:17,119 - Epoch: [12][   24/   24]    Loss 0.083632    Top1 97.500000    Top5 99.983333    
2024-01-15 12:06:17,664 - ==> Top1: 97.500    Top5: 99.983    Loss: 0.084

2024-01-15 12:06:17,665 - ==> Confusion:
[[594   0   2   0   1   2   1   1   2   2]
 [  1 685   0   0   0   0   0   2   0   0]
 [  0   3 559   7   0   1   0   9   4   3]
 [  1   0   2 573   0   3   0   3   1   0]
 [  0   2   1   0 543   1   0   1   1  16]
 [  0   0   0   2   1 512   1   0   1   1]
 [  2   5   0   0   5   8 610   0   1   0]
 [  0   3   3   0   1   1   0 617   0   0]
 [  1   0   0   3   0   8   3   0 567   2]
 [  1   2   0   2   6   5   0   5   4 590]]

2024-01-15 12:06:17,666 - ==> Best [Top1: 97.800   Top5: 99.967   Sparsity:0.00   Params: 71148 on epoch: 10]
2024-01-15 12:06:17,666 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:06:17,671 - 

2024-01-15 12:06:17,671 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:06:25,970 - Epoch: [13][   10/  211]    Overall Loss 0.072303    Objective Loss 0.072303                                        LR 0.100000    Time 0.829771    
2024-01-15 12:06:31,598 - Epoch: [13][   20/  211]    Overall Loss 0.075875    Objective Loss 0.075875                                        LR 0.100000    Time 0.696254    
2024-01-15 12:06:37,241 - Epoch: [13][   30/  211]    Overall Loss 0.082798    Objective Loss 0.082798                                        LR 0.100000    Time 0.652274    
2024-01-15 12:06:42,883 - Epoch: [13][   40/  211]    Overall Loss 0.083067    Objective Loss 0.083067                                        LR 0.100000    Time 0.630207    
2024-01-15 12:06:48,522 - Epoch: [13][   50/  211]    Overall Loss 0.081361    Objective Loss 0.081361                                        LR 0.100000    Time 0.616928    
2024-01-15 12:06:54,158 - Epoch: [13][   60/  211]    Overall Loss 0.079117    Objective Loss 0.079117                                        LR 0.100000    Time 0.608022    
2024-01-15 12:06:59,790 - Epoch: [13][   70/  211]    Overall Loss 0.077645    Objective Loss 0.077645                                        LR 0.100000    Time 0.601624    
2024-01-15 12:07:05,492 - Epoch: [13][   80/  211]    Overall Loss 0.076063    Objective Loss 0.076063                                        LR 0.100000    Time 0.597668    
2024-01-15 12:07:11,179 - Epoch: [13][   90/  211]    Overall Loss 0.074906    Objective Loss 0.074906                                        LR 0.100000    Time 0.594444    
2024-01-15 12:07:16,827 - Epoch: [13][  100/  211]    Overall Loss 0.074407    Objective Loss 0.074407                                        LR 0.100000    Time 0.591482    
2024-01-15 12:07:22,459 - Epoch: [13][  110/  211]    Overall Loss 0.075626    Objective Loss 0.075626                                        LR 0.100000    Time 0.588907    
2024-01-15 12:07:28,254 - Epoch: [13][  120/  211]    Overall Loss 0.075011    Objective Loss 0.075011                                        LR 0.100000    Time 0.588111    
2024-01-15 12:07:33,926 - Epoch: [13][  130/  211]    Overall Loss 0.074824    Objective Loss 0.074824                                        LR 0.100000    Time 0.586495    
2024-01-15 12:07:39,577 - Epoch: [13][  140/  211]    Overall Loss 0.074811    Objective Loss 0.074811                                        LR 0.100000    Time 0.584960    
2024-01-15 12:07:45,227 - Epoch: [13][  150/  211]    Overall Loss 0.074621    Objective Loss 0.074621                                        LR 0.100000    Time 0.583618    
2024-01-15 12:07:50,849 - Epoch: [13][  160/  211]    Overall Loss 0.074266    Objective Loss 0.074266                                        LR 0.100000    Time 0.582278    
2024-01-15 12:07:56,476 - Epoch: [13][  170/  211]    Overall Loss 0.073978    Objective Loss 0.073978                                        LR 0.100000    Time 0.581121    
2024-01-15 12:08:02,104 - Epoch: [13][  180/  211]    Overall Loss 0.073496    Objective Loss 0.073496                                        LR 0.100000    Time 0.580094    
2024-01-15 12:08:07,743 - Epoch: [13][  190/  211]    Overall Loss 0.072879    Objective Loss 0.072879                                        LR 0.100000    Time 0.579241    
2024-01-15 12:08:13,360 - Epoch: [13][  200/  211]    Overall Loss 0.072448    Objective Loss 0.072448                                        LR 0.100000    Time 0.578361    
2024-01-15 12:08:18,968 - Epoch: [13][  210/  211]    Overall Loss 0.072441    Objective Loss 0.072441    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.577520    
2024-01-15 12:08:19,543 - Epoch: [13][  211/  211]    Overall Loss 0.072381    Objective Loss 0.072381    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.577506    
2024-01-15 12:08:20,194 - --- validate (epoch=13)-----------
2024-01-15 12:08:20,194 - 6000 samples (256 per mini-batch)
2024-01-15 12:08:25,432 - Epoch: [13][   10/   24]    Loss 0.069004    Top1 97.890625    Top5 99.960938    
2024-01-15 12:08:27,536 - Epoch: [13][   20/   24]    Loss 0.062346    Top1 98.105469    Top5 99.980469    
2024-01-15 12:08:28,274 - Epoch: [13][   24/   24]    Loss 0.062283    Top1 98.066667    Top5 99.983333    
2024-01-15 12:08:28,821 - ==> Top1: 98.067    Top5: 99.983    Loss: 0.062

2024-01-15 12:08:28,821 - ==> Confusion:
[[598   0   1   1   0   0   1   0   2   2]
 [  0 684   2   1   0   0   0   1   0   0]
 [  0   3 572   3   0   0   1   5   2   0]
 [  1   1   0 575   0   2   0   1   1   2]
 [  0   1   1   0 548   0   0   0   0  15]
 [  2   3   0   3   1 501   3   0   5   0]
 [  1   3   0   0   1   5 619   0   2   0]
 [  0   1   4   3   1   0   0 615   0   1]
 [  0   0   2   1   2   7   0   0 569   3]
 [  0   1   0   0   3   1   1   4   2 603]]

2024-01-15 12:08:28,822 - ==> Best [Top1: 98.067   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 13]
2024-01-15 12:08:28,822 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:08:28,829 - 

2024-01-15 12:08:28,829 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:08:36,921 - Epoch: [14][   10/  211]    Overall Loss 0.079518    Objective Loss 0.079518                                        LR 0.100000    Time 0.809140    
2024-01-15 12:08:42,556 - Epoch: [14][   20/  211]    Overall Loss 0.071848    Objective Loss 0.071848                                        LR 0.100000    Time 0.686244    
2024-01-15 12:08:48,179 - Epoch: [14][   30/  211]    Overall Loss 0.070510    Objective Loss 0.070510                                        LR 0.100000    Time 0.644906    
2024-01-15 12:08:53,797 - Epoch: [14][   40/  211]    Overall Loss 0.068331    Objective Loss 0.068331                                        LR 0.100000    Time 0.624098    
2024-01-15 12:08:59,440 - Epoch: [14][   50/  211]    Overall Loss 0.069869    Objective Loss 0.069869                                        LR 0.100000    Time 0.612144    
2024-01-15 12:09:05,094 - Epoch: [14][   60/  211]    Overall Loss 0.068832    Objective Loss 0.068832                                        LR 0.100000    Time 0.604337    
2024-01-15 12:09:10,742 - Epoch: [14][   70/  211]    Overall Loss 0.069426    Objective Loss 0.069426                                        LR 0.100000    Time 0.598676    
2024-01-15 12:09:16,375 - Epoch: [14][   80/  211]    Overall Loss 0.069681    Objective Loss 0.069681                                        LR 0.100000    Time 0.594250    
2024-01-15 12:09:22,004 - Epoch: [14][   90/  211]    Overall Loss 0.070136    Objective Loss 0.070136                                        LR 0.100000    Time 0.590747    
2024-01-15 12:09:27,992 - Epoch: [14][  100/  211]    Overall Loss 0.070114    Objective Loss 0.070114                                        LR 0.100000    Time 0.591553    
2024-01-15 12:09:33,624 - Epoch: [14][  110/  211]    Overall Loss 0.069457    Objective Loss 0.069457                                        LR 0.100000    Time 0.588963    
2024-01-15 12:09:39,257 - Epoch: [14][  120/  211]    Overall Loss 0.070333    Objective Loss 0.070333                                        LR 0.100000    Time 0.586821    
2024-01-15 12:09:44,882 - Epoch: [14][  130/  211]    Overall Loss 0.070103    Objective Loss 0.070103                                        LR 0.100000    Time 0.584942    
2024-01-15 12:09:50,527 - Epoch: [14][  140/  211]    Overall Loss 0.070348    Objective Loss 0.070348                                        LR 0.100000    Time 0.583478    
2024-01-15 12:09:56,150 - Epoch: [14][  150/  211]    Overall Loss 0.070285    Objective Loss 0.070285                                        LR 0.100000    Time 0.582058    
2024-01-15 12:10:01,835 - Epoch: [14][  160/  211]    Overall Loss 0.069826    Objective Loss 0.069826                                        LR 0.100000    Time 0.581209    
2024-01-15 12:10:07,457 - Epoch: [14][  170/  211]    Overall Loss 0.069452    Objective Loss 0.069452                                        LR 0.100000    Time 0.580084    
2024-01-15 12:10:13,076 - Epoch: [14][  180/  211]    Overall Loss 0.069369    Objective Loss 0.069369                                        LR 0.100000    Time 0.579072    
2024-01-15 12:10:18,705 - Epoch: [14][  190/  211]    Overall Loss 0.069529    Objective Loss 0.069529                                        LR 0.100000    Time 0.578211    
2024-01-15 12:10:24,392 - Epoch: [14][  200/  211]    Overall Loss 0.069509    Objective Loss 0.069509                                        LR 0.100000    Time 0.577738    
2024-01-15 12:10:30,028 - Epoch: [14][  210/  211]    Overall Loss 0.069947    Objective Loss 0.069947    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.577057    
2024-01-15 12:10:30,603 - Epoch: [14][  211/  211]    Overall Loss 0.069830    Objective Loss 0.069830    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.577039    
2024-01-15 12:10:31,172 - --- validate (epoch=14)-----------
2024-01-15 12:10:31,173 - 6000 samples (256 per mini-batch)
2024-01-15 12:10:36,449 - Epoch: [14][   10/   24]    Loss 0.064870    Top1 98.007812    Top5 99.960938    
2024-01-15 12:10:38,561 - Epoch: [14][   20/   24]    Loss 0.067413    Top1 97.890625    Top5 99.960938    
2024-01-15 12:10:39,310 - Epoch: [14][   24/   24]    Loss 0.070057    Top1 97.866667    Top5 99.933333    
2024-01-15 12:10:39,964 - ==> Top1: 97.867    Top5: 99.933    Loss: 0.070

2024-01-15 12:10:39,965 - ==> Confusion:
[[595   0   0   0   0   0   4   4   0   2]
 [  0 684   0   0   0   0   0   4   0   0]
 [  1   3 571   2   1   0   0   7   1   0]
 [  0   0   3 569   0   2   0   5   1   3]
 [  0   1   0   0 553   0   0   3   0   8]
 [  1   1   0   3   0 502   5   0   2   4]
 [  0   3   0   0   2   1 625   0   0   0]
 [  0   3   1   0   0   0   0 621   0   0]
 [  3   3   2   1   2   3  14   0 550   6]
 [  0   1   0   0   5   0   0   6   1 602]]

2024-01-15 12:10:39,967 - ==> Best [Top1: 98.067   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 13]
2024-01-15 12:10:39,967 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:10:39,970 - 

2024-01-15 12:10:39,970 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:10:47,995 - Epoch: [15][   10/  211]    Overall Loss 0.057482    Objective Loss 0.057482                                        LR 0.100000    Time 0.802420    
2024-01-15 12:10:53,634 - Epoch: [15][   20/  211]    Overall Loss 0.065510    Objective Loss 0.065510                                        LR 0.100000    Time 0.683095    
2024-01-15 12:10:59,283 - Epoch: [15][   30/  211]    Overall Loss 0.067155    Objective Loss 0.067155                                        LR 0.100000    Time 0.643686    
2024-01-15 12:11:04,908 - Epoch: [15][   40/  211]    Overall Loss 0.068333    Objective Loss 0.068333                                        LR 0.100000    Time 0.623341    
2024-01-15 12:11:10,545 - Epoch: [15][   50/  211]    Overall Loss 0.066607    Objective Loss 0.066607                                        LR 0.100000    Time 0.611399    
2024-01-15 12:11:16,174 - Epoch: [15][   60/  211]    Overall Loss 0.066363    Objective Loss 0.066363                                        LR 0.100000    Time 0.603316    
2024-01-15 12:11:21,802 - Epoch: [15][   70/  211]    Overall Loss 0.064401    Objective Loss 0.064401                                        LR 0.100000    Time 0.597517    
2024-01-15 12:11:27,503 - Epoch: [15][   80/  211]    Overall Loss 0.064335    Objective Loss 0.064335                                        LR 0.100000    Time 0.594080    
2024-01-15 12:11:33,189 - Epoch: [15][   90/  211]    Overall Loss 0.065749    Objective Loss 0.065749                                        LR 0.100000    Time 0.591239    
2024-01-15 12:11:38,831 - Epoch: [15][  100/  211]    Overall Loss 0.065994    Objective Loss 0.065994                                        LR 0.100000    Time 0.588522    
2024-01-15 12:11:44,455 - Epoch: [15][  110/  211]    Overall Loss 0.066628    Objective Loss 0.066628                                        LR 0.100000    Time 0.586138    
2024-01-15 12:11:50,070 - Epoch: [15][  120/  211]    Overall Loss 0.067169    Objective Loss 0.067169                                        LR 0.100000    Time 0.584080    
2024-01-15 12:11:55,689 - Epoch: [15][  130/  211]    Overall Loss 0.068821    Objective Loss 0.068821                                        LR 0.100000    Time 0.582369    
2024-01-15 12:12:01,312 - Epoch: [15][  140/  211]    Overall Loss 0.069964    Objective Loss 0.069964                                        LR 0.100000    Time 0.580929    
2024-01-15 12:12:06,972 - Epoch: [15][  150/  211]    Overall Loss 0.070294    Objective Loss 0.070294                                        LR 0.100000    Time 0.579933    
2024-01-15 12:12:12,600 - Epoch: [15][  160/  211]    Overall Loss 0.070067    Objective Loss 0.070067                                        LR 0.100000    Time 0.578855    
2024-01-15 12:12:18,263 - Epoch: [15][  170/  211]    Overall Loss 0.070538    Objective Loss 0.070538                                        LR 0.100000    Time 0.578113    
2024-01-15 12:12:23,944 - Epoch: [15][  180/  211]    Overall Loss 0.071338    Objective Loss 0.071338                                        LR 0.100000    Time 0.577548    
2024-01-15 12:12:30,053 - Epoch: [15][  190/  211]    Overall Loss 0.070759    Objective Loss 0.070759                                        LR 0.100000    Time 0.579301    
2024-01-15 12:12:35,693 - Epoch: [15][  200/  211]    Overall Loss 0.070339    Objective Loss 0.070339                                        LR 0.100000    Time 0.578530    
2024-01-15 12:12:41,334 - Epoch: [15][  210/  211]    Overall Loss 0.070114    Objective Loss 0.070114    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.577842    
2024-01-15 12:12:41,903 - Epoch: [15][  211/  211]    Overall Loss 0.070149    Objective Loss 0.070149    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.577795    
2024-01-15 12:12:42,686 - --- validate (epoch=15)-----------
2024-01-15 12:12:42,687 - 6000 samples (256 per mini-batch)
2024-01-15 12:12:48,091 - Epoch: [15][   10/   24]    Loss 0.079238    Top1 97.617188    Top5 99.960938    
2024-01-15 12:12:50,206 - Epoch: [15][   20/   24]    Loss 0.067625    Top1 98.007812    Top5 99.980469    
2024-01-15 12:12:50,951 - Epoch: [15][   24/   24]    Loss 0.068788    Top1 97.966667    Top5 99.983333    
2024-01-15 12:12:51,533 - ==> Top1: 97.967    Top5: 99.983    Loss: 0.069

2024-01-15 12:12:51,533 - ==> Confusion:
[[598   0   1   1   0   0   3   1   1   0]
 [  0 682   0   0   1   0   0   5   0   0]
 [  0   0 576   1   0   0   0   9   0   0]
 [  0   1   3 565   0   5   0   6   1   2]
 [  0   1   0   0 555   0   1   1   0   7]
 [  1   0   0   1   2 511   0   0   2   1]
 [  1   6   0   0   3   4 614   0   2   1]
 [  0   1   1   0   1   0   0 622   0   0]
 [  1   0   1   0   4   3   9   1 557   8]
 [  1   2   0   0   7   1   0   3   3 598]]

2024-01-15 12:12:51,534 - ==> Best [Top1: 98.067   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 13]
2024-01-15 12:12:51,535 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:12:51,538 - 

2024-01-15 12:12:51,538 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:12:59,672 - Epoch: [16][   10/  211]    Overall Loss 0.058938    Objective Loss 0.058938                                        LR 0.100000    Time 0.813358    
2024-01-15 12:13:05,404 - Epoch: [16][   20/  211]    Overall Loss 0.064125    Objective Loss 0.064125                                        LR 0.100000    Time 0.693177    
2024-01-15 12:13:11,114 - Epoch: [16][   30/  211]    Overall Loss 0.066207    Objective Loss 0.066207                                        LR 0.100000    Time 0.652439    
2024-01-15 12:13:16,753 - Epoch: [16][   40/  211]    Overall Loss 0.064234    Objective Loss 0.064234                                        LR 0.100000    Time 0.630278    
2024-01-15 12:13:22,372 - Epoch: [16][   50/  211]    Overall Loss 0.066968    Objective Loss 0.066968                                        LR 0.100000    Time 0.616593    
2024-01-15 12:13:28,169 - Epoch: [16][   60/  211]    Overall Loss 0.067151    Objective Loss 0.067151                                        LR 0.100000    Time 0.610412    
2024-01-15 12:13:33,894 - Epoch: [16][   70/  211]    Overall Loss 0.068467    Objective Loss 0.068467                                        LR 0.100000    Time 0.604990    
2024-01-15 12:13:39,618 - Epoch: [16][   80/  211]    Overall Loss 0.066729    Objective Loss 0.066729                                        LR 0.100000    Time 0.600900    
2024-01-15 12:13:45,556 - Epoch: [16][   90/  211]    Overall Loss 0.066677    Objective Loss 0.066677                                        LR 0.100000    Time 0.600101    
2024-01-15 12:13:51,298 - Epoch: [16][  100/  211]    Overall Loss 0.065624    Objective Loss 0.065624                                        LR 0.100000    Time 0.597507    
2024-01-15 12:13:57,346 - Epoch: [16][  110/  211]    Overall Loss 0.065302    Objective Loss 0.065302                                        LR 0.100000    Time 0.598154    
2024-01-15 12:14:03,114 - Epoch: [16][  120/  211]    Overall Loss 0.065573    Objective Loss 0.065573                                        LR 0.100000    Time 0.596368    
2024-01-15 12:14:08,864 - Epoch: [16][  130/  211]    Overall Loss 0.064891    Objective Loss 0.064891                                        LR 0.100000    Time 0.594717    
2024-01-15 12:14:14,555 - Epoch: [16][  140/  211]    Overall Loss 0.064929    Objective Loss 0.064929                                        LR 0.100000    Time 0.592880    
2024-01-15 12:14:20,192 - Epoch: [16][  150/  211]    Overall Loss 0.064953    Objective Loss 0.064953                                        LR 0.100000    Time 0.590928    
2024-01-15 12:14:26,059 - Epoch: [16][  160/  211]    Overall Loss 0.064853    Objective Loss 0.064853                                        LR 0.100000    Time 0.590654    
2024-01-15 12:14:31,709 - Epoch: [16][  170/  211]    Overall Loss 0.064827    Objective Loss 0.064827                                        LR 0.100000    Time 0.589145    
2024-01-15 12:14:37,342 - Epoch: [16][  180/  211]    Overall Loss 0.064561    Objective Loss 0.064561                                        LR 0.100000    Time 0.587705    
2024-01-15 12:14:43,053 - Epoch: [16][  190/  211]    Overall Loss 0.064004    Objective Loss 0.064004                                        LR 0.100000    Time 0.586826    
2024-01-15 12:14:48,693 - Epoch: [16][  200/  211]    Overall Loss 0.063778    Objective Loss 0.063778                                        LR 0.100000    Time 0.585681    
2024-01-15 12:14:54,327 - Epoch: [16][  210/  211]    Overall Loss 0.063121    Objective Loss 0.063121    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.584614    
2024-01-15 12:14:54,888 - Epoch: [16][  211/  211]    Overall Loss 0.063367    Objective Loss 0.063367    Top1 97.177419    Top5 100.000000    LR 0.100000    Time 0.584505    
2024-01-15 12:14:55,692 - --- validate (epoch=16)-----------
2024-01-15 12:14:55,694 - 6000 samples (256 per mini-batch)
2024-01-15 12:15:01,698 - Epoch: [16][   10/   24]    Loss 0.076156    Top1 97.812500    Top5 99.960938    
2024-01-15 12:15:03,802 - Epoch: [16][   20/   24]    Loss 0.072401    Top1 97.832031    Top5 99.980469    
2024-01-15 12:15:04,539 - Epoch: [16][   24/   24]    Loss 0.069702    Top1 97.866667    Top5 99.983333    
2024-01-15 12:15:05,096 - ==> Top1: 97.867    Top5: 99.983    Loss: 0.070

2024-01-15 12:15:05,097 - ==> Confusion:
[[600   0   2   0   0   0   2   0   1   0]
 [  0 678   3   1   0   1   0   5   0   0]
 [  1   0 576   1   0   1   0   2   3   2]
 [  0   0   6 570   0   1   0   0   3   3]
 [  0   0   7   0 535   0   5   1   0  17]
 [  0   1   1   3   0 508   3   0   2   0]
 [  2   0   0   0   1   1 626   0   1   0]
 [  0   1   5   1   1   0   0 616   0   1]
 [  2   0   1   1   0   1   7   0 570   2]
 [  2   0   1   0   4   2   0   6   7 593]]

2024-01-15 12:15:05,099 - ==> Best [Top1: 98.067   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 13]
2024-01-15 12:15:05,099 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:15:05,103 - 

2024-01-15 12:15:05,103 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:15:13,601 - Epoch: [17][   10/  211]    Overall Loss 0.066625    Objective Loss 0.066625                                        LR 0.100000    Time 0.849733    
2024-01-15 12:15:19,236 - Epoch: [17][   20/  211]    Overall Loss 0.074319    Objective Loss 0.074319                                        LR 0.100000    Time 0.706561    
2024-01-15 12:15:24,987 - Epoch: [17][   30/  211]    Overall Loss 0.069831    Objective Loss 0.069831                                        LR 0.100000    Time 0.662710    
2024-01-15 12:15:30,752 - Epoch: [17][   40/  211]    Overall Loss 0.070008    Objective Loss 0.070008                                        LR 0.100000    Time 0.641137    
2024-01-15 12:15:36,469 - Epoch: [17][   50/  211]    Overall Loss 0.070407    Objective Loss 0.070407                                        LR 0.100000    Time 0.627240    
2024-01-15 12:15:42,132 - Epoch: [17][   60/  211]    Overall Loss 0.069323    Objective Loss 0.069323                                        LR 0.100000    Time 0.617058    
2024-01-15 12:15:47,758 - Epoch: [17][   70/  211]    Overall Loss 0.067068    Objective Loss 0.067068                                        LR 0.100000    Time 0.609272    
2024-01-15 12:15:53,383 - Epoch: [17][   80/  211]    Overall Loss 0.066346    Objective Loss 0.066346                                        LR 0.100000    Time 0.603419    
2024-01-15 12:15:59,010 - Epoch: [17][   90/  211]    Overall Loss 0.064378    Objective Loss 0.064378                                        LR 0.100000    Time 0.598879    
2024-01-15 12:16:04,635 - Epoch: [17][  100/  211]    Overall Loss 0.064637    Objective Loss 0.064637                                        LR 0.100000    Time 0.595243    
2024-01-15 12:16:10,297 - Epoch: [17][  110/  211]    Overall Loss 0.064278    Objective Loss 0.064278                                        LR 0.100000    Time 0.592591    
2024-01-15 12:16:15,939 - Epoch: [17][  120/  211]    Overall Loss 0.063948    Objective Loss 0.063948                                        LR 0.100000    Time 0.590230    
2024-01-15 12:16:21,562 - Epoch: [17][  130/  211]    Overall Loss 0.064160    Objective Loss 0.064160                                        LR 0.100000    Time 0.588066    
2024-01-15 12:16:27,323 - Epoch: [17][  140/  211]    Overall Loss 0.064076    Objective Loss 0.064076                                        LR 0.100000    Time 0.587206    
2024-01-15 12:16:32,952 - Epoch: [17][  150/  211]    Overall Loss 0.064617    Objective Loss 0.064617                                        LR 0.100000    Time 0.585583    
2024-01-15 12:16:38,607 - Epoch: [17][  160/  211]    Overall Loss 0.064215    Objective Loss 0.064215                                        LR 0.100000    Time 0.584323    
2024-01-15 12:16:44,269 - Epoch: [17][  170/  211]    Overall Loss 0.064937    Objective Loss 0.064937                                        LR 0.100000    Time 0.583250    
2024-01-15 12:16:50,021 - Epoch: [17][  180/  211]    Overall Loss 0.064879    Objective Loss 0.064879                                        LR 0.100000    Time 0.582800    
2024-01-15 12:16:55,652 - Epoch: [17][  190/  211]    Overall Loss 0.064082    Objective Loss 0.064082                                        LR 0.100000    Time 0.581757    
2024-01-15 12:17:01,298 - Epoch: [17][  200/  211]    Overall Loss 0.064048    Objective Loss 0.064048                                        LR 0.100000    Time 0.580898    
2024-01-15 12:17:07,011 - Epoch: [17][  210/  211]    Overall Loss 0.064565    Objective Loss 0.064565    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.580434    
2024-01-15 12:17:07,586 - Epoch: [17][  211/  211]    Overall Loss 0.064704    Objective Loss 0.064704    Top1 97.580645    Top5 100.000000    LR 0.100000    Time 0.580410    
2024-01-15 12:17:08,158 - --- validate (epoch=17)-----------
2024-01-15 12:17:08,158 - 6000 samples (256 per mini-batch)
2024-01-15 12:17:13,483 - Epoch: [17][   10/   24]    Loss 0.068757    Top1 98.125000    Top5 99.960938    
2024-01-15 12:17:15,587 - Epoch: [17][   20/   24]    Loss 0.071253    Top1 97.910156    Top5 99.960938    
2024-01-15 12:17:16,332 - Epoch: [17][   24/   24]    Loss 0.069742    Top1 98.000000    Top5 99.950000    
2024-01-15 12:17:16,869 - ==> Top1: 98.000    Top5: 99.950    Loss: 0.070

2024-01-15 12:17:16,870 - ==> Confusion:
[[601   0   2   0   0   0   1   0   0   1]
 [  1 681   3   0   0   0   0   3   0   0]
 [  1   1 573   2   0   1   2   2   3   1]
 [  1   0   6 564   0   3   0   7   0   2]
 [  0   1   1   0 548   0   1   2   0  12]
 [  1   0   1   0   0 508   5   1   2   0]
 [  9   0   0   0   2   0 618   0   2   0]
 [  0   1   3   0   0   0   0 621   0   0]
 [  7   0   1   0   2   3   3   2 562   4]
 [  1   1   0   0   1   2   0   5   1 604]]

2024-01-15 12:17:16,872 - ==> Best [Top1: 98.067   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 13]
2024-01-15 12:17:16,872 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:17:16,876 - 

2024-01-15 12:17:16,877 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:17:25,167 - Epoch: [18][   10/  211]    Overall Loss 0.062762    Objective Loss 0.062762                                        LR 0.100000    Time 0.828957    
2024-01-15 12:17:30,820 - Epoch: [18][   20/  211]    Overall Loss 0.066417    Objective Loss 0.066417                                        LR 0.100000    Time 0.696998    
2024-01-15 12:17:36,447 - Epoch: [18][   30/  211]    Overall Loss 0.064793    Objective Loss 0.064793                                        LR 0.100000    Time 0.652211    
2024-01-15 12:17:42,148 - Epoch: [18][   40/  211]    Overall Loss 0.067221    Objective Loss 0.067221                                        LR 0.100000    Time 0.631665    
2024-01-15 12:17:47,803 - Epoch: [18][   50/  211]    Overall Loss 0.067091    Objective Loss 0.067091                                        LR 0.100000    Time 0.618414    
2024-01-15 12:17:53,422 - Epoch: [18][   60/  211]    Overall Loss 0.066015    Objective Loss 0.066015                                        LR 0.100000    Time 0.608990    
2024-01-15 12:17:59,048 - Epoch: [18][   70/  211]    Overall Loss 0.064736    Objective Loss 0.064736                                        LR 0.100000    Time 0.602350    
2024-01-15 12:18:04,703 - Epoch: [18][   80/  211]    Overall Loss 0.064053    Objective Loss 0.064053                                        LR 0.100000    Time 0.597739    
2024-01-15 12:18:10,373 - Epoch: [18][   90/  211]    Overall Loss 0.062419    Objective Loss 0.062419                                        LR 0.100000    Time 0.594309    
2024-01-15 12:18:15,999 - Epoch: [18][  100/  211]    Overall Loss 0.063849    Objective Loss 0.063849                                        LR 0.100000    Time 0.591134    
2024-01-15 12:18:21,626 - Epoch: [18][  110/  211]    Overall Loss 0.063258    Objective Loss 0.063258                                        LR 0.100000    Time 0.588532    
2024-01-15 12:18:27,331 - Epoch: [18][  120/  211]    Overall Loss 0.063754    Objective Loss 0.063754                                        LR 0.100000    Time 0.587025    
2024-01-15 12:18:33,159 - Epoch: [18][  130/  211]    Overall Loss 0.063525    Objective Loss 0.063525                                        LR 0.100000    Time 0.586692    
2024-01-15 12:18:42,798 - Epoch: [18][  140/  211]    Overall Loss 0.062977    Objective Loss 0.062977                                        LR 0.100000    Time 0.613121    
2024-01-15 12:18:48,635 - Epoch: [18][  150/  211]    Overall Loss 0.062916    Objective Loss 0.062916                                        LR 0.100000    Time 0.611140    
2024-01-15 12:18:54,311 - Epoch: [18][  160/  211]    Overall Loss 0.062042    Objective Loss 0.062042                                        LR 0.100000    Time 0.608413    
2024-01-15 12:18:59,940 - Epoch: [18][  170/  211]    Overall Loss 0.062212    Objective Loss 0.062212                                        LR 0.100000    Time 0.605733    
2024-01-15 12:19:05,676 - Epoch: [18][  180/  211]    Overall Loss 0.062745    Objective Loss 0.062745                                        LR 0.100000    Time 0.603946    
2024-01-15 12:19:11,462 - Epoch: [18][  190/  211]    Overall Loss 0.062276    Objective Loss 0.062276                                        LR 0.100000    Time 0.602605    
2024-01-15 12:21:29,352 - Epoch: [18][  200/  211]    Overall Loss 0.062102    Objective Loss 0.062102                                        LR 0.100000    Time 1.261914    
2024-01-15 12:21:35,259 - Epoch: [18][  210/  211]    Overall Loss 0.061974    Objective Loss 0.061974    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 1.229944    
2024-01-15 12:21:35,942 - Epoch: [18][  211/  211]    Overall Loss 0.062015    Objective Loss 0.062015    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 1.227349    
2024-01-15 12:23:51,999 - --- validate (epoch=18)-----------
2024-01-15 12:23:52,004 - 6000 samples (256 per mini-batch)
2024-01-15 12:23:59,059 - Epoch: [18][   10/   24]    Loss 0.076712    Top1 97.812500    Top5 100.000000    
2024-01-15 12:24:01,180 - Epoch: [18][   20/   24]    Loss 0.066583    Top1 98.105469    Top5 100.000000    
2024-01-15 12:24:01,994 - Epoch: [18][   24/   24]    Loss 0.067360    Top1 98.083333    Top5 100.000000    
2024-01-15 12:24:02,664 - ==> Top1: 98.083    Top5: 100.000    Loss: 0.067

2024-01-15 12:24:02,665 - ==> Confusion:
[[600   0   2   0   0   0   1   0   2   0]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 579   0   0   0   0   6   0   1]
 [  0   0   5 573   0   1   0   3   1   0]
 [  0   1   4   0 547   0   1   1   1  10]
 [  3   0   0   2   0 501   5   1   5   1]
 [  3   2   0   0   2   0 620   0   4   0]
 [  0   3   4   1   0   0   0 617   0   0]
 [  1   2   2   0   1   2   6   0 568   2]
 [  4   2   3   0   2   2   0   3   6 593]]

2024-01-15 12:24:02,667 - ==> Best [Top1: 98.083   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 18]
2024-01-15 12:24:02,668 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 12:24:02,676 - 

2024-01-15 12:24:02,677 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 12:31:19,576 - Epoch: [19][   10/  211]    Overall Loss 0.047221    Objective Loss 0.047221                                        LR 0.100000    Time 43.689870    
2024-01-15 12:31:25,180 - Epoch: [19][   20/  211]    Overall Loss 0.042409    Objective Loss 0.042409                                        LR 0.100000    Time 22.125088    
2024-01-15 12:47:13,551 - Epoch: [19][   30/  211]    Overall Loss 0.044451    Objective Loss 0.044451                                        LR 0.100000    Time 46.362347    
2024-01-15 12:47:22,041 - Epoch: [19][   40/  211]    Overall Loss 0.049145    Objective Loss 0.049145                                        LR 0.100000    Time 34.983974    
2024-01-15 12:47:27,874 - Epoch: [19][   50/  211]    Overall Loss 0.049675    Objective Loss 0.049675                                        LR 0.100000    Time 28.103810    
2024-01-15 12:47:33,460 - Epoch: [19][   60/  211]    Overall Loss 0.053080    Objective Loss 0.053080                                        LR 0.100000    Time 23.512923    
2024-01-15 12:48:15,354 - Epoch: [19][   70/  211]    Overall Loss 0.053418    Objective Loss 0.053418                                        LR 0.100000    Time 20.752409    
2024-01-15 13:00:51,477 - Epoch: [19][   80/  211]    Overall Loss 0.055714    Objective Loss 0.055714                                        LR 0.100000    Time 27.609885    
2024-01-15 13:14:22,005 - Epoch: [19][   90/  211]    Overall Loss 0.057045    Objective Loss 0.057045                                        LR 0.100000    Time 33.547975    
2024-01-15 13:14:27,775 - Epoch: [19][  100/  211]    Overall Loss 0.058683    Objective Loss 0.058683                                        LR 0.100000    Time 30.250863    
2024-01-15 13:27:58,392 - Epoch: [19][  110/  211]    Overall Loss 0.060040    Objective Loss 0.060040                                        LR 0.100000    Time 34.870022    
2024-01-15 13:41:28,845 - Epoch: [19][  120/  211]    Overall Loss 0.059747    Objective Loss 0.059747                                        LR 0.100000    Time 38.717952    
2024-01-15 13:41:34,241 - Epoch: [19][  130/  211]    Overall Loss 0.060204    Objective Loss 0.060204                                        LR 0.100000    Time 35.781121    
2024-01-15 13:42:41,853 - Epoch: [19][  140/  211]    Overall Loss 0.060523    Objective Loss 0.060523                                        LR 0.100000    Time 33.708206    
2024-01-15 13:42:48,217 - Epoch: [19][  150/  211]    Overall Loss 0.061023    Objective Loss 0.061023                                        LR 0.100000    Time 31.503401    
2024-01-15 13:42:55,120 - Epoch: [19][  160/  211]    Overall Loss 0.060396    Objective Loss 0.060396                                        LR 0.100000    Time 29.577575    
2024-01-15 13:43:01,033 - Epoch: [19][  170/  211]    Overall Loss 0.060978    Objective Loss 0.060978                                        LR 0.100000    Time 27.872493    
2024-01-15 13:43:06,830 - Epoch: [19][  180/  211]    Overall Loss 0.061515    Objective Loss 0.061515                                        LR 0.100000    Time 26.356221    
2024-01-15 13:43:12,718 - Epoch: [19][  190/  211]    Overall Loss 0.061748    Objective Loss 0.061748                                        LR 0.100000    Time 25.000028    
2024-01-15 13:43:18,770 - Epoch: [19][  200/  211]    Overall Loss 0.061540    Objective Loss 0.061540                                        LR 0.100000    Time 23.780284    
2024-01-15 13:43:24,573 - Epoch: [19][  210/  211]    Overall Loss 0.060825    Objective Loss 0.060825    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 22.675516    
2024-01-15 13:43:25,245 - Epoch: [19][  211/  211]    Overall Loss 0.060811    Objective Loss 0.060811    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 22.571228    
2024-01-15 13:43:26,628 - --- validate (epoch=19)-----------
2024-01-15 13:43:26,630 - 6000 samples (256 per mini-batch)
2024-01-15 13:43:33,709 - Epoch: [19][   10/   24]    Loss 0.048480    Top1 98.710938    Top5 100.000000    
2024-01-15 13:43:35,972 - Epoch: [19][   20/   24]    Loss 0.054899    Top1 98.339844    Top5 99.960938    
2024-01-15 13:43:36,765 - Epoch: [19][   24/   24]    Loss 0.056192    Top1 98.350000    Top5 99.950000    
2024-01-15 13:43:37,524 - ==> Top1: 98.350    Top5: 99.950    Loss: 0.056

2024-01-15 13:43:37,525 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 681   1   0   0   1   0   5   0   0]
 [  1   1 572   1   0   0   2   2   6   1]
 [  0   0   1 576   0   4   0   1   1   0]
 [  0   1   1   0 549   1   2   1   0  10]
 [  0   0   0   1   0 511   3   0   1   2]
 [  2   1   0   0   1   4 622   0   1   0]
 [  0   2   4   0   0   1   0 617   1   0]
 [  1   0   0   2   1   2   6   0 571   1]
 [  0   1   0   0   6   3   0   1   5 599]]

2024-01-15 13:43:37,528 - ==> Best [Top1: 98.350   Top5: 99.950   Sparsity:0.00   Params: 71148 on epoch: 19]
2024-01-15 13:43:37,528 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 13:43:37,537 - 

2024-01-15 13:43:37,537 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 13:43:50,294 - Epoch: [20][   10/  211]    Overall Loss 0.061504    Objective Loss 0.061504                                        LR 0.100000    Time 1.275397    
2024-01-15 13:43:57,362 - Epoch: [20][   20/  211]    Overall Loss 0.061215    Objective Loss 0.061215                                        LR 0.100000    Time 0.990789    
2024-01-15 13:44:03,385 - Epoch: [20][   30/  211]    Overall Loss 0.060632    Objective Loss 0.060632                                        LR 0.100000    Time 0.861217    
2024-01-15 13:44:09,406 - Epoch: [20][   40/  211]    Overall Loss 0.058728    Objective Loss 0.058728                                        LR 0.100000    Time 0.796418    
2024-01-15 13:44:15,959 - Epoch: [20][   50/  211]    Overall Loss 0.059289    Objective Loss 0.059289                                        LR 0.100000    Time 0.768172    
2024-01-15 13:44:21,947 - Epoch: [20][   60/  211]    Overall Loss 0.059328    Objective Loss 0.059328                                        LR 0.100000    Time 0.739919    
2024-01-15 13:44:27,996 - Epoch: [20][   70/  211]    Overall Loss 0.060136    Objective Loss 0.060136                                        LR 0.100000    Time 0.720604    
2024-01-15 13:44:33,821 - Epoch: [20][   80/  211]    Overall Loss 0.060460    Objective Loss 0.060460                                        LR 0.100000    Time 0.703339    
2024-01-15 13:44:39,632 - Epoch: [20][   90/  211]    Overall Loss 0.060425    Objective Loss 0.060425                                        LR 0.100000    Time 0.689744    
2024-01-15 13:44:45,528 - Epoch: [20][  100/  211]    Overall Loss 0.061192    Objective Loss 0.061192                                        LR 0.100000    Time 0.679713    
2024-01-15 13:44:51,321 - Epoch: [20][  110/  211]    Overall Loss 0.061039    Objective Loss 0.061039                                        LR 0.100000    Time 0.670577    
2024-01-15 13:44:57,336 - Epoch: [20][  120/  211]    Overall Loss 0.060408    Objective Loss 0.060408                                        LR 0.100000    Time 0.664813    
2024-01-15 13:45:03,163 - Epoch: [20][  130/  211]    Overall Loss 0.060732    Objective Loss 0.060732                                        LR 0.100000    Time 0.658470    
2024-01-15 13:45:09,379 - Epoch: [20][  140/  211]    Overall Loss 0.060539    Objective Loss 0.060539                                        LR 0.100000    Time 0.655816    
2024-01-15 13:45:15,771 - Epoch: [20][  150/  211]    Overall Loss 0.060179    Objective Loss 0.060179                                        LR 0.100000    Time 0.654706    
2024-01-15 13:45:22,855 - Epoch: [20][  160/  211]    Overall Loss 0.060098    Objective Loss 0.060098                                        LR 0.100000    Time 0.658050    
2024-01-15 13:45:29,384 - Epoch: [20][  170/  211]    Overall Loss 0.060273    Objective Loss 0.060273                                        LR 0.100000    Time 0.657736    
2024-01-15 13:45:35,297 - Epoch: [20][  180/  211]    Overall Loss 0.060060    Objective Loss 0.060060                                        LR 0.100000    Time 0.654038    
2024-01-15 13:45:41,194 - Epoch: [20][  190/  211]    Overall Loss 0.060128    Objective Loss 0.060128                                        LR 0.100000    Time 0.650644    
2024-01-15 13:45:47,165 - Epoch: [20][  200/  211]    Overall Loss 0.059193    Objective Loss 0.059193                                        LR 0.100000    Time 0.647947    
2024-01-15 13:45:53,026 - Epoch: [20][  210/  211]    Overall Loss 0.059328    Objective Loss 0.059328    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.644993    
2024-01-15 13:45:53,590 - Epoch: [20][  211/  211]    Overall Loss 0.059302    Objective Loss 0.059302    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.644609    
2024-01-15 13:45:54,567 - --- validate (epoch=20)-----------
2024-01-15 13:45:54,568 - 6000 samples (256 per mini-batch)
2024-01-15 13:46:02,167 - Epoch: [20][   10/   24]    Loss 0.059816    Top1 98.203125    Top5 100.000000    
2024-01-15 13:46:04,278 - Epoch: [20][   20/   24]    Loss 0.055890    Top1 98.398438    Top5 100.000000    
2024-01-15 13:46:05,036 - Epoch: [20][   24/   24]    Loss 0.051967    Top1 98.516667    Top5 100.000000    
2024-01-15 13:46:05,774 - ==> Top1: 98.517    Top5: 100.000    Loss: 0.052

2024-01-15 13:46:05,775 - ==> Confusion:
[[603   0   1   0   0   0   0   1   0   0]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 583   0   0   0   0   0   3   0]
 [  0   0   6 568   0   4   0   2   3   0]
 [  0   0   3   0 552   0   0   3   0   7]
 [  0   0   0   1   1 507   4   0   5   0]
 [  2   1   0   0   2   1 624   0   1   0]
 [  0   3   7   0   3   0   0 612   0   0]
 [  4   0   3   1   2   2   2   0 569   1]
 [  0   2   0   0   3   0   0   1   3 606]]

2024-01-15 13:46:05,776 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 13:46:05,776 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 13:46:05,783 - 

2024-01-15 13:46:05,783 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 13:46:15,196 - Epoch: [21][   10/  211]    Overall Loss 0.057227    Objective Loss 0.057227                                        LR 0.100000    Time 0.941169    
2024-01-15 13:46:20,872 - Epoch: [21][   20/  211]    Overall Loss 0.056474    Objective Loss 0.056474                                        LR 0.100000    Time 0.754337    
2024-01-15 13:46:27,465 - Epoch: [21][   30/  211]    Overall Loss 0.058027    Objective Loss 0.058027                                        LR 0.100000    Time 0.722646    
2024-01-15 13:46:33,385 - Epoch: [21][   40/  211]    Overall Loss 0.056317    Objective Loss 0.056317                                        LR 0.100000    Time 0.689940    
2024-01-15 13:46:39,308 - Epoch: [21][   50/  211]    Overall Loss 0.057645    Objective Loss 0.057645                                        LR 0.100000    Time 0.670405    
2024-01-15 13:46:45,420 - Epoch: [21][   60/  211]    Overall Loss 0.059531    Objective Loss 0.059531                                        LR 0.100000    Time 0.660510    
2024-01-15 13:46:51,058 - Epoch: [21][   70/  211]    Overall Loss 0.058045    Objective Loss 0.058045                                        LR 0.100000    Time 0.646685    
2024-01-15 13:46:56,729 - Epoch: [21][   80/  211]    Overall Loss 0.060080    Objective Loss 0.060080                                        LR 0.100000    Time 0.636724    
2024-01-15 13:47:02,470 - Epoch: [21][   90/  211]    Overall Loss 0.060120    Objective Loss 0.060120                                        LR 0.100000    Time 0.629762    
2024-01-15 13:47:08,098 - Epoch: [21][  100/  211]    Overall Loss 0.059528    Objective Loss 0.059528                                        LR 0.100000    Time 0.623061    
2024-01-15 13:47:14,142 - Epoch: [21][  110/  211]    Overall Loss 0.059525    Objective Loss 0.059525                                        LR 0.100000    Time 0.621357    
2024-01-15 13:47:19,962 - Epoch: [21][  120/  211]    Overall Loss 0.059920    Objective Loss 0.059920                                        LR 0.100000    Time 0.618062    
2024-01-15 13:47:25,669 - Epoch: [21][  130/  211]    Overall Loss 0.059167    Objective Loss 0.059167                                        LR 0.100000    Time 0.614407    
2024-01-15 13:47:31,359 - Epoch: [21][  140/  211]    Overall Loss 0.059563    Objective Loss 0.059563                                        LR 0.100000    Time 0.611165    
2024-01-15 13:47:37,026 - Epoch: [21][  150/  211]    Overall Loss 0.059665    Objective Loss 0.059665                                        LR 0.100000    Time 0.608192    
2024-01-15 13:47:43,071 - Epoch: [21][  160/  211]    Overall Loss 0.059513    Objective Loss 0.059513                                        LR 0.100000    Time 0.607955    
2024-01-15 13:47:48,989 - Epoch: [21][  170/  211]    Overall Loss 0.059600    Objective Loss 0.059600                                        LR 0.100000    Time 0.607000    
2024-01-15 13:47:54,701 - Epoch: [21][  180/  211]    Overall Loss 0.060172    Objective Loss 0.060172                                        LR 0.100000    Time 0.605007    
2024-01-15 13:48:00,416 - Epoch: [21][  190/  211]    Overall Loss 0.060007    Objective Loss 0.060007                                        LR 0.100000    Time 0.603237    
2024-01-15 13:48:06,395 - Epoch: [21][  200/  211]    Overall Loss 0.059736    Objective Loss 0.059736                                        LR 0.100000    Time 0.602967    
2024-01-15 13:48:12,332 - Epoch: [21][  210/  211]    Overall Loss 0.059260    Objective Loss 0.059260    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.602519    
2024-01-15 13:48:12,894 - Epoch: [21][  211/  211]    Overall Loss 0.059396    Objective Loss 0.059396    Top1 97.983871    Top5 99.798387    LR 0.100000    Time 0.602325    
2024-01-15 13:48:13,730 - --- validate (epoch=21)-----------
2024-01-15 13:48:13,731 - 6000 samples (256 per mini-batch)
2024-01-15 13:48:20,743 - Epoch: [21][   10/   24]    Loss 0.065098    Top1 98.164062    Top5 100.000000    
2024-01-15 13:48:22,902 - Epoch: [21][   20/   24]    Loss 0.065537    Top1 98.085938    Top5 99.980469    
2024-01-15 13:48:23,662 - Epoch: [21][   24/   24]    Loss 0.068539    Top1 97.950000    Top5 99.966667    
2024-01-15 13:48:24,390 - ==> Top1: 97.950    Top5: 99.967    Loss: 0.069

2024-01-15 13:48:24,391 - ==> Confusion:
[[599   0   1   0   0   0   1   1   1   2]
 [  0 682   2   0   0   0   0   4   0   0]
 [  0   1 577   3   0   0   0   2   1   2]
 [  0   0   3 577   0   0   0   2   1   0]
 [  0   0   4   0 535   1   0   5   2  18]
 [  1   0   1   6   0 499   3   2   5   1]
 [  6   2   0   0   1   4 613   0   5   0]
 [  0   1   2   2   0   0   0 620   0   0]
 [  0   0   1   3   1   2   2   1 573   1]
 [  0   1   0   2   1   2   0   6   1 602]]

2024-01-15 13:48:24,393 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 13:48:24,393 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 13:48:24,397 - 

2024-01-15 13:48:24,397 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 13:48:33,359 - Epoch: [22][   10/  211]    Overall Loss 0.061348    Objective Loss 0.061348                                        LR 0.100000    Time 0.896077    
2024-01-15 13:48:39,134 - Epoch: [22][   20/  211]    Overall Loss 0.060904    Objective Loss 0.060904                                        LR 0.100000    Time 0.736731    
2024-01-15 13:48:44,834 - Epoch: [22][   30/  211]    Overall Loss 0.059421    Objective Loss 0.059421                                        LR 0.100000    Time 0.681154    
2024-01-15 13:48:50,913 - Epoch: [22][   40/  211]    Overall Loss 0.060853    Objective Loss 0.060853                                        LR 0.100000    Time 0.662804    
2024-01-15 13:48:57,644 - Epoch: [22][   50/  211]    Overall Loss 0.060746    Objective Loss 0.060746                                        LR 0.100000    Time 0.664826    
2024-01-15 13:49:03,581 - Epoch: [22][   60/  211]    Overall Loss 0.061082    Objective Loss 0.061082                                        LR 0.100000    Time 0.652950    
2024-01-15 13:49:09,382 - Epoch: [22][   70/  211]    Overall Loss 0.060514    Objective Loss 0.060514                                        LR 0.100000    Time 0.642539    
2024-01-15 13:49:15,077 - Epoch: [22][   80/  211]    Overall Loss 0.060146    Objective Loss 0.060146                                        LR 0.100000    Time 0.633392    
2024-01-15 13:49:20,869 - Epoch: [22][   90/  211]    Overall Loss 0.059340    Objective Loss 0.059340                                        LR 0.100000    Time 0.627364    
2024-01-15 13:49:26,588 - Epoch: [22][  100/  211]    Overall Loss 0.060313    Objective Loss 0.060313                                        LR 0.100000    Time 0.621806    
2024-01-15 13:49:32,261 - Epoch: [22][  110/  211]    Overall Loss 0.060473    Objective Loss 0.060473                                        LR 0.100000    Time 0.616839    
2024-01-15 13:49:38,077 - Epoch: [22][  120/  211]    Overall Loss 0.059984    Objective Loss 0.059984                                        LR 0.100000    Time 0.613895    
2024-01-15 13:49:43,874 - Epoch: [22][  130/  211]    Overall Loss 0.060249    Objective Loss 0.060249                                        LR 0.100000    Time 0.611258    
2024-01-15 13:49:49,597 - Epoch: [22][  140/  211]    Overall Loss 0.060221    Objective Loss 0.060221                                        LR 0.100000    Time 0.608469    
2024-01-15 13:49:55,313 - Epoch: [22][  150/  211]    Overall Loss 0.059638    Objective Loss 0.059638                                        LR 0.100000    Time 0.606007    
2024-01-15 13:50:01,100 - Epoch: [22][  160/  211]    Overall Loss 0.059814    Objective Loss 0.059814                                        LR 0.100000    Time 0.604297    
2024-01-15 13:50:06,805 - Epoch: [22][  170/  211]    Overall Loss 0.059760    Objective Loss 0.059760                                        LR 0.100000    Time 0.602304    
2024-01-15 13:50:12,620 - Epoch: [22][  180/  211]    Overall Loss 0.059936    Objective Loss 0.059936                                        LR 0.100000    Time 0.601143    
2024-01-15 13:50:18,367 - Epoch: [22][  190/  211]    Overall Loss 0.059456    Objective Loss 0.059456                                        LR 0.100000    Time 0.599744    
2024-01-15 13:50:24,218 - Epoch: [22][  200/  211]    Overall Loss 0.060402    Objective Loss 0.060402                                        LR 0.100000    Time 0.599002    
2024-01-15 13:50:29,989 - Epoch: [22][  210/  211]    Overall Loss 0.060230    Objective Loss 0.060230    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.597937    
2024-01-15 13:50:30,566 - Epoch: [22][  211/  211]    Overall Loss 0.060227    Objective Loss 0.060227    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.597831    
2024-01-15 13:50:31,387 - --- validate (epoch=22)-----------
2024-01-15 13:50:31,388 - 6000 samples (256 per mini-batch)
2024-01-15 13:50:38,159 - Epoch: [22][   10/   24]    Loss 0.054595    Top1 98.632812    Top5 100.000000    
2024-01-15 13:50:40,295 - Epoch: [22][   20/   24]    Loss 0.056744    Top1 98.476562    Top5 100.000000    
2024-01-15 13:50:41,048 - Epoch: [22][   24/   24]    Loss 0.054754    Top1 98.500000    Top5 100.000000    
2024-01-15 13:50:41,798 - ==> Top1: 98.500    Top5: 100.000    Loss: 0.055

2024-01-15 13:50:41,799 - ==> Confusion:
[[601   0   1   0   0   0   2   0   0   1]
 [  0 683   0   0   1   1   0   3   0   0]
 [  0   1 576   1   0   0   0   6   1   1]
 [  0   0   2 569   0   5   0   6   1   0]
 [  0   1   1   0 553   0   0   1   0   9]
 [  1   0   1   1   1 507   2   0   3   2]
 [  1   0   0   0   2   1 625   0   2   0]
 [  0   0   0   0   2   1   0 622   0   0]
 [  1   0   0   2   5   3   2   1 568   2]
 [  0   1   0   0   3   1   0   1   3 606]]

2024-01-15 13:50:41,801 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 13:50:41,801 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 13:50:41,805 - 

2024-01-15 13:50:41,805 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 13:50:50,471 - Epoch: [23][   10/  211]    Overall Loss 0.058650    Objective Loss 0.058650                                        LR 0.100000    Time 0.866538    
2024-01-15 13:50:56,219 - Epoch: [23][   20/  211]    Overall Loss 0.060304    Objective Loss 0.060304                                        LR 0.100000    Time 0.720597    
2024-01-15 13:51:02,170 - Epoch: [23][   30/  211]    Overall Loss 0.060816    Objective Loss 0.060816                                        LR 0.100000    Time 0.678718    
2024-01-15 13:51:08,165 - Epoch: [23][   40/  211]    Overall Loss 0.056853    Objective Loss 0.056853                                        LR 0.100000    Time 0.658848    
2024-01-15 13:51:13,964 - Epoch: [23][   50/  211]    Overall Loss 0.056474    Objective Loss 0.056474                                        LR 0.100000    Time 0.643016    
2024-01-15 13:51:19,933 - Epoch: [23][   60/  211]    Overall Loss 0.055006    Objective Loss 0.055006                                        LR 0.100000    Time 0.635311    
2024-01-15 13:51:25,878 - Epoch: [23][   70/  211]    Overall Loss 0.056792    Objective Loss 0.056792                                        LR 0.100000    Time 0.629476    
2024-01-15 13:51:31,707 - Epoch: [23][   80/  211]    Overall Loss 0.056787    Objective Loss 0.056787                                        LR 0.100000    Time 0.623636    
2024-01-15 13:51:37,590 - Epoch: [23][   90/  211]    Overall Loss 0.056619    Objective Loss 0.056619                                        LR 0.100000    Time 0.619701    
2024-01-15 13:51:43,529 - Epoch: [23][  100/  211]    Overall Loss 0.056589    Objective Loss 0.056589                                        LR 0.100000    Time 0.617103    
2024-01-15 13:51:49,392 - Epoch: [23][  110/  211]    Overall Loss 0.056830    Objective Loss 0.056830                                        LR 0.100000    Time 0.614289    
2024-01-15 13:51:55,036 - Epoch: [23][  120/  211]    Overall Loss 0.057258    Objective Loss 0.057258                                        LR 0.100000    Time 0.610122    
2024-01-15 13:52:00,791 - Epoch: [23][  130/  211]    Overall Loss 0.057220    Objective Loss 0.057220                                        LR 0.100000    Time 0.607459    
2024-01-15 13:52:06,637 - Epoch: [23][  140/  211]    Overall Loss 0.056976    Objective Loss 0.056976                                        LR 0.100000    Time 0.605813    
2024-01-15 13:52:12,276 - Epoch: [23][  150/  211]    Overall Loss 0.057053    Objective Loss 0.057053                                        LR 0.100000    Time 0.603012    
2024-01-15 13:52:17,907 - Epoch: [23][  160/  211]    Overall Loss 0.057905    Objective Loss 0.057905                                        LR 0.100000    Time 0.600516    
2024-01-15 13:52:23,532 - Epoch: [23][  170/  211]    Overall Loss 0.058475    Objective Loss 0.058475                                        LR 0.100000    Time 0.598277    
2024-01-15 13:52:29,164 - Epoch: [23][  180/  211]    Overall Loss 0.058441    Objective Loss 0.058441                                        LR 0.100000    Time 0.596323    
2024-01-15 13:52:34,787 - Epoch: [23][  190/  211]    Overall Loss 0.058033    Objective Loss 0.058033                                        LR 0.100000    Time 0.594530    
2024-01-15 13:52:40,411 - Epoch: [23][  200/  211]    Overall Loss 0.058063    Objective Loss 0.058063                                        LR 0.100000    Time 0.592917    
2024-01-15 13:52:46,121 - Epoch: [23][  210/  211]    Overall Loss 0.058018    Objective Loss 0.058018    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.591874    
2024-01-15 13:52:46,687 - Epoch: [23][  211/  211]    Overall Loss 0.057924    Objective Loss 0.057924    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.591745    
2024-01-15 13:52:47,469 - --- validate (epoch=23)-----------
2024-01-15 13:52:47,471 - 6000 samples (256 per mini-batch)
2024-01-15 13:52:53,300 - Epoch: [23][   10/   24]    Loss 0.059118    Top1 98.437500    Top5 100.000000    
2024-01-15 13:52:55,402 - Epoch: [23][   20/   24]    Loss 0.056689    Top1 98.496094    Top5 100.000000    
2024-01-15 13:52:56,138 - Epoch: [23][   24/   24]    Loss 0.060195    Top1 98.400000    Top5 100.000000    
2024-01-15 13:52:56,765 - ==> Top1: 98.400    Top5: 100.000    Loss: 0.060

2024-01-15 13:52:56,766 - ==> Confusion:
[[604   0   0   0   0   0   0   0   0   1]
 [  0 683   3   0   0   0   0   2   0   0]
 [  0   0 578   3   0   0   1   3   1   0]
 [  0   1   4 577   0   1   0   0   0   0]
 [  0   1   1   0 553   0   0   6   0   4]
 [  0   2   0   5   1 505   3   0   1   1]
 [  1   1   0   0   3   3 618   0   5   0]
 [  0   3   3   0   1   0   0 618   0   0]
 [  3   1   2   3   3   2   0   0 569   1]
 [  0   3   0   0   5   0   0   5   3 599]]

2024-01-15 13:52:56,773 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 13:52:56,773 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 13:52:56,777 - 

2024-01-15 13:52:56,777 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 13:53:05,058 - Epoch: [24][   10/  211]    Overall Loss 0.061394    Objective Loss 0.061394                                        LR 0.100000    Time 0.827945    
2024-01-15 13:53:10,757 - Epoch: [24][   20/  211]    Overall Loss 0.056479    Objective Loss 0.056479                                        LR 0.100000    Time 0.698897    
2024-01-15 13:53:16,397 - Epoch: [24][   30/  211]    Overall Loss 0.058233    Objective Loss 0.058233                                        LR 0.100000    Time 0.653891    
2024-01-15 13:53:22,029 - Epoch: [24][   40/  211]    Overall Loss 0.060930    Objective Loss 0.060930                                        LR 0.100000    Time 0.631222    
2024-01-15 13:53:27,670 - Epoch: [24][   50/  211]    Overall Loss 0.058368    Objective Loss 0.058368                                        LR 0.100000    Time 0.617767    
2024-01-15 13:53:33,348 - Epoch: [24][   60/  211]    Overall Loss 0.061162    Objective Loss 0.061162                                        LR 0.100000    Time 0.609430    
2024-01-15 13:53:39,150 - Epoch: [24][   70/  211]    Overall Loss 0.060822    Objective Loss 0.060822                                        LR 0.100000    Time 0.605231    
2024-01-15 13:53:44,889 - Epoch: [24][   80/  211]    Overall Loss 0.060125    Objective Loss 0.060125                                        LR 0.100000    Time 0.601306    
2024-01-15 13:53:50,516 - Epoch: [24][   90/  211]    Overall Loss 0.058922    Objective Loss 0.058922                                        LR 0.100000    Time 0.597017    
2024-01-15 13:53:56,144 - Epoch: [24][  100/  211]    Overall Loss 0.058540    Objective Loss 0.058540                                        LR 0.100000    Time 0.593585    
2024-01-15 13:54:01,991 - Epoch: [24][  110/  211]    Overall Loss 0.058544    Objective Loss 0.058544                                        LR 0.100000    Time 0.592768    
2024-01-15 13:54:07,698 - Epoch: [24][  120/  211]    Overall Loss 0.058187    Objective Loss 0.058187                                        LR 0.100000    Time 0.590921    
2024-01-15 13:54:13,342 - Epoch: [24][  130/  211]    Overall Loss 0.058498    Objective Loss 0.058498                                        LR 0.100000    Time 0.588872    
2024-01-15 13:54:19,012 - Epoch: [24][  140/  211]    Overall Loss 0.057826    Objective Loss 0.057826                                        LR 0.100000    Time 0.587309    
2024-01-15 13:54:24,638 - Epoch: [24][  150/  211]    Overall Loss 0.057649    Objective Loss 0.057649                                        LR 0.100000    Time 0.585655    
2024-01-15 13:54:30,275 - Epoch: [24][  160/  211]    Overall Loss 0.057668    Objective Loss 0.057668                                        LR 0.100000    Time 0.584284    
2024-01-15 13:54:35,907 - Epoch: [24][  170/  211]    Overall Loss 0.057516    Objective Loss 0.057516                                        LR 0.100000    Time 0.583036    
2024-01-15 13:54:41,555 - Epoch: [24][  180/  211]    Overall Loss 0.058050    Objective Loss 0.058050                                        LR 0.100000    Time 0.582015    
2024-01-15 13:54:47,270 - Epoch: [24][  190/  211]    Overall Loss 0.058524    Objective Loss 0.058524                                        LR 0.100000    Time 0.581461    
2024-01-15 13:54:52,923 - Epoch: [24][  200/  211]    Overall Loss 0.058774    Objective Loss 0.058774                                        LR 0.100000    Time 0.580645    
2024-01-15 13:54:58,815 - Epoch: [24][  210/  211]    Overall Loss 0.058647    Objective Loss 0.058647    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.581034    
2024-01-15 13:54:59,483 - Epoch: [24][  211/  211]    Overall Loss 0.058762    Objective Loss 0.058762    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.581431    
2024-01-15 13:55:00,227 - --- validate (epoch=24)-----------
2024-01-15 13:55:00,227 - 6000 samples (256 per mini-batch)
2024-01-15 13:55:05,776 - Epoch: [24][   10/   24]    Loss 0.071076    Top1 97.968750    Top5 100.000000    
2024-01-15 13:55:07,954 - Epoch: [24][   20/   24]    Loss 0.068330    Top1 97.832031    Top5 100.000000    
2024-01-15 13:55:08,780 - Epoch: [24][   24/   24]    Loss 0.067912    Top1 97.883333    Top5 100.000000    
2024-01-15 13:55:09,423 - ==> Top1: 97.883    Top5: 100.000    Loss: 0.068

2024-01-15 13:55:09,424 - ==> Confusion:
[[593   0   2   0   2   0   3   1   0   4]
 [  0 684   0   0   1   0   0   3   0   0]
 [  0   3 545   9   2   0   1  20   4   2]
 [  0   0   0 578   0   2   0   1   1   1]
 [  0   1   0   0 558   0   0   0   0   6]
 [  0   0   0   3   1 510   2   0   2   0]
 [  0   3   0   0   6   2 617   0   3   0]
 [  0   2   0   0   2   1   0 619   0   1]
 [  0   2   2   2   4   1   2   1 568   2]
 [  0   1   0   0   9   1   0   2   1 601]]

2024-01-15 13:55:09,426 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 13:55:09,426 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 13:55:09,430 - 

2024-01-15 13:55:09,430 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 13:55:19,181 - Epoch: [25][   10/  211]    Overall Loss 0.063336    Objective Loss 0.063336                                        LR 0.100000    Time 0.974971    
2024-01-15 13:55:25,094 - Epoch: [25][   20/  211]    Overall Loss 0.061242    Objective Loss 0.061242                                        LR 0.100000    Time 0.783044    
2024-01-15 13:55:31,197 - Epoch: [25][   30/  211]    Overall Loss 0.060721    Objective Loss 0.060721                                        LR 0.100000    Time 0.725391    
2024-01-15 13:55:37,253 - Epoch: [25][   40/  211]    Overall Loss 0.058683    Objective Loss 0.058683                                        LR 0.100000    Time 0.695398    
2024-01-15 13:55:43,597 - Epoch: [25][   50/  211]    Overall Loss 0.058654    Objective Loss 0.058654                                        LR 0.100000    Time 0.683155    
2024-01-15 13:55:49,613 - Epoch: [25][   60/  211]    Overall Loss 0.056177    Objective Loss 0.056177                                        LR 0.100000    Time 0.669482    
2024-01-15 13:55:55,895 - Epoch: [25][   70/  211]    Overall Loss 0.057118    Objective Loss 0.057118                                        LR 0.100000    Time 0.663526    
2024-01-15 13:56:02,167 - Epoch: [25][   80/  211]    Overall Loss 0.057177    Objective Loss 0.057177                                        LR 0.100000    Time 0.658964    
2024-01-15 13:56:07,884 - Epoch: [25][   90/  211]    Overall Loss 0.057098    Objective Loss 0.057098                                        LR 0.100000    Time 0.649251    
2024-01-15 13:56:14,456 - Epoch: [25][  100/  211]    Overall Loss 0.056834    Objective Loss 0.056834                                        LR 0.100000    Time 0.650028    
2024-01-15 13:56:20,304 - Epoch: [25][  110/  211]    Overall Loss 0.056548    Objective Loss 0.056548                                        LR 0.100000    Time 0.644089    
2024-01-15 13:56:26,088 - Epoch: [25][  120/  211]    Overall Loss 0.056908    Objective Loss 0.056908                                        LR 0.100000    Time 0.638606    
2024-01-15 13:56:31,950 - Epoch: [25][  130/  211]    Overall Loss 0.057542    Objective Loss 0.057542                                        LR 0.100000    Time 0.634557    
2024-01-15 13:56:37,708 - Epoch: [25][  140/  211]    Overall Loss 0.056970    Objective Loss 0.056970                                        LR 0.100000    Time 0.630360    
2024-01-15 13:56:44,127 - Epoch: [25][  150/  211]    Overall Loss 0.057531    Objective Loss 0.057531                                        LR 0.100000    Time 0.631123    
2024-01-15 13:56:49,954 - Epoch: [25][  160/  211]    Overall Loss 0.057461    Objective Loss 0.057461                                        LR 0.100000    Time 0.628085    
2024-01-15 13:56:55,749 - Epoch: [25][  170/  211]    Overall Loss 0.057492    Objective Loss 0.057492                                        LR 0.100000    Time 0.625219    
2024-01-15 13:57:02,285 - Epoch: [25][  180/  211]    Overall Loss 0.057429    Objective Loss 0.057429                                        LR 0.100000    Time 0.626792    
2024-01-15 13:57:08,247 - Epoch: [25][  190/  211]    Overall Loss 0.057496    Objective Loss 0.057496                                        LR 0.100000    Time 0.625170    
2024-01-15 13:57:14,019 - Epoch: [25][  200/  211]    Overall Loss 0.057012    Objective Loss 0.057012                                        LR 0.100000    Time 0.622764    
2024-01-15 13:57:20,376 - Epoch: [25][  210/  211]    Overall Loss 0.056619    Objective Loss 0.056619    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.623375    
2024-01-15 13:57:21,010 - Epoch: [25][  211/  211]    Overall Loss 0.056497    Objective Loss 0.056497    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.623422    
2024-01-15 13:57:21,865 - --- validate (epoch=25)-----------
2024-01-15 13:57:21,867 - 6000 samples (256 per mini-batch)
2024-01-15 13:57:30,140 - Epoch: [25][   10/   24]    Loss 0.057683    Top1 98.320312    Top5 100.000000    
2024-01-15 13:57:32,771 - Epoch: [25][   20/   24]    Loss 0.056210    Top1 98.339844    Top5 100.000000    
2024-01-15 13:57:33,601 - Epoch: [25][   24/   24]    Loss 0.055987    Top1 98.333333    Top5 100.000000    
2024-01-15 13:57:34,498 - ==> Top1: 98.333    Top5: 100.000    Loss: 0.056

2024-01-15 13:57:34,500 - ==> Confusion:
[[601   0   1   0   0   0   1   1   0   1]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   2 578   0   0   0   2   3   1   0]
 [  1   0   3 571   0   2   0   6   0   0]
 [  0   1   0   0 556   0   1   1   1   5]
 [  0   0   0   1   0 510   5   1   1   0]
 [  4   2   0   0   0   3 621   0   0   1]
 [  0   3   3   0   1   0   0 618   0   0]
 [  4   0   1   3   3   2   5   0 564   2]
 [  1   3   0   0   5   5   0   4   2 595]]

2024-01-15 13:57:34,502 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 13:57:34,503 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 13:57:34,509 - 

2024-01-15 13:57:34,509 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 13:57:45,240 - Epoch: [26][   10/  211]    Overall Loss 0.035792    Objective Loss 0.035792                                        LR 0.100000    Time 1.072986    
2024-01-15 13:57:51,803 - Epoch: [26][   20/  211]    Overall Loss 0.041373    Objective Loss 0.041373                                        LR 0.100000    Time 0.864536    
2024-01-15 13:57:58,875 - Epoch: [26][   30/  211]    Overall Loss 0.048246    Objective Loss 0.048246                                        LR 0.100000    Time 0.812061    
2024-01-15 13:58:05,300 - Epoch: [26][   40/  211]    Overall Loss 0.049831    Objective Loss 0.049831                                        LR 0.100000    Time 0.769626    
2024-01-15 13:58:11,098 - Epoch: [26][   50/  211]    Overall Loss 0.048875    Objective Loss 0.048875                                        LR 0.100000    Time 0.731639    
2024-01-15 13:58:17,214 - Epoch: [26][   60/  211]    Overall Loss 0.048788    Objective Loss 0.048788                                        LR 0.100000    Time 0.711605    
2024-01-15 13:58:23,600 - Epoch: [26][   70/  211]    Overall Loss 0.050538    Objective Loss 0.050538                                        LR 0.100000    Time 0.701120    
2024-01-15 13:58:29,953 - Epoch: [26][   80/  211]    Overall Loss 0.053204    Objective Loss 0.053204                                        LR 0.100000    Time 0.692870    
2024-01-15 13:58:36,136 - Epoch: [26][   90/  211]    Overall Loss 0.053209    Objective Loss 0.053209                                        LR 0.100000    Time 0.684570    
2024-01-15 13:58:42,194 - Epoch: [26][  100/  211]    Overall Loss 0.052922    Objective Loss 0.052922                                        LR 0.100000    Time 0.676686    
2024-01-15 13:58:48,205 - Epoch: [26][  110/  211]    Overall Loss 0.053383    Objective Loss 0.053383                                        LR 0.100000    Time 0.669794    
2024-01-15 13:58:54,108 - Epoch: [26][  120/  211]    Overall Loss 0.054430    Objective Loss 0.054430                                        LR 0.100000    Time 0.663157    
2024-01-15 13:59:00,322 - Epoch: [26][  130/  211]    Overall Loss 0.054871    Objective Loss 0.054871                                        LR 0.100000    Time 0.659943    
2024-01-15 13:59:06,359 - Epoch: [26][  140/  211]    Overall Loss 0.054904    Objective Loss 0.054904                                        LR 0.100000    Time 0.655914    
2024-01-15 13:59:12,786 - Epoch: [26][  150/  211]    Overall Loss 0.054759    Objective Loss 0.054759                                        LR 0.100000    Time 0.655026    
2024-01-15 13:59:19,090 - Epoch: [26][  160/  211]    Overall Loss 0.054459    Objective Loss 0.054459                                        LR 0.100000    Time 0.653477    
2024-01-15 13:59:24,937 - Epoch: [26][  170/  211]    Overall Loss 0.055144    Objective Loss 0.055144                                        LR 0.100000    Time 0.649426    
2024-01-15 13:59:31,078 - Epoch: [26][  180/  211]    Overall Loss 0.055019    Objective Loss 0.055019                                        LR 0.100000    Time 0.647452    
2024-01-15 13:59:37,492 - Epoch: [26][  190/  211]    Overall Loss 0.055068    Objective Loss 0.055068                                        LR 0.100000    Time 0.647125    
2024-01-15 13:59:43,928 - Epoch: [26][  200/  211]    Overall Loss 0.055058    Objective Loss 0.055058                                        LR 0.100000    Time 0.646945    
2024-01-15 13:59:50,090 - Epoch: [26][  210/  211]    Overall Loss 0.055193    Objective Loss 0.055193    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.645469    
2024-01-15 13:59:50,763 - Epoch: [26][  211/  211]    Overall Loss 0.055155    Objective Loss 0.055155    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.645595    
2024-01-15 13:59:51,518 - --- validate (epoch=26)-----------
2024-01-15 13:59:51,519 - 6000 samples (256 per mini-batch)
2024-01-15 13:59:58,492 - Epoch: [26][   10/   24]    Loss 0.056536    Top1 98.281250    Top5 100.000000    
2024-01-15 14:00:00,667 - Epoch: [26][   20/   24]    Loss 0.054337    Top1 98.437500    Top5 100.000000    
2024-01-15 14:00:01,466 - Epoch: [26][   24/   24]    Loss 0.052082    Top1 98.483333    Top5 99.983333    
2024-01-15 14:00:02,238 - ==> Top1: 98.483    Top5: 99.983    Loss: 0.052

2024-01-15 14:00:02,239 - ==> Confusion:
[[596   0   1   0   0   1   6   0   0   1]
 [  0 686   2   0   0   0   0   0   0   0]
 [  0   1 581   1   0   0   0   2   0   1]
 [  0   0   2 576   1   0   0   3   1   0]
 [  0   1   1   0 553   0   0   1   0   9]
 [  1   0   1   2   0 507   6   1   0   0]
 [  1   0   1   0   2   1 626   0   0   0]
 [  0   2   3   0   2   0   0 616   0   2]
 [  3   0   1   2   1   1   6   0 567   3]
 [  1   1   0   2   3   2   0   3   2 601]]

2024-01-15 14:00:02,241 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 14:00:02,241 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:00:02,245 - 

2024-01-15 14:00:02,246 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:00:13,090 - Epoch: [27][   10/  211]    Overall Loss 0.047935    Objective Loss 0.047935                                        LR 0.100000    Time 1.083913    
2024-01-15 14:00:19,715 - Epoch: [27][   20/  211]    Overall Loss 0.050390    Objective Loss 0.050390                                        LR 0.100000    Time 0.872861    
2024-01-15 14:00:25,626 - Epoch: [27][   30/  211]    Overall Loss 0.051725    Objective Loss 0.051725                                        LR 0.100000    Time 0.778889    
2024-01-15 14:00:31,395 - Epoch: [27][   40/  211]    Overall Loss 0.055743    Objective Loss 0.055743                                        LR 0.100000    Time 0.728385    
2024-01-15 14:00:37,078 - Epoch: [27][   50/  211]    Overall Loss 0.055566    Objective Loss 0.055566                                        LR 0.100000    Time 0.696349    
2024-01-15 14:00:42,769 - Epoch: [27][   60/  211]    Overall Loss 0.053934    Objective Loss 0.053934                                        LR 0.100000    Time 0.675134    
2024-01-15 14:00:48,480 - Epoch: [27][   70/  211]    Overall Loss 0.054879    Objective Loss 0.054879                                        LR 0.100000    Time 0.660267    
2024-01-15 14:00:54,344 - Epoch: [27][   80/  211]    Overall Loss 0.057747    Objective Loss 0.057747                                        LR 0.100000    Time 0.651016    
2024-01-15 14:01:01,176 - Epoch: [27][   90/  211]    Overall Loss 0.057134    Objective Loss 0.057134                                        LR 0.100000    Time 0.654573    
2024-01-15 14:01:06,931 - Epoch: [27][  100/  211]    Overall Loss 0.056245    Objective Loss 0.056245                                        LR 0.100000    Time 0.646654    
2024-01-15 14:01:12,614 - Epoch: [27][  110/  211]    Overall Loss 0.057608    Objective Loss 0.057608                                        LR 0.100000    Time 0.639515    
2024-01-15 14:01:18,331 - Epoch: [27][  120/  211]    Overall Loss 0.058190    Objective Loss 0.058190                                        LR 0.100000    Time 0.633859    
2024-01-15 14:01:24,018 - Epoch: [27][  130/  211]    Overall Loss 0.057709    Objective Loss 0.057709                                        LR 0.100000    Time 0.628839    
2024-01-15 14:01:29,806 - Epoch: [27][  140/  211]    Overall Loss 0.057596    Objective Loss 0.057596                                        LR 0.100000    Time 0.625253    
2024-01-15 14:01:35,767 - Epoch: [27][  150/  211]    Overall Loss 0.057431    Objective Loss 0.057431                                        LR 0.100000    Time 0.623302    
2024-01-15 14:01:41,587 - Epoch: [27][  160/  211]    Overall Loss 0.057376    Objective Loss 0.057376                                        LR 0.100000    Time 0.620715    
2024-01-15 14:01:47,490 - Epoch: [27][  170/  211]    Overall Loss 0.056372    Objective Loss 0.056372                                        LR 0.100000    Time 0.618920    
2024-01-15 14:01:53,561 - Epoch: [27][  180/  211]    Overall Loss 0.056872    Objective Loss 0.056872                                        LR 0.100000    Time 0.618257    
2024-01-15 14:01:59,526 - Epoch: [27][  190/  211]    Overall Loss 0.056500    Objective Loss 0.056500                                        LR 0.100000    Time 0.617105    
2024-01-15 14:02:05,350 - Epoch: [27][  200/  211]    Overall Loss 0.056526    Objective Loss 0.056526                                        LR 0.100000    Time 0.615367    
2024-01-15 14:02:11,037 - Epoch: [27][  210/  211]    Overall Loss 0.056443    Objective Loss 0.056443    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.613138    
2024-01-15 14:02:11,650 - Epoch: [27][  211/  211]    Overall Loss 0.056454    Objective Loss 0.056454    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.613133    
2024-01-15 14:02:12,462 - --- validate (epoch=27)-----------
2024-01-15 14:02:12,463 - 6000 samples (256 per mini-batch)
2024-01-15 14:02:19,414 - Epoch: [27][   10/   24]    Loss 0.050830    Top1 98.515625    Top5 100.000000    
2024-01-15 14:02:21,549 - Epoch: [27][   20/   24]    Loss 0.052622    Top1 98.378906    Top5 100.000000    
2024-01-15 14:02:22,366 - Epoch: [27][   24/   24]    Loss 0.053581    Top1 98.316667    Top5 100.000000    
2024-01-15 14:02:23,160 - ==> Top1: 98.317    Top5: 100.000    Loss: 0.054

2024-01-15 14:02:23,161 - ==> Confusion:
[[600   0   1   0   0   0   4   0   0   0]
 [  0 688   0   0   0   0   0   0   0   0]
 [  1   2 577   1   1   0   0   2   2   0]
 [  0   2   5 571   0   2   0   1   2   0]
 [  0   1   1   0 556   0   0   1   0   6]
 [  1   0   0   1   0 512   2   0   2   0]
 [  1   2   0   0   2   0 626   0   0   0]
 [  0   5   4   0   1   0   0 615   0   0]
 [  0   1   0   2   2   2   9   0 566   2]
 [  2   3   0   1  12   4   0   2   3 588]]

2024-01-15 14:02:23,163 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 14:02:23,163 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:02:23,169 - 

2024-01-15 14:02:23,169 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:02:32,977 - Epoch: [28][   10/  211]    Overall Loss 0.045186    Objective Loss 0.045186                                        LR 0.100000    Time 0.980635    
2024-01-15 14:02:38,803 - Epoch: [28][   20/  211]    Overall Loss 0.049053    Objective Loss 0.049053                                        LR 0.100000    Time 0.781578    
2024-01-15 14:02:44,781 - Epoch: [28][   30/  211]    Overall Loss 0.050943    Objective Loss 0.050943                                        LR 0.100000    Time 0.720278    
2024-01-15 14:02:50,592 - Epoch: [28][   40/  211]    Overall Loss 0.052381    Objective Loss 0.052381                                        LR 0.100000    Time 0.685447    
2024-01-15 14:02:56,725 - Epoch: [28][   50/  211]    Overall Loss 0.053105    Objective Loss 0.053105                                        LR 0.100000    Time 0.670977    
2024-01-15 14:03:02,881 - Epoch: [28][   60/  211]    Overall Loss 0.054035    Objective Loss 0.054035                                        LR 0.100000    Time 0.661734    
2024-01-15 14:03:08,792 - Epoch: [28][   70/  211]    Overall Loss 0.053563    Objective Loss 0.053563                                        LR 0.100000    Time 0.651628    
2024-01-15 14:03:14,616 - Epoch: [28][   80/  211]    Overall Loss 0.053336    Objective Loss 0.053336                                        LR 0.100000    Time 0.642955    
2024-01-15 14:03:20,568 - Epoch: [28][   90/  211]    Overall Loss 0.054618    Objective Loss 0.054618                                        LR 0.100000    Time 0.637641    
2024-01-15 14:03:26,316 - Epoch: [28][  100/  211]    Overall Loss 0.055135    Objective Loss 0.055135                                        LR 0.100000    Time 0.631347    
2024-01-15 14:03:32,033 - Epoch: [28][  110/  211]    Overall Loss 0.054363    Objective Loss 0.054363                                        LR 0.100000    Time 0.625912    
2024-01-15 14:03:38,034 - Epoch: [28][  120/  211]    Overall Loss 0.054853    Objective Loss 0.054853                                        LR 0.100000    Time 0.623749    
2024-01-15 14:03:43,760 - Epoch: [28][  130/  211]    Overall Loss 0.054184    Objective Loss 0.054184                                        LR 0.100000    Time 0.619800    
2024-01-15 14:03:49,587 - Epoch: [28][  140/  211]    Overall Loss 0.054407    Objective Loss 0.054407                                        LR 0.100000    Time 0.617138    
2024-01-15 14:03:55,428 - Epoch: [28][  150/  211]    Overall Loss 0.054390    Objective Loss 0.054390                                        LR 0.100000    Time 0.614927    
2024-01-15 14:04:01,684 - Epoch: [28][  160/  211]    Overall Loss 0.054419    Objective Loss 0.054419                                        LR 0.100000    Time 0.615581    
2024-01-15 14:04:07,579 - Epoch: [28][  170/  211]    Overall Loss 0.055127    Objective Loss 0.055127                                        LR 0.100000    Time 0.614043    
2024-01-15 14:04:13,659 - Epoch: [28][  180/  211]    Overall Loss 0.055434    Objective Loss 0.055434                                        LR 0.100000    Time 0.613700    
2024-01-15 14:04:19,542 - Epoch: [28][  190/  211]    Overall Loss 0.054785    Objective Loss 0.054785                                        LR 0.100000    Time 0.612359    
2024-01-15 14:04:25,600 - Epoch: [28][  200/  211]    Overall Loss 0.055180    Objective Loss 0.055180                                        LR 0.100000    Time 0.612021    
2024-01-15 14:04:31,481 - Epoch: [28][  210/  211]    Overall Loss 0.054909    Objective Loss 0.054909    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.610880    
2024-01-15 14:04:32,216 - Epoch: [28][  211/  211]    Overall Loss 0.055006    Objective Loss 0.055006    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.611460    
2024-01-15 14:04:33,345 - --- validate (epoch=28)-----------
2024-01-15 14:04:33,347 - 6000 samples (256 per mini-batch)
2024-01-15 14:04:41,051 - Epoch: [28][   10/   24]    Loss 0.045722    Top1 98.789062    Top5 100.000000    
2024-01-15 14:04:43,336 - Epoch: [28][   20/   24]    Loss 0.054895    Top1 98.476562    Top5 100.000000    
2024-01-15 14:04:44,117 - Epoch: [28][   24/   24]    Loss 0.053561    Top1 98.500000    Top5 100.000000    
2024-01-15 14:04:44,850 - ==> Top1: 98.500    Top5: 100.000    Loss: 0.054

2024-01-15 14:04:44,851 - ==> Confusion:
[[600   0   1   0   0   0   3   0   1   0]
 [  0 683   1   0   0   1   0   3   0   0]
 [  0   0 582   0   0   0   0   0   4   0]
 [  0   0   4 574   0   1   0   2   2   0]
 [  0   2   1   0 537   0   2   3   2  18]
 [  1   0   2   1   0 507   3   0   4   0]
 [  1   1   0   0   1   1 625   0   2   0]
 [  0   4   3   0   1   0   0 617   0   0]
 [  0   0   0   2   0   2   3   0 575   2]
 [  1   1   0   0   0   0   0   1   2 610]]

2024-01-15 14:04:44,853 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 14:04:44,853 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:04:44,857 - 

2024-01-15 14:04:44,858 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:04:57,863 - Epoch: [29][   10/  211]    Overall Loss 0.049263    Objective Loss 0.049263                                        LR 0.100000    Time 1.299933    
2024-01-15 14:05:04,728 - Epoch: [29][   20/  211]    Overall Loss 0.045796    Objective Loss 0.045796                                        LR 0.100000    Time 0.993063    
2024-01-15 14:05:10,653 - Epoch: [29][   30/  211]    Overall Loss 0.045922    Objective Loss 0.045922                                        LR 0.100000    Time 0.859496    
2024-01-15 14:05:16,513 - Epoch: [29][   40/  211]    Overall Loss 0.045966    Objective Loss 0.045966                                        LR 0.100000    Time 0.791084    
2024-01-15 14:05:22,215 - Epoch: [29][   50/  211]    Overall Loss 0.047731    Objective Loss 0.047731                                        LR 0.100000    Time 0.746872    
2024-01-15 14:05:27,888 - Epoch: [29][   60/  211]    Overall Loss 0.047653    Objective Loss 0.047653                                        LR 0.100000    Time 0.716947    
2024-01-15 14:05:33,734 - Epoch: [29][   70/  211]    Overall Loss 0.048336    Objective Loss 0.048336                                        LR 0.100000    Time 0.698024    
2024-01-15 14:05:39,657 - Epoch: [29][   80/  211]    Overall Loss 0.049912    Objective Loss 0.049912                                        LR 0.100000    Time 0.684780    
2024-01-15 14:05:45,505 - Epoch: [29][   90/  211]    Overall Loss 0.051557    Objective Loss 0.051557                                        LR 0.100000    Time 0.673652    
2024-01-15 14:05:51,289 - Epoch: [29][  100/  211]    Overall Loss 0.052857    Objective Loss 0.052857                                        LR 0.100000    Time 0.664121    
2024-01-15 14:05:57,278 - Epoch: [29][  110/  211]    Overall Loss 0.054208    Objective Loss 0.054208                                        LR 0.100000    Time 0.658174    
2024-01-15 14:06:03,576 - Epoch: [29][  120/  211]    Overall Loss 0.054451    Objective Loss 0.054451                                        LR 0.100000    Time 0.655796    
2024-01-15 14:06:09,772 - Epoch: [29][  130/  211]    Overall Loss 0.054011    Objective Loss 0.054011                                        LR 0.100000    Time 0.653003    
2024-01-15 14:06:16,004 - Epoch: [29][  140/  211]    Overall Loss 0.053557    Objective Loss 0.053557                                        LR 0.100000    Time 0.650869    
2024-01-15 14:06:21,941 - Epoch: [29][  150/  211]    Overall Loss 0.054080    Objective Loss 0.054080                                        LR 0.100000    Time 0.647044    
2024-01-15 14:06:28,063 - Epoch: [29][  160/  211]    Overall Loss 0.053737    Objective Loss 0.053737                                        LR 0.100000    Time 0.644862    
2024-01-15 14:06:34,601 - Epoch: [29][  170/  211]    Overall Loss 0.054364    Objective Loss 0.054364                                        LR 0.100000    Time 0.645378    
2024-01-15 14:06:40,350 - Epoch: [29][  180/  211]    Overall Loss 0.055193    Objective Loss 0.055193                                        LR 0.100000    Time 0.641458    
2024-01-15 14:06:46,204 - Epoch: [29][  190/  211]    Overall Loss 0.055157    Objective Loss 0.055157                                        LR 0.100000    Time 0.638505    
2024-01-15 14:06:52,061 - Epoch: [29][  200/  211]    Overall Loss 0.055309    Objective Loss 0.055309                                        LR 0.100000    Time 0.635856    
2024-01-15 14:06:57,956 - Epoch: [29][  210/  211]    Overall Loss 0.055302    Objective Loss 0.055302    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.633643    
2024-01-15 14:06:58,531 - Epoch: [29][  211/  211]    Overall Loss 0.055347    Objective Loss 0.055347    Top1 97.983871    Top5 99.798387    LR 0.100000    Time 0.633364    
2024-01-15 14:06:59,597 - --- validate (epoch=29)-----------
2024-01-15 14:06:59,602 - 6000 samples (256 per mini-batch)
2024-01-15 14:07:06,433 - Epoch: [29][   10/   24]    Loss 0.055499    Top1 98.515625    Top5 99.960938    
2024-01-15 14:07:08,549 - Epoch: [29][   20/   24]    Loss 0.058254    Top1 98.359375    Top5 99.941406    
2024-01-15 14:07:09,438 - Epoch: [29][   24/   24]    Loss 0.057456    Top1 98.300000    Top5 99.950000    
2024-01-15 14:07:10,193 - ==> Top1: 98.300    Top5: 99.950    Loss: 0.057

2024-01-15 14:07:10,194 - ==> Confusion:
[[604   0   0   0   0   0   0   0   0   1]
 [  0 684   1   0   0   1   1   1   0   0]
 [  1   1 571   2   1   0   1   4   4   1]
 [  1   0   3 575   0   0   0   2   2   0]
 [  0   1   0   0 542   1   0   2   1  18]
 [  3   0   0   3   0 506   4   0   0   2]
 [  5   1   0   0   1   0 619   0   5   0]
 [  1   5   2   0   1   0   0 616   0   0]
 [  2   0   0   0   1   0   4   0 575   2]
 [  0   2   0   0   1   1   0   2   3 606]]

2024-01-15 14:07:10,196 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 14:07:10,196 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:07:10,200 - 

2024-01-15 14:07:10,201 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:07:19,236 - Epoch: [30][   10/  211]    Overall Loss 0.043171    Objective Loss 0.043171                                        LR 0.100000    Time 0.903412    
2024-01-15 14:07:25,033 - Epoch: [30][   20/  211]    Overall Loss 0.047021    Objective Loss 0.047021                                        LR 0.100000    Time 0.741510    
2024-01-15 14:07:30,983 - Epoch: [30][   30/  211]    Overall Loss 0.049002    Objective Loss 0.049002                                        LR 0.100000    Time 0.692636    
2024-01-15 14:07:36,735 - Epoch: [30][   40/  211]    Overall Loss 0.050996    Objective Loss 0.050996                                        LR 0.100000    Time 0.663259    
2024-01-15 14:07:42,515 - Epoch: [30][   50/  211]    Overall Loss 0.050755    Objective Loss 0.050755                                        LR 0.100000    Time 0.646177    
2024-01-15 14:07:48,677 - Epoch: [30][   60/  211]    Overall Loss 0.049438    Objective Loss 0.049438                                        LR 0.100000    Time 0.641165    
2024-01-15 14:07:54,400 - Epoch: [30][   70/  211]    Overall Loss 0.051267    Objective Loss 0.051267                                        LR 0.100000    Time 0.631309    
2024-01-15 14:08:00,983 - Epoch: [30][   80/  211]    Overall Loss 0.050275    Objective Loss 0.050275                                        LR 0.100000    Time 0.634671    
2024-01-15 14:08:06,714 - Epoch: [30][   90/  211]    Overall Loss 0.050301    Objective Loss 0.050301                                        LR 0.100000    Time 0.627814    
2024-01-15 14:08:12,453 - Epoch: [30][  100/  211]    Overall Loss 0.050449    Objective Loss 0.050449                                        LR 0.100000    Time 0.622421    
2024-01-15 14:08:18,198 - Epoch: [30][  110/  211]    Overall Loss 0.050808    Objective Loss 0.050808                                        LR 0.100000    Time 0.618056    
2024-01-15 14:08:23,896 - Epoch: [30][  120/  211]    Overall Loss 0.050619    Objective Loss 0.050619                                        LR 0.100000    Time 0.614030    
2024-01-15 14:08:29,629 - Epoch: [30][  130/  211]    Overall Loss 0.051250    Objective Loss 0.051250                                        LR 0.100000    Time 0.610892    
2024-01-15 14:08:35,288 - Epoch: [30][  140/  211]    Overall Loss 0.051842    Objective Loss 0.051842                                        LR 0.100000    Time 0.607670    
2024-01-15 14:08:40,920 - Epoch: [30][  150/  211]    Overall Loss 0.051844    Objective Loss 0.051844                                        LR 0.100000    Time 0.604698    
2024-01-15 14:08:46,570 - Epoch: [30][  160/  211]    Overall Loss 0.051977    Objective Loss 0.051977                                        LR 0.100000    Time 0.602216    
2024-01-15 14:08:52,202 - Epoch: [30][  170/  211]    Overall Loss 0.052219    Objective Loss 0.052219                                        LR 0.100000    Time 0.599914    
2024-01-15 14:08:58,155 - Epoch: [30][  180/  211]    Overall Loss 0.051939    Objective Loss 0.051939                                        LR 0.100000    Time 0.599654    
2024-01-15 14:09:04,074 - Epoch: [30][  190/  211]    Overall Loss 0.051585    Objective Loss 0.051585                                        LR 0.100000    Time 0.599241    
2024-01-15 14:09:09,858 - Epoch: [30][  200/  211]    Overall Loss 0.051559    Objective Loss 0.051559                                        LR 0.100000    Time 0.598193    
2024-01-15 14:09:15,548 - Epoch: [30][  210/  211]    Overall Loss 0.052170    Objective Loss 0.052170    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.596799    
2024-01-15 14:09:16,126 - Epoch: [30][  211/  211]    Overall Loss 0.052106    Objective Loss 0.052106    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.596707    
2024-01-15 14:09:16,969 - --- validate (epoch=30)-----------
2024-01-15 14:09:16,970 - 6000 samples (256 per mini-batch)
2024-01-15 14:09:23,925 - Epoch: [30][   10/   24]    Loss 0.056030    Top1 98.554688    Top5 100.000000    
2024-01-15 14:09:26,064 - Epoch: [30][   20/   24]    Loss 0.057889    Top1 98.320312    Top5 99.980469    
2024-01-15 14:09:26,819 - Epoch: [30][   24/   24]    Loss 0.056302    Top1 98.433333    Top5 99.950000    
2024-01-15 14:09:27,580 - ==> Top1: 98.433    Top5: 99.950    Loss: 0.056

2024-01-15 14:09:27,581 - ==> Confusion:
[[598   0   1   0   0   0   4   0   2   0]
 [  0 678   1   0   3   1   3   2   0   0]
 [  1   0 575   1   2   0   0   3   3   1]
 [  0   0   1 577   0   2   0   0   3   0]
 [  0   0   2   0 556   0   0   1   1   5]
 [  0   1   0   1   0 505   7   0   4   0]
 [  0   0   0   0   3   0 622   0   6   0]
 [  0   1   1   2   5   0   0 615   0   1]
 [  0   0   0   1   1   0   1   0 581   0]
 [  0   0   0   0   9   1   2   1   3 599]]

2024-01-15 14:09:27,583 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 14:09:27,583 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:09:27,587 - 

2024-01-15 14:09:27,588 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:09:36,016 - Epoch: [31][   10/  211]    Overall Loss 0.055366    Objective Loss 0.055366                                        LR 0.100000    Time 0.842757    
2024-01-15 14:09:41,786 - Epoch: [31][   20/  211]    Overall Loss 0.050724    Objective Loss 0.050724                                        LR 0.100000    Time 0.709808    
2024-01-15 14:09:47,721 - Epoch: [31][   30/  211]    Overall Loss 0.050334    Objective Loss 0.050334                                        LR 0.100000    Time 0.671004    
2024-01-15 14:09:53,452 - Epoch: [31][   40/  211]    Overall Loss 0.051711    Objective Loss 0.051711                                        LR 0.100000    Time 0.646504    
2024-01-15 14:09:59,496 - Epoch: [31][   50/  211]    Overall Loss 0.050780    Objective Loss 0.050780                                        LR 0.100000    Time 0.638049    
2024-01-15 14:10:05,802 - Epoch: [31][   60/  211]    Overall Loss 0.050578    Objective Loss 0.050578                                        LR 0.100000    Time 0.636770    
2024-01-15 14:10:11,862 - Epoch: [31][   70/  211]    Overall Loss 0.052194    Objective Loss 0.052194                                        LR 0.100000    Time 0.632361    
2024-01-15 14:10:17,630 - Epoch: [31][   80/  211]    Overall Loss 0.051241    Objective Loss 0.051241                                        LR 0.100000    Time 0.625399    
2024-01-15 14:10:23,323 - Epoch: [31][   90/  211]    Overall Loss 0.051144    Objective Loss 0.051144                                        LR 0.100000    Time 0.619141    
2024-01-15 14:10:29,063 - Epoch: [31][  100/  211]    Overall Loss 0.050879    Objective Loss 0.050879                                        LR 0.100000    Time 0.614620    
2024-01-15 14:10:34,764 - Epoch: [31][  110/  211]    Overall Loss 0.050732    Objective Loss 0.050732                                        LR 0.100000    Time 0.610564    
2024-01-15 14:10:40,639 - Epoch: [31][  120/  211]    Overall Loss 0.050558    Objective Loss 0.050558                                        LR 0.100000    Time 0.608631    
2024-01-15 14:10:46,569 - Epoch: [31][  130/  211]    Overall Loss 0.050592    Objective Loss 0.050592                                        LR 0.100000    Time 0.607417    
2024-01-15 14:10:52,303 - Epoch: [31][  140/  211]    Overall Loss 0.051319    Objective Loss 0.051319                                        LR 0.100000    Time 0.604980    
2024-01-15 14:10:58,684 - Epoch: [31][  150/  211]    Overall Loss 0.051630    Objective Loss 0.051630                                        LR 0.100000    Time 0.607183    
2024-01-15 14:11:04,327 - Epoch: [31][  160/  211]    Overall Loss 0.051843    Objective Loss 0.051843                                        LR 0.100000    Time 0.604501    
2024-01-15 14:11:10,209 - Epoch: [31][  170/  211]    Overall Loss 0.052171    Objective Loss 0.052171                                        LR 0.100000    Time 0.603536    
2024-01-15 14:11:16,338 - Epoch: [31][  180/  211]    Overall Loss 0.052617    Objective Loss 0.052617                                        LR 0.100000    Time 0.604049    
2024-01-15 14:11:22,237 - Epoch: [31][  190/  211]    Overall Loss 0.052522    Objective Loss 0.052522                                        LR 0.100000    Time 0.603300    
2024-01-15 14:11:28,139 - Epoch: [31][  200/  211]    Overall Loss 0.052627    Objective Loss 0.052627                                        LR 0.100000    Time 0.602637    
2024-01-15 14:11:33,906 - Epoch: [31][  210/  211]    Overall Loss 0.052704    Objective Loss 0.052704    Top1 96.484375    Top5 100.000000    LR 0.100000    Time 0.601397    
2024-01-15 14:11:34,463 - Epoch: [31][  211/  211]    Overall Loss 0.052636    Objective Loss 0.052636    Top1 97.379032    Top5 100.000000    LR 0.100000    Time 0.601182    
2024-01-15 14:11:35,295 - --- validate (epoch=31)-----------
2024-01-15 14:11:35,296 - 6000 samples (256 per mini-batch)
2024-01-15 14:11:42,217 - Epoch: [31][   10/   24]    Loss 0.048077    Top1 98.750000    Top5 100.000000    
2024-01-15 14:11:44,404 - Epoch: [31][   20/   24]    Loss 0.047945    Top1 98.535156    Top5 100.000000    
2024-01-15 14:11:45,154 - Epoch: [31][   24/   24]    Loss 0.051741    Top1 98.483333    Top5 99.983333    
2024-01-15 14:11:45,903 - ==> Top1: 98.483    Top5: 99.983    Loss: 0.052

2024-01-15 14:11:45,905 - ==> Confusion:
[[597   0   2   0   0   0   2   0   2   2]
 [  0 683   4   0   0   0   0   1   0   0]
 [  0   0 580   0   0   0   0   2   4   0]
 [  0   0   3 576   0   0   0   0   3   1]
 [  0   1   4   0 541   0   0   2   4  13]
 [  1   0   1   2   0 504   7   0   3   0]
 [  0   2   0   0   1   0 624   0   4   0]
 [  0   0   7   1   1   0   0 614   0   2]
 [  0   0   0   0   0   1   1   0 582   0]
 [  0   1   0   0   1   0   0   2   3 608]]

2024-01-15 14:11:45,907 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 14:11:45,907 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:11:45,911 - 

2024-01-15 14:11:45,912 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:11:54,500 - Epoch: [32][   10/  211]    Overall Loss 0.047381    Objective Loss 0.047381                                        LR 0.100000    Time 0.858792    
2024-01-15 14:12:00,283 - Epoch: [32][   20/  211]    Overall Loss 0.053741    Objective Loss 0.053741                                        LR 0.100000    Time 0.718453    
2024-01-15 14:12:05,970 - Epoch: [32][   30/  211]    Overall Loss 0.050322    Objective Loss 0.050322                                        LR 0.100000    Time 0.668479    
2024-01-15 14:12:11,611 - Epoch: [32][   40/  211]    Overall Loss 0.048661    Objective Loss 0.048661                                        LR 0.100000    Time 0.642376    
2024-01-15 14:12:17,347 - Epoch: [32][   50/  211]    Overall Loss 0.048744    Objective Loss 0.048744                                        LR 0.100000    Time 0.628607    
2024-01-15 14:12:23,007 - Epoch: [32][   60/  211]    Overall Loss 0.048415    Objective Loss 0.048415                                        LR 0.100000    Time 0.618147    
2024-01-15 14:12:28,659 - Epoch: [32][   70/  211]    Overall Loss 0.048573    Objective Loss 0.048573                                        LR 0.100000    Time 0.610571    
2024-01-15 14:12:34,302 - Epoch: [32][   80/  211]    Overall Loss 0.048762    Objective Loss 0.048762                                        LR 0.100000    Time 0.604773    
2024-01-15 14:12:40,028 - Epoch: [32][   90/  211]    Overall Loss 0.048634    Objective Loss 0.048634                                        LR 0.100000    Time 0.601192    
2024-01-15 14:12:45,711 - Epoch: [32][  100/  211]    Overall Loss 0.049753    Objective Loss 0.049753                                        LR 0.100000    Time 0.597891    
2024-01-15 14:12:51,397 - Epoch: [32][  110/  211]    Overall Loss 0.050213    Objective Loss 0.050213                                        LR 0.100000    Time 0.595223    
2024-01-15 14:12:57,280 - Epoch: [32][  120/  211]    Overall Loss 0.051214    Objective Loss 0.051214                                        LR 0.100000    Time 0.594643    
2024-01-15 14:13:02,981 - Epoch: [32][  130/  211]    Overall Loss 0.051149    Objective Loss 0.051149                                        LR 0.100000    Time 0.592738    
2024-01-15 14:13:08,663 - Epoch: [32][  140/  211]    Overall Loss 0.052133    Objective Loss 0.052133                                        LR 0.100000    Time 0.590976    
2024-01-15 14:13:14,444 - Epoch: [32][  150/  211]    Overall Loss 0.052072    Objective Loss 0.052072                                        LR 0.100000    Time 0.590112    
2024-01-15 14:13:20,191 - Epoch: [32][  160/  211]    Overall Loss 0.052014    Objective Loss 0.052014                                        LR 0.100000    Time 0.589142    
2024-01-15 14:13:25,970 - Epoch: [32][  170/  211]    Overall Loss 0.052458    Objective Loss 0.052458                                        LR 0.100000    Time 0.588474    
2024-01-15 14:13:31,667 - Epoch: [32][  180/  211]    Overall Loss 0.052763    Objective Loss 0.052763                                        LR 0.100000    Time 0.587427    
2024-01-15 14:13:37,400 - Epoch: [32][  190/  211]    Overall Loss 0.052600    Objective Loss 0.052600                                        LR 0.100000    Time 0.586680    
2024-01-15 14:13:43,245 - Epoch: [32][  200/  211]    Overall Loss 0.052714    Objective Loss 0.052714                                        LR 0.100000    Time 0.586567    
2024-01-15 14:13:48,959 - Epoch: [32][  210/  211]    Overall Loss 0.052755    Objective Loss 0.052755    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.585841    
2024-01-15 14:13:49,556 - Epoch: [32][  211/  211]    Overall Loss 0.052696    Objective Loss 0.052696    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.585894    
2024-01-15 14:13:50,156 - --- validate (epoch=32)-----------
2024-01-15 14:13:50,157 - 6000 samples (256 per mini-batch)
2024-01-15 14:13:55,502 - Epoch: [32][   10/   24]    Loss 0.053419    Top1 98.476562    Top5 100.000000    
2024-01-15 14:13:57,750 - Epoch: [32][   20/   24]    Loss 0.051063    Top1 98.535156    Top5 100.000000    
2024-01-15 14:13:58,511 - Epoch: [32][   24/   24]    Loss 0.053812    Top1 98.450000    Top5 100.000000    
2024-01-15 14:13:59,089 - ==> Top1: 98.450    Top5: 100.000    Loss: 0.054

2024-01-15 14:13:59,090 - ==> Confusion:
[[600   0   2   0   0   0   2   0   1   0]
 [  0 687   0   0   0   1   0   0   0   0]
 [  0   0 573   5   0   0   0   0   5   3]
 [  0   0   0 580   0   0   0   2   1   0]
 [  0   1   1   1 541   0   5   1   2  13]
 [  1   0   0   3   0 509   2   0   2   1]
 [  1   0   0   0   0   0 629   0   1   0]
 [  0   3   3   2   0   0   0 615   0   2]
 [  2   0   0   2   0   1   4   0 574   1]
 [  0   5   0   1   0   1   0   2   7 599]]

2024-01-15 14:13:59,092 - ==> Best [Top1: 98.517   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 20]
2024-01-15 14:13:59,092 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:13:59,098 - 

2024-01-15 14:13:59,098 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:14:07,298 - Epoch: [33][   10/  211]    Overall Loss 0.047159    Objective Loss 0.047159                                        LR 0.100000    Time 0.819940    
2024-01-15 14:14:13,091 - Epoch: [33][   20/  211]    Overall Loss 0.051535    Objective Loss 0.051535                                        LR 0.100000    Time 0.699534    
2024-01-15 14:14:18,730 - Epoch: [33][   30/  211]    Overall Loss 0.050833    Objective Loss 0.050833                                        LR 0.100000    Time 0.654301    
2024-01-15 14:14:24,470 - Epoch: [33][   40/  211]    Overall Loss 0.051058    Objective Loss 0.051058                                        LR 0.100000    Time 0.634205    
2024-01-15 14:14:30,154 - Epoch: [33][   50/  211]    Overall Loss 0.052045    Objective Loss 0.052045                                        LR 0.100000    Time 0.621009    
2024-01-15 14:14:35,819 - Epoch: [33][   60/  211]    Overall Loss 0.050064    Objective Loss 0.050064                                        LR 0.100000    Time 0.611923    
2024-01-15 14:14:41,677 - Epoch: [33][   70/  211]    Overall Loss 0.048971    Objective Loss 0.048971                                        LR 0.100000    Time 0.608168    
2024-01-15 14:14:47,428 - Epoch: [33][   80/  211]    Overall Loss 0.050505    Objective Loss 0.050505                                        LR 0.100000    Time 0.604026    
2024-01-15 14:14:53,077 - Epoch: [33][   90/  211]    Overall Loss 0.051496    Objective Loss 0.051496                                        LR 0.100000    Time 0.599665    
2024-01-15 14:14:58,884 - Epoch: [33][  100/  211]    Overall Loss 0.053594    Objective Loss 0.053594                                        LR 0.100000    Time 0.597758    
2024-01-15 14:15:04,576 - Epoch: [33][  110/  211]    Overall Loss 0.054423    Objective Loss 0.054423                                        LR 0.100000    Time 0.595157    
2024-01-15 14:15:10,298 - Epoch: [33][  120/  211]    Overall Loss 0.055319    Objective Loss 0.055319                                        LR 0.100000    Time 0.593236    
2024-01-15 14:15:16,044 - Epoch: [33][  130/  211]    Overall Loss 0.054513    Objective Loss 0.054513                                        LR 0.100000    Time 0.591787    
2024-01-15 14:15:21,755 - Epoch: [33][  140/  211]    Overall Loss 0.053800    Objective Loss 0.053800                                        LR 0.100000    Time 0.590303    
2024-01-15 14:15:27,522 - Epoch: [33][  150/  211]    Overall Loss 0.053294    Objective Loss 0.053294                                        LR 0.100000    Time 0.589383    
2024-01-15 14:15:33,159 - Epoch: [33][  160/  211]    Overall Loss 0.052708    Objective Loss 0.052708                                        LR 0.100000    Time 0.587778    
2024-01-15 14:15:38,898 - Epoch: [33][  170/  211]    Overall Loss 0.052580    Objective Loss 0.052580                                        LR 0.100000    Time 0.586955    
2024-01-15 14:15:44,789 - Epoch: [33][  180/  211]    Overall Loss 0.052951    Objective Loss 0.052951                                        LR 0.100000    Time 0.587048    
2024-01-15 14:15:50,505 - Epoch: [33][  190/  211]    Overall Loss 0.052784    Objective Loss 0.052784                                        LR 0.100000    Time 0.586227    
2024-01-15 14:15:56,361 - Epoch: [33][  200/  211]    Overall Loss 0.053003    Objective Loss 0.053003                                        LR 0.100000    Time 0.586192    
2024-01-15 14:16:02,358 - Epoch: [33][  210/  211]    Overall Loss 0.053073    Objective Loss 0.053073    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.586831    
2024-01-15 14:16:02,981 - Epoch: [33][  211/  211]    Overall Loss 0.053080    Objective Loss 0.053080    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.587000    
2024-01-15 14:16:03,574 - --- validate (epoch=33)-----------
2024-01-15 14:16:03,574 - 6000 samples (256 per mini-batch)
2024-01-15 14:16:08,861 - Epoch: [33][   10/   24]    Loss 0.050787    Top1 98.632812    Top5 100.000000    
2024-01-15 14:16:11,008 - Epoch: [33][   20/   24]    Loss 0.049772    Top1 98.535156    Top5 100.000000    
2024-01-15 14:16:11,802 - Epoch: [33][   24/   24]    Loss 0.050264    Top1 98.566667    Top5 100.000000    
2024-01-15 14:16:12,407 - ==> Top1: 98.567    Top5: 100.000    Loss: 0.050

2024-01-15 14:16:12,408 - ==> Confusion:
[[601   0   1   0   0   0   2   0   1   0]
 [  0 681   2   0   1   0   1   3   0   0]
 [  0   2 578   1   0   0   1   2   2   0]
 [  0   0   2 577   0   1   0   0   1   2]
 [  0   1   1   0 547   1   2   0   0  13]
 [  2   1   0   1   0 506   4   0   3   1]
 [  0   1   1   0   1   1 625   0   2   0]
 [  0   2   5   1   1   0   0 613   0   3]
 [  0   0   0   1   1   0   4   0 576   2]
 [  0   0   0   0   0   1   0   1   3 610]]

2024-01-15 14:16:12,410 - ==> Best [Top1: 98.567   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 33]
2024-01-15 14:16:12,410 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:16:12,420 - 

2024-01-15 14:16:12,420 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:16:20,963 - Epoch: [34][   10/  211]    Overall Loss 0.047538    Objective Loss 0.047538                                        LR 0.100000    Time 0.854208    
2024-01-15 14:16:26,698 - Epoch: [34][   20/  211]    Overall Loss 0.046032    Objective Loss 0.046032                                        LR 0.100000    Time 0.713786    
2024-01-15 14:16:32,677 - Epoch: [34][   30/  211]    Overall Loss 0.053931    Objective Loss 0.053931                                        LR 0.100000    Time 0.675038    
2024-01-15 14:16:38,788 - Epoch: [34][   40/  211]    Overall Loss 0.056342    Objective Loss 0.056342                                        LR 0.100000    Time 0.659007    
2024-01-15 14:16:44,736 - Epoch: [34][   50/  211]    Overall Loss 0.055087    Objective Loss 0.055087                                        LR 0.100000    Time 0.646140    
2024-01-15 14:16:52,764 - Epoch: [34][   60/  211]    Overall Loss 0.053660    Objective Loss 0.053660                                        LR 0.100000    Time 0.672213    
2024-01-15 14:16:58,712 - Epoch: [34][   70/  211]    Overall Loss 0.052021    Objective Loss 0.052021                                        LR 0.100000    Time 0.661134    
2024-01-15 14:17:05,204 - Epoch: [34][   80/  211]    Overall Loss 0.051495    Objective Loss 0.051495                                        LR 0.100000    Time 0.659630    
2024-01-15 14:17:11,048 - Epoch: [34][   90/  211]    Overall Loss 0.051674    Objective Loss 0.051674                                        LR 0.100000    Time 0.651251    
2024-01-15 14:17:16,937 - Epoch: [34][  100/  211]    Overall Loss 0.051711    Objective Loss 0.051711                                        LR 0.100000    Time 0.645012    
2024-01-15 14:17:22,723 - Epoch: [34][  110/  211]    Overall Loss 0.051455    Objective Loss 0.051455                                        LR 0.100000    Time 0.638959    
2024-01-15 14:17:28,541 - Epoch: [34][  120/  211]    Overall Loss 0.052290    Objective Loss 0.052290                                        LR 0.100000    Time 0.634188    
2024-01-15 14:17:34,226 - Epoch: [34][  130/  211]    Overall Loss 0.052378    Objective Loss 0.052378                                        LR 0.100000    Time 0.629133    
2024-01-15 14:17:39,868 - Epoch: [34][  140/  211]    Overall Loss 0.051881    Objective Loss 0.051881                                        LR 0.100000    Time 0.624491    
2024-01-15 14:17:45,575 - Epoch: [34][  150/  211]    Overall Loss 0.052299    Objective Loss 0.052299                                        LR 0.100000    Time 0.620894    
2024-01-15 14:17:51,367 - Epoch: [34][  160/  211]    Overall Loss 0.052640    Objective Loss 0.052640                                        LR 0.100000    Time 0.618278    
2024-01-15 14:17:57,288 - Epoch: [34][  170/  211]    Overall Loss 0.052809    Objective Loss 0.052809                                        LR 0.100000    Time 0.616735    
2024-01-15 14:18:03,202 - Epoch: [34][  180/  211]    Overall Loss 0.053196    Objective Loss 0.053196                                        LR 0.100000    Time 0.615314    
2024-01-15 14:18:09,086 - Epoch: [34][  190/  211]    Overall Loss 0.053247    Objective Loss 0.053247                                        LR 0.100000    Time 0.613890    
2024-01-15 14:18:14,721 - Epoch: [34][  200/  211]    Overall Loss 0.053458    Objective Loss 0.053458                                        LR 0.100000    Time 0.611367    
2024-01-15 14:18:20,485 - Epoch: [34][  210/  211]    Overall Loss 0.053477    Objective Loss 0.053477    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.609700    
2024-01-15 14:18:21,059 - Epoch: [34][  211/  211]    Overall Loss 0.053320    Objective Loss 0.053320    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.609526    
2024-01-15 14:18:22,132 - --- validate (epoch=34)-----------
2024-01-15 14:18:22,134 - 6000 samples (256 per mini-batch)
2024-01-15 14:18:29,100 - Epoch: [34][   10/   24]    Loss 0.061359    Top1 98.203125    Top5 100.000000    
2024-01-15 14:18:31,248 - Epoch: [34][   20/   24]    Loss 0.060903    Top1 98.320312    Top5 99.980469    
2024-01-15 14:18:31,994 - Epoch: [34][   24/   24]    Loss 0.059956    Top1 98.300000    Top5 99.983333    
2024-01-15 14:18:32,553 - ==> Top1: 98.300    Top5: 99.983    Loss: 0.060

2024-01-15 14:18:32,554 - ==> Confusion:
[[594   0   1   1   0   0   5   0   4   0]
 [  0 681   2   1   1   1   1   0   0   1]
 [  0   0 574   3   0   1   1   3   2   2]
 [  0   0   3 575   0   2   0   1   2   0]
 [  0   0   1   0 546   0   1   0   2  15]
 [  2   0   0   1   0 507   5   0   3   0]
 [  1   0   0   0   1   0 627   0   2   0]
 [  0   0   3   4   0   0   0 611   1   6]
 [  1   0   0   1   0   1   2   0 579   0]
 [  2   0   0   0   0   2   1   1   5 604]]

2024-01-15 14:18:32,556 - ==> Best [Top1: 98.567   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 33]
2024-01-15 14:18:32,556 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:18:32,561 - 

2024-01-15 14:18:32,561 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:18:41,363 - Epoch: [35][   10/  211]    Overall Loss 0.049669    Objective Loss 0.049669                                        LR 0.100000    Time 0.880138    
2024-01-15 14:18:47,082 - Epoch: [35][   20/  211]    Overall Loss 0.044143    Objective Loss 0.044143                                        LR 0.100000    Time 0.725941    
2024-01-15 14:18:52,882 - Epoch: [35][   30/  211]    Overall Loss 0.049597    Objective Loss 0.049597                                        LR 0.100000    Time 0.677260    
2024-01-15 14:18:58,818 - Epoch: [35][   40/  211]    Overall Loss 0.049372    Objective Loss 0.049372                                        LR 0.100000    Time 0.656328    
2024-01-15 14:19:04,825 - Epoch: [35][   50/  211]    Overall Loss 0.048404    Objective Loss 0.048404                                        LR 0.100000    Time 0.645165    
2024-01-15 14:19:10,518 - Epoch: [35][   60/  211]    Overall Loss 0.048272    Objective Loss 0.048272                                        LR 0.100000    Time 0.632511    
2024-01-15 14:19:16,458 - Epoch: [35][   70/  211]    Overall Loss 0.047039    Objective Loss 0.047039                                        LR 0.100000    Time 0.627000    
2024-01-15 14:19:22,552 - Epoch: [35][   80/  211]    Overall Loss 0.046706    Objective Loss 0.046706                                        LR 0.100000    Time 0.624780    
2024-01-15 14:19:28,253 - Epoch: [35][   90/  211]    Overall Loss 0.047600    Objective Loss 0.047600                                        LR 0.100000    Time 0.618691    
2024-01-15 14:19:33,902 - Epoch: [35][  100/  211]    Overall Loss 0.047721    Objective Loss 0.047721                                        LR 0.100000    Time 0.613312    
2024-01-15 14:19:39,527 - Epoch: [35][  110/  211]    Overall Loss 0.047582    Objective Loss 0.047582                                        LR 0.100000    Time 0.608681    
2024-01-15 14:19:45,146 - Epoch: [35][  120/  211]    Overall Loss 0.049884    Objective Loss 0.049884                                        LR 0.100000    Time 0.604783    
2024-01-15 14:19:50,987 - Epoch: [35][  130/  211]    Overall Loss 0.051441    Objective Loss 0.051441                                        LR 0.100000    Time 0.603188    
2024-01-15 14:19:56,939 - Epoch: [35][  140/  211]    Overall Loss 0.051605    Objective Loss 0.051605                                        LR 0.100000    Time 0.602608    
2024-01-15 14:20:03,141 - Epoch: [35][  150/  211]    Overall Loss 0.051137    Objective Loss 0.051137                                        LR 0.100000    Time 0.603753    
2024-01-15 14:20:08,946 - Epoch: [35][  160/  211]    Overall Loss 0.051119    Objective Loss 0.051119                                        LR 0.100000    Time 0.602291    
2024-01-15 14:20:14,813 - Epoch: [35][  170/  211]    Overall Loss 0.050707    Objective Loss 0.050707                                        LR 0.100000    Time 0.601356    
2024-01-15 14:20:21,514 - Epoch: [35][  180/  211]    Overall Loss 0.050724    Objective Loss 0.050724                                        LR 0.100000    Time 0.605165    
2024-01-15 14:20:27,456 - Epoch: [35][  190/  211]    Overall Loss 0.050696    Objective Loss 0.050696                                        LR 0.100000    Time 0.604582    
2024-01-15 14:20:34,541 - Epoch: [35][  200/  211]    Overall Loss 0.050302    Objective Loss 0.050302                                        LR 0.100000    Time 0.609768    
2024-01-15 14:20:40,895 - Epoch: [35][  210/  211]    Overall Loss 0.050032    Objective Loss 0.050032    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.610982    
2024-01-15 14:20:41,481 - Epoch: [35][  211/  211]    Overall Loss 0.050165    Objective Loss 0.050165    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.610858    
2024-01-15 14:20:42,379 - --- validate (epoch=35)-----------
2024-01-15 14:20:42,381 - 6000 samples (256 per mini-batch)
2024-01-15 14:20:49,838 - Epoch: [35][   10/   24]    Loss 0.050963    Top1 98.476562    Top5 100.000000    
2024-01-15 14:20:52,021 - Epoch: [35][   20/   24]    Loss 0.050828    Top1 98.476562    Top5 99.980469    
2024-01-15 14:20:52,805 - Epoch: [35][   24/   24]    Loss 0.047639    Top1 98.600000    Top5 99.983333    
2024-01-15 14:20:53,492 - ==> Top1: 98.600    Top5: 99.983    Loss: 0.048

2024-01-15 14:20:53,493 - ==> Confusion:
[[603   0   0   0   0   0   1   0   0   1]
 [  1 681   2   1   0   1   0   2   0   0]
 [  0   0 580   0   0   0   1   2   2   1]
 [  0   0   4 575   0   2   0   1   1   0]
 [  1   1   3   0 550   0   1   1   0   8]
 [  1   0   0   1   0 511   3   0   2   0]
 [  0   1   0   0   2   1 626   0   1   0]
 [  0   2   6   0   1   0   0 616   0   0]
 [  1   0   1   3   1   0   2   0 576   0]
 [  0   1   0   0   7   0   0   3   6 598]]

2024-01-15 14:20:53,496 - ==> Best [Top1: 98.600   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 35]
2024-01-15 14:20:53,496 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:20:53,502 - 

2024-01-15 14:20:53,503 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:21:03,025 - Epoch: [36][   10/  211]    Overall Loss 0.039680    Objective Loss 0.039680                                        LR 0.100000    Time 0.952137    
2024-01-15 14:21:08,719 - Epoch: [36][   20/  211]    Overall Loss 0.041948    Objective Loss 0.041948                                        LR 0.100000    Time 0.760738    
2024-01-15 14:21:14,375 - Epoch: [36][   30/  211]    Overall Loss 0.045799    Objective Loss 0.045799                                        LR 0.100000    Time 0.695670    
2024-01-15 14:21:20,165 - Epoch: [36][   40/  211]    Overall Loss 0.047565    Objective Loss 0.047565                                        LR 0.100000    Time 0.666472    
2024-01-15 14:21:25,891 - Epoch: [36][   50/  211]    Overall Loss 0.046420    Objective Loss 0.046420                                        LR 0.100000    Time 0.647683    
2024-01-15 14:21:31,815 - Epoch: [36][   60/  211]    Overall Loss 0.045877    Objective Loss 0.045877                                        LR 0.100000    Time 0.638444    
2024-01-15 14:21:37,697 - Epoch: [36][   70/  211]    Overall Loss 0.046605    Objective Loss 0.046605                                        LR 0.100000    Time 0.631258    
2024-01-15 14:21:43,624 - Epoch: [36][   80/  211]    Overall Loss 0.046965    Objective Loss 0.046965                                        LR 0.100000    Time 0.626424    
2024-01-15 14:21:49,289 - Epoch: [36][   90/  211]    Overall Loss 0.047776    Objective Loss 0.047776                                        LR 0.100000    Time 0.619761    
2024-01-15 14:21:55,089 - Epoch: [36][  100/  211]    Overall Loss 0.047278    Objective Loss 0.047278                                        LR 0.100000    Time 0.615774    
2024-01-15 14:22:01,142 - Epoch: [36][  110/  211]    Overall Loss 0.047970    Objective Loss 0.047970                                        LR 0.100000    Time 0.614807    
2024-01-15 14:22:07,206 - Epoch: [36][  120/  211]    Overall Loss 0.048149    Objective Loss 0.048149                                        LR 0.100000    Time 0.614088    
2024-01-15 14:22:13,231 - Epoch: [36][  130/  211]    Overall Loss 0.047809    Objective Loss 0.047809                                        LR 0.100000    Time 0.613192    
2024-01-15 14:22:18,908 - Epoch: [36][  140/  211]    Overall Loss 0.047910    Objective Loss 0.047910                                        LR 0.100000    Time 0.609936    
2024-01-15 14:22:24,669 - Epoch: [36][  150/  211]    Overall Loss 0.047463    Objective Loss 0.047463                                        LR 0.100000    Time 0.607674    
2024-01-15 14:22:30,367 - Epoch: [36][  160/  211]    Overall Loss 0.047339    Objective Loss 0.047339                                        LR 0.100000    Time 0.605291    
2024-01-15 14:22:36,020 - Epoch: [36][  170/  211]    Overall Loss 0.047187    Objective Loss 0.047187                                        LR 0.100000    Time 0.602933    
2024-01-15 14:22:41,707 - Epoch: [36][  180/  211]    Overall Loss 0.047879    Objective Loss 0.047879                                        LR 0.100000    Time 0.601027    
2024-01-15 14:22:47,446 - Epoch: [36][  190/  211]    Overall Loss 0.047923    Objective Loss 0.047923                                        LR 0.100000    Time 0.599594    
2024-01-15 14:22:53,146 - Epoch: [36][  200/  211]    Overall Loss 0.047534    Objective Loss 0.047534                                        LR 0.100000    Time 0.598109    
2024-01-15 14:22:58,881 - Epoch: [36][  210/  211]    Overall Loss 0.047884    Objective Loss 0.047884    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.596928    
2024-01-15 14:22:59,495 - Epoch: [36][  211/  211]    Overall Loss 0.047792    Objective Loss 0.047792    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.597000    
2024-01-15 14:23:00,272 - --- validate (epoch=36)-----------
2024-01-15 14:23:00,273 - 6000 samples (256 per mini-batch)
2024-01-15 14:23:07,066 - Epoch: [36][   10/   24]    Loss 0.050631    Top1 98.320312    Top5 100.000000    
2024-01-15 14:23:09,182 - Epoch: [36][   20/   24]    Loss 0.048095    Top1 98.496094    Top5 100.000000    
2024-01-15 14:23:09,922 - Epoch: [36][   24/   24]    Loss 0.047740    Top1 98.533333    Top5 100.000000    
2024-01-15 14:23:10,472 - ==> Top1: 98.533    Top5: 100.000    Loss: 0.048

2024-01-15 14:23:10,473 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 687   0   0   1   0   0   0   0   0]
 [  0   2 574   1   0   0   0   5   0   4]
 [  0   0   2 576   1   1   0   2   0   1]
 [  0   0   1   0 557   0   1   0   0   6]
 [  1   0   0   2   0 510   4   0   1   0]
 [  2   2   0   0   2   1 623   0   1   0]
 [  0   6   2   0   3   0   0 611   0   3]
 [  3   1   0   2   4   2   4   0 566   2]
 [  0   1   0   0   4   1   0   1   2 606]]

2024-01-15 14:23:10,475 - ==> Best [Top1: 98.600   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 35]
2024-01-15 14:23:10,475 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:23:10,479 - 

2024-01-15 14:23:10,479 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:23:18,877 - Epoch: [37][   10/  211]    Overall Loss 0.046556    Objective Loss 0.046556                                        LR 0.100000    Time 0.839736    
2024-01-15 14:23:24,551 - Epoch: [37][   20/  211]    Overall Loss 0.042974    Objective Loss 0.042974                                        LR 0.100000    Time 0.703474    
2024-01-15 14:23:30,530 - Epoch: [37][   30/  211]    Overall Loss 0.043212    Objective Loss 0.043212                                        LR 0.100000    Time 0.668261    
2024-01-15 14:23:36,273 - Epoch: [37][   40/  211]    Overall Loss 0.043820    Objective Loss 0.043820                                        LR 0.100000    Time 0.644754    
2024-01-15 14:23:42,079 - Epoch: [37][   50/  211]    Overall Loss 0.044880    Objective Loss 0.044880                                        LR 0.100000    Time 0.631898    
2024-01-15 14:23:47,853 - Epoch: [37][   60/  211]    Overall Loss 0.044692    Objective Loss 0.044692                                        LR 0.100000    Time 0.622784    
2024-01-15 14:23:53,551 - Epoch: [37][   70/  211]    Overall Loss 0.045035    Objective Loss 0.045035                                        LR 0.100000    Time 0.615213    
2024-01-15 14:23:59,471 - Epoch: [37][   80/  211]    Overall Loss 0.046184    Objective Loss 0.046184                                        LR 0.100000    Time 0.612279    
2024-01-15 14:24:05,367 - Epoch: [37][   90/  211]    Overall Loss 0.046964    Objective Loss 0.046964                                        LR 0.100000    Time 0.609741    
2024-01-15 14:24:11,006 - Epoch: [37][  100/  211]    Overall Loss 0.046946    Objective Loss 0.046946                                        LR 0.100000    Time 0.605157    
2024-01-15 14:24:16,668 - Epoch: [37][  110/  211]    Overall Loss 0.046886    Objective Loss 0.046886                                        LR 0.100000    Time 0.601606    
2024-01-15 14:24:22,519 - Epoch: [37][  120/  211]    Overall Loss 0.047661    Objective Loss 0.047661                                        LR 0.100000    Time 0.600221    
2024-01-15 14:24:28,373 - Epoch: [37][  130/  211]    Overall Loss 0.048341    Objective Loss 0.048341                                        LR 0.100000    Time 0.599069    
2024-01-15 14:24:34,096 - Epoch: [37][  140/  211]    Overall Loss 0.048139    Objective Loss 0.048139                                        LR 0.100000    Time 0.597143    
2024-01-15 14:24:39,821 - Epoch: [37][  150/  211]    Overall Loss 0.048333    Objective Loss 0.048333                                        LR 0.100000    Time 0.595489    
2024-01-15 14:24:45,672 - Epoch: [37][  160/  211]    Overall Loss 0.048971    Objective Loss 0.048971                                        LR 0.100000    Time 0.594834    
2024-01-15 14:24:51,320 - Epoch: [37][  170/  211]    Overall Loss 0.048396    Objective Loss 0.048396                                        LR 0.100000    Time 0.593061    
2024-01-15 14:24:57,418 - Epoch: [37][  180/  211]    Overall Loss 0.048539    Objective Loss 0.048539                                        LR 0.100000    Time 0.593986    
2024-01-15 14:25:03,211 - Epoch: [37][  190/  211]    Overall Loss 0.048034    Objective Loss 0.048034                                        LR 0.100000    Time 0.593208    
2024-01-15 14:25:08,939 - Epoch: [37][  200/  211]    Overall Loss 0.048227    Objective Loss 0.048227                                        LR 0.100000    Time 0.592183    
2024-01-15 14:25:14,596 - Epoch: [37][  210/  211]    Overall Loss 0.047705    Objective Loss 0.047705    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.590917    
2024-01-15 14:25:15,190 - Epoch: [37][  211/  211]    Overall Loss 0.047705    Objective Loss 0.047705    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.590932    
2024-01-15 14:25:16,018 - --- validate (epoch=37)-----------
2024-01-15 14:25:16,019 - 6000 samples (256 per mini-batch)
2024-01-15 14:25:21,626 - Epoch: [37][   10/   24]    Loss 0.048696    Top1 98.476562    Top5 100.000000    
2024-01-15 14:25:23,767 - Epoch: [37][   20/   24]    Loss 0.047682    Top1 98.632812    Top5 99.980469    
2024-01-15 14:25:24,545 - Epoch: [37][   24/   24]    Loss 0.043700    Top1 98.766667    Top5 99.983333    
2024-01-15 14:25:25,180 - ==> Top1: 98.767    Top5: 99.983    Loss: 0.044

2024-01-15 14:25:25,181 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 581   0   0   0   0   4   1   0]
 [  1   0   4 566   0   3   0   7   1   1]
 [  0   0   1   0 560   1   0   0   0   3]
 [  0   0   0   0   0 517   0   0   0   1]
 [  2   0   0   0   3   5 621   0   0   0]
 [  0   1   1   0   0   0   0 622   0   1]
 [  1   1   1   1   0   4   3   0 571   2]
 [  1   2   0   0   5   2   0   4   1 600]]

2024-01-15 14:25:25,183 - ==> Best [Top1: 98.767   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 37]
2024-01-15 14:25:25,183 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:25:25,193 - 

2024-01-15 14:25:25,193 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:25:34,647 - Epoch: [38][   10/  211]    Overall Loss 0.051757    Objective Loss 0.051757                                        LR 0.100000    Time 0.945223    
2024-01-15 14:25:40,674 - Epoch: [38][   20/  211]    Overall Loss 0.048913    Objective Loss 0.048913                                        LR 0.100000    Time 0.773885    
2024-01-15 14:25:46,410 - Epoch: [38][   30/  211]    Overall Loss 0.047739    Objective Loss 0.047739                                        LR 0.100000    Time 0.707081    
2024-01-15 14:25:52,276 - Epoch: [38][   40/  211]    Overall Loss 0.045646    Objective Loss 0.045646                                        LR 0.100000    Time 0.676924    
2024-01-15 14:25:58,373 - Epoch: [38][   50/  211]    Overall Loss 0.044994    Objective Loss 0.044994                                        LR 0.100000    Time 0.663439    
2024-01-15 14:26:04,160 - Epoch: [38][   60/  211]    Overall Loss 0.045343    Objective Loss 0.045343                                        LR 0.100000    Time 0.649312    
2024-01-15 14:26:09,926 - Epoch: [38][   70/  211]    Overall Loss 0.045670    Objective Loss 0.045670                                        LR 0.100000    Time 0.638907    
2024-01-15 14:26:15,628 - Epoch: [38][   80/  211]    Overall Loss 0.045815    Objective Loss 0.045815                                        LR 0.100000    Time 0.630304    
2024-01-15 14:26:21,453 - Epoch: [38][   90/  211]    Overall Loss 0.045846    Objective Loss 0.045846                                        LR 0.100000    Time 0.624978    
2024-01-15 14:26:27,192 - Epoch: [38][  100/  211]    Overall Loss 0.046158    Objective Loss 0.046158                                        LR 0.100000    Time 0.619857    
2024-01-15 14:26:32,975 - Epoch: [38][  110/  211]    Overall Loss 0.046837    Objective Loss 0.046837                                        LR 0.100000    Time 0.616063    
2024-01-15 14:26:38,947 - Epoch: [38][  120/  211]    Overall Loss 0.046118    Objective Loss 0.046118                                        LR 0.100000    Time 0.614487    
2024-01-15 14:26:45,119 - Epoch: [38][  130/  211]    Overall Loss 0.046231    Objective Loss 0.046231                                        LR 0.100000    Time 0.614687    
2024-01-15 14:26:50,830 - Epoch: [38][  140/  211]    Overall Loss 0.046080    Objective Loss 0.046080                                        LR 0.100000    Time 0.611564    
2024-01-15 14:26:56,544 - Epoch: [38][  150/  211]    Overall Loss 0.046213    Objective Loss 0.046213                                        LR 0.100000    Time 0.608878    
2024-01-15 14:27:02,576 - Epoch: [38][  160/  211]    Overall Loss 0.046267    Objective Loss 0.046267                                        LR 0.100000    Time 0.608515    
2024-01-15 14:27:08,511 - Epoch: [38][  170/  211]    Overall Loss 0.045963    Objective Loss 0.045963                                        LR 0.100000    Time 0.607626    
2024-01-15 14:27:14,254 - Epoch: [38][  180/  211]    Overall Loss 0.046113    Objective Loss 0.046113                                        LR 0.100000    Time 0.605770    
2024-01-15 14:27:19,892 - Epoch: [38][  190/  211]    Overall Loss 0.046166    Objective Loss 0.046166                                        LR 0.100000    Time 0.603557    
2024-01-15 14:27:25,521 - Epoch: [38][  200/  211]    Overall Loss 0.045996    Objective Loss 0.045996                                        LR 0.100000    Time 0.601522    
2024-01-15 14:27:31,531 - Epoch: [38][  210/  211]    Overall Loss 0.045729    Objective Loss 0.045729    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.601491    
2024-01-15 14:27:32,139 - Epoch: [38][  211/  211]    Overall Loss 0.045619    Objective Loss 0.045619    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.601520    
2024-01-15 14:27:32,971 - --- validate (epoch=38)-----------
2024-01-15 14:27:32,973 - 6000 samples (256 per mini-batch)
2024-01-15 14:27:40,184 - Epoch: [38][   10/   24]    Loss 0.042380    Top1 98.632812    Top5 100.000000    
2024-01-15 14:27:42,415 - Epoch: [38][   20/   24]    Loss 0.046432    Top1 98.437500    Top5 100.000000    
2024-01-15 14:27:43,186 - Epoch: [38][   24/   24]    Loss 0.047003    Top1 98.416667    Top5 100.000000    
2024-01-15 14:27:43,962 - ==> Top1: 98.417    Top5: 100.000    Loss: 0.047

2024-01-15 14:27:43,964 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 683   2   1   0   0   1   1   0   0]
 [  0   0 575   0   0   0   1   4   6   0]
 [  1   0   2 574   0   1   0   2   2   1]
 [  0   1   4   0 535   0   1   1   8  15]
 [  1   0   0   1   0 512   3   0   1   0]
 [  2   1   0   0   1   2 623   0   2   0]
 [  1   0   0   2   0   0   0 622   0   0]
 [  0   0   0   0   0   1   1   0 581   1]
 [  0   1   0   1   3   2   0   4   8 596]]

2024-01-15 14:27:43,966 - ==> Best [Top1: 98.767   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 37]
2024-01-15 14:27:43,966 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:27:43,970 - 

2024-01-15 14:27:43,971 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:27:53,534 - Epoch: [39][   10/  211]    Overall Loss 0.049046    Objective Loss 0.049046                                        LR 0.100000    Time 0.955995    
2024-01-15 14:28:00,254 - Epoch: [39][   20/  211]    Overall Loss 0.050389    Objective Loss 0.050389                                        LR 0.100000    Time 0.813854    
2024-01-15 14:28:06,040 - Epoch: [39][   30/  211]    Overall Loss 0.048428    Objective Loss 0.048428                                        LR 0.100000    Time 0.735422    
2024-01-15 14:28:21,985 - Epoch: [39][   40/  211]    Overall Loss 0.048212    Objective Loss 0.048212                                        LR 0.100000    Time 0.950134    
2024-01-15 14:28:40,257 - Epoch: [39][   50/  211]    Overall Loss 0.047856    Objective Loss 0.047856                                        LR 0.100000    Time 1.125490    
2024-01-15 14:28:59,901 - Epoch: [39][   60/  211]    Overall Loss 0.048108    Objective Loss 0.048108                                        LR 0.100000    Time 1.265258    
2024-01-15 14:29:18,283 - Epoch: [39][   70/  211]    Overall Loss 0.045784    Objective Loss 0.045784                                        LR 0.100000    Time 1.347052    
2024-01-15 14:29:26,788 - Epoch: [39][   80/  211]    Overall Loss 0.045049    Objective Loss 0.045049                                        LR 0.100000    Time 1.284953    
2024-01-15 14:29:32,492 - Epoch: [39][   90/  211]    Overall Loss 0.044544    Objective Loss 0.044544                                        LR 0.100000    Time 1.205550    
2024-01-15 14:29:38,121 - Epoch: [39][  100/  211]    Overall Loss 0.044634    Objective Loss 0.044634                                        LR 0.100000    Time 1.141282    
2024-01-15 14:29:43,809 - Epoch: [39][  110/  211]    Overall Loss 0.045023    Objective Loss 0.045023                                        LR 0.100000    Time 1.089232    
2024-01-15 14:29:50,363 - Epoch: [39][  120/  211]    Overall Loss 0.044691    Objective Loss 0.044691                                        LR 0.100000    Time 1.053070    
2024-01-15 14:29:58,120 - Epoch: [39][  130/  211]    Overall Loss 0.044829    Objective Loss 0.044829                                        LR 0.100000    Time 1.031719    
2024-01-15 14:30:03,989 - Epoch: [39][  140/  211]    Overall Loss 0.044287    Objective Loss 0.044287                                        LR 0.100000    Time 0.999942    
2024-01-15 14:30:09,750 - Epoch: [39][  150/  211]    Overall Loss 0.044082    Objective Loss 0.044082                                        LR 0.100000    Time 0.971674    
2024-01-15 14:30:15,466 - Epoch: [39][  160/  211]    Overall Loss 0.044197    Objective Loss 0.044197                                        LR 0.100000    Time 0.946667    
2024-01-15 14:30:21,283 - Epoch: [39][  170/  211]    Overall Loss 0.044511    Objective Loss 0.044511                                        LR 0.100000    Time 0.925189    
2024-01-15 14:30:27,005 - Epoch: [39][  180/  211]    Overall Loss 0.044377    Objective Loss 0.044377                                        LR 0.100000    Time 0.905574    
2024-01-15 14:30:32,823 - Epoch: [39][  190/  211]    Overall Loss 0.044389    Objective Loss 0.044389                                        LR 0.100000    Time 0.888528    
2024-01-15 14:30:38,543 - Epoch: [39][  200/  211]    Overall Loss 0.044840    Objective Loss 0.044840                                        LR 0.100000    Time 0.872696    
2024-01-15 14:30:44,561 - Epoch: [39][  210/  211]    Overall Loss 0.044986    Objective Loss 0.044986    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.859789    
2024-01-15 14:30:45,153 - Epoch: [39][  211/  211]    Overall Loss 0.045055    Objective Loss 0.045055    Top1 97.782258    Top5 100.000000    LR 0.100000    Time 0.858518    
2024-01-15 14:30:46,313 - --- validate (epoch=39)-----------
2024-01-15 14:30:46,315 - 6000 samples (256 per mini-batch)
2024-01-15 14:30:53,880 - Epoch: [39][   10/   24]    Loss 0.052524    Top1 98.437500    Top5 100.000000    
2024-01-15 14:30:56,134 - Epoch: [39][   20/   24]    Loss 0.055258    Top1 98.339844    Top5 100.000000    
2024-01-15 14:30:56,983 - Epoch: [39][   24/   24]    Loss 0.054518    Top1 98.366667    Top5 100.000000    
2024-01-15 14:30:57,753 - ==> Top1: 98.367    Top5: 100.000    Loss: 0.055

2024-01-15 14:30:57,755 - ==> Confusion:
[[600   0   2   0   0   0   2   0   0   1]
 [  0 679   3   1   0   1   1   2   1   0]
 [  0   0 578   2   0   0   0   1   4   1]
 [  0   0   0 581   0   1   0   0   1   0]
 [  1   0   3   0 531   0   1   2   8  19]
 [  0   0   0   1   0 509   4   0   3   1]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   1   4   2   1   0   0 616   0   1]
 [  2   0   1   0   0   0   5   0 576   0]
 [  0   0   0   2   2   1   0   1   7 602]]

2024-01-15 14:30:57,757 - ==> Best [Top1: 98.767   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 37]
2024-01-15 14:30:57,757 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:30:57,764 - 

2024-01-15 14:30:57,764 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:31:07,251 - Epoch: [40][   10/  211]    Overall Loss 0.056683    Objective Loss 0.056683                                        LR 0.100000    Time 0.948581    
2024-01-15 14:31:13,064 - Epoch: [40][   20/  211]    Overall Loss 0.048880    Objective Loss 0.048880                                        LR 0.100000    Time 0.764835    
2024-01-15 14:31:18,928 - Epoch: [40][   30/  211]    Overall Loss 0.050945    Objective Loss 0.050945                                        LR 0.100000    Time 0.705316    
2024-01-15 14:31:24,659 - Epoch: [40][   40/  211]    Overall Loss 0.051252    Objective Loss 0.051252                                        LR 0.100000    Time 0.672229    
2024-01-15 14:31:30,419 - Epoch: [40][   50/  211]    Overall Loss 0.048855    Objective Loss 0.048855                                        LR 0.100000    Time 0.652964    
2024-01-15 14:31:36,272 - Epoch: [40][   60/  211]    Overall Loss 0.047859    Objective Loss 0.047859                                        LR 0.100000    Time 0.641673    
2024-01-15 14:31:42,031 - Epoch: [40][   70/  211]    Overall Loss 0.046672    Objective Loss 0.046672                                        LR 0.100000    Time 0.632244    
2024-01-15 14:31:47,808 - Epoch: [40][   80/  211]    Overall Loss 0.048639    Objective Loss 0.048639                                        LR 0.100000    Time 0.625413    
2024-01-15 14:31:54,016 - Epoch: [40][   90/  211]    Overall Loss 0.048771    Objective Loss 0.048771                                        LR 0.100000    Time 0.624883    
2024-01-15 14:32:01,066 - Epoch: [40][  100/  211]    Overall Loss 0.049578    Objective Loss 0.049578                                        LR 0.100000    Time 0.632865    
2024-01-15 14:32:07,078 - Epoch: [40][  110/  211]    Overall Loss 0.048978    Objective Loss 0.048978                                        LR 0.100000    Time 0.629977    
2024-01-15 14:32:12,800 - Epoch: [40][  120/  211]    Overall Loss 0.048365    Objective Loss 0.048365                                        LR 0.100000    Time 0.625153    
2024-01-15 14:32:18,571 - Epoch: [40][  130/  211]    Overall Loss 0.047530    Objective Loss 0.047530                                        LR 0.100000    Time 0.621449    
2024-01-15 14:32:24,343 - Epoch: [40][  140/  211]    Overall Loss 0.047010    Objective Loss 0.047010                                        LR 0.100000    Time 0.618280    
2024-01-15 14:32:29,998 - Epoch: [40][  150/  211]    Overall Loss 0.046767    Objective Loss 0.046767                                        LR 0.100000    Time 0.614763    
2024-01-15 14:32:35,675 - Epoch: [40][  160/  211]    Overall Loss 0.046131    Objective Loss 0.046131                                        LR 0.100000    Time 0.611814    
2024-01-15 14:32:41,349 - Epoch: [40][  170/  211]    Overall Loss 0.046528    Objective Loss 0.046528                                        LR 0.100000    Time 0.609193    
2024-01-15 14:32:47,125 - Epoch: [40][  180/  211]    Overall Loss 0.046695    Objective Loss 0.046695                                        LR 0.100000    Time 0.607432    
2024-01-15 14:32:52,865 - Epoch: [40][  190/  211]    Overall Loss 0.046586    Objective Loss 0.046586                                        LR 0.100000    Time 0.605669    
2024-01-15 14:32:58,678 - Epoch: [40][  200/  211]    Overall Loss 0.046342    Objective Loss 0.046342                                        LR 0.100000    Time 0.604444    
2024-01-15 14:33:04,501 - Epoch: [40][  210/  211]    Overall Loss 0.046365    Objective Loss 0.046365    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.603384    
2024-01-15 14:33:05,084 - Epoch: [40][  211/  211]    Overall Loss 0.046434    Objective Loss 0.046434    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.603283    
2024-01-15 14:33:05,876 - --- validate (epoch=40)-----------
2024-01-15 14:33:05,877 - 6000 samples (256 per mini-batch)
2024-01-15 14:33:12,798 - Epoch: [40][   10/   24]    Loss 0.047983    Top1 98.515625    Top5 99.921875    
2024-01-15 14:33:14,944 - Epoch: [40][   20/   24]    Loss 0.052503    Top1 98.300781    Top5 99.960938    
2024-01-15 14:33:15,761 - Epoch: [40][   24/   24]    Loss 0.056278    Top1 98.266667    Top5 99.966667    
2024-01-15 14:33:16,476 - ==> Top1: 98.267    Top5: 99.967    Loss: 0.056

2024-01-15 14:33:16,477 - ==> Confusion:
[[601   0   2   0   0   0   1   0   1   0]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   0 575   0   2   0   0   7   1   1]
 [  1   0   3 566   1   6   0   4   2   0]
 [  0   2   1   0 556   0   1   1   0   4]
 [  1   0   0   1   0 514   2   0   0   0]
 [  1   3   0   0   2   2 623   0   0   0]
 [  0   3   2   0   0   0   0 620   0   0]
 [  2   0   0   0   3   3   3   0 573   0]
 [  0   2   0   0  17   4   0   9   3 580]]

2024-01-15 14:33:16,479 - ==> Best [Top1: 98.767   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 37]
2024-01-15 14:33:16,480 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:33:16,485 - 

2024-01-15 14:33:16,485 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:33:25,035 - Epoch: [41][   10/  211]    Overall Loss 0.041613    Objective Loss 0.041613                                        LR 0.100000    Time 0.854951    
2024-01-15 14:33:30,906 - Epoch: [41][   20/  211]    Overall Loss 0.041479    Objective Loss 0.041479                                        LR 0.100000    Time 0.720941    
2024-01-15 14:33:36,899 - Epoch: [41][   30/  211]    Overall Loss 0.040224    Objective Loss 0.040224                                        LR 0.100000    Time 0.680339    
2024-01-15 14:33:42,703 - Epoch: [41][   40/  211]    Overall Loss 0.038809    Objective Loss 0.038809                                        LR 0.100000    Time 0.655323    
2024-01-15 14:33:48,433 - Epoch: [41][   50/  211]    Overall Loss 0.040171    Objective Loss 0.040171                                        LR 0.100000    Time 0.638839    
2024-01-15 14:33:54,650 - Epoch: [41][   60/  211]    Overall Loss 0.041173    Objective Loss 0.041173                                        LR 0.100000    Time 0.635969    
2024-01-15 14:34:00,646 - Epoch: [41][   70/  211]    Overall Loss 0.042426    Objective Loss 0.042426                                        LR 0.100000    Time 0.630761    
2024-01-15 14:34:06,538 - Epoch: [41][   80/  211]    Overall Loss 0.042982    Objective Loss 0.042982                                        LR 0.100000    Time 0.625541    
2024-01-15 14:34:12,548 - Epoch: [41][   90/  211]    Overall Loss 0.042539    Objective Loss 0.042539                                        LR 0.100000    Time 0.622794    
2024-01-15 14:34:18,332 - Epoch: [41][  100/  211]    Overall Loss 0.042771    Objective Loss 0.042771                                        LR 0.100000    Time 0.618344    
2024-01-15 14:34:24,204 - Epoch: [41][  110/  211]    Overall Loss 0.042670    Objective Loss 0.042670                                        LR 0.100000    Time 0.615506    
2024-01-15 14:34:30,151 - Epoch: [41][  120/  211]    Overall Loss 0.042521    Objective Loss 0.042521                                        LR 0.100000    Time 0.613767    
2024-01-15 14:34:36,290 - Epoch: [41][  130/  211]    Overall Loss 0.042892    Objective Loss 0.042892                                        LR 0.100000    Time 0.613767    
2024-01-15 14:34:42,258 - Epoch: [41][  140/  211]    Overall Loss 0.043459    Objective Loss 0.043459                                        LR 0.100000    Time 0.612540    
2024-01-15 14:34:48,122 - Epoch: [41][  150/  211]    Overall Loss 0.044055    Objective Loss 0.044055                                        LR 0.100000    Time 0.610795    
2024-01-15 14:34:54,521 - Epoch: [41][  160/  211]    Overall Loss 0.044303    Objective Loss 0.044303                                        LR 0.100000    Time 0.612605    
2024-01-15 14:35:00,652 - Epoch: [41][  170/  211]    Overall Loss 0.045105    Objective Loss 0.045105                                        LR 0.100000    Time 0.612625    
2024-01-15 14:35:08,173 - Epoch: [41][  180/  211]    Overall Loss 0.044595    Objective Loss 0.044595                                        LR 0.100000    Time 0.620358    
2024-01-15 14:35:14,446 - Epoch: [41][  190/  211]    Overall Loss 0.044737    Objective Loss 0.044737                                        LR 0.100000    Time 0.620694    
2024-01-15 14:35:21,504 - Epoch: [41][  200/  211]    Overall Loss 0.044545    Objective Loss 0.044545                                        LR 0.100000    Time 0.624935    
2024-01-15 14:35:28,324 - Epoch: [41][  210/  211]    Overall Loss 0.044500    Objective Loss 0.044500    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.627642    
2024-01-15 14:35:29,031 - Epoch: [41][  211/  211]    Overall Loss 0.044542    Objective Loss 0.044542    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.628008    
2024-01-15 14:35:30,050 - --- validate (epoch=41)-----------
2024-01-15 14:35:30,052 - 6000 samples (256 per mini-batch)
2024-01-15 14:35:38,535 - Epoch: [41][   10/   24]    Loss 0.054331    Top1 98.593750    Top5 100.000000    
2024-01-15 14:35:40,879 - Epoch: [41][   20/   24]    Loss 0.048444    Top1 98.632812    Top5 100.000000    
2024-01-15 14:35:41,639 - Epoch: [41][   24/   24]    Loss 0.046867    Top1 98.650000    Top5 100.000000    
2024-01-15 14:35:42,555 - ==> Top1: 98.650    Top5: 100.000    Loss: 0.047

2024-01-15 14:35:42,557 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 682   1   0   1   0   2   2   0   0]
 [  1   0 582   0   0   0   1   1   0   1]
 [  0   0   1 578   0   2   0   1   1   0]
 [  0   0   1   0 557   0   1   0   0   6]
 [  1   0   1   0   0 510   5   0   1   0]
 [  3   0   0   0   1   2 624   0   1   0]
 [  0   0   9   1   2   0   0 613   0   0]
 [  1   0   1   0   3   0   8   1 568   2]
 [  0   0   0   1   5   1   0   4   2 602]]

2024-01-15 14:35:42,561 - ==> Best [Top1: 98.767   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 37]
2024-01-15 14:35:42,562 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:35:42,567 - 

2024-01-15 14:35:42,568 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:35:52,653 - Epoch: [42][   10/  211]    Overall Loss 0.036984    Objective Loss 0.036984                                        LR 0.100000    Time 1.008305    
2024-01-15 14:35:58,623 - Epoch: [42][   20/  211]    Overall Loss 0.039789    Objective Loss 0.039789                                        LR 0.100000    Time 0.802560    
2024-01-15 14:36:04,705 - Epoch: [42][   30/  211]    Overall Loss 0.043592    Objective Loss 0.043592                                        LR 0.100000    Time 0.737754    
2024-01-15 14:36:10,461 - Epoch: [42][   40/  211]    Overall Loss 0.044484    Objective Loss 0.044484                                        LR 0.100000    Time 0.697190    
2024-01-15 14:36:16,156 - Epoch: [42][   50/  211]    Overall Loss 0.045386    Objective Loss 0.045386                                        LR 0.100000    Time 0.671620    
2024-01-15 14:36:21,842 - Epoch: [42][   60/  211]    Overall Loss 0.045395    Objective Loss 0.045395                                        LR 0.100000    Time 0.654430    
2024-01-15 14:36:28,116 - Epoch: [42][   70/  211]    Overall Loss 0.044894    Objective Loss 0.044894                                        LR 0.100000    Time 0.650552    
2024-01-15 14:36:34,052 - Epoch: [42][   80/  211]    Overall Loss 0.044931    Objective Loss 0.044931                                        LR 0.100000    Time 0.643420    
2024-01-15 14:36:40,861 - Epoch: [42][   90/  211]    Overall Loss 0.043551    Objective Loss 0.043551                                        LR 0.100000    Time 0.647572    
2024-01-15 14:36:46,940 - Epoch: [42][  100/  211]    Overall Loss 0.043553    Objective Loss 0.043553                                        LR 0.100000    Time 0.643588    
2024-01-15 14:36:52,763 - Epoch: [42][  110/  211]    Overall Loss 0.043696    Objective Loss 0.043696                                        LR 0.100000    Time 0.638009    
2024-01-15 14:36:58,929 - Epoch: [42][  120/  211]    Overall Loss 0.043143    Objective Loss 0.043143                                        LR 0.100000    Time 0.636207    
2024-01-15 14:37:04,671 - Epoch: [42][  130/  211]    Overall Loss 0.043502    Objective Loss 0.043502                                        LR 0.100000    Time 0.631431    
2024-01-15 14:37:10,630 - Epoch: [42][  140/  211]    Overall Loss 0.043723    Objective Loss 0.043723                                        LR 0.100000    Time 0.628888    
2024-01-15 14:37:16,337 - Epoch: [42][  150/  211]    Overall Loss 0.044094    Objective Loss 0.044094                                        LR 0.100000    Time 0.624999    
2024-01-15 14:37:22,057 - Epoch: [42][  160/  211]    Overall Loss 0.044253    Objective Loss 0.044253                                        LR 0.100000    Time 0.621682    
2024-01-15 14:37:27,786 - Epoch: [42][  170/  211]    Overall Loss 0.044554    Objective Loss 0.044554                                        LR 0.100000    Time 0.618804    
2024-01-15 14:37:33,502 - Epoch: [42][  180/  211]    Overall Loss 0.044936    Objective Loss 0.044936                                        LR 0.100000    Time 0.616174    
2024-01-15 14:37:39,162 - Epoch: [42][  190/  211]    Overall Loss 0.044539    Objective Loss 0.044539                                        LR 0.100000    Time 0.613524    
2024-01-15 14:37:44,846 - Epoch: [42][  200/  211]    Overall Loss 0.044256    Objective Loss 0.044256                                        LR 0.100000    Time 0.611263    
2024-01-15 14:37:50,512 - Epoch: [42][  210/  211]    Overall Loss 0.044378    Objective Loss 0.044378    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.609133    
2024-01-15 14:37:51,097 - Epoch: [42][  211/  211]    Overall Loss 0.044362    Objective Loss 0.044362    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.609013    
2024-01-15 14:37:52,021 - --- validate (epoch=42)-----------
2024-01-15 14:37:52,023 - 6000 samples (256 per mini-batch)
2024-01-15 14:37:59,106 - Epoch: [42][   10/   24]    Loss 0.041251    Top1 98.867188    Top5 100.000000    
2024-01-15 14:38:01,237 - Epoch: [42][   20/   24]    Loss 0.042293    Top1 98.808594    Top5 100.000000    
2024-01-15 14:38:01,992 - Epoch: [42][   24/   24]    Loss 0.043719    Top1 98.750000    Top5 99.983333    
2024-01-15 14:38:02,739 - ==> Top1: 98.750    Top5: 99.983    Loss: 0.044

2024-01-15 14:38:02,740 - ==> Confusion:
[[599   0   0   0   0   0   4   0   0   2]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   1 577   1   0   0   0   3   3   1]
 [  0   0   2 577   1   0   0   1   2   0]
 [  0   1   1   0 556   1   0   0   1   5]
 [  0   1   0   0   0 512   1   0   3   1]
 [  0   1   1   0   3   0 626   0   0   0]
 [  0   3   3   1   5   0   0 613   0   0]
 [  1   0   0   2   0   1   3   0 577   0]
 [  1   2   0   0   5   3   0   1   3 600]]

2024-01-15 14:38:02,742 - ==> Best [Top1: 98.767   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 37]
2024-01-15 14:38:02,742 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:38:02,746 - 

2024-01-15 14:38:02,746 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:38:11,604 - Epoch: [43][   10/  211]    Overall Loss 0.039205    Objective Loss 0.039205                                        LR 0.100000    Time 0.885665    
2024-01-15 14:38:17,369 - Epoch: [43][   20/  211]    Overall Loss 0.042736    Objective Loss 0.042736                                        LR 0.100000    Time 0.731036    
2024-01-15 14:38:23,320 - Epoch: [43][   30/  211]    Overall Loss 0.044536    Objective Loss 0.044536                                        LR 0.100000    Time 0.685685    
2024-01-15 14:38:30,351 - Epoch: [43][   40/  211]    Overall Loss 0.043750    Objective Loss 0.043750                                        LR 0.100000    Time 0.689955    
2024-01-15 14:38:36,624 - Epoch: [43][   50/  211]    Overall Loss 0.042854    Objective Loss 0.042854                                        LR 0.100000    Time 0.677406    
2024-01-15 14:38:42,914 - Epoch: [43][   60/  211]    Overall Loss 0.044069    Objective Loss 0.044069                                        LR 0.100000    Time 0.669291    
2024-01-15 14:38:48,774 - Epoch: [43][   70/  211]    Overall Loss 0.044533    Objective Loss 0.044533                                        LR 0.100000    Time 0.657383    
2024-01-15 14:38:54,429 - Epoch: [43][   80/  211]    Overall Loss 0.045335    Objective Loss 0.045335                                        LR 0.100000    Time 0.645887    
2024-01-15 14:39:00,517 - Epoch: [43][   90/  211]    Overall Loss 0.045894    Objective Loss 0.045894                                        LR 0.100000    Time 0.641753    
2024-01-15 14:39:06,195 - Epoch: [43][  100/  211]    Overall Loss 0.046068    Objective Loss 0.046068                                        LR 0.100000    Time 0.634343    
2024-01-15 14:39:11,898 - Epoch: [43][  110/  211]    Overall Loss 0.046071    Objective Loss 0.046071                                        LR 0.100000    Time 0.628516    
2024-01-15 14:39:17,679 - Epoch: [43][  120/  211]    Overall Loss 0.045767    Objective Loss 0.045767                                        LR 0.100000    Time 0.624300    
2024-01-15 14:39:23,339 - Epoch: [43][  130/  211]    Overall Loss 0.045925    Objective Loss 0.045925                                        LR 0.100000    Time 0.619817    
2024-01-15 14:39:29,033 - Epoch: [43][  140/  211]    Overall Loss 0.046526    Objective Loss 0.046526                                        LR 0.100000    Time 0.616208    
2024-01-15 14:39:34,692 - Epoch: [43][  150/  211]    Overall Loss 0.046653    Objective Loss 0.046653                                        LR 0.100000    Time 0.612847    
2024-01-15 14:39:40,337 - Epoch: [43][  160/  211]    Overall Loss 0.046307    Objective Loss 0.046307                                        LR 0.100000    Time 0.609821    
2024-01-15 14:39:45,999 - Epoch: [43][  170/  211]    Overall Loss 0.046124    Objective Loss 0.046124                                        LR 0.100000    Time 0.607248    
2024-01-15 14:39:51,728 - Epoch: [43][  180/  211]    Overall Loss 0.045700    Objective Loss 0.045700                                        LR 0.100000    Time 0.605336    
2024-01-15 14:39:57,570 - Epoch: [43][  190/  211]    Overall Loss 0.045057    Objective Loss 0.045057                                        LR 0.100000    Time 0.604216    
2024-01-15 14:40:03,336 - Epoch: [43][  200/  211]    Overall Loss 0.044860    Objective Loss 0.044860                                        LR 0.100000    Time 0.602830    
2024-01-15 14:40:09,074 - Epoch: [43][  210/  211]    Overall Loss 0.044993    Objective Loss 0.044993    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.601443    
2024-01-15 14:40:09,658 - Epoch: [43][  211/  211]    Overall Loss 0.045019    Objective Loss 0.045019    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.601358    
2024-01-15 14:40:10,445 - --- validate (epoch=43)-----------
2024-01-15 14:40:10,446 - 6000 samples (256 per mini-batch)
2024-01-15 14:40:16,963 - Epoch: [43][   10/   24]    Loss 0.038269    Top1 98.828125    Top5 100.000000    
2024-01-15 14:40:19,068 - Epoch: [43][   20/   24]    Loss 0.036551    Top1 98.867188    Top5 99.980469    
2024-01-15 14:40:19,894 - Epoch: [43][   24/   24]    Loss 0.040581    Top1 98.733333    Top5 99.983333    
2024-01-15 14:40:20,511 - ==> Top1: 98.733    Top5: 99.983    Loss: 0.041

2024-01-15 14:40:20,512 - ==> Confusion:
[[602   0   1   0   0   0   1   0   1   0]
 [  0 685   1   0   0   1   0   1   0   0]
 [  0   1 576   1   0   0   1   5   1   1]
 [  0   0   1 578   0   2   0   0   2   0]
 [  0   1   1   0 550   1   1   1   1   9]
 [  1   1   0   1   0 508   5   1   1   0]
 [  2   1   0   0   1   1 624   0   2   0]
 [  0   2   2   0   1   1   0 619   0   0]
 [  1   0   0   0   1   2   3   0 576   1]
 [  0   3   1   0   0   0   0   3   2 606]]

2024-01-15 14:40:20,514 - ==> Best [Top1: 98.767   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 37]
2024-01-15 14:40:20,514 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:40:20,518 - 

2024-01-15 14:40:20,518 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:40:29,267 - Epoch: [44][   10/  211]    Overall Loss 0.040536    Objective Loss 0.040536                                        LR 0.100000    Time 0.874802    
2024-01-15 14:40:34,986 - Epoch: [44][   20/  211]    Overall Loss 0.042957    Objective Loss 0.042957                                        LR 0.100000    Time 0.723310    
2024-01-15 14:40:40,673 - Epoch: [44][   30/  211]    Overall Loss 0.040795    Objective Loss 0.040795                                        LR 0.100000    Time 0.671736    
2024-01-15 14:40:46,316 - Epoch: [44][   40/  211]    Overall Loss 0.040580    Objective Loss 0.040580                                        LR 0.100000    Time 0.644869    
2024-01-15 14:40:52,040 - Epoch: [44][   50/  211]    Overall Loss 0.039648    Objective Loss 0.039648                                        LR 0.100000    Time 0.630351    
2024-01-15 14:40:57,870 - Epoch: [44][   60/  211]    Overall Loss 0.040069    Objective Loss 0.040069                                        LR 0.100000    Time 0.622438    
2024-01-15 14:41:03,579 - Epoch: [44][   70/  211]    Overall Loss 0.042292    Objective Loss 0.042292                                        LR 0.100000    Time 0.615064    
2024-01-15 14:41:09,275 - Epoch: [44][   80/  211]    Overall Loss 0.042455    Objective Loss 0.042455                                        LR 0.100000    Time 0.609367    
2024-01-15 14:41:14,975 - Epoch: [44][   90/  211]    Overall Loss 0.043291    Objective Loss 0.043291                                        LR 0.100000    Time 0.604985    
2024-01-15 14:41:20,650 - Epoch: [44][  100/  211]    Overall Loss 0.043580    Objective Loss 0.043580                                        LR 0.100000    Time 0.601225    
2024-01-15 14:41:26,331 - Epoch: [44][  110/  211]    Overall Loss 0.043182    Objective Loss 0.043182                                        LR 0.100000    Time 0.598213    
2024-01-15 14:41:32,027 - Epoch: [44][  120/  211]    Overall Loss 0.042922    Objective Loss 0.042922                                        LR 0.100000    Time 0.595818    
2024-01-15 14:41:37,685 - Epoch: [44][  130/  211]    Overall Loss 0.043446    Objective Loss 0.043446                                        LR 0.100000    Time 0.593504    
2024-01-15 14:41:43,381 - Epoch: [44][  140/  211]    Overall Loss 0.043721    Objective Loss 0.043721                                        LR 0.100000    Time 0.591792    
2024-01-15 14:41:49,173 - Epoch: [44][  150/  211]    Overall Loss 0.044093    Objective Loss 0.044093                                        LR 0.100000    Time 0.590943    
2024-01-15 14:41:54,869 - Epoch: [44][  160/  211]    Overall Loss 0.044354    Objective Loss 0.044354                                        LR 0.100000    Time 0.589599    
2024-01-15 14:42:00,802 - Epoch: [44][  170/  211]    Overall Loss 0.045343    Objective Loss 0.045343                                        LR 0.100000    Time 0.589814    
2024-01-15 14:42:06,786 - Epoch: [44][  180/  211]    Overall Loss 0.046214    Objective Loss 0.046214                                        LR 0.100000    Time 0.590279    
2024-01-15 14:42:12,507 - Epoch: [44][  190/  211]    Overall Loss 0.046200    Objective Loss 0.046200                                        LR 0.100000    Time 0.589319    
2024-01-15 14:42:18,213 - Epoch: [44][  200/  211]    Overall Loss 0.046026    Objective Loss 0.046026                                        LR 0.100000    Time 0.588375    
2024-01-15 14:42:23,988 - Epoch: [44][  210/  211]    Overall Loss 0.045682    Objective Loss 0.045682    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.587852    
2024-01-15 14:42:24,560 - Epoch: [44][  211/  211]    Overall Loss 0.045605    Objective Loss 0.045605    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.587778    
2024-01-15 14:42:25,193 - --- validate (epoch=44)-----------
2024-01-15 14:42:25,195 - 6000 samples (256 per mini-batch)
2024-01-15 14:42:30,412 - Epoch: [44][   10/   24]    Loss 0.048712    Top1 98.828125    Top5 100.000000    
2024-01-15 14:42:32,550 - Epoch: [44][   20/   24]    Loss 0.045046    Top1 98.867188    Top5 99.980469    
2024-01-15 14:42:33,397 - Epoch: [44][   24/   24]    Loss 0.043430    Top1 98.900000    Top5 99.983333    
2024-01-15 14:42:34,228 - ==> Top1: 98.900    Top5: 99.983    Loss: 0.043

2024-01-15 14:42:34,229 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 687   0   0   1   0   0   0   0   0]
 [  0   0 581   1   0   0   0   3   1   0]
 [  0   0   1 574   0   5   0   0   3   0]
 [  0   1   1   0 551   0   2   1   0   9]
 [  2   0   0   1   0 510   3   0   2   0]
 [  0   2   0   0   2   1 625   0   1   0]
 [  0   4   1   0   0   0   0 620   0   0]
 [  2   0   1   0   0   2   1   0 578   0]
 [  0   1   0   1   0   2   0   3   2 606]]

2024-01-15 14:42:34,232 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 14:42:34,233 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:42:34,244 - 

2024-01-15 14:42:34,245 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:42:44,890 - Epoch: [45][   10/  211]    Overall Loss 0.041337    Objective Loss 0.041337                                        LR 0.100000    Time 1.064364    
2024-01-15 14:42:50,817 - Epoch: [45][   20/  211]    Overall Loss 0.039583    Objective Loss 0.039583                                        LR 0.100000    Time 0.828373    
2024-01-15 14:42:57,177 - Epoch: [45][   30/  211]    Overall Loss 0.041297    Objective Loss 0.041297                                        LR 0.100000    Time 0.764209    
2024-01-15 14:43:03,154 - Epoch: [45][   40/  211]    Overall Loss 0.039286    Objective Loss 0.039286                                        LR 0.100000    Time 0.722540    
2024-01-15 14:43:09,219 - Epoch: [45][   50/  211]    Overall Loss 0.041948    Objective Loss 0.041948                                        LR 0.100000    Time 0.699300    
2024-01-15 14:43:15,211 - Epoch: [45][   60/  211]    Overall Loss 0.041541    Objective Loss 0.041541                                        LR 0.100000    Time 0.682590    
2024-01-15 14:43:21,300 - Epoch: [45][   70/  211]    Overall Loss 0.042281    Objective Loss 0.042281                                        LR 0.100000    Time 0.672031    
2024-01-15 14:43:27,255 - Epoch: [45][   80/  211]    Overall Loss 0.042097    Objective Loss 0.042097                                        LR 0.100000    Time 0.662448    
2024-01-15 14:43:33,145 - Epoch: [45][   90/  211]    Overall Loss 0.042445    Objective Loss 0.042445                                        LR 0.100000    Time 0.654270    
2024-01-15 14:43:39,102 - Epoch: [45][  100/  211]    Overall Loss 0.043171    Objective Loss 0.043171                                        LR 0.100000    Time 0.648393    
2024-01-15 14:43:44,902 - Epoch: [45][  110/  211]    Overall Loss 0.042067    Objective Loss 0.042067                                        LR 0.100000    Time 0.642169    
2024-01-15 14:43:50,717 - Epoch: [45][  120/  211]    Overall Loss 0.041843    Objective Loss 0.041843                                        LR 0.100000    Time 0.637106    
2024-01-15 14:43:56,557 - Epoch: [45][  130/  211]    Overall Loss 0.042018    Objective Loss 0.042018                                        LR 0.100000    Time 0.633020    
2024-01-15 14:44:02,612 - Epoch: [45][  140/  211]    Overall Loss 0.042905    Objective Loss 0.042905                                        LR 0.100000    Time 0.631045    
2024-01-15 14:44:08,260 - Epoch: [45][  150/  211]    Overall Loss 0.043151    Objective Loss 0.043151                                        LR 0.100000    Time 0.626620    
2024-01-15 14:44:14,285 - Epoch: [45][  160/  211]    Overall Loss 0.043264    Objective Loss 0.043264                                        LR 0.100000    Time 0.625109    
2024-01-15 14:44:20,214 - Epoch: [45][  170/  211]    Overall Loss 0.043940    Objective Loss 0.043940                                        LR 0.100000    Time 0.623201    
2024-01-15 14:44:26,196 - Epoch: [45][  180/  211]    Overall Loss 0.043900    Objective Loss 0.043900                                        LR 0.100000    Time 0.621801    
2024-01-15 14:44:32,141 - Epoch: [45][  190/  211]    Overall Loss 0.044161    Objective Loss 0.044161                                        LR 0.100000    Time 0.620359    
2024-01-15 14:44:38,133 - Epoch: [45][  200/  211]    Overall Loss 0.043720    Objective Loss 0.043720                                        LR 0.100000    Time 0.619295    
2024-01-15 14:44:44,027 - Epoch: [45][  210/  211]    Overall Loss 0.043908    Objective Loss 0.043908    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.617863    
2024-01-15 14:44:44,587 - Epoch: [45][  211/  211]    Overall Loss 0.043804    Objective Loss 0.043804    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.617584    
2024-01-15 14:44:45,404 - --- validate (epoch=45)-----------
2024-01-15 14:44:45,405 - 6000 samples (256 per mini-batch)
2024-01-15 14:44:51,951 - Epoch: [45][   10/   24]    Loss 0.052968    Top1 98.242188    Top5 99.960938    
2024-01-15 14:44:54,182 - Epoch: [45][   20/   24]    Loss 0.050032    Top1 98.398438    Top5 99.980469    
2024-01-15 14:44:54,964 - Epoch: [45][   24/   24]    Loss 0.049955    Top1 98.416667    Top5 99.983333    
2024-01-15 14:44:55,712 - ==> Top1: 98.417    Top5: 99.983    Loss: 0.050

2024-01-15 14:44:55,712 - ==> Confusion:
[[602   0   0   0   0   0   3   0   0   0]
 [  0 680   1   1   0   0   3   3   0   0]
 [  0   0 579   2   1   0   0   1   3   0]
 [  0   0   2 577   0   2   0   1   1   0]
 [  0   0   3   0 540   0   4   2   2  14]
 [  0   0   0   1   0 512   5   0   0   0]
 [  1   0   0   0   0   0 630   0   0   0]
 [  1   2   8   4   0   0   0 610   0   0]
 [  2   0   1   2   2   1   3   0 573   0]
 [  1   1   3   1   0   2   0   0   5 602]]

2024-01-15 14:44:55,714 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 14:44:55,714 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:44:55,718 - 

2024-01-15 14:44:55,718 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:45:04,805 - Epoch: [46][   10/  211]    Overall Loss 0.045551    Objective Loss 0.045551                                        LR 0.100000    Time 0.908575    
2024-01-15 14:45:10,516 - Epoch: [46][   20/  211]    Overall Loss 0.041319    Objective Loss 0.041319                                        LR 0.100000    Time 0.739762    
2024-01-15 14:45:16,294 - Epoch: [46][   30/  211]    Overall Loss 0.046162    Objective Loss 0.046162                                        LR 0.100000    Time 0.685755    
2024-01-15 14:45:21,996 - Epoch: [46][   40/  211]    Overall Loss 0.044726    Objective Loss 0.044726                                        LR 0.100000    Time 0.656842    
2024-01-15 14:45:27,685 - Epoch: [46][   50/  211]    Overall Loss 0.044833    Objective Loss 0.044833                                        LR 0.100000    Time 0.639234    
2024-01-15 14:45:33,635 - Epoch: [46][   60/  211]    Overall Loss 0.044614    Objective Loss 0.044614                                        LR 0.100000    Time 0.631850    
2024-01-15 14:45:39,318 - Epoch: [46][   70/  211]    Overall Loss 0.044060    Objective Loss 0.044060                                        LR 0.100000    Time 0.622755    
2024-01-15 14:45:45,068 - Epoch: [46][   80/  211]    Overall Loss 0.043797    Objective Loss 0.043797                                        LR 0.100000    Time 0.616777    
2024-01-15 14:45:50,915 - Epoch: [46][   90/  211]    Overall Loss 0.043794    Objective Loss 0.043794                                        LR 0.100000    Time 0.613201    
2024-01-15 14:45:56,768 - Epoch: [46][  100/  211]    Overall Loss 0.044045    Objective Loss 0.044045                                        LR 0.100000    Time 0.610402    
2024-01-15 14:46:02,693 - Epoch: [46][  110/  211]    Overall Loss 0.043924    Objective Loss 0.043924                                        LR 0.100000    Time 0.608761    
2024-01-15 14:46:08,594 - Epoch: [46][  120/  211]    Overall Loss 0.044471    Objective Loss 0.044471                                        LR 0.100000    Time 0.607196    
2024-01-15 14:46:14,297 - Epoch: [46][  130/  211]    Overall Loss 0.045564    Objective Loss 0.045564                                        LR 0.100000    Time 0.604354    
2024-01-15 14:46:20,009 - Epoch: [46][  140/  211]    Overall Loss 0.045670    Objective Loss 0.045670                                        LR 0.100000    Time 0.601976    
2024-01-15 14:46:25,826 - Epoch: [46][  150/  211]    Overall Loss 0.045124    Objective Loss 0.045124                                        LR 0.100000    Time 0.600619    
2024-01-15 14:46:31,613 - Epoch: [46][  160/  211]    Overall Loss 0.044979    Objective Loss 0.044979                                        LR 0.100000    Time 0.599243    
2024-01-15 14:46:37,399 - Epoch: [46][  170/  211]    Overall Loss 0.044814    Objective Loss 0.044814                                        LR 0.100000    Time 0.598024    
2024-01-15 14:46:43,188 - Epoch: [46][  180/  211]    Overall Loss 0.044431    Objective Loss 0.044431                                        LR 0.100000    Time 0.596956    
2024-01-15 14:46:50,208 - Epoch: [46][  190/  211]    Overall Loss 0.044267    Objective Loss 0.044267                                        LR 0.100000    Time 0.602480    
2024-01-15 14:46:58,601 - Epoch: [46][  200/  211]    Overall Loss 0.043997    Objective Loss 0.043997                                        LR 0.100000    Time 0.614312    
2024-01-15 14:47:04,506 - Epoch: [46][  210/  211]    Overall Loss 0.044626    Objective Loss 0.044626    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.613176    
2024-01-15 14:47:05,082 - Epoch: [46][  211/  211]    Overall Loss 0.044597    Objective Loss 0.044597    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.612998    
2024-01-15 14:47:05,929 - --- validate (epoch=46)-----------
2024-01-15 14:47:05,931 - 6000 samples (256 per mini-batch)
2024-01-15 14:47:12,639 - Epoch: [46][   10/   24]    Loss 0.046747    Top1 98.554688    Top5 100.000000    
2024-01-15 14:47:14,765 - Epoch: [46][   20/   24]    Loss 0.053951    Top1 98.496094    Top5 99.960938    
2024-01-15 14:47:15,530 - Epoch: [46][   24/   24]    Loss 0.057285    Top1 98.483333    Top5 99.966667    
2024-01-15 14:47:16,144 - ==> Top1: 98.483    Top5: 99.967    Loss: 0.057

2024-01-15 14:47:16,144 - ==> Confusion:
[[601   0   2   0   0   1   1   0   0   0]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   0 573   6   0   0   0   5   1   1]
 [  0   0   2 579   0   1   0   0   1   0]
 [  2   1   2   0 542   1   2   2   0  13]
 [  0   0   1   5   0 507   2   2   1   0]
 [  0   1   0   0   2   1 624   0   3   0]
 [  0   0   0   0   0   0   0 625   0   0]
 [  0   0   0   7   0   2   2   1 570   2]
 [  0   1   0   1   1   3   0   5   2 602]]

2024-01-15 14:47:16,146 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 14:47:16,146 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:47:16,150 - 

2024-01-15 14:47:16,151 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:47:25,084 - Epoch: [47][   10/  211]    Overall Loss 0.051489    Objective Loss 0.051489                                        LR 0.100000    Time 0.893269    
2024-01-15 14:47:31,050 - Epoch: [47][   20/  211]    Overall Loss 0.044192    Objective Loss 0.044192                                        LR 0.100000    Time 0.744843    
2024-01-15 14:47:36,756 - Epoch: [47][   30/  211]    Overall Loss 0.041167    Objective Loss 0.041167                                        LR 0.100000    Time 0.686736    
2024-01-15 14:47:56,582 - Epoch: [47][   40/  211]    Overall Loss 0.041469    Objective Loss 0.041469                                        LR 0.100000    Time 1.010692    
2024-01-15 14:48:02,302 - Epoch: [47][   50/  211]    Overall Loss 0.042438    Objective Loss 0.042438                                        LR 0.100000    Time 0.922935    
2024-01-15 14:48:07,990 - Epoch: [47][   60/  211]    Overall Loss 0.041509    Objective Loss 0.041509                                        LR 0.100000    Time 0.863900    
2024-01-15 14:48:13,896 - Epoch: [47][   70/  211]    Overall Loss 0.041927    Objective Loss 0.041927                                        LR 0.100000    Time 0.824836    
2024-01-15 14:48:19,538 - Epoch: [47][   80/  211]    Overall Loss 0.040903    Objective Loss 0.040903                                        LR 0.100000    Time 0.792247    
2024-01-15 14:48:25,183 - Epoch: [47][   90/  211]    Overall Loss 0.041828    Objective Loss 0.041828                                        LR 0.100000    Time 0.766941    
2024-01-15 14:48:30,830 - Epoch: [47][  100/  211]    Overall Loss 0.041149    Objective Loss 0.041149                                        LR 0.100000    Time 0.746698    
2024-01-15 14:48:36,473 - Epoch: [47][  110/  211]    Overall Loss 0.041041    Objective Loss 0.041041                                        LR 0.100000    Time 0.730115    
2024-01-15 14:48:42,140 - Epoch: [47][  120/  211]    Overall Loss 0.041123    Objective Loss 0.041123                                        LR 0.100000    Time 0.716490    
2024-01-15 14:50:33,759 - Epoch: [47][  130/  211]    Overall Loss 0.041672    Objective Loss 0.041672                                        LR 0.100000    Time 1.519951    
2024-01-15 14:50:40,351 - Epoch: [47][  140/  211]    Overall Loss 0.042808    Objective Loss 0.042808                                        LR 0.100000    Time 1.458452    
2024-01-15 14:50:46,263 - Epoch: [47][  150/  211]    Overall Loss 0.043532    Objective Loss 0.043532                                        LR 0.100000    Time 1.400627    
2024-01-15 14:50:51,963 - Epoch: [47][  160/  211]    Overall Loss 0.044729    Objective Loss 0.044729                                        LR 0.100000    Time 1.348705    
2024-01-15 14:50:57,985 - Epoch: [47][  170/  211]    Overall Loss 0.045011    Objective Loss 0.045011                                        LR 0.100000    Time 1.304787    
2024-01-15 14:51:03,838 - Epoch: [47][  180/  211]    Overall Loss 0.045260    Objective Loss 0.045260                                        LR 0.100000    Time 1.264809    
2024-01-15 14:51:09,590 - Epoch: [47][  190/  211]    Overall Loss 0.045656    Objective Loss 0.045656                                        LR 0.100000    Time 1.228511    
2024-01-15 14:51:15,411 - Epoch: [47][  200/  211]    Overall Loss 0.046385    Objective Loss 0.046385                                        LR 0.100000    Time 1.196159    
2024-01-15 14:51:21,250 - Epoch: [47][  210/  211]    Overall Loss 0.046545    Objective Loss 0.046545    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 1.166994    
2024-01-15 14:51:21,844 - Epoch: [47][  211/  211]    Overall Loss 0.046717    Objective Loss 0.046717    Top1 97.782258    Top5 100.000000    LR 0.100000    Time 1.164270    
2024-01-15 14:51:22,844 - --- validate (epoch=47)-----------
2024-01-15 14:51:22,847 - 6000 samples (256 per mini-batch)
2024-01-15 14:51:29,678 - Epoch: [47][   10/   24]    Loss 0.046831    Top1 98.671875    Top5 100.000000    
2024-01-15 14:51:31,808 - Epoch: [47][   20/   24]    Loss 0.055971    Top1 98.359375    Top5 100.000000    
2024-01-15 14:51:32,576 - Epoch: [47][   24/   24]    Loss 0.054131    Top1 98.450000    Top5 100.000000    
2024-01-15 14:51:33,307 - ==> Top1: 98.450    Top5: 100.000    Loss: 0.054

2024-01-15 14:51:33,309 - ==> Confusion:
[[601   0   0   1   0   1   1   0   1   0]
 [  0 684   1   1   1   1   0   0   0   0]
 [  1   0 569   3   0   0   2   1  10   0]
 [  0   0   1 576   1   2   0   1   1   1]
 [  0   0   0   0 554   0   0   1   2   8]
 [  0   0   0   2   0 511   3   0   1   1]
 [  0   1   0   0   1   0 628   0   1   0]
 [  1   6   3   2   2   0   0 603   1   7]
 [  1   0   0   1   0   0   3   0 578   1]
 [  0   1   0   0   5   1   0   0   5 603]]

2024-01-15 14:51:33,311 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 14:51:33,312 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:51:33,316 - 

2024-01-15 14:51:33,316 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:51:45,196 - Epoch: [48][   10/  211]    Overall Loss 0.044900    Objective Loss 0.044900                                        LR 0.100000    Time 1.187855    
2024-01-15 14:51:51,029 - Epoch: [48][   20/  211]    Overall Loss 0.044866    Objective Loss 0.044866                                        LR 0.100000    Time 0.885494    
2024-01-15 14:51:57,354 - Epoch: [48][   30/  211]    Overall Loss 0.042940    Objective Loss 0.042940                                        LR 0.100000    Time 0.801142    
2024-01-15 14:52:03,092 - Epoch: [48][   40/  211]    Overall Loss 0.044606    Objective Loss 0.044606                                        LR 0.100000    Time 0.744260    
2024-01-15 14:52:08,941 - Epoch: [48][   50/  211]    Overall Loss 0.044562    Objective Loss 0.044562                                        LR 0.100000    Time 0.712379    
2024-01-15 14:52:14,829 - Epoch: [48][   60/  211]    Overall Loss 0.043574    Objective Loss 0.043574                                        LR 0.100000    Time 0.691764    
2024-01-15 14:52:20,621 - Epoch: [48][   70/  211]    Overall Loss 0.043791    Objective Loss 0.043791                                        LR 0.100000    Time 0.675669    
2024-01-15 14:52:26,615 - Epoch: [48][   80/  211]    Overall Loss 0.044514    Objective Loss 0.044514                                        LR 0.100000    Time 0.666108    
2024-01-15 14:52:32,315 - Epoch: [48][   90/  211]    Overall Loss 0.043775    Objective Loss 0.043775                                        LR 0.100000    Time 0.655412    
2024-01-15 14:52:38,062 - Epoch: [48][  100/  211]    Overall Loss 0.044544    Objective Loss 0.044544                                        LR 0.100000    Time 0.647327    
2024-01-15 14:52:43,788 - Epoch: [48][  110/  211]    Overall Loss 0.044058    Objective Loss 0.044058                                        LR 0.100000    Time 0.640530    
2024-01-15 14:52:49,726 - Epoch: [48][  120/  211]    Overall Loss 0.044149    Objective Loss 0.044149                                        LR 0.100000    Time 0.636621    
2024-01-15 14:52:55,630 - Epoch: [48][  130/  211]    Overall Loss 0.043772    Objective Loss 0.043772                                        LR 0.100000    Time 0.633056    
2024-01-15 14:53:01,431 - Epoch: [48][  140/  211]    Overall Loss 0.043653    Objective Loss 0.043653                                        LR 0.100000    Time 0.629264    
2024-01-15 14:53:07,134 - Epoch: [48][  150/  211]    Overall Loss 0.043346    Objective Loss 0.043346                                        LR 0.100000    Time 0.625329    
2024-01-15 14:53:12,804 - Epoch: [48][  160/  211]    Overall Loss 0.043210    Objective Loss 0.043210                                        LR 0.100000    Time 0.621677    
2024-01-15 14:53:18,466 - Epoch: [48][  170/  211]    Overall Loss 0.043470    Objective Loss 0.043470                                        LR 0.100000    Time 0.618409    
2024-01-15 14:53:24,400 - Epoch: [48][  180/  211]    Overall Loss 0.043667    Objective Loss 0.043667                                        LR 0.100000    Time 0.617013    
2024-01-15 14:53:30,126 - Epoch: [48][  190/  211]    Overall Loss 0.043729    Objective Loss 0.043729                                        LR 0.100000    Time 0.614666    
2024-01-15 14:53:36,606 - Epoch: [48][  200/  211]    Overall Loss 0.044034    Objective Loss 0.044034                                        LR 0.100000    Time 0.616325    
2024-01-15 14:53:42,874 - Epoch: [48][  210/  211]    Overall Loss 0.044256    Objective Loss 0.044256    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.616819    
2024-01-15 14:53:43,428 - Epoch: [48][  211/  211]    Overall Loss 0.044163    Objective Loss 0.044163    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.616519    
2024-01-15 14:53:44,269 - --- validate (epoch=48)-----------
2024-01-15 14:53:44,270 - 6000 samples (256 per mini-batch)
2024-01-15 14:53:51,048 - Epoch: [48][   10/   24]    Loss 0.058738    Top1 98.203125    Top5 100.000000    
2024-01-15 14:53:53,161 - Epoch: [48][   20/   24]    Loss 0.050662    Top1 98.593750    Top5 99.960938    
2024-01-15 14:53:53,912 - Epoch: [48][   24/   24]    Loss 0.047517    Top1 98.700000    Top5 99.966667    
2024-01-15 14:53:54,487 - ==> Top1: 98.700    Top5: 99.967    Loss: 0.048

2024-01-15 14:53:54,488 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 685   0   0   0   1   0   2   0   0]
 [  0   3 578   0   0   0   0   4   0   1]
 [  1   2   2 574   0   2   0   1   1   0]
 [  1   1   0   0 556   0   0   2   0   5]
 [  0   0   0   2   0 509   6   0   0   1]
 [  0   3   0   0   2   1 625   0   0   0]
 [  0   4   1   2   0   0   0 618   0   0]
 [  2   0   0   2   0   0   4   1 574   1]
 [  0   1   0   0   6   2   0   3   2 601]]

2024-01-15 14:53:54,490 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 14:53:54,490 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:53:54,494 - 

2024-01-15 14:53:54,494 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:54:02,875 - Epoch: [49][   10/  211]    Overall Loss 0.058495    Objective Loss 0.058495                                        LR 0.100000    Time 0.838027    
2024-01-15 14:54:08,542 - Epoch: [49][   20/  211]    Overall Loss 0.051013    Objective Loss 0.051013                                        LR 0.100000    Time 0.702299    
2024-01-15 14:54:14,170 - Epoch: [49][   30/  211]    Overall Loss 0.050272    Objective Loss 0.050272                                        LR 0.100000    Time 0.655772    
2024-01-15 14:54:19,809 - Epoch: [49][   40/  211]    Overall Loss 0.050903    Objective Loss 0.050903                                        LR 0.100000    Time 0.632787    
2024-01-15 14:54:25,556 - Epoch: [49][   50/  211]    Overall Loss 0.049765    Objective Loss 0.049765                                        LR 0.100000    Time 0.621150    
2024-01-15 14:54:31,331 - Epoch: [49][   60/  211]    Overall Loss 0.049283    Objective Loss 0.049283                                        LR 0.100000    Time 0.613853    
2024-01-15 14:54:36,969 - Epoch: [49][   70/  211]    Overall Loss 0.049216    Objective Loss 0.049216                                        LR 0.100000    Time 0.606691    
2024-01-15 14:54:42,645 - Epoch: [49][   80/  211]    Overall Loss 0.048827    Objective Loss 0.048827                                        LR 0.100000    Time 0.601799    
2024-01-15 14:54:48,382 - Epoch: [49][   90/  211]    Overall Loss 0.047630    Objective Loss 0.047630                                        LR 0.100000    Time 0.598663    
2024-01-15 14:54:54,070 - Epoch: [49][  100/  211]    Overall Loss 0.048686    Objective Loss 0.048686                                        LR 0.100000    Time 0.595671    
2024-01-15 14:55:00,113 - Epoch: [49][  110/  211]    Overall Loss 0.047938    Objective Loss 0.047938                                        LR 0.100000    Time 0.596446    
2024-01-15 14:55:05,821 - Epoch: [49][  120/  211]    Overall Loss 0.047658    Objective Loss 0.047658                                        LR 0.100000    Time 0.594293    
2024-01-15 14:55:11,686 - Epoch: [49][  130/  211]    Overall Loss 0.047351    Objective Loss 0.047351                                        LR 0.100000    Time 0.593679    
2024-01-15 14:55:17,717 - Epoch: [49][  140/  211]    Overall Loss 0.046899    Objective Loss 0.046899                                        LR 0.100000    Time 0.594342    
2024-01-15 14:55:23,522 - Epoch: [49][  150/  211]    Overall Loss 0.046632    Objective Loss 0.046632                                        LR 0.100000    Time 0.593412    
2024-01-15 14:55:29,352 - Epoch: [49][  160/  211]    Overall Loss 0.046463    Objective Loss 0.046463                                        LR 0.100000    Time 0.592755    
2024-01-15 14:55:35,013 - Epoch: [49][  170/  211]    Overall Loss 0.045761    Objective Loss 0.045761                                        LR 0.100000    Time 0.591181    
2024-01-15 14:55:40,680 - Epoch: [49][  180/  211]    Overall Loss 0.045303    Objective Loss 0.045303                                        LR 0.100000    Time 0.589817    
2024-01-15 14:55:46,495 - Epoch: [49][  190/  211]    Overall Loss 0.044698    Objective Loss 0.044698                                        LR 0.100000    Time 0.589374    
2024-01-15 14:55:52,197 - Epoch: [49][  200/  211]    Overall Loss 0.045063    Objective Loss 0.045063                                        LR 0.100000    Time 0.588410    
2024-01-15 14:55:58,058 - Epoch: [49][  210/  211]    Overall Loss 0.045333    Objective Loss 0.045333    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.588293    
2024-01-15 14:55:58,691 - Epoch: [49][  211/  211]    Overall Loss 0.045265    Objective Loss 0.045265    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.588505    
2024-01-15 14:55:59,517 - --- validate (epoch=49)-----------
2024-01-15 14:55:59,519 - 6000 samples (256 per mini-batch)
2024-01-15 14:56:06,303 - Epoch: [49][   10/   24]    Loss 0.045784    Top1 98.671875    Top5 99.960938    
2024-01-15 14:56:08,440 - Epoch: [49][   20/   24]    Loss 0.041142    Top1 98.847656    Top5 99.980469    
2024-01-15 14:56:09,187 - Epoch: [49][   24/   24]    Loss 0.044803    Top1 98.750000    Top5 99.983333    
2024-01-15 14:56:09,852 - ==> Top1: 98.750    Top5: 99.983    Loss: 0.045

2024-01-15 14:56:09,853 - ==> Confusion:
[[601   0   0   0   0   0   2   0   2   0]
 [  0 684   0   1   0   1   0   2   0   0]
 [  1   0 584   1   0   0   0   0   0   0]
 [  0   0   1 581   0   1   0   0   0   0]
 [  0   1   3   0 545   1   0   2   2  11]
 [  1   0   0   1   0 514   2   0   0   0]
 [  0   1   1   0   1   3 619   0   6   0]
 [  0   0   7   0   1   0   0 617   0   0]
 [  1   0   0   2   1   0   1   0 579   0]
 [  0   1   0   0   1   2   0   5   5 601]]

2024-01-15 14:56:09,855 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 14:56:09,855 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:56:09,859 - 

2024-01-15 14:56:09,859 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:56:18,466 - Epoch: [50][   10/  211]    Overall Loss 0.061866    Objective Loss 0.061866                                        LR 0.100000    Time 0.860588    
2024-01-15 14:56:24,183 - Epoch: [50][   20/  211]    Overall Loss 0.063368    Objective Loss 0.063368                                        LR 0.100000    Time 0.716092    
2024-01-15 14:56:29,847 - Epoch: [50][   30/  211]    Overall Loss 0.057817    Objective Loss 0.057817                                        LR 0.100000    Time 0.666157    
2024-01-15 14:56:35,475 - Epoch: [50][   40/  211]    Overall Loss 0.052583    Objective Loss 0.052583                                        LR 0.100000    Time 0.640306    
2024-01-15 14:56:41,107 - Epoch: [50][   50/  211]    Overall Loss 0.050213    Objective Loss 0.050213                                        LR 0.100000    Time 0.624869    
2024-01-15 14:56:47,405 - Epoch: [50][   60/  211]    Overall Loss 0.049547    Objective Loss 0.049547                                        LR 0.100000    Time 0.625673    
2024-01-15 14:56:54,096 - Epoch: [50][   70/  211]    Overall Loss 0.047880    Objective Loss 0.047880                                        LR 0.100000    Time 0.631763    
2024-01-15 14:57:00,787 - Epoch: [50][   80/  211]    Overall Loss 0.047602    Objective Loss 0.047602                                        LR 0.100000    Time 0.636413    
2024-01-15 14:57:06,427 - Epoch: [50][   90/  211]    Overall Loss 0.046337    Objective Loss 0.046337                                        LR 0.100000    Time 0.628357    
2024-01-15 14:57:12,077 - Epoch: [50][  100/  211]    Overall Loss 0.045865    Objective Loss 0.045865                                        LR 0.100000    Time 0.622008    
2024-01-15 14:57:17,863 - Epoch: [50][  110/  211]    Overall Loss 0.045541    Objective Loss 0.045541                                        LR 0.100000    Time 0.618053    
2024-01-15 14:57:23,650 - Epoch: [50][  120/  211]    Overall Loss 0.045659    Objective Loss 0.045659                                        LR 0.100000    Time 0.614764    
2024-01-15 14:57:29,365 - Epoch: [50][  130/  211]    Overall Loss 0.045430    Objective Loss 0.045430                                        LR 0.100000    Time 0.611424    
2024-01-15 14:57:35,037 - Epoch: [50][  140/  211]    Overall Loss 0.044713    Objective Loss 0.044713                                        LR 0.100000    Time 0.608264    
2024-01-15 14:57:40,741 - Epoch: [50][  150/  211]    Overall Loss 0.044556    Objective Loss 0.044556                                        LR 0.100000    Time 0.605733    
2024-01-15 14:57:46,483 - Epoch: [50][  160/  211]    Overall Loss 0.044532    Objective Loss 0.044532                                        LR 0.100000    Time 0.603755    
2024-01-15 14:57:52,212 - Epoch: [50][  170/  211]    Overall Loss 0.044602    Objective Loss 0.044602                                        LR 0.100000    Time 0.601934    
2024-01-15 14:57:58,100 - Epoch: [50][  180/  211]    Overall Loss 0.043880    Objective Loss 0.043880                                        LR 0.100000    Time 0.601197    
2024-01-15 14:58:03,902 - Epoch: [50][  190/  211]    Overall Loss 0.043585    Objective Loss 0.043585                                        LR 0.100000    Time 0.600082    
2024-01-15 14:58:09,736 - Epoch: [50][  200/  211]    Overall Loss 0.042989    Objective Loss 0.042989                                        LR 0.100000    Time 0.599231    
2024-01-15 14:58:15,465 - Epoch: [50][  210/  211]    Overall Loss 0.042731    Objective Loss 0.042731    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.597964    
2024-01-15 14:58:16,014 - Epoch: [50][  211/  211]    Overall Loss 0.042679    Objective Loss 0.042679    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.597724    
2024-01-15 14:58:16,932 - --- validate (epoch=50)-----------
2024-01-15 14:58:16,934 - 6000 samples (256 per mini-batch)
2024-01-15 14:58:23,927 - Epoch: [50][   10/   24]    Loss 0.042205    Top1 98.710938    Top5 99.960938    
2024-01-15 14:58:26,080 - Epoch: [50][   20/   24]    Loss 0.043131    Top1 98.613281    Top5 99.980469    
2024-01-15 14:58:26,884 - Epoch: [50][   24/   24]    Loss 0.042735    Top1 98.583333    Top5 99.983333    
2024-01-15 14:58:27,698 - ==> Top1: 98.583    Top5: 99.983    Loss: 0.043

2024-01-15 14:58:27,699 - ==> Confusion:
[[598   0   3   0   0   0   1   1   1   1]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   0 578   2   0   0   1   4   1   0]
 [  0   1   2 575   0   1   0   3   1   0]
 [  0   1   4   0 552   0   0   3   0   5]
 [  1   1   1   3   0 506   3   0   2   1]
 [  1   1   0   0   3   2 621   0   3   0]
 [  0   1   4   0   0   0   0 620   0   0]
 [  0   0   0   2   0   0   2   1 579   0]
 [  2   1   0   0   4   2   0   2   4 600]]

2024-01-15 14:58:27,701 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 14:58:27,702 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 14:58:27,707 - 

2024-01-15 14:58:27,708 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 14:58:36,789 - Epoch: [51][   10/  211]    Overall Loss 0.050605    Objective Loss 0.050605                                        LR 0.100000    Time 0.907998    
2024-01-15 14:58:42,538 - Epoch: [51][   20/  211]    Overall Loss 0.043494    Objective Loss 0.043494                                        LR 0.100000    Time 0.741380    
2024-01-15 14:58:48,389 - Epoch: [51][   30/  211]    Overall Loss 0.041509    Objective Loss 0.041509                                        LR 0.100000    Time 0.689277    
2024-01-15 14:58:54,084 - Epoch: [51][   40/  211]    Overall Loss 0.042145    Objective Loss 0.042145                                        LR 0.100000    Time 0.659309    
2024-01-15 14:59:00,060 - Epoch: [51][   50/  211]    Overall Loss 0.040849    Objective Loss 0.040849                                        LR 0.100000    Time 0.646939    
2024-01-15 14:59:05,736 - Epoch: [51][   60/  211]    Overall Loss 0.040833    Objective Loss 0.040833                                        LR 0.100000    Time 0.633694    
2024-01-15 14:59:11,450 - Epoch: [51][   70/  211]    Overall Loss 0.042036    Objective Loss 0.042036                                        LR 0.100000    Time 0.624784    
2024-01-15 14:59:17,301 - Epoch: [51][   80/  211]    Overall Loss 0.042611    Objective Loss 0.042611                                        LR 0.100000    Time 0.619818    
2024-01-15 14:59:22,974 - Epoch: [51][   90/  211]    Overall Loss 0.042578    Objective Loss 0.042578                                        LR 0.100000    Time 0.613965    
2024-01-15 14:59:28,936 - Epoch: [51][  100/  211]    Overall Loss 0.041916    Objective Loss 0.041916                                        LR 0.100000    Time 0.612180    
2024-01-15 14:59:34,723 - Epoch: [51][  110/  211]    Overall Loss 0.042331    Objective Loss 0.042331                                        LR 0.100000    Time 0.609126    
2024-01-15 14:59:40,355 - Epoch: [51][  120/  211]    Overall Loss 0.041681    Objective Loss 0.041681                                        LR 0.100000    Time 0.605289    
2024-01-15 14:59:45,988 - Epoch: [51][  130/  211]    Overall Loss 0.042109    Objective Loss 0.042109                                        LR 0.100000    Time 0.602056    
2024-01-15 14:59:51,634 - Epoch: [51][  140/  211]    Overall Loss 0.042412    Objective Loss 0.042412                                        LR 0.100000    Time 0.599374    
2024-01-15 14:59:57,707 - Epoch: [51][  150/  211]    Overall Loss 0.042508    Objective Loss 0.042508                                        LR 0.100000    Time 0.599894    
2024-01-15 15:00:03,421 - Epoch: [51][  160/  211]    Overall Loss 0.042708    Objective Loss 0.042708                                        LR 0.100000    Time 0.598102    
2024-01-15 15:00:09,105 - Epoch: [51][  170/  211]    Overall Loss 0.042615    Objective Loss 0.042615                                        LR 0.100000    Time 0.596350    
2024-01-15 15:00:14,752 - Epoch: [51][  180/  211]    Overall Loss 0.042048    Objective Loss 0.042048                                        LR 0.100000    Time 0.594586    
2024-01-15 15:00:20,399 - Epoch: [51][  190/  211]    Overall Loss 0.041690    Objective Loss 0.041690                                        LR 0.100000    Time 0.593010    
2024-01-15 15:00:26,048 - Epoch: [51][  200/  211]    Overall Loss 0.042153    Objective Loss 0.042153                                        LR 0.100000    Time 0.591600    
2024-01-15 15:00:31,756 - Epoch: [51][  210/  211]    Overall Loss 0.042525    Objective Loss 0.042525    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.590607    
2024-01-15 15:00:32,321 - Epoch: [51][  211/  211]    Overall Loss 0.042554    Objective Loss 0.042554    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.590481    
2024-01-15 15:00:33,238 - --- validate (epoch=51)-----------
2024-01-15 15:00:33,239 - 6000 samples (256 per mini-batch)
2024-01-15 15:00:39,890 - Epoch: [51][   10/   24]    Loss 0.054319    Top1 98.281250    Top5 99.960938    
2024-01-15 15:00:42,020 - Epoch: [51][   20/   24]    Loss 0.051765    Top1 98.378906    Top5 99.980469    
2024-01-15 15:00:42,776 - Epoch: [51][   24/   24]    Loss 0.049675    Top1 98.416667    Top5 99.983333    
2024-01-15 15:00:43,347 - ==> Top1: 98.417    Top5: 99.983    Loss: 0.050

2024-01-15 15:00:43,348 - ==> Confusion:
[[604   0   1   0   0   0   0   0   0   0]
 [  0 682   1   0   0   0   0   5   0   0]
 [  0   0 575   0   0   0   0   7   1   3]
 [  0   0   4 573   0   1   0   4   1   0]
 [  0   1   0   0 555   0   0   1   0   8]
 [  1   0   0   3   1 509   2   0   2   0]
 [ 10   3   0   0   3   1 607   0   7   0]
 [  0   1   1   0   1   0   0 622   0   0]
 [  1   0   0   1   1   1   0   0 578   2]
 [  1   0   0   0   3   1   0   6   4 600]]

2024-01-15 15:00:43,349 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:00:43,350 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:00:43,355 - 

2024-01-15 15:00:43,355 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:00:51,903 - Epoch: [52][   10/  211]    Overall Loss 0.050122    Objective Loss 0.050122                                        LR 0.100000    Time 0.854716    
2024-01-15 15:00:57,706 - Epoch: [52][   20/  211]    Overall Loss 0.044945    Objective Loss 0.044945                                        LR 0.100000    Time 0.717405    
2024-01-15 15:01:03,359 - Epoch: [52][   30/  211]    Overall Loss 0.041684    Objective Loss 0.041684                                        LR 0.100000    Time 0.666698    
2024-01-15 15:01:09,044 - Epoch: [52][   40/  211]    Overall Loss 0.042967    Objective Loss 0.042967                                        LR 0.100000    Time 0.642134    
2024-01-15 15:01:14,711 - Epoch: [52][   50/  211]    Overall Loss 0.043239    Objective Loss 0.043239                                        LR 0.100000    Time 0.627014    
2024-01-15 15:01:20,399 - Epoch: [52][   60/  211]    Overall Loss 0.043154    Objective Loss 0.043154                                        LR 0.100000    Time 0.617306    
2024-01-15 15:01:26,559 - Epoch: [52][   70/  211]    Overall Loss 0.041815    Objective Loss 0.041815                                        LR 0.100000    Time 0.617107    
2024-01-15 15:01:32,535 - Epoch: [52][   80/  211]    Overall Loss 0.041691    Objective Loss 0.041691                                        LR 0.100000    Time 0.614651    
2024-01-15 15:01:38,193 - Epoch: [52][   90/  211]    Overall Loss 0.041710    Objective Loss 0.041710                                        LR 0.100000    Time 0.609199    
2024-01-15 15:01:43,826 - Epoch: [52][  100/  211]    Overall Loss 0.041912    Objective Loss 0.041912                                        LR 0.100000    Time 0.604606    
2024-01-15 15:01:49,448 - Epoch: [52][  110/  211]    Overall Loss 0.041973    Objective Loss 0.041973                                        LR 0.100000    Time 0.600743    
2024-01-15 15:01:55,151 - Epoch: [52][  120/  211]    Overall Loss 0.042332    Objective Loss 0.042332                                        LR 0.100000    Time 0.598202    
2024-01-15 15:02:00,938 - Epoch: [52][  130/  211]    Overall Loss 0.043056    Objective Loss 0.043056                                        LR 0.100000    Time 0.596695    
2024-01-15 15:02:06,625 - Epoch: [52][  140/  211]    Overall Loss 0.044101    Objective Loss 0.044101                                        LR 0.100000    Time 0.594685    
2024-01-15 15:02:12,258 - Epoch: [52][  150/  211]    Overall Loss 0.044476    Objective Loss 0.044476                                        LR 0.100000    Time 0.592590    
2024-01-15 15:02:17,929 - Epoch: [52][  160/  211]    Overall Loss 0.044999    Objective Loss 0.044999                                        LR 0.100000    Time 0.590985    
2024-01-15 15:02:23,562 - Epoch: [52][  170/  211]    Overall Loss 0.044537    Objective Loss 0.044537                                        LR 0.100000    Time 0.589359    
2024-01-15 15:02:29,389 - Epoch: [52][  180/  211]    Overall Loss 0.044094    Objective Loss 0.044094                                        LR 0.100000    Time 0.588984    
2024-01-15 15:02:35,072 - Epoch: [52][  190/  211]    Overall Loss 0.043601    Objective Loss 0.043601                                        LR 0.100000    Time 0.587885    
2024-01-15 15:02:40,703 - Epoch: [52][  200/  211]    Overall Loss 0.043756    Objective Loss 0.043756                                        LR 0.100000    Time 0.586645    
2024-01-15 15:02:46,334 - Epoch: [52][  210/  211]    Overall Loss 0.043575    Objective Loss 0.043575    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.585519    
2024-01-15 15:02:46,891 - Epoch: [52][  211/  211]    Overall Loss 0.043685    Objective Loss 0.043685    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.585386    
2024-01-15 15:02:47,700 - --- validate (epoch=52)-----------
2024-01-15 15:02:47,702 - 6000 samples (256 per mini-batch)
2024-01-15 15:02:54,379 - Epoch: [52][   10/   24]    Loss 0.042948    Top1 98.515625    Top5 100.000000    
2024-01-15 15:02:56,604 - Epoch: [52][   20/   24]    Loss 0.040268    Top1 98.750000    Top5 99.980469    
2024-01-15 15:02:57,344 - Epoch: [52][   24/   24]    Loss 0.040421    Top1 98.750000    Top5 99.983333    
2024-01-15 15:02:57,988 - ==> Top1: 98.750    Top5: 99.983    Loss: 0.040

2024-01-15 15:02:57,989 - ==> Confusion:
[[603   0   0   0   0   1   1   0   0   0]
 [  0 687   1   0   0   0   0   0   0   0]
 [  0   1 582   1   0   0   1   0   1   0]
 [  0   0   2 576   0   2   0   1   1   1]
 [  0   1   1   1 547   1   1   1   0  12]
 [  2   0   0   1   0 514   1   0   0   0]
 [  1   1   0   0   2   1 626   0   0   0]
 [  0   4   4   1   0   1   0 614   0   1]
 [  1   0   1   2   0   5   3   0 569   3]
 [  0   2   0   0   2   2   0   1   1 607]]

2024-01-15 15:02:57,992 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:02:57,993 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:02:57,999 - 

2024-01-15 15:02:58,000 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:03:06,785 - Epoch: [53][   10/  211]    Overall Loss 0.037986    Objective Loss 0.037986                                        LR 0.100000    Time 0.878406    
2024-01-15 15:03:12,426 - Epoch: [53][   20/  211]    Overall Loss 0.036129    Objective Loss 0.036129                                        LR 0.100000    Time 0.721166    
2024-01-15 15:03:18,053 - Epoch: [53][   30/  211]    Overall Loss 0.041175    Objective Loss 0.041175                                        LR 0.100000    Time 0.668340    
2024-01-15 15:03:23,687 - Epoch: [53][   40/  211]    Overall Loss 0.040139    Objective Loss 0.040139                                        LR 0.100000    Time 0.642086    
2024-01-15 15:03:29,362 - Epoch: [53][   50/  211]    Overall Loss 0.041338    Objective Loss 0.041338                                        LR 0.100000    Time 0.627167    
2024-01-15 15:03:35,076 - Epoch: [53][   60/  211]    Overall Loss 0.040747    Objective Loss 0.040747                                        LR 0.100000    Time 0.617846    
2024-01-15 15:03:40,715 - Epoch: [53][   70/  211]    Overall Loss 0.041910    Objective Loss 0.041910                                        LR 0.100000    Time 0.610128    
2024-01-15 15:03:46,461 - Epoch: [53][   80/  211]    Overall Loss 0.042896    Objective Loss 0.042896                                        LR 0.100000    Time 0.605674    
2024-01-15 15:03:52,134 - Epoch: [53][   90/  211]    Overall Loss 0.043912    Objective Loss 0.043912                                        LR 0.100000    Time 0.601406    
2024-01-15 15:03:57,992 - Epoch: [53][  100/  211]    Overall Loss 0.044634    Objective Loss 0.044634                                        LR 0.100000    Time 0.599827    
2024-01-15 15:04:03,726 - Epoch: [53][  110/  211]    Overall Loss 0.043970    Objective Loss 0.043970                                        LR 0.100000    Time 0.597422    
2024-01-15 15:04:09,409 - Epoch: [53][  120/  211]    Overall Loss 0.044038    Objective Loss 0.044038                                        LR 0.100000    Time 0.594982    
2024-01-15 15:04:15,046 - Epoch: [53][  130/  211]    Overall Loss 0.044278    Objective Loss 0.044278                                        LR 0.100000    Time 0.592563    
2024-01-15 15:04:20,675 - Epoch: [53][  140/  211]    Overall Loss 0.044306    Objective Loss 0.044306                                        LR 0.100000    Time 0.590444    
2024-01-15 15:04:26,310 - Epoch: [53][  150/  211]    Overall Loss 0.044124    Objective Loss 0.044124                                        LR 0.100000    Time 0.588648    
2024-01-15 15:04:31,940 - Epoch: [53][  160/  211]    Overall Loss 0.044341    Objective Loss 0.044341                                        LR 0.100000    Time 0.587039    
2024-01-15 15:04:37,561 - Epoch: [53][  170/  211]    Overall Loss 0.044136    Objective Loss 0.044136                                        LR 0.100000    Time 0.585572    
2024-01-15 15:04:43,204 - Epoch: [53][  180/  211]    Overall Loss 0.044107    Objective Loss 0.044107                                        LR 0.100000    Time 0.584390    
2024-01-15 15:04:48,836 - Epoch: [53][  190/  211]    Overall Loss 0.044256    Objective Loss 0.044256                                        LR 0.100000    Time 0.583269    
2024-01-15 15:04:54,466 - Epoch: [53][  200/  211]    Overall Loss 0.044436    Objective Loss 0.044436                                        LR 0.100000    Time 0.582254    
2024-01-15 15:05:00,265 - Epoch: [53][  210/  211]    Overall Loss 0.044298    Objective Loss 0.044298    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.582135    
2024-01-15 15:05:00,811 - Epoch: [53][  211/  211]    Overall Loss 0.044349    Objective Loss 0.044349    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.581960    
2024-01-15 15:05:01,727 - --- validate (epoch=53)-----------
2024-01-15 15:05:01,728 - 6000 samples (256 per mini-batch)
2024-01-15 15:05:07,391 - Epoch: [53][   10/   24]    Loss 0.043159    Top1 98.593750    Top5 100.000000    
2024-01-15 15:05:09,503 - Epoch: [53][   20/   24]    Loss 0.049774    Top1 98.437500    Top5 100.000000    
2024-01-15 15:05:10,243 - Epoch: [53][   24/   24]    Loss 0.049188    Top1 98.433333    Top5 100.000000    
2024-01-15 15:05:10,800 - ==> Top1: 98.433    Top5: 100.000    Loss: 0.049

2024-01-15 15:05:10,801 - ==> Confusion:
[[600   0   1   0   0   0   1   2   0   1]
 [  0 685   0   0   0   0   0   3   0   0]
 [  0   2 572   3   1   0   0   5   2   1]
 [  0   1   1 574   0   3   0   1   2   1]
 [  0   0   0   0 550   0   0   6   0   9]
 [  1   0   0   1   0 514   0   0   2   0]
 [  0   3   0   0   3   6 616   0   3   0]
 [  0   1   0   2   0   0   0 622   0   0]
 [  1   0   1   0   2   2   2   3 572   1]
 [  0   3   0   0   1   3   0   5   2 601]]

2024-01-15 15:05:10,803 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:05:10,803 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:05:10,808 - 

2024-01-15 15:05:10,808 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:05:19,060 - Epoch: [54][   10/  211]    Overall Loss 0.055476    Objective Loss 0.055476                                        LR 0.100000    Time 0.825129    
2024-01-15 15:05:24,705 - Epoch: [54][   20/  211]    Overall Loss 0.046385    Objective Loss 0.046385                                        LR 0.100000    Time 0.694760    
2024-01-15 15:05:30,366 - Epoch: [54][   30/  211]    Overall Loss 0.045133    Objective Loss 0.045133                                        LR 0.100000    Time 0.651843    
2024-01-15 15:05:36,431 - Epoch: [54][   40/  211]    Overall Loss 0.044330    Objective Loss 0.044330                                        LR 0.100000    Time 0.640478    
2024-01-15 15:05:42,919 - Epoch: [54][   50/  211]    Overall Loss 0.043900    Objective Loss 0.043900                                        LR 0.100000    Time 0.642125    
2024-01-15 15:05:48,804 - Epoch: [54][   60/  211]    Overall Loss 0.042490    Objective Loss 0.042490                                        LR 0.100000    Time 0.633167    
2024-01-15 15:05:54,528 - Epoch: [54][   70/  211]    Overall Loss 0.043085    Objective Loss 0.043085                                        LR 0.100000    Time 0.624476    
2024-01-15 15:06:00,549 - Epoch: [54][   80/  211]    Overall Loss 0.042236    Objective Loss 0.042236                                        LR 0.100000    Time 0.621662    
2024-01-15 15:06:06,369 - Epoch: [54][   90/  211]    Overall Loss 0.042035    Objective Loss 0.042035                                        LR 0.100000    Time 0.617240    
2024-01-15 15:06:12,087 - Epoch: [54][  100/  211]    Overall Loss 0.041091    Objective Loss 0.041091                                        LR 0.100000    Time 0.612682    
2024-01-15 15:06:17,740 - Epoch: [54][  110/  211]    Overall Loss 0.041343    Objective Loss 0.041343                                        LR 0.100000    Time 0.608375    
2024-01-15 15:06:23,383 - Epoch: [54][  120/  211]    Overall Loss 0.040804    Objective Loss 0.040804                                        LR 0.100000    Time 0.604696    
2024-01-15 15:06:29,020 - Epoch: [54][  130/  211]    Overall Loss 0.040684    Objective Loss 0.040684                                        LR 0.100000    Time 0.601532    
2024-01-15 15:06:34,738 - Epoch: [54][  140/  211]    Overall Loss 0.040838    Objective Loss 0.040838                                        LR 0.100000    Time 0.599406    
2024-01-15 15:06:40,480 - Epoch: [54][  150/  211]    Overall Loss 0.040426    Objective Loss 0.040426                                        LR 0.100000    Time 0.597715    
2024-01-15 15:06:46,359 - Epoch: [54][  160/  211]    Overall Loss 0.040641    Objective Loss 0.040641                                        LR 0.100000    Time 0.597094    
2024-01-15 15:06:52,014 - Epoch: [54][  170/  211]    Overall Loss 0.040654    Objective Loss 0.040654                                        LR 0.100000    Time 0.595232    
2024-01-15 15:06:57,995 - Epoch: [54][  180/  211]    Overall Loss 0.040290    Objective Loss 0.040290                                        LR 0.100000    Time 0.595382    
2024-01-15 15:07:04,514 - Epoch: [54][  190/  211]    Overall Loss 0.040258    Objective Loss 0.040258                                        LR 0.100000    Time 0.598354    
2024-01-15 15:07:11,853 - Epoch: [54][  200/  211]    Overall Loss 0.040347    Objective Loss 0.040347                                        LR 0.100000    Time 0.605114    
2024-01-15 15:07:18,290 - Epoch: [54][  210/  211]    Overall Loss 0.040285    Objective Loss 0.040285    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.606947    
2024-01-15 15:07:19,010 - Epoch: [54][  211/  211]    Overall Loss 0.040393    Objective Loss 0.040393    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.607474    
2024-01-15 15:07:20,241 - --- validate (epoch=54)-----------
2024-01-15 15:07:20,243 - 6000 samples (256 per mini-batch)
2024-01-15 15:07:27,992 - Epoch: [54][   10/   24]    Loss 0.037506    Top1 98.906250    Top5 100.000000    
2024-01-15 15:07:30,384 - Epoch: [54][   20/   24]    Loss 0.042901    Top1 98.867188    Top5 100.000000    
2024-01-15 15:07:31,272 - Epoch: [54][   24/   24]    Loss 0.043434    Top1 98.800000    Top5 99.983333    
2024-01-15 15:07:32,359 - ==> Top1: 98.800    Top5: 99.983    Loss: 0.043

2024-01-15 15:07:32,362 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 685   0   0   0   0   0   3   0   0]
 [  0   0 577   0   0   0   1   5   3   0]
 [  0   0   1 579   0   2   0   0   1   0]
 [  0   0   0   0 545   0   3   2   0  15]
 [  1   0   0   1   0 510   4   0   2   0]
 [  0   0   0   0   1   1 627   0   2   0]
 [  0   3   1   0   0   1   0 620   0   0]
 [  3   0   0   2   0   3   2   0 573   1]
 [  0   1   0   0   1   0   0   1   3 609]]

2024-01-15 15:07:32,365 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:07:32,366 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:07:32,373 - 

2024-01-15 15:07:32,374 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:07:45,717 - Epoch: [55][   10/  211]    Overall Loss 0.046514    Objective Loss 0.046514                                        LR 0.100000    Time 1.334031    
2024-01-15 15:07:51,674 - Epoch: [55][   20/  211]    Overall Loss 0.043801    Objective Loss 0.043801                                        LR 0.100000    Time 0.964799    
2024-01-15 15:07:57,774 - Epoch: [55][   30/  211]    Overall Loss 0.044455    Objective Loss 0.044455                                        LR 0.100000    Time 0.846487    
2024-01-15 15:08:05,273 - Epoch: [55][   40/  211]    Overall Loss 0.044349    Objective Loss 0.044349                                        LR 0.100000    Time 0.822311    
2024-01-15 15:08:11,993 - Epoch: [55][   50/  211]    Overall Loss 0.042792    Objective Loss 0.042792                                        LR 0.100000    Time 0.792208    
2024-01-15 15:08:18,090 - Epoch: [55][   60/  211]    Overall Loss 0.041838    Objective Loss 0.041838                                        LR 0.100000    Time 0.761783    
2024-01-15 15:08:23,974 - Epoch: [55][   70/  211]    Overall Loss 0.041377    Objective Loss 0.041377                                        LR 0.100000    Time 0.736995    
2024-01-15 15:08:29,868 - Epoch: [55][   80/  211]    Overall Loss 0.040393    Objective Loss 0.040393                                        LR 0.100000    Time 0.718536    
2024-01-15 15:08:36,103 - Epoch: [55][   90/  211]    Overall Loss 0.040713    Objective Loss 0.040713                                        LR 0.100000    Time 0.707967    
2024-01-15 15:08:42,060 - Epoch: [55][  100/  211]    Overall Loss 0.041286    Objective Loss 0.041286                                        LR 0.100000    Time 0.696723    
2024-01-15 15:08:47,923 - Epoch: [55][  110/  211]    Overall Loss 0.040900    Objective Loss 0.040900                                        LR 0.100000    Time 0.686679    
2024-01-15 15:08:53,748 - Epoch: [55][  120/  211]    Overall Loss 0.041073    Objective Loss 0.041073                                        LR 0.100000    Time 0.677992    
2024-01-15 15:08:59,624 - Epoch: [55][  130/  211]    Overall Loss 0.041542    Objective Loss 0.041542                                        LR 0.100000    Time 0.671033    
2024-01-15 15:09:05,470 - Epoch: [55][  140/  211]    Overall Loss 0.041913    Objective Loss 0.041913                                        LR 0.100000    Time 0.664848    
2024-01-15 15:09:11,461 - Epoch: [55][  150/  211]    Overall Loss 0.042150    Objective Loss 0.042150                                        LR 0.100000    Time 0.660464    
2024-01-15 15:09:17,237 - Epoch: [55][  160/  211]    Overall Loss 0.041798    Objective Loss 0.041798                                        LR 0.100000    Time 0.655280    
2024-01-15 15:09:22,895 - Epoch: [55][  170/  211]    Overall Loss 0.042317    Objective Loss 0.042317                                        LR 0.100000    Time 0.650012    
2024-01-15 15:09:28,869 - Epoch: [55][  180/  211]    Overall Loss 0.042534    Objective Loss 0.042534                                        LR 0.100000    Time 0.647076    
2024-01-15 15:09:34,755 - Epoch: [55][  190/  211]    Overall Loss 0.042373    Objective Loss 0.042373                                        LR 0.100000    Time 0.643990    
2024-01-15 15:09:40,508 - Epoch: [55][  200/  211]    Overall Loss 0.042728    Objective Loss 0.042728                                        LR 0.100000    Time 0.640551    
2024-01-15 15:09:46,175 - Epoch: [55][  210/  211]    Overall Loss 0.042572    Objective Loss 0.042572    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.637032    
2024-01-15 15:09:46,735 - Epoch: [55][  211/  211]    Overall Loss 0.042546    Objective Loss 0.042546    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.636660    
2024-01-15 15:09:47,558 - --- validate (epoch=55)-----------
2024-01-15 15:09:47,560 - 6000 samples (256 per mini-batch)
2024-01-15 15:09:54,343 - Epoch: [55][   10/   24]    Loss 0.055588    Top1 98.398438    Top5 100.000000    
2024-01-15 15:09:56,601 - Epoch: [55][   20/   24]    Loss 0.046225    Top1 98.613281    Top5 100.000000    
2024-01-15 15:09:57,367 - Epoch: [55][   24/   24]    Loss 0.046919    Top1 98.633333    Top5 100.000000    
2024-01-15 15:09:57,943 - ==> Top1: 98.633    Top5: 100.000    Loss: 0.047

2024-01-15 15:09:57,944 - ==> Confusion:
[[604   0   1   0   0   0   0   0   0   0]
 [  0 682   3   1   0   1   0   1   0   0]
 [  0   0 584   0   0   0   0   1   1   0]
 [  0   0   4 572   0   3   0   3   1   0]
 [  0   0   1   0 551   0   1   1   0  11]
 [  2   0   0   3   0 509   3   0   1   0]
 [  2   1   0   0   2   0 626   0   0   0]
 [  0   2   1   0   0   1   0 620   0   1]
 [  5   1   0   3   2   2   3   2 565   1]
 [  1   1   0   0   2   0   0   4   2 605]]

2024-01-15 15:09:57,946 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:09:57,947 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:09:57,952 - 

2024-01-15 15:09:57,952 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:10:06,292 - Epoch: [56][   10/  211]    Overall Loss 0.036189    Objective Loss 0.036189                                        LR 0.100000    Time 0.833945    
2024-01-15 15:10:11,939 - Epoch: [56][   20/  211]    Overall Loss 0.040535    Objective Loss 0.040535                                        LR 0.100000    Time 0.699253    
2024-01-15 15:10:17,642 - Epoch: [56][   30/  211]    Overall Loss 0.041900    Objective Loss 0.041900                                        LR 0.100000    Time 0.656247    
2024-01-15 15:10:24,183 - Epoch: [56][   40/  211]    Overall Loss 0.041204    Objective Loss 0.041204                                        LR 0.100000    Time 0.655695    
2024-01-15 15:10:29,860 - Epoch: [56][   50/  211]    Overall Loss 0.041724    Objective Loss 0.041724                                        LR 0.100000    Time 0.638065    
2024-01-15 15:10:35,495 - Epoch: [56][   60/  211]    Overall Loss 0.043744    Objective Loss 0.043744                                        LR 0.100000    Time 0.625617    
2024-01-15 15:10:41,188 - Epoch: [56][   70/  211]    Overall Loss 0.044962    Objective Loss 0.044962                                        LR 0.100000    Time 0.617572    
2024-01-15 15:10:46,912 - Epoch: [56][   80/  211]    Overall Loss 0.044729    Objective Loss 0.044729                                        LR 0.100000    Time 0.611911    
2024-01-15 15:10:52,708 - Epoch: [56][   90/  211]    Overall Loss 0.044675    Objective Loss 0.044675                                        LR 0.100000    Time 0.608307    
2024-01-15 15:10:58,824 - Epoch: [56][  100/  211]    Overall Loss 0.043701    Objective Loss 0.043701                                        LR 0.100000    Time 0.608620    
2024-01-15 15:11:05,301 - Epoch: [56][  110/  211]    Overall Loss 0.043592    Objective Loss 0.043592                                        LR 0.100000    Time 0.612158    
2024-01-15 15:11:11,421 - Epoch: [56][  120/  211]    Overall Loss 0.042669    Objective Loss 0.042669                                        LR 0.100000    Time 0.612136    
2024-01-15 15:11:17,231 - Epoch: [56][  130/  211]    Overall Loss 0.042824    Objective Loss 0.042824                                        LR 0.100000    Time 0.609717    
2024-01-15 15:11:24,191 - Epoch: [56][  140/  211]    Overall Loss 0.043050    Objective Loss 0.043050                                        LR 0.100000    Time 0.615872    
2024-01-15 15:11:30,453 - Epoch: [56][  150/  211]    Overall Loss 0.042980    Objective Loss 0.042980                                        LR 0.100000    Time 0.616552    
2024-01-15 15:11:36,764 - Epoch: [56][  160/  211]    Overall Loss 0.042918    Objective Loss 0.042918                                        LR 0.100000    Time 0.617448    
2024-01-15 15:11:42,538 - Epoch: [56][  170/  211]    Overall Loss 0.042234    Objective Loss 0.042234                                        LR 0.100000    Time 0.615082    
2024-01-15 15:11:49,576 - Epoch: [56][  180/  211]    Overall Loss 0.041691    Objective Loss 0.041691                                        LR 0.100000    Time 0.620008    
2024-01-15 15:11:56,387 - Epoch: [56][  190/  211]    Overall Loss 0.042232    Objective Loss 0.042232                                        LR 0.100000    Time 0.623207    
2024-01-15 15:12:02,612 - Epoch: [56][  200/  211]    Overall Loss 0.042713    Objective Loss 0.042713                                        LR 0.100000    Time 0.623164    
2024-01-15 15:12:08,509 - Epoch: [56][  210/  211]    Overall Loss 0.043234    Objective Loss 0.043234    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.621564    
2024-01-15 15:12:09,068 - Epoch: [56][  211/  211]    Overall Loss 0.043186    Objective Loss 0.043186    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.621264    
2024-01-15 15:12:10,025 - --- validate (epoch=56)-----------
2024-01-15 15:12:10,027 - 6000 samples (256 per mini-batch)
2024-01-15 15:12:17,779 - Epoch: [56][   10/   24]    Loss 0.052505    Top1 98.554688    Top5 99.921875    
2024-01-15 15:12:20,007 - Epoch: [56][   20/   24]    Loss 0.052684    Top1 98.476562    Top5 99.960938    
2024-01-15 15:12:20,766 - Epoch: [56][   24/   24]    Loss 0.051843    Top1 98.533333    Top5 99.966667    
2024-01-15 15:12:21,597 - ==> Top1: 98.533    Top5: 99.967    Loss: 0.052

2024-01-15 15:12:21,598 - ==> Confusion:
[[601   0   0   1   0   1   2   0   0   0]
 [  0 685   0   0   0   0   0   3   0   0]
 [  0   0 577   2   1   0   0   4   1   1]
 [  0   0   0 571   1   7   0   1   1   2]
 [  2   0   1   0 553   0   2   0   1   6]
 [  0   1   0   1   0 516   0   0   0   0]
 [  0   0   0   0   3   4 624   0   0   0]
 [  1   1   2   4   4   0   0 613   0   0]
 [  0   0   0   1   1   4   3   0 573   2]
 [  0   1   0   1   2   2   0   3   7 599]]

2024-01-15 15:12:21,600 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:12:21,601 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:12:21,604 - 

2024-01-15 15:12:21,604 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:12:32,399 - Epoch: [57][   10/  211]    Overall Loss 0.040071    Objective Loss 0.040071                                        LR 0.100000    Time 1.079362    
2024-01-15 15:12:38,568 - Epoch: [57][   20/  211]    Overall Loss 0.042269    Objective Loss 0.042269                                        LR 0.100000    Time 0.848020    
2024-01-15 15:12:44,533 - Epoch: [57][   30/  211]    Overall Loss 0.042875    Objective Loss 0.042875                                        LR 0.100000    Time 0.764140    
2024-01-15 15:12:50,477 - Epoch: [57][   40/  211]    Overall Loss 0.043581    Objective Loss 0.043581                                        LR 0.100000    Time 0.721663    
2024-01-15 15:12:56,477 - Epoch: [57][   50/  211]    Overall Loss 0.042562    Objective Loss 0.042562                                        LR 0.100000    Time 0.697314    
2024-01-15 15:13:02,256 - Epoch: [57][   60/  211]    Overall Loss 0.042210    Objective Loss 0.042210                                        LR 0.100000    Time 0.677389    
2024-01-15 15:13:08,373 - Epoch: [57][   70/  211]    Overall Loss 0.043219    Objective Loss 0.043219                                        LR 0.100000    Time 0.667992    
2024-01-15 15:13:14,233 - Epoch: [57][   80/  211]    Overall Loss 0.043824    Objective Loss 0.043824                                        LR 0.100000    Time 0.657730    
2024-01-15 15:13:20,142 - Epoch: [57][   90/  211]    Overall Loss 0.043921    Objective Loss 0.043921                                        LR 0.100000    Time 0.650279    
2024-01-15 15:13:25,943 - Epoch: [57][  100/  211]    Overall Loss 0.044638    Objective Loss 0.044638                                        LR 0.100000    Time 0.643250    
2024-01-15 15:13:31,678 - Epoch: [57][  110/  211]    Overall Loss 0.045023    Objective Loss 0.045023                                        LR 0.100000    Time 0.636897    
2024-01-15 15:13:37,948 - Epoch: [57][  120/  211]    Overall Loss 0.044750    Objective Loss 0.044750                                        LR 0.100000    Time 0.636062    
2024-01-15 15:13:43,662 - Epoch: [57][  130/  211]    Overall Loss 0.044494    Objective Loss 0.044494                                        LR 0.100000    Time 0.631071    
2024-01-15 15:13:49,335 - Epoch: [57][  140/  211]    Overall Loss 0.044068    Objective Loss 0.044068                                        LR 0.100000    Time 0.626511    
2024-01-15 15:13:55,599 - Epoch: [57][  150/  211]    Overall Loss 0.043911    Objective Loss 0.043911                                        LR 0.100000    Time 0.626484    
2024-01-15 15:14:01,340 - Epoch: [57][  160/  211]    Overall Loss 0.043652    Objective Loss 0.043652                                        LR 0.100000    Time 0.623205    
2024-01-15 15:14:07,374 - Epoch: [57][  170/  211]    Overall Loss 0.043765    Objective Loss 0.043765                                        LR 0.100000    Time 0.622034    
2024-01-15 15:14:13,207 - Epoch: [57][  180/  211]    Overall Loss 0.043553    Objective Loss 0.043553                                        LR 0.100000    Time 0.619874    
2024-01-15 15:14:18,887 - Epoch: [57][  190/  211]    Overall Loss 0.042971    Objective Loss 0.042971                                        LR 0.100000    Time 0.617139    
2024-01-15 15:14:24,686 - Epoch: [57][  200/  211]    Overall Loss 0.042769    Objective Loss 0.042769                                        LR 0.100000    Time 0.615275    
2024-01-15 15:14:30,921 - Epoch: [57][  210/  211]    Overall Loss 0.042540    Objective Loss 0.042540    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.615657    
2024-01-15 15:14:31,484 - Epoch: [57][  211/  211]    Overall Loss 0.042470    Objective Loss 0.042470    Top1 99.395161    Top5 100.000000    LR 0.100000    Time 0.615404    
2024-01-15 15:14:32,240 - --- validate (epoch=57)-----------
2024-01-15 15:14:32,240 - 6000 samples (256 per mini-batch)
2024-01-15 15:14:39,160 - Epoch: [57][   10/   24]    Loss 0.044776    Top1 98.710938    Top5 99.960938    
2024-01-15 15:14:41,278 - Epoch: [57][   20/   24]    Loss 0.045969    Top1 98.593750    Top5 99.980469    
2024-01-15 15:14:42,017 - Epoch: [57][   24/   24]    Loss 0.045519    Top1 98.583333    Top5 99.983333    
2024-01-15 15:14:42,567 - ==> Top1: 98.583    Top5: 99.983    Loss: 0.046

2024-01-15 15:14:42,567 - ==> Confusion:
[[601   0   1   0   0   0   2   0   0   1]
 [  0 684   2   0   0   1   0   1   0   0]
 [  0   0 582   0   0   0   0   3   0   1]
 [  1   0   9 558   1  10   0   2   1   1]
 [  0   1   0   0 554   0   1   1   0   8]
 [  1   0   0   1   0 507   7   0   2   0]
 [  0   2   0   0   2   0 627   0   0   0]
 [  0   0   4   0   0   0   0 621   0   0]
 [  2   0   0   0   0   2   2   1 576   1]
 [  0   1   0   0   3   1   0   2   3 605]]

2024-01-15 15:14:42,569 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:14:42,569 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:14:42,573 - 

2024-01-15 15:14:42,573 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:14:51,211 - Epoch: [58][   10/  211]    Overall Loss 0.040646    Objective Loss 0.040646                                        LR 0.100000    Time 0.863726    
2024-01-15 15:14:57,349 - Epoch: [58][   20/  211]    Overall Loss 0.036269    Objective Loss 0.036269                                        LR 0.100000    Time 0.738639    
2024-01-15 15:15:03,799 - Epoch: [58][   30/  211]    Overall Loss 0.035301    Objective Loss 0.035301                                        LR 0.100000    Time 0.707420    
2024-01-15 15:15:10,492 - Epoch: [58][   40/  211]    Overall Loss 0.035583    Objective Loss 0.035583                                        LR 0.100000    Time 0.697834    
2024-01-15 15:15:16,387 - Epoch: [58][   50/  211]    Overall Loss 0.037771    Objective Loss 0.037771                                        LR 0.100000    Time 0.676152    
2024-01-15 15:15:22,423 - Epoch: [58][   60/  211]    Overall Loss 0.037688    Objective Loss 0.037688                                        LR 0.100000    Time 0.663996    
2024-01-15 15:15:28,420 - Epoch: [58][   70/  211]    Overall Loss 0.036784    Objective Loss 0.036784                                        LR 0.100000    Time 0.654796    
2024-01-15 15:15:34,375 - Epoch: [58][   80/  211]    Overall Loss 0.037151    Objective Loss 0.037151                                        LR 0.100000    Time 0.647371    
2024-01-15 15:15:40,246 - Epoch: [58][   90/  211]    Overall Loss 0.036735    Objective Loss 0.036735                                        LR 0.100000    Time 0.640657    
2024-01-15 15:15:46,254 - Epoch: [58][  100/  211]    Overall Loss 0.037183    Objective Loss 0.037183                                        LR 0.100000    Time 0.636658    
2024-01-15 15:15:52,464 - Epoch: [58][  110/  211]    Overall Loss 0.037808    Objective Loss 0.037808                                        LR 0.100000    Time 0.635223    
2024-01-15 15:15:58,231 - Epoch: [58][  120/  211]    Overall Loss 0.038627    Objective Loss 0.038627                                        LR 0.100000    Time 0.630334    
2024-01-15 15:16:04,349 - Epoch: [58][  130/  211]    Overall Loss 0.039304    Objective Loss 0.039304                                        LR 0.100000    Time 0.628902    
2024-01-15 15:16:10,318 - Epoch: [58][  140/  211]    Overall Loss 0.039546    Objective Loss 0.039546                                        LR 0.100000    Time 0.626604    
2024-01-15 15:16:16,092 - Epoch: [58][  150/  211]    Overall Loss 0.040008    Objective Loss 0.040008                                        LR 0.100000    Time 0.623318    
2024-01-15 15:16:21,746 - Epoch: [58][  160/  211]    Overall Loss 0.039849    Objective Loss 0.039849                                        LR 0.100000    Time 0.619694    
2024-01-15 15:16:27,398 - Epoch: [58][  170/  211]    Overall Loss 0.039803    Objective Loss 0.039803                                        LR 0.100000    Time 0.616482    
2024-01-15 15:16:33,170 - Epoch: [58][  180/  211]    Overall Loss 0.039853    Objective Loss 0.039853                                        LR 0.100000    Time 0.614297    
2024-01-15 15:16:38,934 - Epoch: [58][  190/  211]    Overall Loss 0.040226    Objective Loss 0.040226                                        LR 0.100000    Time 0.612301    
2024-01-15 15:16:44,723 - Epoch: [58][  200/  211]    Overall Loss 0.040557    Objective Loss 0.040557                                        LR 0.100000    Time 0.610621    
2024-01-15 15:16:50,584 - Epoch: [58][  210/  211]    Overall Loss 0.040597    Objective Loss 0.040597    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.609443    
2024-01-15 15:16:51,150 - Epoch: [58][  211/  211]    Overall Loss 0.040760    Objective Loss 0.040760    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.609237    
2024-01-15 15:16:52,116 - --- validate (epoch=58)-----------
2024-01-15 15:16:52,117 - 6000 samples (256 per mini-batch)
2024-01-15 15:16:59,050 - Epoch: [58][   10/   24]    Loss 0.044721    Top1 98.828125    Top5 100.000000    
2024-01-15 15:17:01,210 - Epoch: [58][   20/   24]    Loss 0.046137    Top1 98.652344    Top5 100.000000    
2024-01-15 15:17:01,980 - Epoch: [58][   24/   24]    Loss 0.045066    Top1 98.683333    Top5 99.983333    
2024-01-15 15:17:02,777 - ==> Top1: 98.683    Top5: 99.983    Loss: 0.045

2024-01-15 15:17:02,778 - ==> Confusion:
[[602   0   2   0   0   0   1   0   0   0]
 [  0 686   0   1   0   0   0   1   0   0]
 [  0   2 578   1   1   0   0   2   2   0]
 [  0   1   2 571   0   4   0   1   4   0]
 [  0   1   0   0 560   0   0   0   0   4]
 [  1   0   0   2   0 508   3   0   4   0]
 [  1   2   0   0   3   0 621   0   4   0]
 [  0   0   3   0   1   0   0 620   0   1]
 [  0   0   1   1   3   0   0   0 576   3]
 [  0   1   0   1   9   1   0   2   2 599]]

2024-01-15 15:17:02,780 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:17:02,780 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:17:02,785 - 

2024-01-15 15:17:02,785 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:17:12,345 - Epoch: [59][   10/  211]    Overall Loss 0.037628    Objective Loss 0.037628                                        LR 0.100000    Time 0.955870    
2024-01-15 15:17:18,251 - Epoch: [59][   20/  211]    Overall Loss 0.039431    Objective Loss 0.039431                                        LR 0.100000    Time 0.773116    
2024-01-15 15:17:23,943 - Epoch: [59][   30/  211]    Overall Loss 0.036961    Objective Loss 0.036961                                        LR 0.100000    Time 0.705143    
2024-01-15 15:17:29,867 - Epoch: [59][   40/  211]    Overall Loss 0.039166    Objective Loss 0.039166                                        LR 0.100000    Time 0.676913    
2024-01-15 15:17:35,515 - Epoch: [59][   50/  211]    Overall Loss 0.039817    Objective Loss 0.039817                                        LR 0.100000    Time 0.654479    
2024-01-15 15:17:41,387 - Epoch: [59][   60/  211]    Overall Loss 0.043338    Objective Loss 0.043338                                        LR 0.100000    Time 0.643252    
2024-01-15 15:17:47,066 - Epoch: [59][   70/  211]    Overall Loss 0.045445    Objective Loss 0.045445                                        LR 0.100000    Time 0.632460    
2024-01-15 15:17:52,723 - Epoch: [59][   80/  211]    Overall Loss 0.045082    Objective Loss 0.045082                                        LR 0.100000    Time 0.624107    
2024-01-15 15:17:58,930 - Epoch: [59][   90/  211]    Overall Loss 0.045816    Objective Loss 0.045816                                        LR 0.100000    Time 0.623715    
2024-01-15 15:18:04,726 - Epoch: [59][  100/  211]    Overall Loss 0.045743    Objective Loss 0.045743                                        LR 0.100000    Time 0.619284    
2024-01-15 15:18:10,751 - Epoch: [59][  110/  211]    Overall Loss 0.045330    Objective Loss 0.045330                                        LR 0.100000    Time 0.617695    
2024-01-15 15:18:16,542 - Epoch: [59][  120/  211]    Overall Loss 0.045055    Objective Loss 0.045055                                        LR 0.100000    Time 0.614469    
2024-01-15 15:18:22,275 - Epoch: [59][  130/  211]    Overall Loss 0.044521    Objective Loss 0.044521                                        LR 0.100000    Time 0.611294    
2024-01-15 15:18:27,964 - Epoch: [59][  140/  211]    Overall Loss 0.044406    Objective Loss 0.044406                                        LR 0.100000    Time 0.608259    
2024-01-15 15:18:34,075 - Epoch: [59][  150/  211]    Overall Loss 0.044206    Objective Loss 0.044206                                        LR 0.100000    Time 0.608436    
2024-01-15 15:18:39,916 - Epoch: [59][  160/  211]    Overall Loss 0.043987    Objective Loss 0.043987                                        LR 0.100000    Time 0.606913    
2024-01-15 15:18:45,965 - Epoch: [59][  170/  211]    Overall Loss 0.044441    Objective Loss 0.044441                                        LR 0.100000    Time 0.606781    
2024-01-15 15:18:51,770 - Epoch: [59][  180/  211]    Overall Loss 0.044205    Objective Loss 0.044205                                        LR 0.100000    Time 0.605314    
2024-01-15 15:18:57,820 - Epoch: [59][  190/  211]    Overall Loss 0.043645    Objective Loss 0.043645                                        LR 0.100000    Time 0.605293    
2024-01-15 15:19:03,517 - Epoch: [59][  200/  211]    Overall Loss 0.043669    Objective Loss 0.043669                                        LR 0.100000    Time 0.603508    
2024-01-15 15:19:09,180 - Epoch: [59][  210/  211]    Overall Loss 0.043705    Objective Loss 0.043705    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.601732    
2024-01-15 15:19:09,749 - Epoch: [59][  211/  211]    Overall Loss 0.043778    Objective Loss 0.043778    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.601576    
2024-01-15 15:19:10,560 - --- validate (epoch=59)-----------
2024-01-15 15:19:10,563 - 6000 samples (256 per mini-batch)
2024-01-15 15:19:16,780 - Epoch: [59][   10/   24]    Loss 0.047121    Top1 98.632812    Top5 100.000000    
2024-01-15 15:19:18,936 - Epoch: [59][   20/   24]    Loss 0.049300    Top1 98.515625    Top5 99.980469    
2024-01-15 15:19:19,689 - Epoch: [59][   24/   24]    Loss 0.047304    Top1 98.583333    Top5 99.966667    
2024-01-15 15:19:20,288 - ==> Top1: 98.583    Top5: 99.967    Loss: 0.047

2024-01-15 15:19:20,289 - ==> Confusion:
[[602   0   0   0   0   0   1   0   0   2]
 [  0 682   1   0   0   1   0   3   1   0]
 [  1   2 567   1   1   0   0   7   4   3]
 [  0   0   0 572   0   2   0   6   2   1]
 [  0   1   0   0 549   0   1   1   0  13]
 [  2   0   0   1   0 512   0   0   2   1]
 [  4   0   0   0   3   0 622   0   2   0]
 [  0   0   1   0   1   0   0 622   0   1]
 [  0   0   0   0   1   1   0   1 579   2]
 [  1   0   0   0   1   1   0   2   2 608]]

2024-01-15 15:19:20,291 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:19:20,291 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:19:20,295 - 

2024-01-15 15:19:20,295 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:19:28,586 - Epoch: [60][   10/  211]    Overall Loss 0.037773    Objective Loss 0.037773                                        LR 0.100000    Time 0.829018    
2024-01-15 15:19:34,341 - Epoch: [60][   20/  211]    Overall Loss 0.040044    Objective Loss 0.040044                                        LR 0.100000    Time 0.702212    
2024-01-15 15:19:39,969 - Epoch: [60][   30/  211]    Overall Loss 0.039529    Objective Loss 0.039529                                        LR 0.100000    Time 0.655737    
2024-01-15 15:19:45,862 - Epoch: [60][   40/  211]    Overall Loss 0.042291    Objective Loss 0.042291                                        LR 0.100000    Time 0.639078    
2024-01-15 15:19:51,542 - Epoch: [60][   50/  211]    Overall Loss 0.043303    Objective Loss 0.043303                                        LR 0.100000    Time 0.624854    
2024-01-15 15:19:57,406 - Epoch: [60][   60/  211]    Overall Loss 0.041962    Objective Loss 0.041962                                        LR 0.100000    Time 0.618432    
2024-01-15 15:20:03,149 - Epoch: [60][   70/  211]    Overall Loss 0.042551    Objective Loss 0.042551                                        LR 0.100000    Time 0.612108    
2024-01-15 15:20:08,961 - Epoch: [60][   80/  211]    Overall Loss 0.041558    Objective Loss 0.041558                                        LR 0.100000    Time 0.608238    
2024-01-15 15:20:14,727 - Epoch: [60][   90/  211]    Overall Loss 0.041698    Objective Loss 0.041698                                        LR 0.100000    Time 0.604708    
2024-01-15 15:20:20,530 - Epoch: [60][  100/  211]    Overall Loss 0.042345    Objective Loss 0.042345                                        LR 0.100000    Time 0.602251    
2024-01-15 15:20:26,310 - Epoch: [60][  110/  211]    Overall Loss 0.042191    Objective Loss 0.042191                                        LR 0.100000    Time 0.600038    
2024-01-15 15:20:32,033 - Epoch: [60][  120/  211]    Overall Loss 0.041803    Objective Loss 0.041803                                        LR 0.100000    Time 0.597720    
2024-01-15 15:20:37,737 - Epoch: [60][  130/  211]    Overall Loss 0.041983    Objective Loss 0.041983                                        LR 0.100000    Time 0.595603    
2024-01-15 15:20:43,404 - Epoch: [60][  140/  211]    Overall Loss 0.041703    Objective Loss 0.041703                                        LR 0.100000    Time 0.593534    
2024-01-15 15:20:49,230 - Epoch: [60][  150/  211]    Overall Loss 0.042447    Objective Loss 0.042447                                        LR 0.100000    Time 0.592801    
2024-01-15 15:20:55,252 - Epoch: [60][  160/  211]    Overall Loss 0.042944    Objective Loss 0.042944                                        LR 0.100000    Time 0.593379    
2024-01-15 15:21:00,920 - Epoch: [60][  170/  211]    Overall Loss 0.042381    Objective Loss 0.042381                                        LR 0.100000    Time 0.591811    
2024-01-15 15:21:06,689 - Epoch: [60][  180/  211]    Overall Loss 0.042897    Objective Loss 0.042897                                        LR 0.100000    Time 0.590978    
2024-01-15 15:21:12,684 - Epoch: [60][  190/  211]    Overall Loss 0.042728    Objective Loss 0.042728                                        LR 0.100000    Time 0.591421    
2024-01-15 15:21:18,408 - Epoch: [60][  200/  211]    Overall Loss 0.042303    Objective Loss 0.042303                                        LR 0.100000    Time 0.590460    
2024-01-15 15:21:24,053 - Epoch: [60][  210/  211]    Overall Loss 0.042044    Objective Loss 0.042044    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.589224    
2024-01-15 15:21:24,626 - Epoch: [60][  211/  211]    Overall Loss 0.041933    Objective Loss 0.041933    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.589139    
2024-01-15 15:21:25,500 - --- validate (epoch=60)-----------
2024-01-15 15:21:25,502 - 6000 samples (256 per mini-batch)
2024-01-15 15:21:32,144 - Epoch: [60][   10/   24]    Loss 0.039245    Top1 98.828125    Top5 99.960938    
2024-01-15 15:21:34,260 - Epoch: [60][   20/   24]    Loss 0.042887    Top1 98.710938    Top5 99.980469    
2024-01-15 15:21:35,014 - Epoch: [60][   24/   24]    Loss 0.047623    Top1 98.633333    Top5 99.966667    
2024-01-15 15:21:35,592 - ==> Top1: 98.633    Top5: 99.967    Loss: 0.048

2024-01-15 15:21:35,594 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 683   1   1   1   1   1   0   0   0]
 [  0   0 582   1   0   0   0   2   0   1]
 [  0   1   2 574   0   2   0   2   2   0]
 [  0   1   4   0 553   0   0   0   0   7]
 [  1   0   0   1   0 503   9   2   1   1]
 [  0   0   0   0   1   0 629   0   1   0]
 [  0   2   4   0   1   0   0 618   0   0]
 [  0   0   2   1   0   1   2   1 577   0]
 [  1   3   0   0   8   0   0   4   2 597]]

2024-01-15 15:21:35,596 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:21:35,596 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:21:35,600 - 

2024-01-15 15:21:35,600 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:21:43,836 - Epoch: [61][   10/  211]    Overall Loss 0.036859    Objective Loss 0.036859                                        LR 0.100000    Time 0.823476    
2024-01-15 15:21:49,502 - Epoch: [61][   20/  211]    Overall Loss 0.036273    Objective Loss 0.036273                                        LR 0.100000    Time 0.695018    
2024-01-15 15:21:55,193 - Epoch: [61][   30/  211]    Overall Loss 0.036832    Objective Loss 0.036832                                        LR 0.100000    Time 0.653014    
2024-01-15 15:22:00,853 - Epoch: [61][   40/  211]    Overall Loss 0.038462    Objective Loss 0.038462                                        LR 0.100000    Time 0.631250    
2024-01-15 15:22:06,488 - Epoch: [61][   50/  211]    Overall Loss 0.039832    Objective Loss 0.039832                                        LR 0.100000    Time 0.617672    
2024-01-15 15:22:12,576 - Epoch: [61][   60/  211]    Overall Loss 0.040342    Objective Loss 0.040342                                        LR 0.100000    Time 0.616178    
2024-01-15 15:22:18,239 - Epoch: [61][   70/  211]    Overall Loss 0.040606    Objective Loss 0.040606                                        LR 0.100000    Time 0.609041    
2024-01-15 15:22:23,884 - Epoch: [61][   80/  211]    Overall Loss 0.040495    Objective Loss 0.040495                                        LR 0.100000    Time 0.603463    
2024-01-15 15:22:29,542 - Epoch: [61][   90/  211]    Overall Loss 0.040253    Objective Loss 0.040253                                        LR 0.100000    Time 0.599264    
2024-01-15 15:22:35,200 - Epoch: [61][  100/  211]    Overall Loss 0.040151    Objective Loss 0.040151                                        LR 0.100000    Time 0.595919    
2024-01-15 15:22:40,832 - Epoch: [61][  110/  211]    Overall Loss 0.040264    Objective Loss 0.040264                                        LR 0.100000    Time 0.592930    
2024-01-15 15:22:46,466 - Epoch: [61][  120/  211]    Overall Loss 0.041133    Objective Loss 0.041133                                        LR 0.100000    Time 0.590467    
2024-01-15 15:22:52,184 - Epoch: [61][  130/  211]    Overall Loss 0.040861    Objective Loss 0.040861                                        LR 0.100000    Time 0.589022    
2024-01-15 15:22:58,113 - Epoch: [61][  140/  211]    Overall Loss 0.040651    Objective Loss 0.040651                                        LR 0.100000    Time 0.589287    
2024-01-15 15:23:03,763 - Epoch: [61][  150/  211]    Overall Loss 0.040864    Objective Loss 0.040864                                        LR 0.100000    Time 0.587667    
2024-01-15 15:23:09,410 - Epoch: [61][  160/  211]    Overall Loss 0.040457    Objective Loss 0.040457                                        LR 0.100000    Time 0.586223    
2024-01-15 15:23:15,122 - Epoch: [61][  170/  211]    Overall Loss 0.040366    Objective Loss 0.040366                                        LR 0.100000    Time 0.585338    
2024-01-15 15:23:20,872 - Epoch: [61][  180/  211]    Overall Loss 0.041035    Objective Loss 0.041035                                        LR 0.100000    Time 0.584733    
2024-01-15 15:23:26,773 - Epoch: [61][  190/  211]    Overall Loss 0.041109    Objective Loss 0.041109                                        LR 0.100000    Time 0.584991    
2024-01-15 15:23:32,553 - Epoch: [61][  200/  211]    Overall Loss 0.041502    Objective Loss 0.041502                                        LR 0.100000    Time 0.584633    
2024-01-15 15:23:38,204 - Epoch: [61][  210/  211]    Overall Loss 0.041127    Objective Loss 0.041127    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.583696    
2024-01-15 15:23:38,758 - Epoch: [61][  211/  211]    Overall Loss 0.041024    Objective Loss 0.041024    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.583554    
2024-01-15 15:23:39,585 - --- validate (epoch=61)-----------
2024-01-15 15:23:39,587 - 6000 samples (256 per mini-batch)
2024-01-15 15:23:45,869 - Epoch: [61][   10/   24]    Loss 0.037634    Top1 98.750000    Top5 100.000000    
2024-01-15 15:23:47,998 - Epoch: [61][   20/   24]    Loss 0.042390    Top1 98.730469    Top5 100.000000    
2024-01-15 15:23:48,800 - Epoch: [61][   24/   24]    Loss 0.045172    Top1 98.700000    Top5 100.000000    
2024-01-15 15:23:49,426 - ==> Top1: 98.700    Top5: 100.000    Loss: 0.045

2024-01-15 15:23:49,427 - ==> Confusion:
[[601   0   0   0   1   0   3   0   0   0]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   0 569   3   1   1   1  11   0   0]
 [  0   1   0 577   0   3   0   1   1   0]
 [  0   1   0   0 559   0   0   1   0   4]
 [  0   0   0   1   0 514   3   0   0   0]
 [  0   1   0   0   3   0 627   0   0   0]
 [  1   2   1   1   1   0   0 619   0   0]
 [  1   0   0   0   1   1   3   0 576   2]
 [  0   2   0   1   9   4   0   1   4 594]]

2024-01-15 15:23:49,430 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:23:49,431 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:23:49,435 - 

2024-01-15 15:23:49,435 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:23:59,759 - Epoch: [62][   10/  211]    Overall Loss 0.035633    Objective Loss 0.035633                                        LR 0.100000    Time 1.032154    
2024-01-15 15:24:05,882 - Epoch: [62][   20/  211]    Overall Loss 0.037232    Objective Loss 0.037232                                        LR 0.100000    Time 0.822155    
2024-01-15 15:24:12,123 - Epoch: [62][   30/  211]    Overall Loss 0.037581    Objective Loss 0.037581                                        LR 0.100000    Time 0.756048    
2024-01-15 15:24:18,037 - Epoch: [62][   40/  211]    Overall Loss 0.040671    Objective Loss 0.040671                                        LR 0.100000    Time 0.714852    
2024-01-15 15:24:23,756 - Epoch: [62][   50/  211]    Overall Loss 0.044472    Objective Loss 0.044472                                        LR 0.100000    Time 0.686253    
2024-01-15 15:24:29,493 - Epoch: [62][   60/  211]    Overall Loss 0.043891    Objective Loss 0.043891                                        LR 0.100000    Time 0.667477    
2024-01-15 15:24:35,150 - Epoch: [62][   70/  211]    Overall Loss 0.043606    Objective Loss 0.043606                                        LR 0.100000    Time 0.652925    
2024-01-15 15:24:40,898 - Epoch: [62][   80/  211]    Overall Loss 0.044464    Objective Loss 0.044464                                        LR 0.100000    Time 0.643147    
2024-01-15 15:24:46,569 - Epoch: [62][   90/  211]    Overall Loss 0.043909    Objective Loss 0.043909                                        LR 0.100000    Time 0.634687    
2024-01-15 15:24:52,334 - Epoch: [62][  100/  211]    Overall Loss 0.043245    Objective Loss 0.043245                                        LR 0.100000    Time 0.628854    
2024-01-15 15:24:58,203 - Epoch: [62][  110/  211]    Overall Loss 0.043154    Objective Loss 0.043154                                        LR 0.100000    Time 0.625030    
2024-01-15 15:25:04,463 - Epoch: [62][  120/  211]    Overall Loss 0.043718    Objective Loss 0.043718                                        LR 0.100000    Time 0.625105    
2024-01-15 15:25:10,178 - Epoch: [62][  130/  211]    Overall Loss 0.043287    Objective Loss 0.043287                                        LR 0.100000    Time 0.620972    
2024-01-15 15:25:15,916 - Epoch: [62][  140/  211]    Overall Loss 0.043313    Objective Loss 0.043313                                        LR 0.100000    Time 0.617595    
2024-01-15 15:25:21,842 - Epoch: [62][  150/  211]    Overall Loss 0.042825    Objective Loss 0.042825                                        LR 0.100000    Time 0.615922    
2024-01-15 15:25:27,725 - Epoch: [62][  160/  211]    Overall Loss 0.042379    Objective Loss 0.042379                                        LR 0.100000    Time 0.614186    
2024-01-15 15:25:33,486 - Epoch: [62][  170/  211]    Overall Loss 0.042299    Objective Loss 0.042299                                        LR 0.100000    Time 0.611936    
2024-01-15 15:25:39,262 - Epoch: [62][  180/  211]    Overall Loss 0.041907    Objective Loss 0.041907                                        LR 0.100000    Time 0.610024    
2024-01-15 15:25:45,116 - Epoch: [62][  190/  211]    Overall Loss 0.041625    Objective Loss 0.041625                                        LR 0.100000    Time 0.608720    
2024-01-15 15:25:50,791 - Epoch: [62][  200/  211]    Overall Loss 0.041370    Objective Loss 0.041370                                        LR 0.100000    Time 0.606657    
2024-01-15 15:25:56,763 - Epoch: [62][  210/  211]    Overall Loss 0.041233    Objective Loss 0.041233    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.606199    
2024-01-15 15:25:57,351 - Epoch: [62][  211/  211]    Overall Loss 0.041211    Objective Loss 0.041211    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.606111    
2024-01-15 15:25:58,222 - --- validate (epoch=62)-----------
2024-01-15 15:25:58,224 - 6000 samples (256 per mini-batch)
2024-01-15 15:26:05,346 - Epoch: [62][   10/   24]    Loss 0.043652    Top1 98.710938    Top5 99.960938    
2024-01-15 15:26:07,466 - Epoch: [62][   20/   24]    Loss 0.044386    Top1 98.593750    Top5 99.980469    
2024-01-15 15:26:08,220 - Epoch: [62][   24/   24]    Loss 0.047304    Top1 98.516667    Top5 99.966667    
2024-01-15 15:26:08,979 - ==> Top1: 98.517    Top5: 99.967    Loss: 0.047

2024-01-15 15:26:08,980 - ==> Confusion:
[[600   0   1   0   0   0   2   0   2   0]
 [  0 684   1   1   0   1   0   1   0   0]
 [  0   0 581   1   0   0   1   1   2   0]
 [  0   0   4 577   0   1   0   0   1   0]
 [  0   1   0   0 555   1   2   1   0   5]
 [  1   1   0   2   0 510   2   0   2   0]
 [  0   0   0   0   1   0 629   0   1   0]
 [  0   2   8   5   2   0   0 607   0   1]
 [  0   0   1   2   0   1   2   0 578   0]
 [  0   0   1   1   6   3   0   5   9 590]]

2024-01-15 15:26:08,982 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:26:08,982 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:26:08,986 - 

2024-01-15 15:26:08,986 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:26:18,340 - Epoch: [63][   10/  211]    Overall Loss 0.043238    Objective Loss 0.043238                                        LR 0.100000    Time 0.935310    
2024-01-15 15:26:24,008 - Epoch: [63][   20/  211]    Overall Loss 0.040243    Objective Loss 0.040243                                        LR 0.100000    Time 0.751021    
2024-01-15 15:26:29,856 - Epoch: [63][   30/  211]    Overall Loss 0.039696    Objective Loss 0.039696                                        LR 0.100000    Time 0.695561    
2024-01-15 15:26:35,750 - Epoch: [63][   40/  211]    Overall Loss 0.040949    Objective Loss 0.040949                                        LR 0.100000    Time 0.668988    
2024-01-15 15:26:41,400 - Epoch: [63][   50/  211]    Overall Loss 0.041634    Objective Loss 0.041634                                        LR 0.100000    Time 0.648179    
2024-01-15 15:26:47,169 - Epoch: [63][   60/  211]    Overall Loss 0.041063    Objective Loss 0.041063                                        LR 0.100000    Time 0.636284    
2024-01-15 15:26:53,046 - Epoch: [63][   70/  211]    Overall Loss 0.041537    Objective Loss 0.041537                                        LR 0.100000    Time 0.629323    
2024-01-15 15:26:58,869 - Epoch: [63][   80/  211]    Overall Loss 0.040578    Objective Loss 0.040578                                        LR 0.100000    Time 0.623432    
2024-01-15 15:27:04,730 - Epoch: [63][   90/  211]    Overall Loss 0.040020    Objective Loss 0.040020                                        LR 0.100000    Time 0.619266    
2024-01-15 15:27:10,413 - Epoch: [63][  100/  211]    Overall Loss 0.039724    Objective Loss 0.039724                                        LR 0.100000    Time 0.614159    
2024-01-15 15:27:16,093 - Epoch: [63][  110/  211]    Overall Loss 0.039722    Objective Loss 0.039722                                        LR 0.100000    Time 0.609956    
2024-01-15 15:27:22,019 - Epoch: [63][  120/  211]    Overall Loss 0.040031    Objective Loss 0.040031                                        LR 0.100000    Time 0.608499    
2024-01-15 15:27:27,843 - Epoch: [63][  130/  211]    Overall Loss 0.039697    Objective Loss 0.039697                                        LR 0.100000    Time 0.606480    
2024-01-15 15:27:33,946 - Epoch: [63][  140/  211]    Overall Loss 0.039282    Objective Loss 0.039282                                        LR 0.100000    Time 0.606747    
2024-01-15 15:27:39,795 - Epoch: [63][  150/  211]    Overall Loss 0.039498    Objective Loss 0.039498                                        LR 0.100000    Time 0.605277    
2024-01-15 15:27:45,457 - Epoch: [63][  160/  211]    Overall Loss 0.039276    Objective Loss 0.039276                                        LR 0.100000    Time 0.602833    
2024-01-15 15:27:51,120 - Epoch: [63][  170/  211]    Overall Loss 0.039188    Objective Loss 0.039188                                        LR 0.100000    Time 0.600683    
2024-01-15 15:27:57,029 - Epoch: [63][  180/  211]    Overall Loss 0.039217    Objective Loss 0.039217                                        LR 0.100000    Time 0.600131    
2024-01-15 15:28:02,755 - Epoch: [63][  190/  211]    Overall Loss 0.039034    Objective Loss 0.039034                                        LR 0.100000    Time 0.598671    
2024-01-15 15:28:08,647 - Epoch: [63][  200/  211]    Overall Loss 0.039524    Objective Loss 0.039524                                        LR 0.100000    Time 0.598193    
2024-01-15 15:28:14,348 - Epoch: [63][  210/  211]    Overall Loss 0.039632    Objective Loss 0.039632    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.596848    
2024-01-15 15:28:14,927 - Epoch: [63][  211/  211]    Overall Loss 0.039801    Objective Loss 0.039801    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.596763    
2024-01-15 15:28:15,696 - --- validate (epoch=63)-----------
2024-01-15 15:28:15,697 - 6000 samples (256 per mini-batch)
2024-01-15 15:28:22,499 - Epoch: [63][   10/   24]    Loss 0.038356    Top1 98.867188    Top5 100.000000    
2024-01-15 15:28:24,622 - Epoch: [63][   20/   24]    Loss 0.047547    Top1 98.554688    Top5 100.000000    
2024-01-15 15:28:25,382 - Epoch: [63][   24/   24]    Loss 0.048278    Top1 98.550000    Top5 100.000000    
2024-01-15 15:28:25,983 - ==> Top1: 98.550    Top5: 100.000    Loss: 0.048

2024-01-15 15:28:25,984 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 685   2   0   1   0   0   0   0   0]
 [  0   1 577   0   1   0   0   6   1   0]
 [  0   0   1 575   1   2   0   2   2   0]
 [  0   1   1   0 557   0   0   3   0   3]
 [  1   0   0   0   0 513   2   1   1   0]
 [  1   2   0   0   5   0 623   0   0   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  0   0   1   2   2   2   1   0 575   1]
 [  1   1   0   1  17   2   0   5   5 583]]

2024-01-15 15:28:25,986 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:28:25,986 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:28:25,990 - 

2024-01-15 15:28:25,990 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:28:34,622 - Epoch: [64][   10/  211]    Overall Loss 0.048090    Objective Loss 0.048090                                        LR 0.100000    Time 0.863070    
2024-01-15 15:28:40,307 - Epoch: [64][   20/  211]    Overall Loss 0.049208    Objective Loss 0.049208                                        LR 0.100000    Time 0.715718    
2024-01-15 15:28:46,004 - Epoch: [64][   30/  211]    Overall Loss 0.048148    Objective Loss 0.048148                                        LR 0.100000    Time 0.667037    
2024-01-15 15:28:51,685 - Epoch: [64][   40/  211]    Overall Loss 0.047636    Objective Loss 0.047636                                        LR 0.100000    Time 0.642260    
2024-01-15 15:28:57,789 - Epoch: [64][   50/  211]    Overall Loss 0.046511    Objective Loss 0.046511                                        LR 0.100000    Time 0.635888    
2024-01-15 15:29:03,645 - Epoch: [64][   60/  211]    Overall Loss 0.044808    Objective Loss 0.044808                                        LR 0.100000    Time 0.627477    
2024-01-15 15:29:09,763 - Epoch: [64][   70/  211]    Overall Loss 0.043676    Objective Loss 0.043676                                        LR 0.100000    Time 0.625215    
2024-01-15 15:29:15,487 - Epoch: [64][   80/  211]    Overall Loss 0.042829    Objective Loss 0.042829                                        LR 0.100000    Time 0.618606    
2024-01-15 15:29:21,184 - Epoch: [64][   90/  211]    Overall Loss 0.043238    Objective Loss 0.043238                                        LR 0.100000    Time 0.613159    
2024-01-15 15:29:26,906 - Epoch: [64][  100/  211]    Overall Loss 0.043509    Objective Loss 0.043509                                        LR 0.100000    Time 0.609038    
2024-01-15 15:29:32,657 - Epoch: [64][  110/  211]    Overall Loss 0.042440    Objective Loss 0.042440                                        LR 0.100000    Time 0.605930    
2024-01-15 15:29:38,430 - Epoch: [64][  120/  211]    Overall Loss 0.041664    Objective Loss 0.041664                                        LR 0.100000    Time 0.603540    
2024-01-15 15:29:44,091 - Epoch: [64][  130/  211]    Overall Loss 0.040517    Objective Loss 0.040517                                        LR 0.100000    Time 0.600651    
2024-01-15 15:29:49,814 - Epoch: [64][  140/  211]    Overall Loss 0.040641    Objective Loss 0.040641                                        LR 0.100000    Time 0.598621    
2024-01-15 15:29:55,869 - Epoch: [64][  150/  211]    Overall Loss 0.040652    Objective Loss 0.040652                                        LR 0.100000    Time 0.599074    
2024-01-15 15:30:01,613 - Epoch: [64][  160/  211]    Overall Loss 0.040833    Objective Loss 0.040833                                        LR 0.100000    Time 0.597524    
2024-01-15 15:30:07,466 - Epoch: [64][  170/  211]    Overall Loss 0.041264    Objective Loss 0.041264                                        LR 0.100000    Time 0.596801    
2024-01-15 15:30:13,259 - Epoch: [64][  180/  211]    Overall Loss 0.040619    Objective Loss 0.040619                                        LR 0.100000    Time 0.595813    
2024-01-15 15:30:19,215 - Epoch: [64][  190/  211]    Overall Loss 0.040163    Objective Loss 0.040163                                        LR 0.100000    Time 0.595792    
2024-01-15 15:30:25,063 - Epoch: [64][  200/  211]    Overall Loss 0.040125    Objective Loss 0.040125                                        LR 0.100000    Time 0.595223    
2024-01-15 15:30:30,887 - Epoch: [64][  210/  211]    Overall Loss 0.040154    Objective Loss 0.040154    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.594606    
2024-01-15 15:30:31,463 - Epoch: [64][  211/  211]    Overall Loss 0.040044    Objective Loss 0.040044    Top1 99.596774    Top5 100.000000    LR 0.100000    Time 0.594511    
2024-01-15 15:30:32,237 - --- validate (epoch=64)-----------
2024-01-15 15:30:32,238 - 6000 samples (256 per mini-batch)
2024-01-15 15:30:37,891 - Epoch: [64][   10/   24]    Loss 0.043441    Top1 98.828125    Top5 100.000000    
2024-01-15 15:30:40,015 - Epoch: [64][   20/   24]    Loss 0.041583    Top1 98.847656    Top5 100.000000    
2024-01-15 15:30:40,780 - Epoch: [64][   24/   24]    Loss 0.042618    Top1 98.800000    Top5 100.000000    
2024-01-15 15:30:41,380 - ==> Top1: 98.800    Top5: 100.000    Loss: 0.043

2024-01-15 15:30:41,381 - ==> Confusion:
[[602   0   2   0   0   0   0   0   0   1]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 585   0   0   0   0   1   0   0]
 [  0   0   0 581   0   1   0   1   0   0]
 [  0   1   3   0 541   0   0   6   0  14]
 [  0   0   1   1   1 514   0   0   1   0]
 [  1   0   0   0   3   1 625   0   1   0]
 [  0   0   2   0   0   0   0 622   0   1]
 [  1   0   2   2   0   3   2   1 573   0]
 [  1   1   0   1   2   2   0   7   2 599]]

2024-01-15 15:30:41,383 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:30:41,383 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:30:41,386 - 

2024-01-15 15:30:41,387 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:30:50,218 - Epoch: [65][   10/  211]    Overall Loss 0.038979    Objective Loss 0.038979                                        LR 0.100000    Time 0.882955    
2024-01-15 15:30:56,150 - Epoch: [65][   20/  211]    Overall Loss 0.041633    Objective Loss 0.041633                                        LR 0.100000    Time 0.737985    
2024-01-15 15:31:01,812 - Epoch: [65][   30/  211]    Overall Loss 0.044796    Objective Loss 0.044796                                        LR 0.100000    Time 0.680667    
2024-01-15 15:31:07,743 - Epoch: [65][   40/  211]    Overall Loss 0.045774    Objective Loss 0.045774                                        LR 0.100000    Time 0.658778    
2024-01-15 15:31:13,611 - Epoch: [65][   50/  211]    Overall Loss 0.047486    Objective Loss 0.047486                                        LR 0.100000    Time 0.644358    
2024-01-15 15:31:19,488 - Epoch: [65][   60/  211]    Overall Loss 0.048141    Objective Loss 0.048141                                        LR 0.100000    Time 0.634895    
2024-01-15 15:31:25,301 - Epoch: [65][   70/  211]    Overall Loss 0.046565    Objective Loss 0.046565                                        LR 0.100000    Time 0.627227    
2024-01-15 15:31:31,255 - Epoch: [65][   80/  211]    Overall Loss 0.046935    Objective Loss 0.046935                                        LR 0.100000    Time 0.623227    
2024-01-15 15:31:37,071 - Epoch: [65][   90/  211]    Overall Loss 0.044893    Objective Loss 0.044893                                        LR 0.100000    Time 0.618588    
2024-01-15 15:31:42,932 - Epoch: [65][  100/  211]    Overall Loss 0.045029    Objective Loss 0.045029                                        LR 0.100000    Time 0.615333    
2024-01-15 15:31:49,122 - Epoch: [65][  110/  211]    Overall Loss 0.044697    Objective Loss 0.044697                                        LR 0.100000    Time 0.615644    
2024-01-15 15:31:54,922 - Epoch: [65][  120/  211]    Overall Loss 0.045107    Objective Loss 0.045107                                        LR 0.100000    Time 0.612643    
2024-01-15 15:32:00,695 - Epoch: [65][  130/  211]    Overall Loss 0.045363    Objective Loss 0.045363                                        LR 0.100000    Time 0.609918    
2024-01-15 15:32:06,416 - Epoch: [65][  140/  211]    Overall Loss 0.045629    Objective Loss 0.045629                                        LR 0.100000    Time 0.607209    
2024-01-15 15:32:12,068 - Epoch: [65][  150/  211]    Overall Loss 0.045666    Objective Loss 0.045666                                        LR 0.100000    Time 0.604399    
2024-01-15 15:32:17,965 - Epoch: [65][  160/  211]    Overall Loss 0.045196    Objective Loss 0.045196                                        LR 0.100000    Time 0.603476    
2024-01-15 15:32:23,858 - Epoch: [65][  170/  211]    Overall Loss 0.045427    Objective Loss 0.045427                                        LR 0.100000    Time 0.602633    
2024-01-15 15:32:29,885 - Epoch: [65][  180/  211]    Overall Loss 0.044635    Objective Loss 0.044635                                        LR 0.100000    Time 0.602633    
2024-01-15 15:32:35,713 - Epoch: [65][  190/  211]    Overall Loss 0.044157    Objective Loss 0.044157                                        LR 0.100000    Time 0.601581    
2024-01-15 15:32:41,538 - Epoch: [65][  200/  211]    Overall Loss 0.043687    Objective Loss 0.043687                                        LR 0.100000    Time 0.600620    
2024-01-15 15:32:47,206 - Epoch: [65][  210/  211]    Overall Loss 0.043048    Objective Loss 0.043048    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.599010    
2024-01-15 15:32:47,782 - Epoch: [65][  211/  211]    Overall Loss 0.043178    Objective Loss 0.043178    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.598895    
2024-01-15 15:32:48,583 - --- validate (epoch=65)-----------
2024-01-15 15:32:48,584 - 6000 samples (256 per mini-batch)
2024-01-15 15:32:53,916 - Epoch: [65][   10/   24]    Loss 0.043344    Top1 98.750000    Top5 100.000000    
2024-01-15 15:32:56,423 - Epoch: [65][   20/   24]    Loss 0.048562    Top1 98.437500    Top5 99.980469    
2024-01-15 15:32:57,394 - Epoch: [65][   24/   24]    Loss 0.048458    Top1 98.450000    Top5 99.983333    
2024-01-15 15:32:58,177 - ==> Top1: 98.450    Top5: 99.983    Loss: 0.048

2024-01-15 15:32:58,178 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 687   1   0   0   0   0   0   0   0]
 [  1   0 574   3   0   0   0   5   2   1]
 [  0   0   2 575   0   1   1   3   1   0]
 [  0   1   0   0 557   0   0   3   1   3]
 [  1   1   0   3   1 506   3   0   3   0]
 [  3   0   0   0   2   0 624   0   2   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   0   1   1   0   3   2 576   1]
 [  0   1   0   1  16   4   0   7   5 581]]

2024-01-15 15:32:58,181 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:32:58,181 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:32:58,185 - 

2024-01-15 15:32:58,187 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:33:07,515 - Epoch: [66][   10/  211]    Overall Loss 0.040889    Objective Loss 0.040889                                        LR 0.100000    Time 0.932688    
2024-01-15 15:33:13,505 - Epoch: [66][   20/  211]    Overall Loss 0.039380    Objective Loss 0.039380                                        LR 0.100000    Time 0.765800    
2024-01-15 15:33:19,188 - Epoch: [66][   30/  211]    Overall Loss 0.037647    Objective Loss 0.037647                                        LR 0.100000    Time 0.699949    
2024-01-15 15:33:24,846 - Epoch: [66][   40/  211]    Overall Loss 0.036440    Objective Loss 0.036440                                        LR 0.100000    Time 0.666405    
2024-01-15 15:33:32,060 - Epoch: [66][   50/  211]    Overall Loss 0.037336    Objective Loss 0.037336                                        LR 0.100000    Time 0.677375    
2024-01-15 15:34:03,979 - Epoch: [66][   60/  211]    Overall Loss 0.038575    Objective Loss 0.038575                                        LR 0.100000    Time 1.096430    
2024-01-15 15:34:09,614 - Epoch: [66][   70/  211]    Overall Loss 0.038666    Objective Loss 0.038666                                        LR 0.100000    Time 1.020284    
2024-01-15 15:34:15,256 - Epoch: [66][   80/  211]    Overall Loss 0.039236    Objective Loss 0.039236                                        LR 0.100000    Time 0.963262    
2024-01-15 15:34:20,986 - Epoch: [66][   90/  211]    Overall Loss 0.039610    Objective Loss 0.039610                                        LR 0.100000    Time 0.919895    
2024-01-15 15:34:26,656 - Epoch: [66][  100/  211]    Overall Loss 0.039361    Objective Loss 0.039361                                        LR 0.100000    Time 0.884593    
2024-01-15 15:34:32,292 - Epoch: [66][  110/  211]    Overall Loss 0.040800    Objective Loss 0.040800                                        LR 0.100000    Time 0.855414    
2024-01-15 15:34:37,934 - Epoch: [66][  120/  211]    Overall Loss 0.041106    Objective Loss 0.041106                                        LR 0.100000    Time 0.831130    
2024-01-15 15:34:43,565 - Epoch: [66][  130/  211]    Overall Loss 0.041248    Objective Loss 0.041248                                        LR 0.100000    Time 0.810509    
2024-01-15 15:36:12,843 - Epoch: [66][  140/  211]    Overall Loss 0.041124    Objective Loss 0.041124                                        LR 0.100000    Time 1.390307    
2024-01-15 15:36:18,883 - Epoch: [66][  150/  211]    Overall Loss 0.040648    Objective Loss 0.040648                                        LR 0.100000    Time 1.337877    
2024-01-15 15:36:24,774 - Epoch: [66][  160/  211]    Overall Loss 0.040632    Objective Loss 0.040632                                        LR 0.100000    Time 1.291067    
2024-01-15 15:36:30,610 - Epoch: [66][  170/  211]    Overall Loss 0.040483    Objective Loss 0.040483                                        LR 0.100000    Time 1.249443    
2024-01-15 15:36:36,650 - Epoch: [66][  180/  211]    Overall Loss 0.040577    Objective Loss 0.040577                                        LR 0.100000    Time 1.213580    
2024-01-15 15:36:42,375 - Epoch: [66][  190/  211]    Overall Loss 0.041243    Objective Loss 0.041243                                        LR 0.100000    Time 1.179822    
2024-01-15 15:36:48,401 - Epoch: [66][  200/  211]    Overall Loss 0.041370    Objective Loss 0.041370                                        LR 0.100000    Time 1.150956    
2024-01-15 15:36:54,189 - Epoch: [66][  210/  211]    Overall Loss 0.041249    Objective Loss 0.041249    Top1 100.000000    Top5 100.000000    LR 0.100000    Time 1.123706    
2024-01-15 15:36:54,748 - Epoch: [66][  211/  211]    Overall Loss 0.041222    Objective Loss 0.041222    Top1 99.395161    Top5 100.000000    LR 0.100000    Time 1.121028    
2024-01-15 15:36:55,572 - --- validate (epoch=66)-----------
2024-01-15 15:36:55,575 - 6000 samples (256 per mini-batch)
2024-01-15 15:37:02,750 - Epoch: [66][   10/   24]    Loss 0.036536    Top1 98.789062    Top5 100.000000    
2024-01-15 15:37:04,902 - Epoch: [66][   20/   24]    Loss 0.035238    Top1 98.886719    Top5 100.000000    
2024-01-15 15:37:05,881 - Epoch: [66][   24/   24]    Loss 0.037965    Top1 98.883333    Top5 99.983333    
2024-01-15 15:37:06,645 - ==> Top1: 98.883    Top5: 99.983    Loss: 0.038

2024-01-15 15:37:06,647 - ==> Confusion:
[[599   0   1   0   0   0   2   0   1   2]
 [  0 683   1   1   0   1   0   2   0   0]
 [  0   0 582   0   0   0   0   2   2   0]
 [  0   0   2 576   0   3   0   0   2   0]
 [  0   1   1   0 555   0   0   0   0   8]
 [  0   0   0   1   0 510   6   0   1   0]
 [  1   1   0   0   3   0 625   0   1   0]
 [  0   2   3   1   0   1   0 618   0   0]
 [  1   0   1   0   1   1   1   0 579   0]
 [  0   1   0   1   2   0   0   2   3 606]]

2024-01-15 15:37:06,650 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:37:06,651 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:37:06,658 - 

2024-01-15 15:37:06,658 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:37:15,985 - Epoch: [67][   10/  211]    Overall Loss 0.038584    Objective Loss 0.038584                                        LR 0.100000    Time 0.932630    
2024-01-15 15:37:22,484 - Epoch: [67][   20/  211]    Overall Loss 0.038591    Objective Loss 0.038591                                        LR 0.100000    Time 0.791171    
2024-01-15 15:37:28,319 - Epoch: [67][   30/  211]    Overall Loss 0.038722    Objective Loss 0.038722                                        LR 0.100000    Time 0.721890    
2024-01-15 15:37:34,121 - Epoch: [67][   40/  211]    Overall Loss 0.038294    Objective Loss 0.038294                                        LR 0.100000    Time 0.686469    
2024-01-15 15:37:40,109 - Epoch: [67][   50/  211]    Overall Loss 0.040210    Objective Loss 0.040210                                        LR 0.100000    Time 0.668900    
2024-01-15 15:37:46,396 - Epoch: [67][   60/  211]    Overall Loss 0.039949    Objective Loss 0.039949                                        LR 0.100000    Time 0.662191    
2024-01-15 15:37:52,303 - Epoch: [67][   70/  211]    Overall Loss 0.040666    Objective Loss 0.040666                                        LR 0.100000    Time 0.651949    
2024-01-15 15:37:58,251 - Epoch: [67][   80/  211]    Overall Loss 0.040773    Objective Loss 0.040773                                        LR 0.100000    Time 0.644792    
2024-01-15 15:38:04,014 - Epoch: [67][   90/  211]    Overall Loss 0.040520    Objective Loss 0.040520                                        LR 0.100000    Time 0.637175    
2024-01-15 15:38:09,755 - Epoch: [67][  100/  211]    Overall Loss 0.041791    Objective Loss 0.041791                                        LR 0.100000    Time 0.630858    
2024-01-15 15:38:15,682 - Epoch: [67][  110/  211]    Overall Loss 0.042031    Objective Loss 0.042031                                        LR 0.100000    Time 0.627380    
2024-01-15 15:38:21,554 - Epoch: [67][  120/  211]    Overall Loss 0.042057    Objective Loss 0.042057                                        LR 0.100000    Time 0.624023    
2024-01-15 15:38:27,244 - Epoch: [67][  130/  211]    Overall Loss 0.041609    Objective Loss 0.041609                                        LR 0.100000    Time 0.619778    
2024-01-15 15:38:33,089 - Epoch: [67][  140/  211]    Overall Loss 0.042217    Objective Loss 0.042217                                        LR 0.100000    Time 0.617249    
2024-01-15 15:38:38,906 - Epoch: [67][  150/  211]    Overall Loss 0.042077    Objective Loss 0.042077                                        LR 0.100000    Time 0.614869    
2024-01-15 15:38:45,255 - Epoch: [67][  160/  211]    Overall Loss 0.042508    Objective Loss 0.042508                                        LR 0.100000    Time 0.616111    
2024-01-15 15:38:51,700 - Epoch: [67][  170/  211]    Overall Loss 0.042377    Objective Loss 0.042377                                        LR 0.100000    Time 0.617771    
2024-01-15 15:38:57,809 - Epoch: [67][  180/  211]    Overall Loss 0.042141    Objective Loss 0.042141                                        LR 0.100000    Time 0.617376    
2024-01-15 15:39:03,900 - Epoch: [67][  190/  211]    Overall Loss 0.041798    Objective Loss 0.041798                                        LR 0.100000    Time 0.616937    
2024-01-15 15:39:09,663 - Epoch: [67][  200/  211]    Overall Loss 0.042512    Objective Loss 0.042512                                        LR 0.100000    Time 0.614896    
2024-01-15 15:39:15,584 - Epoch: [67][  210/  211]    Overall Loss 0.042471    Objective Loss 0.042471    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.613805    
2024-01-15 15:39:16,165 - Epoch: [67][  211/  211]    Overall Loss 0.042470    Objective Loss 0.042470    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.613647    
2024-01-15 15:39:17,023 - --- validate (epoch=67)-----------
2024-01-15 15:39:17,025 - 6000 samples (256 per mini-batch)
2024-01-15 15:39:24,539 - Epoch: [67][   10/   24]    Loss 0.034289    Top1 98.984375    Top5 100.000000    
2024-01-15 15:39:26,668 - Epoch: [67][   20/   24]    Loss 0.037313    Top1 98.906250    Top5 100.000000    
2024-01-15 15:39:27,438 - Epoch: [67][   24/   24]    Loss 0.037849    Top1 98.850000    Top5 100.000000    
2024-01-15 15:39:28,241 - ==> Top1: 98.850    Top5: 100.000    Loss: 0.038

2024-01-15 15:39:28,242 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 681   2   0   2   1   0   2   0   0]
 [  0   0 581   1   1   0   0   2   1   0]
 [  0   1   4 572   0   4   0   1   1   0]
 [  0   1   0   0 558   0   0   2   0   4]
 [  1   0   0   1   0 513   1   0   1   1]
 [  0   1   0   0   2   0 626   0   2   0]
 [  0   0   4   0   2   0   0 619   0   0]
 [  0   0   1   0   1   2   1   1 577   1]
 [  0   1   0   0   8   0   0   2   3 601]]

2024-01-15 15:39:28,244 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:39:28,244 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:39:28,250 - 

2024-01-15 15:39:28,250 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:39:40,901 - Epoch: [68][   10/  211]    Overall Loss 0.041733    Objective Loss 0.041733                                        LR 0.100000    Time 1.265009    
2024-01-15 15:39:47,546 - Epoch: [68][   20/  211]    Overall Loss 0.038413    Objective Loss 0.038413                                        LR 0.100000    Time 0.964673    
2024-01-15 15:39:53,993 - Epoch: [68][   30/  211]    Overall Loss 0.039559    Objective Loss 0.039559                                        LR 0.100000    Time 0.857957    
2024-01-15 15:39:59,672 - Epoch: [68][   40/  211]    Overall Loss 0.039094    Objective Loss 0.039094                                        LR 0.100000    Time 0.785420    
2024-01-15 15:40:05,889 - Epoch: [68][   50/  211]    Overall Loss 0.040009    Objective Loss 0.040009                                        LR 0.100000    Time 0.752663    
2024-01-15 15:40:11,707 - Epoch: [68][   60/  211]    Overall Loss 0.038557    Objective Loss 0.038557                                        LR 0.100000    Time 0.724160    
2024-01-15 15:40:17,956 - Epoch: [68][   70/  211]    Overall Loss 0.037194    Objective Loss 0.037194                                        LR 0.100000    Time 0.709964    
2024-01-15 15:40:24,649 - Epoch: [68][   80/  211]    Overall Loss 0.036348    Objective Loss 0.036348                                        LR 0.100000    Time 0.704854    
2024-01-15 15:40:30,688 - Epoch: [68][   90/  211]    Overall Loss 0.035937    Objective Loss 0.035937                                        LR 0.100000    Time 0.693626    
2024-01-15 15:40:36,655 - Epoch: [68][  100/  211]    Overall Loss 0.036686    Objective Loss 0.036686                                        LR 0.100000    Time 0.683923    
2024-01-15 15:40:42,901 - Epoch: [68][  110/  211]    Overall Loss 0.037156    Objective Loss 0.037156                                        LR 0.100000    Time 0.678518    
2024-01-15 15:40:48,906 - Epoch: [68][  120/  211]    Overall Loss 0.037816    Objective Loss 0.037816                                        LR 0.100000    Time 0.672008    
2024-01-15 15:40:54,661 - Epoch: [68][  130/  211]    Overall Loss 0.038692    Objective Loss 0.038692                                        LR 0.100000    Time 0.664573    
2024-01-15 15:41:00,487 - Epoch: [68][  140/  211]    Overall Loss 0.039716    Objective Loss 0.039716                                        LR 0.100000    Time 0.658715    
2024-01-15 15:41:06,539 - Epoch: [68][  150/  211]    Overall Loss 0.040699    Objective Loss 0.040699                                        LR 0.100000    Time 0.655136    
2024-01-15 15:41:12,571 - Epoch: [68][  160/  211]    Overall Loss 0.040875    Objective Loss 0.040875                                        LR 0.100000    Time 0.651877    
2024-01-15 15:41:18,476 - Epoch: [68][  170/  211]    Overall Loss 0.040864    Objective Loss 0.040864                                        LR 0.100000    Time 0.648263    
2024-01-15 15:41:24,409 - Epoch: [68][  180/  211]    Overall Loss 0.040982    Objective Loss 0.040982                                        LR 0.100000    Time 0.645201    
2024-01-15 15:41:30,653 - Epoch: [68][  190/  211]    Overall Loss 0.041128    Objective Loss 0.041128                                        LR 0.100000    Time 0.644096    
2024-01-15 15:41:36,944 - Epoch: [68][  200/  211]    Overall Loss 0.041212    Objective Loss 0.041212                                        LR 0.100000    Time 0.643341    
2024-01-15 15:41:43,445 - Epoch: [68][  210/  211]    Overall Loss 0.040988    Objective Loss 0.040988    Top1 96.875000    Top5 100.000000    LR 0.100000    Time 0.643649    
2024-01-15 15:41:44,092 - Epoch: [68][  211/  211]    Overall Loss 0.040872    Objective Loss 0.040872    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.643664    
2024-01-15 15:41:45,221 - --- validate (epoch=68)-----------
2024-01-15 15:41:45,224 - 6000 samples (256 per mini-batch)
2024-01-15 15:41:52,291 - Epoch: [68][   10/   24]    Loss 0.042347    Top1 98.945312    Top5 100.000000    
2024-01-15 15:41:54,484 - Epoch: [68][   20/   24]    Loss 0.045833    Top1 98.710938    Top5 100.000000    
2024-01-15 15:41:55,267 - Epoch: [68][   24/   24]    Loss 0.044577    Top1 98.733333    Top5 100.000000    
2024-01-15 15:41:56,096 - ==> Top1: 98.733    Top5: 100.000    Loss: 0.045

2024-01-15 15:41:56,097 - ==> Confusion:
[[601   0   2   0   0   0   2   0   0   0]
 [  0 683   1   0   1   1   0   2   0   0]
 [  0   0 584   0   0   0   1   1   0   0]
 [  0   0   1 578   0   1   0   2   1   0]
 [  0   1   3   0 548   0   1   3   0   9]
 [  1   0   0   1   0 514   2   0   0   0]
 [  1   2   0   0   2   1 624   0   1   0]
 [  1   1   0   1   2   0   0 620   0   0]
 [  1   0   1   0   2   2   2   1 574   1]
 [  1   1   1   0   5   0   0   6   3 598]]

2024-01-15 15:41:56,099 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:41:56,100 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:41:56,104 - 

2024-01-15 15:41:56,104 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:42:05,842 - Epoch: [69][   10/  211]    Overall Loss 0.036424    Objective Loss 0.036424                                        LR 0.100000    Time 0.973738    
2024-01-15 15:42:11,740 - Epoch: [69][   20/  211]    Overall Loss 0.036541    Objective Loss 0.036541                                        LR 0.100000    Time 0.781664    
2024-01-15 15:42:17,683 - Epoch: [69][   30/  211]    Overall Loss 0.037859    Objective Loss 0.037859                                        LR 0.100000    Time 0.719170    
2024-01-15 15:42:24,274 - Epoch: [69][   40/  211]    Overall Loss 0.040924    Objective Loss 0.040924                                        LR 0.100000    Time 0.704114    
2024-01-15 15:42:30,124 - Epoch: [69][   50/  211]    Overall Loss 0.041029    Objective Loss 0.041029                                        LR 0.100000    Time 0.680257    
2024-01-15 15:42:35,955 - Epoch: [69][   60/  211]    Overall Loss 0.040484    Objective Loss 0.040484                                        LR 0.100000    Time 0.664050    
2024-01-15 15:42:42,026 - Epoch: [69][   70/  211]    Overall Loss 0.040566    Objective Loss 0.040566                                        LR 0.100000    Time 0.655901    
2024-01-15 15:42:49,018 - Epoch: [69][   80/  211]    Overall Loss 0.041851    Objective Loss 0.041851                                        LR 0.100000    Time 0.661294    
2024-01-15 15:42:54,705 - Epoch: [69][   90/  211]    Overall Loss 0.040882    Objective Loss 0.040882                                        LR 0.100000    Time 0.650997    
2024-01-15 15:43:00,348 - Epoch: [69][  100/  211]    Overall Loss 0.040726    Objective Loss 0.040726                                        LR 0.100000    Time 0.642309    
2024-01-15 15:43:05,983 - Epoch: [69][  110/  211]    Overall Loss 0.041982    Objective Loss 0.041982                                        LR 0.100000    Time 0.635146    
2024-01-15 15:43:11,717 - Epoch: [69][  120/  211]    Overall Loss 0.041746    Objective Loss 0.041746                                        LR 0.100000    Time 0.629986    
2024-01-15 15:43:17,898 - Epoch: [69][  130/  211]    Overall Loss 0.041554    Objective Loss 0.041554                                        LR 0.100000    Time 0.629071    
2024-01-15 15:43:23,925 - Epoch: [69][  140/  211]    Overall Loss 0.040371    Objective Loss 0.040371                                        LR 0.100000    Time 0.627175    
2024-01-15 15:43:29,704 - Epoch: [69][  150/  211]    Overall Loss 0.040011    Objective Loss 0.040011                                        LR 0.100000    Time 0.623880    
2024-01-15 15:43:35,346 - Epoch: [69][  160/  211]    Overall Loss 0.039910    Objective Loss 0.039910                                        LR 0.100000    Time 0.620144    
2024-01-15 15:43:41,036 - Epoch: [69][  170/  211]    Overall Loss 0.039531    Objective Loss 0.039531                                        LR 0.100000    Time 0.617132    
2024-01-15 15:43:47,336 - Epoch: [69][  180/  211]    Overall Loss 0.039389    Objective Loss 0.039389                                        LR 0.100000    Time 0.617844    
2024-01-15 15:43:53,142 - Epoch: [69][  190/  211]    Overall Loss 0.039218    Objective Loss 0.039218                                        LR 0.100000    Time 0.615875    
2024-01-15 15:43:58,914 - Epoch: [69][  200/  211]    Overall Loss 0.038955    Objective Loss 0.038955                                        LR 0.100000    Time 0.613936    
2024-01-15 15:44:04,693 - Epoch: [69][  210/  211]    Overall Loss 0.038891    Objective Loss 0.038891    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.612214    
2024-01-15 15:44:05,241 - Epoch: [69][  211/  211]    Overall Loss 0.038997    Objective Loss 0.038997    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.611911    
2024-01-15 15:44:06,141 - --- validate (epoch=69)-----------
2024-01-15 15:44:06,142 - 6000 samples (256 per mini-batch)
2024-01-15 15:44:12,794 - Epoch: [69][   10/   24]    Loss 0.038301    Top1 98.789062    Top5 99.960938    
2024-01-15 15:44:15,019 - Epoch: [69][   20/   24]    Loss 0.044064    Top1 98.613281    Top5 99.960938    
2024-01-15 15:44:15,907 - Epoch: [69][   24/   24]    Loss 0.044949    Top1 98.583333    Top5 99.966667    
2024-01-15 15:44:16,517 - ==> Top1: 98.583    Top5: 99.967    Loss: 0.045

2024-01-15 15:44:16,518 - ==> Confusion:
[[596   0   3   2   0   0   1   0   0   3]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   2 569   2   1   0   1   8   2   1]
 [  0   0   0 582   0   1   0   0   0   0]
 [  0   1   1   0 556   0   0   1   1   5]
 [  2   0   0   4   0 506   4   0   2   0]
 [  1   3   0   0   4   0 622   0   1   0]
 [  0   5   0   3   0   0   0 616   1   0]
 [  0   0   0   0   2   0   1   0 581   0]
 [  0   2   0   1   6   0   0   3   3 600]]

2024-01-15 15:44:16,520 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:44:16,520 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:44:16,524 - 

2024-01-15 15:44:16,524 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:44:25,023 - Epoch: [70][   10/  211]    Overall Loss 0.033036    Objective Loss 0.033036                                        LR 0.100000    Time 0.849832    
2024-01-15 15:44:30,674 - Epoch: [70][   20/  211]    Overall Loss 0.034872    Objective Loss 0.034872                                        LR 0.100000    Time 0.707298    
2024-01-15 15:44:36,412 - Epoch: [70][   30/  211]    Overall Loss 0.037306    Objective Loss 0.037306                                        LR 0.100000    Time 0.662735    
2024-01-15 15:44:42,374 - Epoch: [70][   40/  211]    Overall Loss 0.042036    Objective Loss 0.042036                                        LR 0.100000    Time 0.645940    
2024-01-15 15:44:48,350 - Epoch: [70][   50/  211]    Overall Loss 0.043763    Objective Loss 0.043763                                        LR 0.100000    Time 0.636253    
2024-01-15 15:44:54,001 - Epoch: [70][   60/  211]    Overall Loss 0.044104    Objective Loss 0.044104                                        LR 0.100000    Time 0.624370    
2024-01-15 15:44:59,821 - Epoch: [70][   70/  211]    Overall Loss 0.045039    Objective Loss 0.045039                                        LR 0.100000    Time 0.618314    
2024-01-15 15:45:05,547 - Epoch: [70][   80/  211]    Overall Loss 0.044948    Objective Loss 0.044948                                        LR 0.100000    Time 0.612575    
2024-01-15 15:45:11,272 - Epoch: [70][   90/  211]    Overall Loss 0.045112    Objective Loss 0.045112                                        LR 0.100000    Time 0.608109    
2024-01-15 15:45:16,916 - Epoch: [70][  100/  211]    Overall Loss 0.045351    Objective Loss 0.045351                                        LR 0.100000    Time 0.603733    
2024-01-15 15:45:22,626 - Epoch: [70][  110/  211]    Overall Loss 0.043886    Objective Loss 0.043886                                        LR 0.100000    Time 0.600744    
2024-01-15 15:45:28,346 - Epoch: [70][  120/  211]    Overall Loss 0.043245    Objective Loss 0.043245                                        LR 0.100000    Time 0.598345    
2024-01-15 15:45:34,139 - Epoch: [70][  130/  211]    Overall Loss 0.042869    Objective Loss 0.042869                                        LR 0.100000    Time 0.596871    
2024-01-15 15:45:40,005 - Epoch: [70][  140/  211]    Overall Loss 0.042898    Objective Loss 0.042898                                        LR 0.100000    Time 0.596128    
2024-01-15 15:45:46,043 - Epoch: [70][  150/  211]    Overall Loss 0.042164    Objective Loss 0.042164                                        LR 0.100000    Time 0.596629    
2024-01-15 15:45:52,049 - Epoch: [70][  160/  211]    Overall Loss 0.041618    Objective Loss 0.041618                                        LR 0.100000    Time 0.596874    
2024-01-15 15:45:57,803 - Epoch: [70][  170/  211]    Overall Loss 0.042562    Objective Loss 0.042562                                        LR 0.100000    Time 0.595582    
2024-01-15 15:46:03,611 - Epoch: [70][  180/  211]    Overall Loss 0.042345    Objective Loss 0.042345                                        LR 0.100000    Time 0.594756    
2024-01-15 15:46:09,339 - Epoch: [70][  190/  211]    Overall Loss 0.041873    Objective Loss 0.041873                                        LR 0.100000    Time 0.593597    
2024-01-15 15:46:15,064 - Epoch: [70][  200/  211]    Overall Loss 0.041962    Objective Loss 0.041962                                        LR 0.100000    Time 0.592533    
2024-01-15 15:46:20,737 - Epoch: [70][  210/  211]    Overall Loss 0.042156    Objective Loss 0.042156    Top1 97.656250    Top5 100.000000    LR 0.100000    Time 0.591329    
2024-01-15 15:46:21,310 - Epoch: [70][  211/  211]    Overall Loss 0.042115    Objective Loss 0.042115    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.591237    
2024-01-15 15:46:22,184 - --- validate (epoch=70)-----------
2024-01-15 15:46:22,184 - 6000 samples (256 per mini-batch)
2024-01-15 15:46:27,584 - Epoch: [70][   10/   24]    Loss 0.044319    Top1 98.710938    Top5 100.000000    
2024-01-15 15:46:29,725 - Epoch: [70][   20/   24]    Loss 0.047833    Top1 98.574219    Top5 100.000000    
2024-01-15 15:46:30,488 - Epoch: [70][   24/   24]    Loss 0.043232    Top1 98.750000    Top5 100.000000    
2024-01-15 15:46:31,061 - ==> Top1: 98.750    Top5: 100.000    Loss: 0.043

2024-01-15 15:46:31,062 - ==> Confusion:
[[596   0   4   0   0   0   3   1   1   0]
 [  0 684   1   1   0   0   0   2   0   0]
 [  0   0 582   1   0   0   0   2   1   0]
 [  0   0   3 578   0   1   0   0   1   0]
 [  0   0   0   0 561   0   0   2   0   2]
 [  0   0   0   2   1 508   3   0   4   0]
 [  0   1   0   0   3   1 625   0   1   0]
 [  0   1   4   1   0   0   0 618   0   1]
 [  0   0   0   0   0   0   1   1 582   0]
 [  0   1   1   0   8   1   0   7   6 591]]

2024-01-15 15:46:31,064 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:46:31,064 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:46:31,068 - 

2024-01-15 15:46:31,069 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:46:39,346 - Epoch: [71][   10/  211]    Overall Loss 0.044103    Objective Loss 0.044103                                        LR 0.100000    Time 0.827644    
2024-01-15 15:46:45,237 - Epoch: [71][   20/  211]    Overall Loss 0.042158    Objective Loss 0.042158                                        LR 0.100000    Time 0.708284    
2024-01-15 15:46:50,993 - Epoch: [71][   30/  211]    Overall Loss 0.044202    Objective Loss 0.044202                                        LR 0.100000    Time 0.664028    
2024-01-15 15:46:56,992 - Epoch: [71][   40/  211]    Overall Loss 0.043298    Objective Loss 0.043298                                        LR 0.100000    Time 0.647959    
2024-01-15 15:47:02,856 - Epoch: [71][   50/  211]    Overall Loss 0.042188    Objective Loss 0.042188                                        LR 0.100000    Time 0.635624    
2024-01-15 15:47:08,791 - Epoch: [71][   60/  211]    Overall Loss 0.041966    Objective Loss 0.041966                                        LR 0.100000    Time 0.628561    
2024-01-15 15:47:14,481 - Epoch: [71][   70/  211]    Overall Loss 0.041956    Objective Loss 0.041956                                        LR 0.100000    Time 0.620038    
2024-01-15 15:47:20,326 - Epoch: [71][   80/  211]    Overall Loss 0.041020    Objective Loss 0.041020                                        LR 0.100000    Time 0.615582    
2024-01-15 15:47:26,799 - Epoch: [71][   90/  211]    Overall Loss 0.041024    Objective Loss 0.041024                                        LR 0.100000    Time 0.619094    
2024-01-15 15:47:32,679 - Epoch: [71][  100/  211]    Overall Loss 0.040626    Objective Loss 0.040626                                        LR 0.100000    Time 0.615966    
2024-01-15 15:47:38,439 - Epoch: [71][  110/  211]    Overall Loss 0.040666    Objective Loss 0.040666                                        LR 0.100000    Time 0.612323    
2024-01-15 15:47:44,462 - Epoch: [71][  120/  211]    Overall Loss 0.040603    Objective Loss 0.040603                                        LR 0.100000    Time 0.611478    
2024-01-15 15:47:50,201 - Epoch: [71][  130/  211]    Overall Loss 0.041060    Objective Loss 0.041060                                        LR 0.100000    Time 0.608578    
2024-01-15 15:47:55,995 - Epoch: [71][  140/  211]    Overall Loss 0.040868    Objective Loss 0.040868                                        LR 0.100000    Time 0.606489    
2024-01-15 15:48:01,686 - Epoch: [71][  150/  211]    Overall Loss 0.040839    Objective Loss 0.040839                                        LR 0.100000    Time 0.603988    
2024-01-15 15:48:07,473 - Epoch: [71][  160/  211]    Overall Loss 0.041096    Objective Loss 0.041096                                        LR 0.100000    Time 0.602398    
2024-01-15 15:48:13,697 - Epoch: [71][  170/  211]    Overall Loss 0.041030    Objective Loss 0.041030                                        LR 0.100000    Time 0.603567    
2024-01-15 15:48:19,455 - Epoch: [71][  180/  211]    Overall Loss 0.040997    Objective Loss 0.040997                                        LR 0.100000    Time 0.602019    
2024-01-15 15:48:25,197 - Epoch: [71][  190/  211]    Overall Loss 0.040528    Objective Loss 0.040528                                        LR 0.100000    Time 0.600550    
2024-01-15 15:48:31,190 - Epoch: [71][  200/  211]    Overall Loss 0.040552    Objective Loss 0.040552                                        LR 0.100000    Time 0.600474    
2024-01-15 15:48:37,094 - Epoch: [71][  210/  211]    Overall Loss 0.040993    Objective Loss 0.040993    Top1 97.265625    Top5 100.000000    LR 0.100000    Time 0.599986    
2024-01-15 15:48:37,708 - Epoch: [71][  211/  211]    Overall Loss 0.040939    Objective Loss 0.040939    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.600042    
2024-01-15 15:48:38,712 - --- validate (epoch=71)-----------
2024-01-15 15:48:38,714 - 6000 samples (256 per mini-batch)
2024-01-15 15:48:45,829 - Epoch: [71][   10/   24]    Loss 0.048690    Top1 98.515625    Top5 100.000000    
2024-01-15 15:48:47,964 - Epoch: [71][   20/   24]    Loss 0.045119    Top1 98.691406    Top5 100.000000    
2024-01-15 15:48:48,782 - Epoch: [71][   24/   24]    Loss 0.046397    Top1 98.666667    Top5 100.000000    
2024-01-15 15:48:49,653 - ==> Top1: 98.667    Top5: 100.000    Loss: 0.046

2024-01-15 15:48:49,654 - ==> Confusion:
[[602   0   1   0   0   0   1   1   0   0]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   3 577   1   1   0   0   2   2   0]
 [  0   0   2 576   0   2   0   1   2   0]
 [  0   1   0   0 557   0   0   2   0   5]
 [  0   1   0   2   0 512   3   0   0   0]
 [  3   4   0   0   2   0 619   0   3   0]
 [  1   3   1   4   1   0   0 615   0   0]
 [  1   1   0   1   3   2   1   1 574   0]
 [  0   1   0   1   4   3   0   2   2 602]]

2024-01-15 15:48:49,657 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:48:49,657 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:48:49,663 - 

2024-01-15 15:48:49,663 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:48:59,998 - Epoch: [72][   10/  211]    Overall Loss 0.039477    Objective Loss 0.039477                                        LR 0.100000    Time 1.033407    
2024-01-15 15:49:05,740 - Epoch: [72][   20/  211]    Overall Loss 0.042142    Objective Loss 0.042142                                        LR 0.100000    Time 0.803714    
2024-01-15 15:49:11,514 - Epoch: [72][   30/  211]    Overall Loss 0.041775    Objective Loss 0.041775                                        LR 0.100000    Time 0.728215    
2024-01-15 15:49:17,235 - Epoch: [72][   40/  211]    Overall Loss 0.040570    Objective Loss 0.040570                                        LR 0.100000    Time 0.689154    
2024-01-15 15:49:23,228 - Epoch: [72][   50/  211]    Overall Loss 0.040326    Objective Loss 0.040326                                        LR 0.100000    Time 0.671158    
2024-01-15 15:49:29,066 - Epoch: [72][   60/  211]    Overall Loss 0.040570    Objective Loss 0.040570                                        LR 0.100000    Time 0.656528    
2024-01-15 15:49:34,776 - Epoch: [72][   70/  211]    Overall Loss 0.040326    Objective Loss 0.040326                                        LR 0.100000    Time 0.644288    
2024-01-15 15:49:40,607 - Epoch: [72][   80/  211]    Overall Loss 0.040836    Objective Loss 0.040836                                        LR 0.100000    Time 0.636621    
2024-01-15 15:49:46,552 - Epoch: [72][   90/  211]    Overall Loss 0.040018    Objective Loss 0.040018                                        LR 0.100000    Time 0.631929    
2024-01-15 15:49:52,220 - Epoch: [72][  100/  211]    Overall Loss 0.039718    Objective Loss 0.039718                                        LR 0.100000    Time 0.625401    
2024-01-15 15:49:58,288 - Epoch: [72][  110/  211]    Overall Loss 0.039253    Objective Loss 0.039253                                        LR 0.100000    Time 0.623696    
2024-01-15 15:50:04,056 - Epoch: [72][  120/  211]    Overall Loss 0.038724    Objective Loss 0.038724                                        LR 0.100000    Time 0.619776    
2024-01-15 15:50:09,780 - Epoch: [72][  130/  211]    Overall Loss 0.038310    Objective Loss 0.038310                                        LR 0.100000    Time 0.616122    
2024-01-15 15:50:16,011 - Epoch: [72][  140/  211]    Overall Loss 0.038365    Objective Loss 0.038365                                        LR 0.100000    Time 0.616613    
2024-01-15 15:50:22,079 - Epoch: [72][  150/  211]    Overall Loss 0.038222    Objective Loss 0.038222                                        LR 0.100000    Time 0.615951    
2024-01-15 15:50:27,987 - Epoch: [72][  160/  211]    Overall Loss 0.038054    Objective Loss 0.038054                                        LR 0.100000    Time 0.614370    
2024-01-15 15:50:33,909 - Epoch: [72][  170/  211]    Overall Loss 0.037695    Objective Loss 0.037695                                        LR 0.100000    Time 0.613052    
2024-01-15 15:50:39,836 - Epoch: [72][  180/  211]    Overall Loss 0.037924    Objective Loss 0.037924                                        LR 0.100000    Time 0.611917    
2024-01-15 15:50:45,653 - Epoch: [72][  190/  211]    Overall Loss 0.037991    Objective Loss 0.037991                                        LR 0.100000    Time 0.610318    
2024-01-15 15:50:51,344 - Epoch: [72][  200/  211]    Overall Loss 0.038105    Objective Loss 0.038105                                        LR 0.100000    Time 0.608250    
2024-01-15 15:50:57,111 - Epoch: [72][  210/  211]    Overall Loss 0.037926    Objective Loss 0.037926    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.606746    
2024-01-15 15:50:57,681 - Epoch: [72][  211/  211]    Overall Loss 0.037914    Objective Loss 0.037914    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.606565    
2024-01-15 15:50:58,527 - --- validate (epoch=72)-----------
2024-01-15 15:50:58,529 - 6000 samples (256 per mini-batch)
2024-01-15 15:51:05,330 - Epoch: [72][   10/   24]    Loss 0.046334    Top1 98.632812    Top5 100.000000    
2024-01-15 15:51:07,439 - Epoch: [72][   20/   24]    Loss 0.049791    Top1 98.535156    Top5 100.000000    
2024-01-15 15:51:08,177 - Epoch: [72][   24/   24]    Loss 0.048613    Top1 98.583333    Top5 100.000000    
2024-01-15 15:51:08,811 - ==> Top1: 98.583    Top5: 100.000    Loss: 0.049

2024-01-15 15:51:08,812 - ==> Confusion:
[[601   0   0   0   0   0   1   0   3   0]
 [  0 682   1   1   0   1   0   3   0   0]
 [  1   1 568   4   1   0   0   5   6   0]
 [  0   0   1 580   0   0   0   0   1   1]
 [  0   1   1   0 544   0   2   0   1  16]
 [  0   0   0   3   0 506   5   0   2   2]
 [  1   2   0   0   1   0 625   0   2   0]
 [  0   2   0   3   0   0   0 617   1   2]
 [  0   0   0   1   0   0   2   0 580   1]
 [  0   0   0   0   0   0   0   1   2 612]]

2024-01-15 15:51:08,814 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:51:08,814 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:51:08,820 - 

2024-01-15 15:51:08,820 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:51:17,597 - Epoch: [73][   10/  211]    Overall Loss 0.052267    Objective Loss 0.052267                                        LR 0.100000    Time 0.877575    
2024-01-15 15:51:23,479 - Epoch: [73][   20/  211]    Overall Loss 0.047913    Objective Loss 0.047913                                        LR 0.100000    Time 0.732832    
2024-01-15 15:51:29,396 - Epoch: [73][   30/  211]    Overall Loss 0.045002    Objective Loss 0.045002                                        LR 0.100000    Time 0.685756    
2024-01-15 15:51:35,129 - Epoch: [73][   40/  211]    Overall Loss 0.044578    Objective Loss 0.044578                                        LR 0.100000    Time 0.657607    
2024-01-15 15:51:41,165 - Epoch: [73][   50/  211]    Overall Loss 0.042883    Objective Loss 0.042883                                        LR 0.100000    Time 0.646798    
2024-01-15 15:51:47,359 - Epoch: [73][   60/  211]    Overall Loss 0.042967    Objective Loss 0.042967                                        LR 0.100000    Time 0.642204    
2024-01-15 15:51:53,042 - Epoch: [73][   70/  211]    Overall Loss 0.042333    Objective Loss 0.042333                                        LR 0.100000    Time 0.631635    
2024-01-15 15:51:58,878 - Epoch: [73][   80/  211]    Overall Loss 0.041900    Objective Loss 0.041900                                        LR 0.100000    Time 0.625605    
2024-01-15 15:52:04,710 - Epoch: [73][   90/  211]    Overall Loss 0.041123    Objective Loss 0.041123                                        LR 0.100000    Time 0.620885    
2024-01-15 15:52:10,403 - Epoch: [73][  100/  211]    Overall Loss 0.040149    Objective Loss 0.040149                                        LR 0.100000    Time 0.615721    
2024-01-15 15:52:16,757 - Epoch: [73][  110/  211]    Overall Loss 0.039760    Objective Loss 0.039760                                        LR 0.100000    Time 0.617504    
2024-01-15 15:52:22,540 - Epoch: [73][  120/  211]    Overall Loss 0.040662    Objective Loss 0.040662                                        LR 0.100000    Time 0.614221    
2024-01-15 15:52:28,814 - Epoch: [73][  130/  211]    Overall Loss 0.041251    Objective Loss 0.041251                                        LR 0.100000    Time 0.615177    
2024-01-15 15:52:34,656 - Epoch: [73][  140/  211]    Overall Loss 0.040827    Objective Loss 0.040827                                        LR 0.100000    Time 0.612902    
2024-01-15 15:52:41,487 - Epoch: [73][  150/  211]    Overall Loss 0.040773    Objective Loss 0.040773                                        LR 0.100000    Time 0.617524    
2024-01-15 15:52:48,105 - Epoch: [73][  160/  211]    Overall Loss 0.040570    Objective Loss 0.040570                                        LR 0.100000    Time 0.620240    
2024-01-15 15:52:53,772 - Epoch: [73][  170/  211]    Overall Loss 0.040671    Objective Loss 0.040671                                        LR 0.100000    Time 0.617091    
2024-01-15 15:52:59,426 - Epoch: [73][  180/  211]    Overall Loss 0.040537    Objective Loss 0.040537                                        LR 0.100000    Time 0.614214    
2024-01-15 15:53:05,119 - Epoch: [73][  190/  211]    Overall Loss 0.040414    Objective Loss 0.040414                                        LR 0.100000    Time 0.611848    
2024-01-15 15:53:10,822 - Epoch: [73][  200/  211]    Overall Loss 0.040510    Objective Loss 0.040510                                        LR 0.100000    Time 0.609767    
2024-01-15 15:53:16,527 - Epoch: [73][  210/  211]    Overall Loss 0.040813    Objective Loss 0.040813    Top1 98.828125    Top5 99.609375    LR 0.100000    Time 0.607892    
2024-01-15 15:53:17,145 - Epoch: [73][  211/  211]    Overall Loss 0.040805    Objective Loss 0.040805    Top1 99.193548    Top5 99.798387    LR 0.100000    Time 0.607938    
2024-01-15 15:53:18,081 - --- validate (epoch=73)-----------
2024-01-15 15:53:18,083 - 6000 samples (256 per mini-batch)
2024-01-15 15:53:25,765 - Epoch: [73][   10/   24]    Loss 0.049702    Top1 98.515625    Top5 100.000000    
2024-01-15 15:53:27,977 - Epoch: [73][   20/   24]    Loss 0.042995    Top1 98.730469    Top5 100.000000    
2024-01-15 15:53:28,751 - Epoch: [73][   24/   24]    Loss 0.043366    Top1 98.783333    Top5 99.983333    
2024-01-15 15:53:29,514 - ==> Top1: 98.783    Top5: 99.983    Loss: 0.043

2024-01-15 15:53:29,516 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 684   2   1   0   0   0   1   0   0]
 [  0   0 584   1   0   0   0   0   1   0]
 [  0   0   4 575   0   1   0   0   3   0]
 [  0   0   1   0 554   1   0   1   1   7]
 [  2   1   0   4   0 504   5   0   2   0]
 [  0   0   0   0   1   0 629   0   1   0]
 [  0   0   2   1   2   0   0 619   0   1]
 [  0   0   0   0   2   1   0   0 581   0]
 [  0   1   0   0  11   1   0   2   6 594]]

2024-01-15 15:53:29,518 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:53:29,519 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:53:29,526 - 

2024-01-15 15:53:29,526 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:53:39,583 - Epoch: [74][   10/  211]    Overall Loss 0.043405    Objective Loss 0.043405                                        LR 0.100000    Time 1.005593    
2024-01-15 15:53:45,626 - Epoch: [74][   20/  211]    Overall Loss 0.042286    Objective Loss 0.042286                                        LR 0.100000    Time 0.804868    
2024-01-15 15:53:51,358 - Epoch: [74][   30/  211]    Overall Loss 0.042518    Objective Loss 0.042518                                        LR 0.100000    Time 0.727595    
2024-01-15 15:53:57,308 - Epoch: [74][   40/  211]    Overall Loss 0.042675    Objective Loss 0.042675                                        LR 0.100000    Time 0.694424    
2024-01-15 15:54:03,009 - Epoch: [74][   50/  211]    Overall Loss 0.041976    Objective Loss 0.041976                                        LR 0.100000    Time 0.669542    
2024-01-15 15:54:09,057 - Epoch: [74][   60/  211]    Overall Loss 0.041920    Objective Loss 0.041920                                        LR 0.100000    Time 0.658714    
2024-01-15 15:54:14,916 - Epoch: [74][   70/  211]    Overall Loss 0.042519    Objective Loss 0.042519                                        LR 0.100000    Time 0.648294    
2024-01-15 15:54:20,941 - Epoch: [74][   80/  211]    Overall Loss 0.041636    Objective Loss 0.041636                                        LR 0.100000    Time 0.642563    
2024-01-15 15:54:26,629 - Epoch: [74][   90/  211]    Overall Loss 0.041151    Objective Loss 0.041151                                        LR 0.100000    Time 0.634349    
2024-01-15 15:54:32,378 - Epoch: [74][  100/  211]    Overall Loss 0.041200    Objective Loss 0.041200                                        LR 0.100000    Time 0.628391    
2024-01-15 15:54:38,463 - Epoch: [74][  110/  211]    Overall Loss 0.041178    Objective Loss 0.041178                                        LR 0.100000    Time 0.626566    
2024-01-15 15:54:44,665 - Epoch: [74][  120/  211]    Overall Loss 0.042556    Objective Loss 0.042556                                        LR 0.100000    Time 0.626029    
2024-01-15 15:54:50,474 - Epoch: [74][  130/  211]    Overall Loss 0.042227    Objective Loss 0.042227                                        LR 0.100000    Time 0.622549    
2024-01-15 15:54:56,278 - Epoch: [74][  140/  211]    Overall Loss 0.042073    Objective Loss 0.042073                                        LR 0.100000    Time 0.619529    
2024-01-15 15:55:02,243 - Epoch: [74][  150/  211]    Overall Loss 0.041896    Objective Loss 0.041896                                        LR 0.100000    Time 0.617989    
2024-01-15 15:55:07,967 - Epoch: [74][  160/  211]    Overall Loss 0.041816    Objective Loss 0.041816                                        LR 0.100000    Time 0.615131    
2024-01-15 15:55:13,651 - Epoch: [74][  170/  211]    Overall Loss 0.041813    Objective Loss 0.041813                                        LR 0.100000    Time 0.612376    
2024-01-15 15:55:19,462 - Epoch: [74][  180/  211]    Overall Loss 0.041385    Objective Loss 0.041385                                        LR 0.100000    Time 0.610631    
2024-01-15 15:55:25,361 - Epoch: [74][  190/  211]    Overall Loss 0.041322    Objective Loss 0.041322                                        LR 0.100000    Time 0.609520    
2024-01-15 15:55:32,774 - Epoch: [74][  200/  211]    Overall Loss 0.040981    Objective Loss 0.040981                                        LR 0.100000    Time 0.616094    
2024-01-15 15:55:39,043 - Epoch: [74][  210/  211]    Overall Loss 0.040784    Objective Loss 0.040784    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.616598    
2024-01-15 15:55:39,740 - Epoch: [74][  211/  211]    Overall Loss 0.040821    Objective Loss 0.040821    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.616973    
2024-01-15 15:55:40,690 - --- validate (epoch=74)-----------
2024-01-15 15:55:40,691 - 6000 samples (256 per mini-batch)
2024-01-15 15:55:48,979 - Epoch: [74][   10/   24]    Loss 0.049616    Top1 98.515625    Top5 100.000000    
2024-01-15 15:55:51,138 - Epoch: [74][   20/   24]    Loss 0.042701    Top1 98.691406    Top5 100.000000    
2024-01-15 15:55:51,908 - Epoch: [74][   24/   24]    Loss 0.044523    Top1 98.683333    Top5 100.000000    
2024-01-15 15:55:52,659 - ==> Top1: 98.683    Top5: 100.000    Loss: 0.045

2024-01-15 15:55:52,659 - ==> Confusion:
[[596   0   2   1   0   0   2   0   4   0]
 [  0 683   0   0   1   1   0   3   0   0]
 [  0   1 574   5   2   0   0   3   1   0]
 [  0   0   1 576   0   3   0   2   1   0]
 [  0   1   0   0 556   0   0   1   0   7]
 [  0   0   0   2   0 514   1   0   1   0]
 [  0   2   0   0   2   2 624   0   1   0]
 [  0   2   1   1   0   0   0 620   0   1]
 [  1   0   1   1   1   1   1   0 577   1]
 [  0   2   0   1   4   2   0   2   3 601]]

2024-01-15 15:55:52,661 - ==> Best [Top1: 98.900   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 44]
2024-01-15 15:55:52,662 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:55:52,665 - 

2024-01-15 15:55:52,666 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:56:01,856 - Epoch: [75][   10/  211]    Overall Loss 0.032377    Objective Loss 0.032377                                        LR 0.100000    Time 0.918960    
2024-01-15 15:56:07,557 - Epoch: [75][   20/  211]    Overall Loss 0.035906    Objective Loss 0.035906                                        LR 0.100000    Time 0.744456    
2024-01-15 15:56:13,420 - Epoch: [75][   30/  211]    Overall Loss 0.036590    Objective Loss 0.036590                                        LR 0.100000    Time 0.691709    
2024-01-15 15:56:19,338 - Epoch: [75][   40/  211]    Overall Loss 0.037680    Objective Loss 0.037680                                        LR 0.100000    Time 0.666704    
2024-01-15 15:56:25,463 - Epoch: [75][   50/  211]    Overall Loss 0.038983    Objective Loss 0.038983                                        LR 0.100000    Time 0.655816    
2024-01-15 15:56:31,879 - Epoch: [75][   60/  211]    Overall Loss 0.039422    Objective Loss 0.039422                                        LR 0.100000    Time 0.653410    
2024-01-15 15:56:37,721 - Epoch: [75][   70/  211]    Overall Loss 0.040824    Objective Loss 0.040824                                        LR 0.100000    Time 0.643492    
2024-01-15 15:56:43,857 - Epoch: [75][   80/  211]    Overall Loss 0.042009    Objective Loss 0.042009                                        LR 0.100000    Time 0.639750    
2024-01-15 15:56:50,330 - Epoch: [75][   90/  211]    Overall Loss 0.041579    Objective Loss 0.041579                                        LR 0.100000    Time 0.640513    
2024-01-15 15:56:56,287 - Epoch: [75][  100/  211]    Overall Loss 0.040620    Objective Loss 0.040620                                        LR 0.100000    Time 0.635974    
2024-01-15 15:57:02,033 - Epoch: [75][  110/  211]    Overall Loss 0.041037    Objective Loss 0.041037                                        LR 0.100000    Time 0.630383    
2024-01-15 15:57:07,999 - Epoch: [75][  120/  211]    Overall Loss 0.041138    Objective Loss 0.041138                                        LR 0.100000    Time 0.627564    
2024-01-15 15:57:14,199 - Epoch: [75][  130/  211]    Overall Loss 0.040969    Objective Loss 0.040969                                        LR 0.100000    Time 0.626963    
2024-01-15 15:57:20,107 - Epoch: [75][  140/  211]    Overall Loss 0.040317    Objective Loss 0.040317                                        LR 0.100000    Time 0.624370    
2024-01-15 15:57:25,887 - Epoch: [75][  150/  211]    Overall Loss 0.040124    Objective Loss 0.040124                                        LR 0.100000    Time 0.621274    
2024-01-15 15:57:31,642 - Epoch: [75][  160/  211]    Overall Loss 0.040344    Objective Loss 0.040344                                        LR 0.100000    Time 0.618405    
2024-01-15 15:57:37,328 - Epoch: [75][  170/  211]    Overall Loss 0.040211    Objective Loss 0.040211                                        LR 0.100000    Time 0.615473    
2024-01-15 15:57:43,266 - Epoch: [75][  180/  211]    Overall Loss 0.040057    Objective Loss 0.040057                                        LR 0.100000    Time 0.614261    
2024-01-15 15:57:48,965 - Epoch: [75][  190/  211]    Overall Loss 0.039964    Objective Loss 0.039964                                        LR 0.100000    Time 0.611922    
2024-01-15 15:57:54,895 - Epoch: [75][  200/  211]    Overall Loss 0.039764    Objective Loss 0.039764                                        LR 0.100000    Time 0.610970    
2024-01-15 15:58:00,685 - Epoch: [75][  210/  211]    Overall Loss 0.039779    Objective Loss 0.039779    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.609445    
2024-01-15 15:58:01,260 - Epoch: [75][  211/  211]    Overall Loss 0.039783    Objective Loss 0.039783    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.609275    
2024-01-15 15:58:02,133 - --- validate (epoch=75)-----------
2024-01-15 15:58:02,135 - 6000 samples (256 per mini-batch)
2024-01-15 15:58:09,093 - Epoch: [75][   10/   24]    Loss 0.031130    Top1 99.023438    Top5 100.000000    
2024-01-15 15:58:11,236 - Epoch: [75][   20/   24]    Loss 0.036432    Top1 98.984375    Top5 100.000000    
2024-01-15 15:58:11,994 - Epoch: [75][   24/   24]    Loss 0.036023    Top1 98.933333    Top5 100.000000    
2024-01-15 15:58:12,725 - ==> Top1: 98.933    Top5: 100.000    Loss: 0.036

2024-01-15 15:58:12,726 - ==> Confusion:
[[599   0   1   0   0   1   2   0   0   2]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   0 582   2   0   0   0   0   2   0]
 [  0   0   2 574   0   5   1   0   0   1]
 [  0   0   0   0 555   0   1   2   0   7]
 [  1   0   0   0   0 513   3   0   1   0]
 [  0   1   0   0   2   0 628   0   0   0]
 [  0   2   3   0   0   0   0 620   0   0]
 [  1   0   0   0   0   1   5   1 573   3]
 [  0   1   0   0   3   1   0   2   2 606]]

2024-01-15 15:58:12,728 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 15:58:12,728 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 15:58:12,734 - 

2024-01-15 15:58:12,735 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 15:58:21,942 - Epoch: [76][   10/  211]    Overall Loss 0.046378    Objective Loss 0.046378                                        LR 0.100000    Time 0.920676    
2024-01-15 15:58:27,818 - Epoch: [76][   20/  211]    Overall Loss 0.043055    Objective Loss 0.043055                                        LR 0.100000    Time 0.754047    
2024-01-15 15:58:33,670 - Epoch: [76][   30/  211]    Overall Loss 0.040326    Objective Loss 0.040326                                        LR 0.100000    Time 0.697742    
2024-01-15 15:58:39,454 - Epoch: [76][   40/  211]    Overall Loss 0.038262    Objective Loss 0.038262                                        LR 0.100000    Time 0.667885    
2024-01-15 15:58:46,025 - Epoch: [76][   50/  211]    Overall Loss 0.039011    Objective Loss 0.039011                                        LR 0.100000    Time 0.665679    
2024-01-15 15:58:52,579 - Epoch: [76][   60/  211]    Overall Loss 0.038575    Objective Loss 0.038575                                        LR 0.100000    Time 0.663943    
2024-01-15 15:58:58,817 - Epoch: [76][   70/  211]    Overall Loss 0.037489    Objective Loss 0.037489                                        LR 0.100000    Time 0.658185    
2024-01-15 15:59:04,672 - Epoch: [76][   80/  211]    Overall Loss 0.038030    Objective Loss 0.038030                                        LR 0.100000    Time 0.649081    
2024-01-15 15:59:11,220 - Epoch: [76][   90/  211]    Overall Loss 0.038395    Objective Loss 0.038395                                        LR 0.100000    Time 0.649699    
2024-01-15 15:59:17,234 - Epoch: [76][  100/  211]    Overall Loss 0.038842    Objective Loss 0.038842                                        LR 0.100000    Time 0.644857    
2024-01-15 15:59:23,206 - Epoch: [76][  110/  211]    Overall Loss 0.038436    Objective Loss 0.038436                                        LR 0.100000    Time 0.640516    
2024-01-15 15:59:28,919 - Epoch: [76][  120/  211]    Overall Loss 0.038593    Objective Loss 0.038593                                        LR 0.100000    Time 0.634742    
2024-01-15 15:59:34,969 - Epoch: [76][  130/  211]    Overall Loss 0.039108    Objective Loss 0.039108                                        LR 0.100000    Time 0.632443    
2024-01-15 15:59:40,750 - Epoch: [76][  140/  211]    Overall Loss 0.039404    Objective Loss 0.039404                                        LR 0.100000    Time 0.628551    
2024-01-15 15:59:46,815 - Epoch: [76][  150/  211]    Overall Loss 0.039622    Objective Loss 0.039622                                        LR 0.100000    Time 0.627067    
2024-01-15 15:59:52,507 - Epoch: [76][  160/  211]    Overall Loss 0.039832    Objective Loss 0.039832                                        LR 0.100000    Time 0.623444    
2024-01-15 15:59:59,127 - Epoch: [76][  170/  211]    Overall Loss 0.039848    Objective Loss 0.039848                                        LR 0.100000    Time 0.625710    
2024-01-15 16:00:04,912 - Epoch: [76][  180/  211]    Overall Loss 0.039744    Objective Loss 0.039744                                        LR 0.100000    Time 0.623081    
2024-01-15 16:00:10,990 - Epoch: [76][  190/  211]    Overall Loss 0.039763    Objective Loss 0.039763                                        LR 0.100000    Time 0.622268    
2024-01-15 16:00:16,648 - Epoch: [76][  200/  211]    Overall Loss 0.039942    Objective Loss 0.039942                                        LR 0.100000    Time 0.619442    
2024-01-15 16:00:22,349 - Epoch: [76][  210/  211]    Overall Loss 0.039955    Objective Loss 0.039955    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.617092    
2024-01-15 16:00:22,935 - Epoch: [76][  211/  211]    Overall Loss 0.039897    Objective Loss 0.039897    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.616939    
2024-01-15 16:00:23,725 - --- validate (epoch=76)-----------
2024-01-15 16:00:23,726 - 6000 samples (256 per mini-batch)
2024-01-15 16:00:30,676 - Epoch: [76][   10/   24]    Loss 0.044034    Top1 98.554688    Top5 100.000000    
2024-01-15 16:00:32,806 - Epoch: [76][   20/   24]    Loss 0.038333    Top1 98.925781    Top5 99.980469    
2024-01-15 16:00:33,569 - Epoch: [76][   24/   24]    Loss 0.041311    Top1 98.883333    Top5 99.983333    
2024-01-15 16:00:34,160 - ==> Top1: 98.883    Top5: 99.983    Loss: 0.041

2024-01-15 16:00:34,161 - ==> Confusion:
[[599   0   1   1   0   0   2   0   2   0]
 [  0 680   2   1   0   1   1   3   0   0]
 [  0   0 584   0   1   0   0   1   0   0]
 [  0   0   2 577   0   2   0   0   2   0]
 [  0   0   1   0 552   1   1   3   1   6]
 [  1   0   0   2   0 513   1   0   1   0]
 [  0   0   0   0   1   2 627   0   1   0]
 [  0   0   1   0   0   0   0 624   0   0]
 [  0   0   1   2   0   3   2   0 576   0]
 [  0   0   0   1   4   4   1   2   2 601]]

2024-01-15 16:00:34,163 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:00:34,164 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:00:34,168 - 

2024-01-15 16:00:34,168 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:00:43,239 - Epoch: [77][   10/  211]    Overall Loss 0.032730    Objective Loss 0.032730                                        LR 0.100000    Time 0.906918    
2024-01-15 16:00:48,982 - Epoch: [77][   20/  211]    Overall Loss 0.037686    Objective Loss 0.037686                                        LR 0.100000    Time 0.740592    
2024-01-15 16:00:54,742 - Epoch: [77][   30/  211]    Overall Loss 0.042446    Objective Loss 0.042446                                        LR 0.100000    Time 0.685699    
2024-01-15 16:01:00,538 - Epoch: [77][   40/  211]    Overall Loss 0.041701    Objective Loss 0.041701                                        LR 0.100000    Time 0.659148    
2024-01-15 16:01:06,340 - Epoch: [77][   50/  211]    Overall Loss 0.041266    Objective Loss 0.041266                                        LR 0.100000    Time 0.643318    
2024-01-15 16:01:12,411 - Epoch: [77][   60/  211]    Overall Loss 0.040296    Objective Loss 0.040296                                        LR 0.100000    Time 0.637269    
2024-01-15 16:01:19,703 - Epoch: [77][   70/  211]    Overall Loss 0.039933    Objective Loss 0.039933                                        LR 0.100000    Time 0.650379    
2024-01-15 16:01:25,864 - Epoch: [77][   80/  211]    Overall Loss 0.042140    Objective Loss 0.042140                                        LR 0.100000    Time 0.646075    
2024-01-15 16:01:31,588 - Epoch: [77][   90/  211]    Overall Loss 0.042050    Objective Loss 0.042050                                        LR 0.100000    Time 0.637878    
2024-01-15 16:01:37,606 - Epoch: [77][  100/  211]    Overall Loss 0.042263    Objective Loss 0.042263                                        LR 0.100000    Time 0.634262    
2024-01-15 16:01:43,852 - Epoch: [77][  110/  211]    Overall Loss 0.041551    Objective Loss 0.041551                                        LR 0.100000    Time 0.633369    
2024-01-15 16:01:50,576 - Epoch: [77][  120/  211]    Overall Loss 0.040899    Objective Loss 0.040899                                        LR 0.100000    Time 0.636598    
2024-01-15 16:01:58,143 - Epoch: [77][  130/  211]    Overall Loss 0.040517    Objective Loss 0.040517                                        LR 0.100000    Time 0.645824    
2024-01-15 16:02:04,284 - Epoch: [77][  140/  211]    Overall Loss 0.040756    Objective Loss 0.040756                                        LR 0.100000    Time 0.643551    
2024-01-15 16:02:11,283 - Epoch: [77][  150/  211]    Overall Loss 0.040443    Objective Loss 0.040443                                        LR 0.100000    Time 0.647289    
2024-01-15 16:02:17,276 - Epoch: [77][  160/  211]    Overall Loss 0.040562    Objective Loss 0.040562                                        LR 0.100000    Time 0.644239    
2024-01-15 16:02:23,207 - Epoch: [77][  170/  211]    Overall Loss 0.040898    Objective Loss 0.040898                                        LR 0.100000    Time 0.641218    
2024-01-15 16:02:29,906 - Epoch: [77][  180/  211]    Overall Loss 0.040805    Objective Loss 0.040805                                        LR 0.100000    Time 0.642804    
2024-01-15 16:02:36,122 - Epoch: [77][  190/  211]    Overall Loss 0.040768    Objective Loss 0.040768                                        LR 0.100000    Time 0.641681    
2024-01-15 16:02:42,761 - Epoch: [77][  200/  211]    Overall Loss 0.041111    Objective Loss 0.041111                                        LR 0.100000    Time 0.642784    
2024-01-15 16:02:48,867 - Epoch: [77][  210/  211]    Overall Loss 0.041434    Objective Loss 0.041434    Top1 98.046875    Top5 99.609375    LR 0.100000    Time 0.641241    
2024-01-15 16:02:49,530 - Epoch: [77][  211/  211]    Overall Loss 0.041681    Objective Loss 0.041681    Top1 97.782258    Top5 99.798387    LR 0.100000    Time 0.641342    
2024-01-15 16:02:50,523 - --- validate (epoch=77)-----------
2024-01-15 16:02:50,525 - 6000 samples (256 per mini-batch)
2024-01-15 16:02:58,375 - Epoch: [77][   10/   24]    Loss 0.045580    Top1 98.593750    Top5 100.000000    
2024-01-15 16:03:00,622 - Epoch: [77][   20/   24]    Loss 0.045974    Top1 98.691406    Top5 100.000000    
2024-01-15 16:03:01,424 - Epoch: [77][   24/   24]    Loss 0.044054    Top1 98.750000    Top5 100.000000    
2024-01-15 16:03:02,268 - ==> Top1: 98.750    Top5: 100.000    Loss: 0.044

2024-01-15 16:03:02,270 - ==> Confusion:
[[602   0   1   1   0   0   1   0   0   0]
 [  0 684   0   1   0   0   1   2   0   0]
 [  0   0 569  11   0   0   0   6   0   0]
 [  0   0   0 581   0   1   0   0   1   0]
 [  0   0   0   0 561   0   1   0   0   3]
 [  1   1   0   8   0 506   1   1   0   0]
 [  0   0   0   0   1   1 628   0   1   0]
 [  0   2   2   1   1   0   0 618   0   1]
 [  0   0   0   5   2   2   1   1 571   2]
 [  1   1   0   1   0   1   1   3   2 605]]

2024-01-15 16:03:02,273 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:03:02,274 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:03:02,280 - 

2024-01-15 16:03:02,281 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:03:12,719 - Epoch: [78][   10/  211]    Overall Loss 0.045651    Objective Loss 0.045651                                        LR 0.100000    Time 1.043676    
2024-01-15 16:03:18,571 - Epoch: [78][   20/  211]    Overall Loss 0.041408    Objective Loss 0.041408                                        LR 0.100000    Time 0.814372    
2024-01-15 16:03:25,306 - Epoch: [78][   30/  211]    Overall Loss 0.043902    Objective Loss 0.043902                                        LR 0.100000    Time 0.767359    
2024-01-15 16:03:31,450 - Epoch: [78][   40/  211]    Overall Loss 0.044112    Objective Loss 0.044112                                        LR 0.100000    Time 0.729087    
2024-01-15 16:03:37,582 - Epoch: [78][   50/  211]    Overall Loss 0.043450    Objective Loss 0.043450                                        LR 0.100000    Time 0.705879    
2024-01-15 16:03:43,819 - Epoch: [78][   60/  211]    Overall Loss 0.042008    Objective Loss 0.042008                                        LR 0.100000    Time 0.692134    
2024-01-15 16:03:50,539 - Epoch: [78][   70/  211]    Overall Loss 0.041404    Objective Loss 0.041404                                        LR 0.100000    Time 0.689237    
2024-01-15 16:03:56,285 - Epoch: [78][   80/  211]    Overall Loss 0.042423    Objective Loss 0.042423                                        LR 0.100000    Time 0.674886    
2024-01-15 16:04:02,012 - Epoch: [78][   90/  211]    Overall Loss 0.042595    Objective Loss 0.042595                                        LR 0.100000    Time 0.663528    
2024-01-15 16:04:07,677 - Epoch: [78][  100/  211]    Overall Loss 0.041783    Objective Loss 0.041783                                        LR 0.100000    Time 0.653815    
2024-01-15 16:04:13,368 - Epoch: [78][  110/  211]    Overall Loss 0.041549    Objective Loss 0.041549                                        LR 0.100000    Time 0.646107    
2024-01-15 16:04:18,998 - Epoch: [78][  120/  211]    Overall Loss 0.041443    Objective Loss 0.041443                                        LR 0.100000    Time 0.639173    
2024-01-15 16:04:24,685 - Epoch: [78][  130/  211]    Overall Loss 0.041546    Objective Loss 0.041546                                        LR 0.100000    Time 0.633750    
2024-01-15 16:04:30,554 - Epoch: [78][  140/  211]    Overall Loss 0.041828    Objective Loss 0.041828                                        LR 0.100000    Time 0.630399    
2024-01-15 16:04:36,333 - Epoch: [78][  150/  211]    Overall Loss 0.041819    Objective Loss 0.041819                                        LR 0.100000    Time 0.626893    
2024-01-15 16:04:42,018 - Epoch: [78][  160/  211]    Overall Loss 0.041822    Objective Loss 0.041822                                        LR 0.100000    Time 0.623233    
2024-01-15 16:04:48,040 - Epoch: [78][  170/  211]    Overall Loss 0.041977    Objective Loss 0.041977                                        LR 0.100000    Time 0.621995    
2024-01-15 16:04:53,792 - Epoch: [78][  180/  211]    Overall Loss 0.041535    Objective Loss 0.041535                                        LR 0.100000    Time 0.619383    
2024-01-15 16:04:59,422 - Epoch: [78][  190/  211]    Overall Loss 0.041884    Objective Loss 0.041884                                        LR 0.100000    Time 0.616415    
2024-01-15 16:05:05,333 - Epoch: [78][  200/  211]    Overall Loss 0.041503    Objective Loss 0.041503                                        LR 0.100000    Time 0.615139    
2024-01-15 16:05:11,320 - Epoch: [78][  210/  211]    Overall Loss 0.041593    Objective Loss 0.041593    Top1 98.046875    Top5 100.000000    LR 0.100000    Time 0.614346    
2024-01-15 16:05:11,910 - Epoch: [78][  211/  211]    Overall Loss 0.041623    Objective Loss 0.041623    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.614228    
2024-01-15 16:05:12,703 - --- validate (epoch=78)-----------
2024-01-15 16:05:12,704 - 6000 samples (256 per mini-batch)
2024-01-15 16:05:19,294 - Epoch: [78][   10/   24]    Loss 0.045881    Top1 98.828125    Top5 100.000000    
2024-01-15 16:05:21,457 - Epoch: [78][   20/   24]    Loss 0.041559    Top1 98.867188    Top5 100.000000    
2024-01-15 16:05:22,227 - Epoch: [78][   24/   24]    Loss 0.045757    Top1 98.800000    Top5 100.000000    
2024-01-15 16:05:22,900 - ==> Top1: 98.800    Top5: 100.000    Loss: 0.046

2024-01-15 16:05:22,901 - ==> Confusion:
[[597   0   3   1   0   0   1   3   0   0]
 [  0 685   1   0   0   0   1   1   0   0]
 [  0   0 579   1   0   1   0   4   1   0]
 [  0   0   0 580   0   1   0   1   1   0]
 [  0   1   1   0 549   0   1   5   0   8]
 [  0   1   0   3   0 511   1   0   1   1]
 [  2   1   0   0   1   2 625   0   0   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   1   6   1   3   1   0 571   1]
 [  0   1   0   1   1   1   0   3   1 607]]

2024-01-15 16:05:22,903 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:05:22,904 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:05:22,908 - 

2024-01-15 16:05:22,908 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:05:31,665 - Epoch: [79][   10/  211]    Overall Loss 0.042939    Objective Loss 0.042939                                        LR 0.100000    Time 0.875604    
2024-01-15 16:05:37,471 - Epoch: [79][   20/  211]    Overall Loss 0.044368    Objective Loss 0.044368                                        LR 0.100000    Time 0.728060    
2024-01-15 16:05:43,275 - Epoch: [79][   30/  211]    Overall Loss 0.049691    Objective Loss 0.049691                                        LR 0.100000    Time 0.678797    
2024-01-15 16:05:48,958 - Epoch: [79][   40/  211]    Overall Loss 0.047622    Objective Loss 0.047622                                        LR 0.100000    Time 0.651147    
2024-01-15 16:05:54,754 - Epoch: [79][   50/  211]    Overall Loss 0.046070    Objective Loss 0.046070                                        LR 0.100000    Time 0.636823    
2024-01-15 16:06:00,463 - Epoch: [79][   60/  211]    Overall Loss 0.045833    Objective Loss 0.045833                                        LR 0.100000    Time 0.625820    
2024-01-15 16:06:06,095 - Epoch: [79][   70/  211]    Overall Loss 0.044458    Objective Loss 0.044458                                        LR 0.100000    Time 0.616866    
2024-01-15 16:06:11,871 - Epoch: [79][   80/  211]    Overall Loss 0.044420    Objective Loss 0.044420                                        LR 0.100000    Time 0.611948    
2024-01-15 16:06:18,306 - Epoch: [79][   90/  211]    Overall Loss 0.043567    Objective Loss 0.043567                                        LR 0.100000    Time 0.615428    
2024-01-15 16:06:24,044 - Epoch: [79][  100/  211]    Overall Loss 0.042487    Objective Loss 0.042487                                        LR 0.100000    Time 0.611248    
2024-01-15 16:06:29,763 - Epoch: [79][  110/  211]    Overall Loss 0.041315    Objective Loss 0.041315                                        LR 0.100000    Time 0.607661    
2024-01-15 16:06:35,813 - Epoch: [79][  120/  211]    Overall Loss 0.041298    Objective Loss 0.041298                                        LR 0.100000    Time 0.607432    
2024-01-15 16:06:41,504 - Epoch: [79][  130/  211]    Overall Loss 0.040893    Objective Loss 0.040893                                        LR 0.100000    Time 0.604473    
2024-01-15 16:06:47,204 - Epoch: [79][  140/  211]    Overall Loss 0.041278    Objective Loss 0.041278                                        LR 0.100000    Time 0.602005    
2024-01-15 16:06:52,849 - Epoch: [79][  150/  211]    Overall Loss 0.041411    Objective Loss 0.041411                                        LR 0.100000    Time 0.599505    
2024-01-15 16:06:59,186 - Epoch: [79][  160/  211]    Overall Loss 0.042068    Objective Loss 0.042068                                        LR 0.100000    Time 0.601635    
2024-01-15 16:07:05,066 - Epoch: [79][  170/  211]    Overall Loss 0.042483    Objective Loss 0.042483                                        LR 0.100000    Time 0.600824    
2024-01-15 16:07:10,747 - Epoch: [79][  180/  211]    Overall Loss 0.042636    Objective Loss 0.042636                                        LR 0.100000    Time 0.599006    
2024-01-15 16:07:16,536 - Epoch: [79][  190/  211]    Overall Loss 0.042328    Objective Loss 0.042328                                        LR 0.100000    Time 0.597937    
2024-01-15 16:07:22,167 - Epoch: [79][  200/  211]    Overall Loss 0.042023    Objective Loss 0.042023                                        LR 0.100000    Time 0.596191    
2024-01-15 16:07:27,875 - Epoch: [79][  210/  211]    Overall Loss 0.042071    Objective Loss 0.042071    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.594981    
2024-01-15 16:07:28,446 - Epoch: [79][  211/  211]    Overall Loss 0.042084    Objective Loss 0.042084    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.594865    
2024-01-15 16:07:29,326 - --- validate (epoch=79)-----------
2024-01-15 16:07:29,328 - 6000 samples (256 per mini-batch)
2024-01-15 16:07:36,307 - Epoch: [79][   10/   24]    Loss 0.051774    Top1 98.437500    Top5 100.000000    
2024-01-15 16:07:38,416 - Epoch: [79][   20/   24]    Loss 0.044463    Top1 98.671875    Top5 100.000000    
2024-01-15 16:07:39,152 - Epoch: [79][   24/   24]    Loss 0.042516    Top1 98.683333    Top5 100.000000    
2024-01-15 16:07:40,258 - ==> Top1: 98.683    Top5: 100.000    Loss: 0.043

2024-01-15 16:07:40,260 - ==> Confusion:
[[602   0   0   1   0   0   2   0   0   0]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   1 584   0   0   0   0   1   0   0]
 [  0   1   4 574   0   3   0   1   0   0]
 [  0   1   0   0 560   0   0   0   0   4]
 [  1   1   0   1   0 509   6   0   0   0]
 [  0   0   0   0   2   1 628   0   0   0]
 [  1   5   2   0   1   0   0 616   0   0]
 [  5   2   1   0   1   1  10   0 562   2]
 [  1   5   0   0   5   2   0   2   2 598]]

2024-01-15 16:07:40,263 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:07:40,264 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:07:40,270 - 

2024-01-15 16:07:40,271 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:07:51,403 - Epoch: [80][   10/  211]    Overall Loss 0.043293    Objective Loss 0.043293                                        LR 0.100000    Time 1.113054    
2024-01-15 16:07:57,600 - Epoch: [80][   20/  211]    Overall Loss 0.040288    Objective Loss 0.040288                                        LR 0.100000    Time 0.866319    
2024-01-15 16:08:03,374 - Epoch: [80][   30/  211]    Overall Loss 0.039911    Objective Loss 0.039911                                        LR 0.100000    Time 0.769990    
2024-01-15 16:08:09,049 - Epoch: [80][   40/  211]    Overall Loss 0.040433    Objective Loss 0.040433                                        LR 0.100000    Time 0.719336    
2024-01-15 16:08:14,931 - Epoch: [80][   50/  211]    Overall Loss 0.041164    Objective Loss 0.041164                                        LR 0.100000    Time 0.693087    
2024-01-15 16:08:20,559 - Epoch: [80][   60/  211]    Overall Loss 0.041736    Objective Loss 0.041736                                        LR 0.100000    Time 0.671364    
2024-01-15 16:08:26,237 - Epoch: [80][   70/  211]    Overall Loss 0.042036    Objective Loss 0.042036                                        LR 0.100000    Time 0.656564    
2024-01-15 16:08:31,911 - Epoch: [80][   80/  211]    Overall Loss 0.041484    Objective Loss 0.041484                                        LR 0.100000    Time 0.645404    
2024-01-15 16:08:37,568 - Epoch: [80][   90/  211]    Overall Loss 0.041471    Objective Loss 0.041471                                        LR 0.100000    Time 0.636540    
2024-01-15 16:08:43,299 - Epoch: [80][  100/  211]    Overall Loss 0.041259    Objective Loss 0.041259                                        LR 0.100000    Time 0.630193    
2024-01-15 16:08:49,102 - Epoch: [80][  110/  211]    Overall Loss 0.040663    Objective Loss 0.040663                                        LR 0.100000    Time 0.625646    
2024-01-15 16:08:55,678 - Epoch: [80][  120/  211]    Overall Loss 0.040509    Objective Loss 0.040509                                        LR 0.100000    Time 0.628294    
2024-01-15 16:09:02,221 - Epoch: [80][  130/  211]    Overall Loss 0.040507    Objective Loss 0.040507                                        LR 0.100000    Time 0.630290    
2024-01-15 16:09:08,688 - Epoch: [80][  140/  211]    Overall Loss 0.040066    Objective Loss 0.040066                                        LR 0.100000    Time 0.631452    
2024-01-15 16:09:16,201 - Epoch: [80][  150/  211]    Overall Loss 0.040075    Objective Loss 0.040075                                        LR 0.100000    Time 0.639424    
2024-01-15 16:09:23,660 - Epoch: [80][  160/  211]    Overall Loss 0.039568    Objective Loss 0.039568                                        LR 0.100000    Time 0.646070    
2024-01-15 16:09:29,542 - Epoch: [80][  170/  211]    Overall Loss 0.039374    Objective Loss 0.039374                                        LR 0.100000    Time 0.642662    
2024-01-15 16:09:35,377 - Epoch: [80][  180/  211]    Overall Loss 0.039937    Objective Loss 0.039937                                        LR 0.100000    Time 0.639367    
2024-01-15 16:09:41,082 - Epoch: [80][  190/  211]    Overall Loss 0.039922    Objective Loss 0.039922                                        LR 0.100000    Time 0.635721    
2024-01-15 16:09:47,138 - Epoch: [80][  200/  211]    Overall Loss 0.039823    Objective Loss 0.039823                                        LR 0.100000    Time 0.634198    
2024-01-15 16:09:53,161 - Epoch: [80][  210/  211]    Overall Loss 0.040202    Objective Loss 0.040202    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.632674    
2024-01-15 16:09:53,812 - Epoch: [80][  211/  211]    Overall Loss 0.040391    Objective Loss 0.040391    Top1 97.782258    Top5 99.798387    LR 0.100000    Time 0.632749    
2024-01-15 16:09:54,783 - --- validate (epoch=80)-----------
2024-01-15 16:09:54,785 - 6000 samples (256 per mini-batch)
2024-01-15 16:10:03,011 - Epoch: [80][   10/   24]    Loss 0.041561    Top1 98.632812    Top5 100.000000    
2024-01-15 16:10:05,512 - Epoch: [80][   20/   24]    Loss 0.048561    Top1 98.593750    Top5 99.941406    
2024-01-15 16:10:06,476 - Epoch: [80][   24/   24]    Loss 0.046858    Top1 98.600000    Top5 99.950000    
2024-01-15 16:10:07,314 - ==> Top1: 98.600    Top5: 99.950    Loss: 0.047

2024-01-15 16:10:07,318 - ==> Confusion:
[[598   0   2   0   0   0   2   0   0   3]
 [  0 679   1   1   0   1   2   4   0   0]
 [  0   1 579   0   0   0   0   5   1   0]
 [  0   0   4 576   0   2   0   0   1   0]
 [  0   0   1   0 544   0   2   1   0  17]
 [  0   0   0   1   0 516   1   0   0   0]
 [  0   0   0   0   1   2 627   0   1   0]
 [  0   0   2   1   0   1   0 619   0   2]
 [  0   0   2   5   0   2   3   0 570   2]
 [  1   0   1   0   0   1   0   1   3 608]]

2024-01-15 16:10:07,323 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:10:07,325 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:10:07,338 - 

2024-01-15 16:10:07,339 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:10:17,763 - Epoch: [81][   10/  211]    Overall Loss 0.042487    Objective Loss 0.042487                                        LR 0.100000    Time 1.042254    
2024-01-15 16:10:23,640 - Epoch: [81][   20/  211]    Overall Loss 0.040296    Objective Loss 0.040296                                        LR 0.100000    Time 0.814946    
2024-01-15 16:10:29,551 - Epoch: [81][   30/  211]    Overall Loss 0.042485    Objective Loss 0.042485                                        LR 0.100000    Time 0.740286    
2024-01-15 16:10:35,950 - Epoch: [81][   40/  211]    Overall Loss 0.042569    Objective Loss 0.042569                                        LR 0.100000    Time 0.715140    
2024-01-15 16:10:42,037 - Epoch: [81][   50/  211]    Overall Loss 0.043726    Objective Loss 0.043726                                        LR 0.100000    Time 0.693829    
2024-01-15 16:10:47,862 - Epoch: [81][   60/  211]    Overall Loss 0.042908    Objective Loss 0.042908                                        LR 0.100000    Time 0.675250    
2024-01-15 16:10:53,535 - Epoch: [81][   70/  211]    Overall Loss 0.042060    Objective Loss 0.042060                                        LR 0.100000    Time 0.659833    
2024-01-15 16:10:59,167 - Epoch: [81][   80/  211]    Overall Loss 0.041581    Objective Loss 0.041581                                        LR 0.100000    Time 0.647735    
2024-01-15 16:11:05,138 - Epoch: [81][   90/  211]    Overall Loss 0.041413    Objective Loss 0.041413                                        LR 0.100000    Time 0.642094    
2024-01-15 16:11:10,898 - Epoch: [81][  100/  211]    Overall Loss 0.040095    Objective Loss 0.040095                                        LR 0.100000    Time 0.635468    
2024-01-15 16:11:16,696 - Epoch: [81][  110/  211]    Overall Loss 0.039877    Objective Loss 0.039877                                        LR 0.100000    Time 0.630394    
2024-01-15 16:11:22,326 - Epoch: [81][  120/  211]    Overall Loss 0.039698    Objective Loss 0.039698                                        LR 0.100000    Time 0.624769    
2024-01-15 16:11:27,951 - Epoch: [81][  130/  211]    Overall Loss 0.039421    Objective Loss 0.039421                                        LR 0.100000    Time 0.619981    
2024-01-15 16:11:33,694 - Epoch: [81][  140/  211]    Overall Loss 0.038766    Objective Loss 0.038766                                        LR 0.100000    Time 0.616708    
2024-01-15 16:11:39,676 - Epoch: [81][  150/  211]    Overall Loss 0.038228    Objective Loss 0.038228                                        LR 0.100000    Time 0.615463    
2024-01-15 16:11:46,418 - Epoch: [81][  160/  211]    Overall Loss 0.038570    Objective Loss 0.038570                                        LR 0.100000    Time 0.619123    
2024-01-15 16:11:52,174 - Epoch: [81][  170/  211]    Overall Loss 0.038343    Objective Loss 0.038343                                        LR 0.100000    Time 0.616549    
2024-01-15 16:11:57,842 - Epoch: [81][  180/  211]    Overall Loss 0.039035    Objective Loss 0.039035                                        LR 0.100000    Time 0.613781    
2024-01-15 16:12:03,546 - Epoch: [81][  190/  211]    Overall Loss 0.039510    Objective Loss 0.039510                                        LR 0.100000    Time 0.611493    
2024-01-15 16:12:09,220 - Epoch: [81][  200/  211]    Overall Loss 0.039554    Objective Loss 0.039554                                        LR 0.100000    Time 0.609283    
2024-01-15 16:12:15,175 - Epoch: [81][  210/  211]    Overall Loss 0.039273    Objective Loss 0.039273    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.608623    
2024-01-15 16:12:15,756 - Epoch: [81][  211/  211]    Overall Loss 0.039308    Objective Loss 0.039308    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.608491    
2024-01-15 16:12:16,637 - --- validate (epoch=81)-----------
2024-01-15 16:12:16,639 - 6000 samples (256 per mini-batch)
2024-01-15 16:12:23,421 - Epoch: [81][   10/   24]    Loss 0.038721    Top1 98.867188    Top5 100.000000    
2024-01-15 16:12:25,592 - Epoch: [81][   20/   24]    Loss 0.038288    Top1 98.945312    Top5 100.000000    
2024-01-15 16:12:26,349 - Epoch: [81][   24/   24]    Loss 0.043796    Top1 98.866667    Top5 100.000000    
2024-01-15 16:12:27,074 - ==> Top1: 98.867    Top5: 100.000    Loss: 0.044

2024-01-15 16:12:27,075 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 684   0   0   2   1   1   0   0   0]
 [  0   0 581   0   0   0   0   3   1   1]
 [  1   0   2 572   0   1   0   3   3   1]
 [  0   1   0   0 558   0   0   1   0   5]
 [  4   0   0   2   0 501   2   0   6   3]
 [  2   0   0   0   1   0 628   0   0   0]
 [  1   2   2   0   3   0   0 617   0   0]
 [  0   0   1   0   2   0   1   1 578   1]
 [  0   1   0   0   3   0   0   0   2 609]]

2024-01-15 16:12:27,077 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:12:27,078 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:12:27,082 - 

2024-01-15 16:12:27,082 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:12:36,121 - Epoch: [82][   10/  211]    Overall Loss 0.037800    Objective Loss 0.037800                                        LR 0.100000    Time 0.903764    
2024-01-15 16:12:41,784 - Epoch: [82][   20/  211]    Overall Loss 0.035080    Objective Loss 0.035080                                        LR 0.100000    Time 0.735001    
2024-01-15 16:12:47,629 - Epoch: [82][   30/  211]    Overall Loss 0.039175    Objective Loss 0.039175                                        LR 0.100000    Time 0.684809    
2024-01-15 16:12:53,499 - Epoch: [82][   40/  211]    Overall Loss 0.038548    Objective Loss 0.038548                                        LR 0.100000    Time 0.660312    
2024-01-15 16:12:59,260 - Epoch: [82][   50/  211]    Overall Loss 0.038530    Objective Loss 0.038530                                        LR 0.100000    Time 0.643441    
2024-01-15 16:13:05,376 - Epoch: [82][   60/  211]    Overall Loss 0.038506    Objective Loss 0.038506                                        LR 0.100000    Time 0.638124    
2024-01-15 16:13:11,129 - Epoch: [82][   70/  211]    Overall Loss 0.037280    Objective Loss 0.037280                                        LR 0.100000    Time 0.629130    
2024-01-15 16:13:17,072 - Epoch: [82][   80/  211]    Overall Loss 0.037241    Objective Loss 0.037241                                        LR 0.100000    Time 0.624762    
2024-01-15 16:13:22,827 - Epoch: [82][   90/  211]    Overall Loss 0.037676    Objective Loss 0.037676                                        LR 0.100000    Time 0.619262    
2024-01-15 16:13:28,573 - Epoch: [82][  100/  211]    Overall Loss 0.037876    Objective Loss 0.037876                                        LR 0.100000    Time 0.614783    
2024-01-15 16:13:34,310 - Epoch: [82][  110/  211]    Overall Loss 0.038448    Objective Loss 0.038448                                        LR 0.100000    Time 0.611040    
2024-01-15 16:13:39,969 - Epoch: [82][  120/  211]    Overall Loss 0.038187    Objective Loss 0.038187                                        LR 0.100000    Time 0.607277    
2024-01-15 16:13:46,142 - Epoch: [82][  130/  211]    Overall Loss 0.038052    Objective Loss 0.038052                                        LR 0.100000    Time 0.608035    
2024-01-15 16:13:51,841 - Epoch: [82][  140/  211]    Overall Loss 0.037806    Objective Loss 0.037806                                        LR 0.100000    Time 0.605303    
2024-01-15 16:13:57,643 - Epoch: [82][  150/  211]    Overall Loss 0.038396    Objective Loss 0.038396                                        LR 0.100000    Time 0.603626    
2024-01-15 16:14:03,346 - Epoch: [82][  160/  211]    Overall Loss 0.038833    Objective Loss 0.038833                                        LR 0.100000    Time 0.601537    
2024-01-15 16:14:08,994 - Epoch: [82][  170/  211]    Overall Loss 0.038664    Objective Loss 0.038664                                        LR 0.100000    Time 0.599374    
2024-01-15 16:14:14,845 - Epoch: [82][  180/  211]    Overall Loss 0.038519    Objective Loss 0.038519                                        LR 0.100000    Time 0.598572    
2024-01-15 16:14:20,569 - Epoch: [82][  190/  211]    Overall Loss 0.038427    Objective Loss 0.038427                                        LR 0.100000    Time 0.597189    
2024-01-15 16:14:26,247 - Epoch: [82][  200/  211]    Overall Loss 0.038318    Objective Loss 0.038318                                        LR 0.100000    Time 0.595717    
2024-01-15 16:14:31,928 - Epoch: [82][  210/  211]    Overall Loss 0.038414    Objective Loss 0.038414    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.594393    
2024-01-15 16:14:32,608 - Epoch: [82][  211/  211]    Overall Loss 0.038560    Objective Loss 0.038560    Top1 98.185484    Top5 100.000000    LR 0.100000    Time 0.594792    
2024-01-15 16:14:33,421 - --- validate (epoch=82)-----------
2024-01-15 16:14:33,423 - 6000 samples (256 per mini-batch)
2024-01-15 16:14:40,505 - Epoch: [82][   10/   24]    Loss 0.041532    Top1 98.671875    Top5 100.000000    
2024-01-15 16:14:42,768 - Epoch: [82][   20/   24]    Loss 0.041797    Top1 98.769531    Top5 100.000000    
2024-01-15 16:14:43,573 - Epoch: [82][   24/   24]    Loss 0.041907    Top1 98.816667    Top5 100.000000    
2024-01-15 16:14:44,355 - ==> Top1: 98.817    Top5: 100.000    Loss: 0.042

2024-01-15 16:14:44,356 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 687   0   0   0   1   0   0   0   0]
 [  0   0 580   1   0   0   1   1   2   1]
 [  0   0   3 571   0   4   0   3   2   0]
 [  0   1   0   0 558   0   1   0   0   5]
 [  1   1   1   1   0 507   6   0   1   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   1   2   0   0   0   0 622   0   0]
 [  1   0   0   0   1   2   4   1 574   1]
 [  2   1   0   0   5   3   0   4   3 597]]

2024-01-15 16:14:44,358 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:14:44,358 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:14:44,362 - 

2024-01-15 16:14:44,363 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:14:53,548 - Epoch: [83][   10/  211]    Overall Loss 0.041900    Objective Loss 0.041900                                        LR 0.100000    Time 0.918400    
2024-01-15 16:14:59,339 - Epoch: [83][   20/  211]    Overall Loss 0.044515    Objective Loss 0.044515                                        LR 0.100000    Time 0.748707    
2024-01-15 16:15:05,049 - Epoch: [83][   30/  211]    Overall Loss 0.041591    Objective Loss 0.041591                                        LR 0.100000    Time 0.689423    
2024-01-15 16:15:10,736 - Epoch: [83][   40/  211]    Overall Loss 0.040449    Objective Loss 0.040449                                        LR 0.100000    Time 0.659207    
2024-01-15 16:15:16,514 - Epoch: [83][   50/  211]    Overall Loss 0.040863    Objective Loss 0.040863                                        LR 0.100000    Time 0.642908    
2024-01-15 16:15:23,389 - Epoch: [83][   60/  211]    Overall Loss 0.040476    Objective Loss 0.040476                                        LR 0.100000    Time 0.650294    
2024-01-15 16:15:29,136 - Epoch: [83][   70/  211]    Overall Loss 0.038051    Objective Loss 0.038051                                        LR 0.100000    Time 0.639483    
2024-01-15 16:15:34,887 - Epoch: [83][   80/  211]    Overall Loss 0.038911    Objective Loss 0.038911                                        LR 0.100000    Time 0.631417    
2024-01-15 16:15:40,589 - Epoch: [83][   90/  211]    Overall Loss 0.038802    Objective Loss 0.038802                                        LR 0.100000    Time 0.624610    
2024-01-15 16:15:46,394 - Epoch: [83][  100/  211]    Overall Loss 0.039025    Objective Loss 0.039025                                        LR 0.100000    Time 0.620186    
2024-01-15 16:15:52,289 - Epoch: [83][  110/  211]    Overall Loss 0.039389    Objective Loss 0.039389                                        LR 0.100000    Time 0.617389    
2024-01-15 16:15:57,974 - Epoch: [83][  120/  211]    Overall Loss 0.038853    Objective Loss 0.038853                                        LR 0.100000    Time 0.613308    
2024-01-15 16:16:03,606 - Epoch: [83][  130/  211]    Overall Loss 0.039024    Objective Loss 0.039024                                        LR 0.100000    Time 0.609445    
2024-01-15 16:16:09,614 - Epoch: [83][  140/  211]    Overall Loss 0.038845    Objective Loss 0.038845                                        LR 0.100000    Time 0.608820    
2024-01-15 16:16:15,533 - Epoch: [83][  150/  211]    Overall Loss 0.038127    Objective Loss 0.038127                                        LR 0.100000    Time 0.607679    
2024-01-15 16:16:21,230 - Epoch: [83][  160/  211]    Overall Loss 0.038316    Objective Loss 0.038316                                        LR 0.100000    Time 0.605301    
2024-01-15 16:16:26,917 - Epoch: [83][  170/  211]    Overall Loss 0.038173    Objective Loss 0.038173                                        LR 0.100000    Time 0.603144    
2024-01-15 16:16:32,569 - Epoch: [83][  180/  211]    Overall Loss 0.038407    Objective Loss 0.038407                                        LR 0.100000    Time 0.601033    
2024-01-15 16:16:38,436 - Epoch: [83][  190/  211]    Overall Loss 0.037981    Objective Loss 0.037981                                        LR 0.100000    Time 0.600274    
2024-01-15 16:16:44,909 - Epoch: [83][  200/  211]    Overall Loss 0.039024    Objective Loss 0.039024                                        LR 0.100000    Time 0.602616    
2024-01-15 16:16:51,126 - Epoch: [83][  210/  211]    Overall Loss 0.038965    Objective Loss 0.038965    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.603516    
2024-01-15 16:16:51,696 - Epoch: [83][  211/  211]    Overall Loss 0.038887    Objective Loss 0.038887    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.603357    
2024-01-15 16:16:52,532 - --- validate (epoch=83)-----------
2024-01-15 16:16:52,534 - 6000 samples (256 per mini-batch)
2024-01-15 16:16:59,676 - Epoch: [83][   10/   24]    Loss 0.035272    Top1 98.945312    Top5 100.000000    
2024-01-15 16:17:01,887 - Epoch: [83][   20/   24]    Loss 0.036072    Top1 98.886719    Top5 100.000000    
2024-01-15 16:17:02,646 - Epoch: [83][   24/   24]    Loss 0.037378    Top1 98.850000    Top5 100.000000    
2024-01-15 16:17:03,414 - ==> Top1: 98.850    Top5: 100.000    Loss: 0.037

2024-01-15 16:17:03,415 - ==> Confusion:
[[603   0   0   0   0   0   1   0   0   1]
 [  0 686   0   1   0   0   0   1   0   0]
 [  0   0 581   1   0   0   0   3   1   0]
 [  0   0   2 574   0   4   0   2   1   0]
 [  0   0   1   0 551   0   2   3   0   8]
 [  2   1   0   1   0 510   2   0   2   0]
 [  1   2   0   0   1   0 625   0   2   0]
 [  0   0   2   1   0   0   0 622   0   0]
 [  2   1   1   0   2   2   1   1 574   0]
 [  1   1   0   0   2   1   0   3   2 605]]

2024-01-15 16:17:03,417 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:17:03,417 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:17:03,421 - 

2024-01-15 16:17:03,421 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:17:12,598 - Epoch: [84][   10/  211]    Overall Loss 0.046109    Objective Loss 0.046109                                        LR 0.100000    Time 0.917596    
2024-01-15 16:17:18,465 - Epoch: [84][   20/  211]    Overall Loss 0.041482    Objective Loss 0.041482                                        LR 0.100000    Time 0.752073    
2024-01-15 16:17:24,158 - Epoch: [84][   30/  211]    Overall Loss 0.042891    Objective Loss 0.042891                                        LR 0.100000    Time 0.691092    
2024-01-15 16:17:29,851 - Epoch: [84][   40/  211]    Overall Loss 0.042981    Objective Loss 0.042981                                        LR 0.100000    Time 0.660640    
2024-01-15 16:17:35,569 - Epoch: [84][   50/  211]    Overall Loss 0.041151    Objective Loss 0.041151                                        LR 0.100000    Time 0.642854    
2024-01-15 16:17:41,425 - Epoch: [84][   60/  211]    Overall Loss 0.040119    Objective Loss 0.040119                                        LR 0.100000    Time 0.633276    
2024-01-15 16:17:47,374 - Epoch: [84][   70/  211]    Overall Loss 0.039607    Objective Loss 0.039607                                        LR 0.100000    Time 0.627785    
2024-01-15 16:17:53,140 - Epoch: [84][   80/  211]    Overall Loss 0.038521    Objective Loss 0.038521                                        LR 0.100000    Time 0.621368    
2024-01-15 16:17:58,826 - Epoch: [84][   90/  211]    Overall Loss 0.040687    Objective Loss 0.040687                                        LR 0.100000    Time 0.615497    
2024-01-15 16:18:04,567 - Epoch: [84][  100/  211]    Overall Loss 0.040830    Objective Loss 0.040830                                        LR 0.100000    Time 0.611342    
2024-01-15 16:18:10,370 - Epoch: [84][  110/  211]    Overall Loss 0.040862    Objective Loss 0.040862                                        LR 0.100000    Time 0.608511    
2024-01-15 16:18:16,129 - Epoch: [84][  120/  211]    Overall Loss 0.040789    Objective Loss 0.040789                                        LR 0.100000    Time 0.605781    
2024-01-15 16:18:22,024 - Epoch: [84][  130/  211]    Overall Loss 0.040085    Objective Loss 0.040085                                        LR 0.100000    Time 0.604515    
2024-01-15 16:18:28,352 - Epoch: [84][  140/  211]    Overall Loss 0.039827    Objective Loss 0.039827                                        LR 0.100000    Time 0.606524    
2024-01-15 16:18:34,172 - Epoch: [84][  150/  211]    Overall Loss 0.040012    Objective Loss 0.040012                                        LR 0.100000    Time 0.604880    
2024-01-15 16:18:39,966 - Epoch: [84][  160/  211]    Overall Loss 0.039750    Objective Loss 0.039750                                        LR 0.100000    Time 0.603285    
2024-01-15 16:18:45,813 - Epoch: [84][  170/  211]    Overall Loss 0.039901    Objective Loss 0.039901                                        LR 0.100000    Time 0.602180    
2024-01-15 16:18:51,652 - Epoch: [84][  180/  211]    Overall Loss 0.039455    Objective Loss 0.039455                                        LR 0.100000    Time 0.601154    
2024-01-15 16:18:57,361 - Epoch: [84][  190/  211]    Overall Loss 0.038850    Objective Loss 0.038850                                        LR 0.100000    Time 0.599557    
2024-01-15 16:19:03,098 - Epoch: [84][  200/  211]    Overall Loss 0.038810    Objective Loss 0.038810                                        LR 0.100000    Time 0.598259    
2024-01-15 16:19:08,752 - Epoch: [84][  210/  211]    Overall Loss 0.038870    Objective Loss 0.038870    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.596693    
2024-01-15 16:19:09,316 - Epoch: [84][  211/  211]    Overall Loss 0.038944    Objective Loss 0.038944    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 0.596539    
2024-01-15 16:19:10,063 - --- validate (epoch=84)-----------
2024-01-15 16:19:10,064 - 6000 samples (256 per mini-batch)
2024-01-15 16:19:17,248 - Epoch: [84][   10/   24]    Loss 0.037740    Top1 98.867188    Top5 100.000000    
2024-01-15 16:19:19,446 - Epoch: [84][   20/   24]    Loss 0.037424    Top1 98.867188    Top5 100.000000    
2024-01-15 16:19:20,195 - Epoch: [84][   24/   24]    Loss 0.038007    Top1 98.833333    Top5 100.000000    
2024-01-15 16:19:20,932 - ==> Top1: 98.833    Top5: 100.000    Loss: 0.038

2024-01-15 16:19:20,933 - ==> Confusion:
[[600   0   1   0   0   0   1   0   0   3]
 [  0 680   3   0   2   0   0   3   0   0]
 [  0   0 579   0   1   0   0   6   0   0]
 [  0   0   3 578   2   0   0   0   0   0]
 [  0   0   0   0 562   0   0   1   0   2]
 [  2   0   0   2   0 509   3   1   1   0]
 [  1   0   0   0   1   0 627   0   2   0]
 [  1   0   1   0   0   0   0 623   0   0]
 [  1   0   0   1   2   1   0   2 576   1]
 [  0   1   0   0   8   1   0   6   3 596]]

2024-01-15 16:19:20,935 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:19:20,935 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:19:20,940 - 

2024-01-15 16:19:20,940 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:19:30,165 - Epoch: [85][   10/  211]    Overall Loss 0.035440    Objective Loss 0.035440                                        LR 0.100000    Time 0.922384    
2024-01-15 16:19:35,979 - Epoch: [85][   20/  211]    Overall Loss 0.039402    Objective Loss 0.039402                                        LR 0.100000    Time 0.751820    
2024-01-15 16:19:41,711 - Epoch: [85][   30/  211]    Overall Loss 0.034032    Objective Loss 0.034032                                        LR 0.100000    Time 0.692232    
2024-01-15 16:19:47,781 - Epoch: [85][   40/  211]    Overall Loss 0.034141    Objective Loss 0.034141                                        LR 0.100000    Time 0.670909    
2024-01-15 16:19:53,522 - Epoch: [85][   50/  211]    Overall Loss 0.035105    Objective Loss 0.035105                                        LR 0.100000    Time 0.651533    
2024-01-15 16:19:59,264 - Epoch: [85][   60/  211]    Overall Loss 0.035415    Objective Loss 0.035415                                        LR 0.100000    Time 0.638620    
2024-01-15 16:20:05,089 - Epoch: [85][   70/  211]    Overall Loss 0.035446    Objective Loss 0.035446                                        LR 0.100000    Time 0.630597    
2024-01-15 16:20:10,860 - Epoch: [85][   80/  211]    Overall Loss 0.035171    Objective Loss 0.035171                                        LR 0.100000    Time 0.623882    
2024-01-15 16:20:16,591 - Epoch: [85][   90/  211]    Overall Loss 0.034842    Objective Loss 0.034842                                        LR 0.100000    Time 0.618226    
2024-01-15 16:20:22,449 - Epoch: [85][  100/  211]    Overall Loss 0.035029    Objective Loss 0.035029                                        LR 0.100000    Time 0.614980    
2024-01-15 16:20:28,530 - Epoch: [85][  110/  211]    Overall Loss 0.035675    Objective Loss 0.035675                                        LR 0.100000    Time 0.614346    
2024-01-15 16:20:34,382 - Epoch: [85][  120/  211]    Overall Loss 0.036198    Objective Loss 0.036198                                        LR 0.100000    Time 0.611908    
2024-01-15 16:20:40,018 - Epoch: [85][  130/  211]    Overall Loss 0.036407    Objective Loss 0.036407                                        LR 0.100000    Time 0.608186    
2024-01-15 16:20:46,136 - Epoch: [85][  140/  211]    Overall Loss 0.036146    Objective Loss 0.036146                                        LR 0.100000    Time 0.608435    
2024-01-15 16:20:51,881 - Epoch: [85][  150/  211]    Overall Loss 0.036073    Objective Loss 0.036073                                        LR 0.100000    Time 0.606164    
2024-01-15 16:20:57,803 - Epoch: [85][  160/  211]    Overall Loss 0.036168    Objective Loss 0.036168                                        LR 0.100000    Time 0.605282    
2024-01-15 16:21:03,561 - Epoch: [85][  170/  211]    Overall Loss 0.036374    Objective Loss 0.036374                                        LR 0.100000    Time 0.603541    
2024-01-15 16:21:09,331 - Epoch: [85][  180/  211]    Overall Loss 0.036828    Objective Loss 0.036828                                        LR 0.100000    Time 0.602060    
2024-01-15 16:21:15,092 - Epoch: [85][  190/  211]    Overall Loss 0.037341    Objective Loss 0.037341                                        LR 0.100000    Time 0.600629    
2024-01-15 16:21:20,849 - Epoch: [85][  200/  211]    Overall Loss 0.037673    Objective Loss 0.037673                                        LR 0.100000    Time 0.599380    
2024-01-15 16:21:26,650 - Epoch: [85][  210/  211]    Overall Loss 0.037403    Objective Loss 0.037403    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.598454    
2024-01-15 16:21:27,200 - Epoch: [85][  211/  211]    Overall Loss 0.037409    Objective Loss 0.037409    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.598225    
2024-01-15 16:21:27,985 - --- validate (epoch=85)-----------
2024-01-15 16:21:27,985 - 6000 samples (256 per mini-batch)
2024-01-15 16:21:33,563 - Epoch: [85][   10/   24]    Loss 0.045275    Top1 98.515625    Top5 99.960938    
2024-01-15 16:21:35,670 - Epoch: [85][   20/   24]    Loss 0.045977    Top1 98.515625    Top5 99.980469    
2024-01-15 16:21:36,442 - Epoch: [85][   24/   24]    Loss 0.042641    Top1 98.650000    Top5 99.983333    
2024-01-15 16:21:37,001 - ==> Top1: 98.650    Top5: 99.983    Loss: 0.043

2024-01-15 16:21:37,002 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   1 576   5   0   0   0   2   1   1]
 [  0   0   2 578   0   1   0   1   1   0]
 [  0   2   2   0 547   0   0   1   1  12]
 [  1   0   0   2   0 513   2   0   0   0]
 [  2   2   0   0   1   0 624   0   2   0]
 [  0   3   2   1   0   1   0 618   0   0]
 [  0   0   1   3   1   1   2   0 575   1]
 [  1   2   0   2   1   1   0   6   3 599]]

2024-01-15 16:21:37,004 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:21:37,004 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:21:37,007 - 

2024-01-15 16:21:37,008 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:21:45,544 - Epoch: [86][   10/  211]    Overall Loss 0.047238    Objective Loss 0.047238                                        LR 0.100000    Time 0.853586    
2024-01-15 16:21:51,261 - Epoch: [86][   20/  211]    Overall Loss 0.041307    Objective Loss 0.041307                                        LR 0.100000    Time 0.712559    
2024-01-15 16:21:57,159 - Epoch: [86][   30/  211]    Overall Loss 0.038910    Objective Loss 0.038910                                        LR 0.100000    Time 0.671611    
2024-01-15 16:22:02,954 - Epoch: [86][   40/  211]    Overall Loss 0.036912    Objective Loss 0.036912                                        LR 0.100000    Time 0.648537    
2024-01-15 16:22:08,655 - Epoch: [86][   50/  211]    Overall Loss 0.037559    Objective Loss 0.037559                                        LR 0.100000    Time 0.632845    
2024-01-15 16:22:14,505 - Epoch: [86][   60/  211]    Overall Loss 0.038059    Objective Loss 0.038059                                        LR 0.100000    Time 0.624837    
2024-01-15 16:22:20,352 - Epoch: [86][   70/  211]    Overall Loss 0.038631    Objective Loss 0.038631                                        LR 0.100000    Time 0.619070    
2024-01-15 16:22:26,308 - Epoch: [86][   80/  211]    Overall Loss 0.038157    Objective Loss 0.038157                                        LR 0.100000    Time 0.616102    
2024-01-15 16:22:31,978 - Epoch: [86][   90/  211]    Overall Loss 0.038448    Objective Loss 0.038448                                        LR 0.100000    Time 0.610633    
2024-01-15 16:22:37,664 - Epoch: [86][  100/  211]    Overall Loss 0.039699    Objective Loss 0.039699                                        LR 0.100000    Time 0.606421    
2024-01-15 16:22:43,661 - Epoch: [86][  110/  211]    Overall Loss 0.039607    Objective Loss 0.039607                                        LR 0.100000    Time 0.605809    
2024-01-15 16:22:49,368 - Epoch: [86][  120/  211]    Overall Loss 0.038946    Objective Loss 0.038946                                        LR 0.100000    Time 0.602867    
2024-01-15 16:22:55,239 - Epoch: [86][  130/  211]    Overall Loss 0.038475    Objective Loss 0.038475                                        LR 0.100000    Time 0.601648    
2024-01-15 16:23:01,527 - Epoch: [86][  140/  211]    Overall Loss 0.038745    Objective Loss 0.038745                                        LR 0.100000    Time 0.603583    
2024-01-15 16:23:07,312 - Epoch: [86][  150/  211]    Overall Loss 0.039032    Objective Loss 0.039032                                        LR 0.100000    Time 0.601901    
2024-01-15 16:23:13,204 - Epoch: [86][  160/  211]    Overall Loss 0.038474    Objective Loss 0.038474                                        LR 0.100000    Time 0.601102    
2024-01-15 16:23:18,902 - Epoch: [86][  170/  211]    Overall Loss 0.038965    Objective Loss 0.038965                                        LR 0.100000    Time 0.599252    
2024-01-15 16:23:24,580 - Epoch: [86][  180/  211]    Overall Loss 0.039248    Objective Loss 0.039248                                        LR 0.100000    Time 0.597501    
2024-01-15 16:23:30,280 - Epoch: [86][  190/  211]    Overall Loss 0.038800    Objective Loss 0.038800                                        LR 0.100000    Time 0.596047    
2024-01-15 16:23:35,979 - Epoch: [86][  200/  211]    Overall Loss 0.038303    Objective Loss 0.038303                                        LR 0.100000    Time 0.594735    
2024-01-15 16:23:41,642 - Epoch: [86][  210/  211]    Overall Loss 0.038342    Objective Loss 0.038342    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.593379    
2024-01-15 16:23:42,347 - Epoch: [86][  211/  211]    Overall Loss 0.038548    Objective Loss 0.038548    Top1 97.983871    Top5 100.000000    LR 0.100000    Time 0.593905    
2024-01-15 16:23:43,167 - --- validate (epoch=86)-----------
2024-01-15 16:23:43,168 - 6000 samples (256 per mini-batch)
2024-01-15 16:23:49,923 - Epoch: [86][   10/   24]    Loss 0.049705    Top1 98.398438    Top5 99.960938    
2024-01-15 16:23:52,289 - Epoch: [86][   20/   24]    Loss 0.042772    Top1 98.652344    Top5 99.980469    
2024-01-15 16:23:53,088 - Epoch: [86][   24/   24]    Loss 0.043636    Top1 98.666667    Top5 99.983333    
2024-01-15 16:23:53,944 - ==> Top1: 98.667    Top5: 99.983    Loss: 0.044

2024-01-15 16:23:53,945 - ==> Confusion:
[[598   0   1   0   0   0   3   0   3   0]
 [  0 686   1   0   0   1   0   0   0   0]
 [  0   0 582   1   0   0   0   0   3   0]
 [  0   0   2 578   0   1   0   0   2   0]
 [  0   1   1   0 550   0   3   1   3   6]
 [  0   0   0   1   0 514   2   0   1   0]
 [  0   0   0   0   2   1 626   0   2   0]
 [  0   3   1   0   1   0   0 619   0   1]
 [  0   0   0   0   0   1   3   0 579   1]
 [  1   3   0   0   7   2   0   3  11 588]]

2024-01-15 16:23:53,948 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:23:53,948 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:23:53,953 - 

2024-01-15 16:23:53,953 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:24:04,093 - Epoch: [87][   10/  211]    Overall Loss 0.042441    Objective Loss 0.042441                                        LR 0.100000    Time 1.013872    
2024-01-15 16:24:09,885 - Epoch: [87][   20/  211]    Overall Loss 0.038955    Objective Loss 0.038955                                        LR 0.100000    Time 0.796472    
2024-01-15 16:24:15,718 - Epoch: [87][   30/  211]    Overall Loss 0.037411    Objective Loss 0.037411                                        LR 0.100000    Time 0.725375    
2024-01-15 16:24:21,390 - Epoch: [87][   40/  211]    Overall Loss 0.037406    Objective Loss 0.037406                                        LR 0.100000    Time 0.685793    
2024-01-15 16:24:27,491 - Epoch: [87][   50/  211]    Overall Loss 0.038075    Objective Loss 0.038075                                        LR 0.100000    Time 0.670628    
2024-01-15 16:24:33,186 - Epoch: [87][   60/  211]    Overall Loss 0.038415    Objective Loss 0.038415                                        LR 0.100000    Time 0.653758    
2024-01-15 16:24:38,878 - Epoch: [87][   70/  211]    Overall Loss 0.038594    Objective Loss 0.038594                                        LR 0.100000    Time 0.641667    
2024-01-15 16:24:44,940 - Epoch: [87][   80/  211]    Overall Loss 0.038858    Objective Loss 0.038858                                        LR 0.100000    Time 0.637222    
2024-01-15 16:24:50,684 - Epoch: [87][   90/  211]    Overall Loss 0.039921    Objective Loss 0.039921                                        LR 0.100000    Time 0.630226    
2024-01-15 16:24:56,414 - Epoch: [87][  100/  211]    Overall Loss 0.039924    Objective Loss 0.039924                                        LR 0.100000    Time 0.624496    
2024-01-15 16:25:02,078 - Epoch: [87][  110/  211]    Overall Loss 0.040156    Objective Loss 0.040156                                        LR 0.100000    Time 0.619196    
2024-01-15 16:25:07,708 - Epoch: [87][  120/  211]    Overall Loss 0.039523    Objective Loss 0.039523                                        LR 0.100000    Time 0.614511    
2024-01-15 16:25:13,518 - Epoch: [87][  130/  211]    Overall Loss 0.039614    Objective Loss 0.039614                                        LR 0.100000    Time 0.611925    
2024-01-15 16:25:19,288 - Epoch: [87][  140/  211]    Overall Loss 0.039334    Objective Loss 0.039334                                        LR 0.100000    Time 0.609424    
2024-01-15 16:25:24,986 - Epoch: [87][  150/  211]    Overall Loss 0.039654    Objective Loss 0.039654                                        LR 0.100000    Time 0.606774    
2024-01-15 16:25:30,658 - Epoch: [87][  160/  211]    Overall Loss 0.039949    Objective Loss 0.039949                                        LR 0.100000    Time 0.604300    
2024-01-15 16:25:36,352 - Epoch: [87][  170/  211]    Overall Loss 0.040097    Objective Loss 0.040097                                        LR 0.100000    Time 0.602240    
2024-01-15 16:25:42,038 - Epoch: [87][  180/  211]    Overall Loss 0.040286    Objective Loss 0.040286                                        LR 0.100000    Time 0.600370    
2024-01-15 16:25:48,186 - Epoch: [87][  190/  211]    Overall Loss 0.040318    Objective Loss 0.040318                                        LR 0.100000    Time 0.601117    
2024-01-15 16:25:53,922 - Epoch: [87][  200/  211]    Overall Loss 0.040054    Objective Loss 0.040054                                        LR 0.100000    Time 0.599739    
2024-01-15 16:25:59,662 - Epoch: [87][  210/  211]    Overall Loss 0.039904    Objective Loss 0.039904    Top1 100.000000    Top5 100.000000    LR 0.100000    Time 0.598512    
2024-01-15 16:26:00,220 - Epoch: [87][  211/  211]    Overall Loss 0.039937    Objective Loss 0.039937    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.598313    
2024-01-15 16:26:00,983 - --- validate (epoch=87)-----------
2024-01-15 16:26:00,984 - 6000 samples (256 per mini-batch)
2024-01-15 16:26:07,566 - Epoch: [87][   10/   24]    Loss 0.036465    Top1 98.984375    Top5 99.960938    
2024-01-15 16:26:09,698 - Epoch: [87][   20/   24]    Loss 0.036706    Top1 98.964844    Top5 99.980469    
2024-01-15 16:26:10,468 - Epoch: [87][   24/   24]    Loss 0.037704    Top1 98.916667    Top5 99.983333    
2024-01-15 16:26:11,010 - ==> Top1: 98.917    Top5: 99.983    Loss: 0.038

2024-01-15 16:26:11,011 - ==> Confusion:
[[599   0   1   2   0   0   1   0   2   0]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   1 572   7   0   0   0   3   3   0]
 [  0   0   1 580   0   1   0   0   1   0]
 [  0   1   0   0 557   0   0   3   1   3]
 [  1   0   0   3   0 509   3   0   2   0]
 [  1   1   0   0   1   0 625   0   3   0]
 [  0   0   0   2   0   0   0 623   0   0]
 [  0   0   0   0   1   2   0   0 581   0]
 [  2   1   0   0   4   0   0   2   4 602]]

2024-01-15 16:26:11,013 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:26:11,013 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:26:11,017 - 

2024-01-15 16:26:11,017 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:26:19,366 - Epoch: [88][   10/  211]    Overall Loss 0.031329    Objective Loss 0.031329                                        LR 0.100000    Time 0.834809    
2024-01-15 16:26:25,034 - Epoch: [88][   20/  211]    Overall Loss 0.035724    Objective Loss 0.035724                                        LR 0.100000    Time 0.700761    
2024-01-15 16:26:30,723 - Epoch: [88][   30/  211]    Overall Loss 0.037022    Objective Loss 0.037022                                        LR 0.100000    Time 0.656784    
2024-01-15 16:26:36,372 - Epoch: [88][   40/  211]    Overall Loss 0.036568    Objective Loss 0.036568                                        LR 0.100000    Time 0.633813    
2024-01-15 16:26:42,034 - Epoch: [88][   50/  211]    Overall Loss 0.036320    Objective Loss 0.036320                                        LR 0.100000    Time 0.620258    
2024-01-15 16:26:47,788 - Epoch: [88][   60/  211]    Overall Loss 0.036987    Objective Loss 0.036987                                        LR 0.100000    Time 0.612763    
2024-01-15 16:26:53,439 - Epoch: [88][   70/  211]    Overall Loss 0.037239    Objective Loss 0.037239                                        LR 0.100000    Time 0.605944    
2024-01-15 16:26:59,095 - Epoch: [88][   80/  211]    Overall Loss 0.036348    Objective Loss 0.036348                                        LR 0.100000    Time 0.600892    
2024-01-15 16:27:04,760 - Epoch: [88][   90/  211]    Overall Loss 0.035593    Objective Loss 0.035593                                        LR 0.100000    Time 0.597063    
2024-01-15 16:27:10,407 - Epoch: [88][  100/  211]    Overall Loss 0.036876    Objective Loss 0.036876                                        LR 0.100000    Time 0.593823    
2024-01-15 16:27:16,069 - Epoch: [88][  110/  211]    Overall Loss 0.037403    Objective Loss 0.037403                                        LR 0.100000    Time 0.591307    
2024-01-15 16:27:21,720 - Epoch: [88][  120/  211]    Overall Loss 0.037577    Objective Loss 0.037577                                        LR 0.100000    Time 0.589119    
2024-01-15 16:27:27,522 - Epoch: [88][  130/  211]    Overall Loss 0.037055    Objective Loss 0.037055                                        LR 0.100000    Time 0.588421    
2024-01-15 16:27:33,365 - Epoch: [88][  140/  211]    Overall Loss 0.037182    Objective Loss 0.037182                                        LR 0.100000    Time 0.588121    
2024-01-15 16:27:39,160 - Epoch: [88][  150/  211]    Overall Loss 0.037719    Objective Loss 0.037719                                        LR 0.100000    Time 0.587539    
2024-01-15 16:27:45,113 - Epoch: [88][  160/  211]    Overall Loss 0.038445    Objective Loss 0.038445                                        LR 0.100000    Time 0.588015    
2024-01-15 16:27:50,853 - Epoch: [88][  170/  211]    Overall Loss 0.038238    Objective Loss 0.038238                                        LR 0.100000    Time 0.587183    
2024-01-15 16:27:56,571 - Epoch: [88][  180/  211]    Overall Loss 0.038056    Objective Loss 0.038056                                        LR 0.100000    Time 0.586326    
2024-01-15 16:28:02,337 - Epoch: [88][  190/  211]    Overall Loss 0.037702    Objective Loss 0.037702                                        LR 0.100000    Time 0.585808    
2024-01-15 16:28:08,037 - Epoch: [88][  200/  211]    Overall Loss 0.037780    Objective Loss 0.037780                                        LR 0.100000    Time 0.585013    
2024-01-15 16:28:13,899 - Epoch: [88][  210/  211]    Overall Loss 0.038029    Objective Loss 0.038029    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.585064    
2024-01-15 16:28:14,466 - Epoch: [88][  211/  211]    Overall Loss 0.037991    Objective Loss 0.037991    Top1 99.395161    Top5 100.000000    LR 0.100000    Time 0.584976    
2024-01-15 16:28:15,066 - --- validate (epoch=88)-----------
2024-01-15 16:28:15,066 - 6000 samples (256 per mini-batch)
2024-01-15 16:28:20,418 - Epoch: [88][   10/   24]    Loss 0.048355    Top1 98.632812    Top5 99.960938    
2024-01-15 16:28:22,547 - Epoch: [88][   20/   24]    Loss 0.040354    Top1 98.925781    Top5 99.980469    
2024-01-15 16:28:23,353 - Epoch: [88][   24/   24]    Loss 0.043937    Top1 98.800000    Top5 99.966667    
2024-01-15 16:28:23,978 - ==> Top1: 98.800    Top5: 99.967    Loss: 0.044

2024-01-15 16:28:23,979 - ==> Confusion:
[[601   0   1   0   0   0   2   1   0   0]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   1 581   0   0   0   0   3   0   1]
 [  0   0   1 578   0   1   0   3   0   0]
 [  0   2   2   0 555   0   1   1   0   4]
 [  0   1   0   4   0 509   3   0   0   1]
 [  0   2   0   0   1   1 627   0   0   0]
 [  0   5   0   0   0   0   0 620   0   0]
 [  1   1   1   5   1   3   3   1 565   3]
 [  0   1   0   1   2   0   0   6   1 604]]

2024-01-15 16:28:23,981 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:28:23,982 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:28:23,985 - 

2024-01-15 16:28:23,986 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:28:32,308 - Epoch: [89][   10/  211]    Overall Loss 0.040687    Objective Loss 0.040687                                        LR 0.100000    Time 0.832185    
2024-01-15 16:28:38,017 - Epoch: [89][   20/  211]    Overall Loss 0.039028    Objective Loss 0.039028                                        LR 0.100000    Time 0.701323    
2024-01-15 16:28:43,915 - Epoch: [89][   30/  211]    Overall Loss 0.037565    Objective Loss 0.037565                                        LR 0.100000    Time 0.664062    
2024-01-15 16:28:49,698 - Epoch: [89][   40/  211]    Overall Loss 0.037986    Objective Loss 0.037986                                        LR 0.100000    Time 0.642608    
2024-01-15 16:28:55,342 - Epoch: [89][   50/  211]    Overall Loss 0.038531    Objective Loss 0.038531                                        LR 0.100000    Time 0.626957    
2024-01-15 16:29:01,077 - Epoch: [89][   60/  211]    Overall Loss 0.042032    Objective Loss 0.042032                                        LR 0.100000    Time 0.618013    
2024-01-15 16:29:06,773 - Epoch: [89][   70/  211]    Overall Loss 0.043829    Objective Loss 0.043829                                        LR 0.100000    Time 0.611082    
2024-01-15 16:29:12,453 - Epoch: [89][   80/  211]    Overall Loss 0.045038    Objective Loss 0.045038                                        LR 0.100000    Time 0.605679    
2024-01-15 16:29:18,207 - Epoch: [89][   90/  211]    Overall Loss 0.044556    Objective Loss 0.044556                                        LR 0.100000    Time 0.602311    
2024-01-15 16:29:23,884 - Epoch: [89][  100/  211]    Overall Loss 0.043715    Objective Loss 0.043715                                        LR 0.100000    Time 0.598840    
2024-01-15 16:29:29,547 - Epoch: [89][  110/  211]    Overall Loss 0.042517    Objective Loss 0.042517                                        LR 0.100000    Time 0.595870    
2024-01-15 16:29:35,223 - Epoch: [89][  120/  211]    Overall Loss 0.041687    Objective Loss 0.041687                                        LR 0.100000    Time 0.593507    
2024-01-15 16:29:40,907 - Epoch: [89][  130/  211]    Overall Loss 0.041301    Objective Loss 0.041301                                        LR 0.100000    Time 0.591573    
2024-01-15 16:29:46,792 - Epoch: [89][  140/  211]    Overall Loss 0.041061    Objective Loss 0.041061                                        LR 0.100000    Time 0.591341    
2024-01-15 16:29:52,463 - Epoch: [89][  150/  211]    Overall Loss 0.040554    Objective Loss 0.040554                                        LR 0.100000    Time 0.589717    
2024-01-15 16:29:58,134 - Epoch: [89][  160/  211]    Overall Loss 0.040602    Objective Loss 0.040602                                        LR 0.100000    Time 0.588297    
2024-01-15 16:30:03,800 - Epoch: [89][  170/  211]    Overall Loss 0.040237    Objective Loss 0.040237                                        LR 0.100000    Time 0.587013    
2024-01-15 16:30:09,496 - Epoch: [89][  180/  211]    Overall Loss 0.040451    Objective Loss 0.040451                                        LR 0.100000    Time 0.586040    
2024-01-15 16:30:15,238 - Epoch: [89][  190/  211]    Overall Loss 0.040214    Objective Loss 0.040214                                        LR 0.100000    Time 0.585409    
2024-01-15 16:30:20,941 - Epoch: [89][  200/  211]    Overall Loss 0.040302    Objective Loss 0.040302                                        LR 0.100000    Time 0.584648    
2024-01-15 16:30:27,858 - Epoch: [89][  210/  211]    Overall Loss 0.040112    Objective Loss 0.040112    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.589737    
2024-01-15 16:30:28,426 - Epoch: [89][  211/  211]    Overall Loss 0.040081    Objective Loss 0.040081    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.589632    
2024-01-15 16:30:29,313 - --- validate (epoch=89)-----------
2024-01-15 16:30:29,315 - 6000 samples (256 per mini-batch)
2024-01-15 16:30:35,904 - Epoch: [89][   10/   24]    Loss 0.036163    Top1 98.867188    Top5 100.000000    
2024-01-15 16:30:38,183 - Epoch: [89][   20/   24]    Loss 0.036493    Top1 98.867188    Top5 100.000000    
2024-01-15 16:30:38,976 - Epoch: [89][   24/   24]    Loss 0.037782    Top1 98.833333    Top5 100.000000    
2024-01-15 16:30:39,747 - ==> Top1: 98.833    Top5: 100.000    Loss: 0.038

2024-01-15 16:30:39,748 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 684   0   0   0   1   0   3   0   0]
 [  0   0 575   1   0   0   1   7   2   0]
 [  0   0   3 575   0   2   0   2   1   0]
 [  0   0   0   0 558   0   0   2   0   5]
 [  1   0   0   1   0 511   2   0   2   1]
 [  1   1   0   0   2   1 624   0   2   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  0   0   0   1   0   2   1   2 578   0]
 [  0   1   0   0   6   2   0   4   3 599]]

2024-01-15 16:30:39,751 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:30:39,751 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:30:39,756 - 

2024-01-15 16:30:39,756 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:30:49,038 - Epoch: [90][   10/  211]    Overall Loss 0.037439    Objective Loss 0.037439                                        LR 0.100000    Time 0.928104    
2024-01-15 16:30:55,209 - Epoch: [90][   20/  211]    Overall Loss 0.034419    Objective Loss 0.034419                                        LR 0.100000    Time 0.772430    
2024-01-15 16:31:01,180 - Epoch: [90][   30/  211]    Overall Loss 0.034008    Objective Loss 0.034008                                        LR 0.100000    Time 0.713934    
2024-01-15 16:31:06,909 - Epoch: [90][   40/  211]    Overall Loss 0.034402    Objective Loss 0.034402                                        LR 0.100000    Time 0.678648    
2024-01-15 16:31:12,747 - Epoch: [90][   50/  211]    Overall Loss 0.036252    Objective Loss 0.036252                                        LR 0.100000    Time 0.659645    
2024-01-15 16:31:18,627 - Epoch: [90][   60/  211]    Overall Loss 0.038040    Objective Loss 0.038040                                        LR 0.100000    Time 0.647677    
2024-01-15 16:31:24,429 - Epoch: [90][   70/  211]    Overall Loss 0.038323    Objective Loss 0.038323                                        LR 0.100000    Time 0.638021    
2024-01-15 16:31:30,298 - Epoch: [90][   80/  211]    Overall Loss 0.038520    Objective Loss 0.038520                                        LR 0.100000    Time 0.631611    
2024-01-15 16:31:36,343 - Epoch: [90][   90/  211]    Overall Loss 0.039096    Objective Loss 0.039096                                        LR 0.100000    Time 0.628586    
2024-01-15 16:31:42,424 - Epoch: [90][  100/  211]    Overall Loss 0.038449    Objective Loss 0.038449                                        LR 0.100000    Time 0.626528    
2024-01-15 16:31:48,162 - Epoch: [90][  110/  211]    Overall Loss 0.038670    Objective Loss 0.038670                                        LR 0.100000    Time 0.621719    
2024-01-15 16:31:54,209 - Epoch: [90][  120/  211]    Overall Loss 0.039018    Objective Loss 0.039018                                        LR 0.100000    Time 0.620295    
2024-01-15 16:32:01,194 - Epoch: [90][  130/  211]    Overall Loss 0.040044    Objective Loss 0.040044                                        LR 0.100000    Time 0.626301    
2024-01-15 16:32:07,783 - Epoch: [90][  140/  211]    Overall Loss 0.039304    Objective Loss 0.039304                                        LR 0.100000    Time 0.628615    
2024-01-15 16:32:13,579 - Epoch: [90][  150/  211]    Overall Loss 0.039127    Objective Loss 0.039127                                        LR 0.100000    Time 0.625343    
2024-01-15 16:32:19,463 - Epoch: [90][  160/  211]    Overall Loss 0.038978    Objective Loss 0.038978                                        LR 0.100000    Time 0.623028    
2024-01-15 16:32:25,173 - Epoch: [90][  170/  211]    Overall Loss 0.038613    Objective Loss 0.038613                                        LR 0.100000    Time 0.619959    
2024-01-15 16:32:30,955 - Epoch: [90][  180/  211]    Overall Loss 0.038509    Objective Loss 0.038509                                        LR 0.100000    Time 0.617635    
2024-01-15 16:32:36,735 - Epoch: [90][  190/  211]    Overall Loss 0.038301    Objective Loss 0.038301                                        LR 0.100000    Time 0.615510    
2024-01-15 16:32:43,091 - Epoch: [90][  200/  211]    Overall Loss 0.038450    Objective Loss 0.038450                                        LR 0.100000    Time 0.616507    
2024-01-15 16:32:49,078 - Epoch: [90][  210/  211]    Overall Loss 0.038344    Objective Loss 0.038344    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.615650    
2024-01-15 16:32:49,683 - Epoch: [90][  211/  211]    Overall Loss 0.038254    Objective Loss 0.038254    Top1 99.798387    Top5 100.000000    LR 0.100000    Time 0.615597    
2024-01-15 16:32:50,639 - --- validate (epoch=90)-----------
2024-01-15 16:32:50,640 - 6000 samples (256 per mini-batch)
2024-01-15 16:32:57,834 - Epoch: [90][   10/   24]    Loss 0.042512    Top1 98.632812    Top5 99.960938    
2024-01-15 16:32:59,994 - Epoch: [90][   20/   24]    Loss 0.044183    Top1 98.593750    Top5 99.980469    
2024-01-15 16:33:00,837 - Epoch: [90][   24/   24]    Loss 0.043225    Top1 98.633333    Top5 99.983333    
2024-01-15 16:33:01,633 - ==> Top1: 98.633    Top5: 99.983    Loss: 0.043

2024-01-15 16:33:01,634 - ==> Confusion:
[[600   0   1   0   0   0   1   0   1   2]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   0 573   1   0   0   0  10   2   0]
 [  0   1   0 578   0   2   0   1   1   0]
 [  0   1   0   0 549   0   0   4   0  11]
 [  1   0   0   2   0 512   0   0   2   1]
 [  3   3   0   0   2   4 609   0  10   0]
 [  0   1   0   1   0   0   0 623   0   0]
 [  0   0   0   0   0   1   0   0 583   0]
 [  2   1   0   0   1   0   0   3   3 605]]

2024-01-15 16:33:01,636 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:33:01,637 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:33:01,642 - 

2024-01-15 16:33:01,642 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:33:10,589 - Epoch: [91][   10/  211]    Overall Loss 0.041654    Objective Loss 0.041654                                        LR 0.100000    Time 0.894571    
2024-01-15 16:33:16,333 - Epoch: [91][   20/  211]    Overall Loss 0.036862    Objective Loss 0.036862                                        LR 0.100000    Time 0.734365    
2024-01-15 16:33:22,244 - Epoch: [91][   30/  211]    Overall Loss 0.035828    Objective Loss 0.035828                                        LR 0.100000    Time 0.686569    
2024-01-15 16:33:27,915 - Epoch: [91][   40/  211]    Overall Loss 0.034953    Objective Loss 0.034953                                        LR 0.100000    Time 0.656684    
2024-01-15 16:33:33,637 - Epoch: [91][   50/  211]    Overall Loss 0.035571    Objective Loss 0.035571                                        LR 0.100000    Time 0.639795    
2024-01-15 16:33:39,307 - Epoch: [91][   60/  211]    Overall Loss 0.036506    Objective Loss 0.036506                                        LR 0.100000    Time 0.627652    
2024-01-15 16:33:45,284 - Epoch: [91][   70/  211]    Overall Loss 0.036789    Objective Loss 0.036789                                        LR 0.100000    Time 0.623353    
2024-01-15 16:33:50,991 - Epoch: [91][   80/  211]    Overall Loss 0.037632    Objective Loss 0.037632                                        LR 0.100000    Time 0.616756    
2024-01-15 16:33:56,627 - Epoch: [91][   90/  211]    Overall Loss 0.037659    Objective Loss 0.037659                                        LR 0.100000    Time 0.610842    
2024-01-15 16:34:02,283 - Epoch: [91][  100/  211]    Overall Loss 0.038152    Objective Loss 0.038152                                        LR 0.100000    Time 0.606308    
2024-01-15 16:34:07,929 - Epoch: [91][  110/  211]    Overall Loss 0.037419    Objective Loss 0.037419                                        LR 0.100000    Time 0.602504    
2024-01-15 16:34:14,869 - Epoch: [91][  120/  211]    Overall Loss 0.037082    Objective Loss 0.037082                                        LR 0.100000    Time 0.610103    
2024-01-15 16:38:21,298 - Epoch: [91][  130/  211]    Overall Loss 0.036887    Objective Loss 0.036887                                        LR 0.100000    Time 2.458761    
2024-01-15 16:38:27,108 - Epoch: [91][  140/  211]    Overall Loss 0.036073    Objective Loss 0.036073                                        LR 0.100000    Time 2.324628    
2024-01-15 16:38:32,708 - Epoch: [91][  150/  211]    Overall Loss 0.036104    Objective Loss 0.036104                                        LR 0.100000    Time 2.206982    
2024-01-15 16:38:38,493 - Epoch: [91][  160/  211]    Overall Loss 0.035682    Objective Loss 0.035682                                        LR 0.100000    Time 2.105193    
2024-01-15 16:38:46,473 - Epoch: [91][  170/  211]    Overall Loss 0.035600    Objective Loss 0.035600                                        LR 0.100000    Time 2.028290    
2024-01-15 16:38:53,821 - Epoch: [91][  180/  211]    Overall Loss 0.035500    Objective Loss 0.035500                                        LR 0.100000    Time 1.956414    
2024-01-15 16:39:00,382 - Epoch: [91][  190/  211]    Overall Loss 0.035615    Objective Loss 0.035615                                        LR 0.100000    Time 1.887968    
2024-01-15 16:39:07,015 - Epoch: [91][  200/  211]    Overall Loss 0.035849    Objective Loss 0.035849                                        LR 0.100000    Time 1.826727    
2024-01-15 16:39:13,084 - Epoch: [91][  210/  211]    Overall Loss 0.035891    Objective Loss 0.035891    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 1.768635    
2024-01-15 16:39:14,126 - Epoch: [91][  211/  211]    Overall Loss 0.035889    Objective Loss 0.035889    Top1 98.991935    Top5 100.000000    LR 0.100000    Time 1.765186    
2024-01-15 16:39:16,057 - --- validate (epoch=91)-----------
2024-01-15 16:39:16,060 - 6000 samples (256 per mini-batch)
2024-01-15 16:39:24,053 - Epoch: [91][   10/   24]    Loss 0.039202    Top1 98.867188    Top5 99.960938    
2024-01-15 16:39:26,409 - Epoch: [91][   20/   24]    Loss 0.045785    Top1 98.691406    Top5 99.960938    
2024-01-15 16:39:27,193 - Epoch: [91][   24/   24]    Loss 0.043579    Top1 98.750000    Top5 99.966667    
2024-01-15 16:39:27,941 - ==> Top1: 98.750    Top5: 99.967    Loss: 0.044

2024-01-15 16:39:27,944 - ==> Confusion:
[[597   0   2   1   0   0   3   0   1   1]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 571   1   0   0   1   9   3   1]
 [  0   0   0 577   0   3   0   1   1   1]
 [  0   1   0   0 547   0   0   1   2  14]
 [  0   0   0   0   0 511   4   0   2   1]
 [  0   1   0   0   1   0 628   0   1   0]
 [  0   3   1   1   0   0   0 620   0   0]
 [  0   0   0   1   1   0   2   0 579   1]
 [  0   0   0   0   2   0   0   2   3 608]]

2024-01-15 16:39:27,947 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:39:27,948 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:39:27,956 - 

2024-01-15 16:39:27,957 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:39:38,852 - Epoch: [92][   10/  211]    Overall Loss 0.030589    Objective Loss 0.030589                                        LR 0.100000    Time 1.089375    
2024-01-15 16:39:46,579 - Epoch: [92][   20/  211]    Overall Loss 0.029709    Objective Loss 0.029709                                        LR 0.100000    Time 0.930862    
2024-01-15 16:39:53,117 - Epoch: [92][   30/  211]    Overall Loss 0.030541    Objective Loss 0.030541                                        LR 0.100000    Time 0.838435    
2024-01-15 16:39:59,909 - Epoch: [92][   40/  211]    Overall Loss 0.033905    Objective Loss 0.033905                                        LR 0.100000    Time 0.798584    
2024-01-15 16:40:06,184 - Epoch: [92][   50/  211]    Overall Loss 0.036579    Objective Loss 0.036579                                        LR 0.100000    Time 0.764349    
2024-01-15 16:40:12,968 - Epoch: [92][   60/  211]    Overall Loss 0.037464    Objective Loss 0.037464                                        LR 0.100000    Time 0.749979    
2024-01-15 16:40:19,056 - Epoch: [92][   70/  211]    Overall Loss 0.037929    Objective Loss 0.037929                                        LR 0.100000    Time 0.729786    
2024-01-15 16:40:24,991 - Epoch: [92][   80/  211]    Overall Loss 0.037785    Objective Loss 0.037785                                        LR 0.100000    Time 0.712700    
2024-01-15 16:40:31,478 - Epoch: [92][   90/  211]    Overall Loss 0.038698    Objective Loss 0.038698                                        LR 0.100000    Time 0.705509    
2024-01-15 16:40:37,939 - Epoch: [92][  100/  211]    Overall Loss 0.038556    Objective Loss 0.038556                                        LR 0.100000    Time 0.699557    
2024-01-15 16:40:43,838 - Epoch: [92][  110/  211]    Overall Loss 0.038448    Objective Loss 0.038448                                        LR 0.100000    Time 0.689576    
2024-01-15 16:40:49,636 - Epoch: [92][  120/  211]    Overall Loss 0.038344    Objective Loss 0.038344                                        LR 0.100000    Time 0.680414    
2024-01-15 16:40:56,178 - Epoch: [92][  130/  211]    Overall Loss 0.038940    Objective Loss 0.038940                                        LR 0.100000    Time 0.678387    
2024-01-15 16:41:02,303 - Epoch: [92][  140/  211]    Overall Loss 0.038573    Objective Loss 0.038573                                        LR 0.100000    Time 0.673669    
2024-01-15 16:41:08,723 - Epoch: [92][  150/  211]    Overall Loss 0.038292    Objective Loss 0.038292                                        LR 0.100000    Time 0.671542    
2024-01-15 16:41:14,843 - Epoch: [92][  160/  211]    Overall Loss 0.038254    Objective Loss 0.038254                                        LR 0.100000    Time 0.667812    
2024-01-15 16:41:21,293 - Epoch: [92][  170/  211]    Overall Loss 0.038751    Objective Loss 0.038751                                        LR 0.100000    Time 0.666462    
2024-01-15 16:41:27,734 - Epoch: [92][  180/  211]    Overall Loss 0.038779    Objective Loss 0.038779                                        LR 0.100000    Time 0.665217    
2024-01-15 16:41:33,960 - Epoch: [92][  190/  211]    Overall Loss 0.038814    Objective Loss 0.038814                                        LR 0.100000    Time 0.662965    
2024-01-15 16:41:40,337 - Epoch: [92][  200/  211]    Overall Loss 0.038748    Objective Loss 0.038748                                        LR 0.100000    Time 0.661694    
2024-01-15 16:41:47,552 - Epoch: [92][  210/  211]    Overall Loss 0.038711    Objective Loss 0.038711    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.664534    
2024-01-15 16:41:48,262 - Epoch: [92][  211/  211]    Overall Loss 0.038707    Objective Loss 0.038707    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.664746    
2024-01-15 16:41:49,432 - --- validate (epoch=92)-----------
2024-01-15 16:41:49,434 - 6000 samples (256 per mini-batch)
2024-01-15 16:41:56,809 - Epoch: [92][   10/   24]    Loss 0.042485    Top1 98.671875    Top5 100.000000    
2024-01-15 16:41:59,130 - Epoch: [92][   20/   24]    Loss 0.040985    Top1 98.769531    Top5 100.000000    
2024-01-15 16:42:00,047 - Epoch: [92][   24/   24]    Loss 0.043878    Top1 98.750000    Top5 100.000000    
2024-01-15 16:42:00,978 - ==> Top1: 98.750    Top5: 100.000    Loss: 0.044

2024-01-15 16:42:00,980 - ==> Confusion:
[[596   0   4   0   0   0   4   1   0   0]
 [  0 685   1   0   0   0   2   0   0   0]
 [  0   0 584   1   0   0   0   0   1   0]
 [  0   0   6 570   0   5   0   0   1   1]
 [  0   0   1   0 557   0   1   0   0   6]
 [  0   0   0   1   0 512   5   0   0   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   2   5   0   1   0   0 617   0   0]
 [  0   0   1   2   0   2   8   0 570   1]
 [  1   1   0   0   4   0   0   3   2 604]]

2024-01-15 16:42:00,982 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:42:00,983 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:42:00,989 - 

2024-01-15 16:42:00,989 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:42:12,490 - Epoch: [93][   10/  211]    Overall Loss 0.040241    Objective Loss 0.040241                                        LR 0.100000    Time 1.150046    
2024-01-15 16:42:18,847 - Epoch: [93][   20/  211]    Overall Loss 0.037007    Objective Loss 0.037007                                        LR 0.100000    Time 0.892759    
2024-01-15 16:42:24,911 - Epoch: [93][   30/  211]    Overall Loss 0.033782    Objective Loss 0.033782                                        LR 0.100000    Time 0.797270    
2024-01-15 16:42:31,659 - Epoch: [93][   40/  211]    Overall Loss 0.034446    Objective Loss 0.034446                                        LR 0.100000    Time 0.766637    
2024-01-15 16:42:38,146 - Epoch: [93][   50/  211]    Overall Loss 0.033329    Objective Loss 0.033329                                        LR 0.100000    Time 0.743021    
2024-01-15 16:42:45,266 - Epoch: [93][   60/  211]    Overall Loss 0.035694    Objective Loss 0.035694                                        LR 0.100000    Time 0.737808    
2024-01-15 16:42:51,396 - Epoch: [93][   70/  211]    Overall Loss 0.036317    Objective Loss 0.036317                                        LR 0.100000    Time 0.719964    
2024-01-15 16:42:57,064 - Epoch: [93][   80/  211]    Overall Loss 0.036929    Objective Loss 0.036929                                        LR 0.100000    Time 0.700801    
2024-01-15 16:43:02,764 - Epoch: [93][   90/  211]    Overall Loss 0.038029    Objective Loss 0.038029                                        LR 0.100000    Time 0.686261    
2024-01-15 16:43:08,397 - Epoch: [93][  100/  211]    Overall Loss 0.038798    Objective Loss 0.038798                                        LR 0.100000    Time 0.673956    
2024-01-15 16:43:14,642 - Epoch: [93][  110/  211]    Overall Loss 0.038987    Objective Loss 0.038987                                        LR 0.100000    Time 0.669458    
2024-01-15 16:43:21,524 - Epoch: [93][  120/  211]    Overall Loss 0.039081    Objective Loss 0.039081                                        LR 0.100000    Time 0.671010    
2024-01-15 16:43:28,077 - Epoch: [93][  130/  211]    Overall Loss 0.039833    Objective Loss 0.039833                                        LR 0.100000    Time 0.669785    
2024-01-15 16:43:34,148 - Epoch: [93][  140/  211]    Overall Loss 0.038898    Objective Loss 0.038898                                        LR 0.100000    Time 0.665303    
2024-01-15 16:43:40,049 - Epoch: [93][  150/  211]    Overall Loss 0.038471    Objective Loss 0.038471                                        LR 0.100000    Time 0.660279    
2024-01-15 16:43:46,489 - Epoch: [93][  160/  211]    Overall Loss 0.038267    Objective Loss 0.038267                                        LR 0.100000    Time 0.659246    
2024-01-15 16:43:53,174 - Epoch: [93][  170/  211]    Overall Loss 0.038125    Objective Loss 0.038125                                        LR 0.100000    Time 0.659779    
2024-01-15 16:43:59,346 - Epoch: [93][  180/  211]    Overall Loss 0.037550    Objective Loss 0.037550                                        LR 0.100000    Time 0.657405    
2024-01-15 16:44:05,449 - Epoch: [93][  190/  211]    Overall Loss 0.037100    Objective Loss 0.037100                                        LR 0.100000    Time 0.654921    
2024-01-15 16:44:11,446 - Epoch: [93][  200/  211]    Overall Loss 0.037027    Objective Loss 0.037027                                        LR 0.100000    Time 0.652152    
2024-01-15 16:44:17,119 - Epoch: [93][  210/  211]    Overall Loss 0.036767    Objective Loss 0.036767    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.648109    
2024-01-15 16:44:17,726 - Epoch: [93][  211/  211]    Overall Loss 0.036712    Objective Loss 0.036712    Top1 99.193548    Top5 100.000000    LR 0.100000    Time 0.647910    
2024-01-15 16:44:18,659 - --- validate (epoch=93)-----------
2024-01-15 16:44:18,660 - 6000 samples (256 per mini-batch)
2024-01-15 16:44:26,028 - Epoch: [93][   10/   24]    Loss 0.035401    Top1 98.945312    Top5 100.000000    
2024-01-15 16:44:28,228 - Epoch: [93][   20/   24]    Loss 0.034170    Top1 98.906250    Top5 100.000000    
2024-01-15 16:44:29,014 - Epoch: [93][   24/   24]    Loss 0.033367    Top1 98.916667    Top5 100.000000    
2024-01-15 16:44:29,763 - ==> Top1: 98.917    Top5: 100.000    Loss: 0.033

2024-01-15 16:44:29,764 - ==> Confusion:
[[602   0   0   0   0   0   3   0   0   0]
 [  0 682   1   0   0   1   0   4   0   0]
 [  0   0 579   2   0   0   1   2   2   0]
 [  0   0   1 579   0   1   0   1   1   0]
 [  0   1   0   0 558   0   1   1   0   4]
 [  0   0   0   1   0 513   2   0   2   0]
 [  0   1   0   0   1   0 628   0   1   0]
 [  0   1   1   2   0   1   0 620   0   0]
 [  0   0   1   1   2   1   3   1 575   0]
 [  0   1   0   1   3   1   0   4   6 599]]

2024-01-15 16:44:29,766 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:44:29,766 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:44:29,772 - 

2024-01-15 16:44:29,773 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:44:41,249 - Epoch: [94][   10/  211]    Overall Loss 0.035062    Objective Loss 0.035062                                        LR 0.100000    Time 1.147556    
2024-01-15 16:44:47,381 - Epoch: [94][   20/  211]    Overall Loss 0.035861    Objective Loss 0.035861                                        LR 0.100000    Time 0.880290    
2024-01-15 16:44:53,386 - Epoch: [94][   30/  211]    Overall Loss 0.042102    Objective Loss 0.042102                                        LR 0.100000    Time 0.786984    
2024-01-15 16:44:59,899 - Epoch: [94][   40/  211]    Overall Loss 0.042242    Objective Loss 0.042242                                        LR 0.100000    Time 0.753009    
2024-01-15 16:45:05,781 - Epoch: [94][   50/  211]    Overall Loss 0.041267    Objective Loss 0.041267                                        LR 0.100000    Time 0.720008    
2024-01-15 16:45:12,326 - Epoch: [94][   60/  211]    Overall Loss 0.041317    Objective Loss 0.041317                                        LR 0.100000    Time 0.709071    
2024-01-15 16:45:18,322 - Epoch: [94][   70/  211]    Overall Loss 0.040455    Objective Loss 0.040455                                        LR 0.100000    Time 0.693359    
2024-01-15 16:45:24,622 - Epoch: [94][   80/  211]    Overall Loss 0.040620    Objective Loss 0.040620                                        LR 0.100000    Time 0.685399    
2024-01-15 16:45:31,529 - Epoch: [94][   90/  211]    Overall Loss 0.040082    Objective Loss 0.040082                                        LR 0.100000    Time 0.685977    
2024-01-15 16:45:37,799 - Epoch: [94][  100/  211]    Overall Loss 0.039661    Objective Loss 0.039661                                        LR 0.100000    Time 0.680048    
2024-01-15 16:45:44,677 - Epoch: [94][  110/  211]    Overall Loss 0.039231    Objective Loss 0.039231                                        LR 0.100000    Time 0.680731    
2024-01-15 16:45:51,114 - Epoch: [94][  120/  211]    Overall Loss 0.038394    Objective Loss 0.038394                                        LR 0.100000    Time 0.677639    
2024-01-15 16:45:57,849 - Epoch: [94][  130/  211]    Overall Loss 0.039189    Objective Loss 0.039189                                        LR 0.100000    Time 0.677313    
2024-01-15 16:46:04,043 - Epoch: [94][  140/  211]    Overall Loss 0.038686    Objective Loss 0.038686                                        LR 0.100000    Time 0.673167    
2024-01-15 16:46:10,129 - Epoch: [94][  150/  211]    Overall Loss 0.038827    Objective Loss 0.038827                                        LR 0.100000    Time 0.668852    
2024-01-15 16:46:16,317 - Epoch: [94][  160/  211]    Overall Loss 0.039311    Objective Loss 0.039311                                        LR 0.100000    Time 0.665703    
2024-01-15 16:46:22,418 - Epoch: [94][  170/  211]    Overall Loss 0.039224    Objective Loss 0.039224                                        LR 0.100000    Time 0.662420    
2024-01-15 16:46:28,541 - Epoch: [94][  180/  211]    Overall Loss 0.039128    Objective Loss 0.039128                                        LR 0.100000    Time 0.659627    
2024-01-15 16:46:34,738 - Epoch: [94][  190/  211]    Overall Loss 0.038823    Objective Loss 0.038823                                        LR 0.100000    Time 0.657521    
2024-01-15 16:46:41,527 - Epoch: [94][  200/  211]    Overall Loss 0.038537    Objective Loss 0.038537                                        LR 0.100000    Time 0.658578    
2024-01-15 16:46:47,810 - Epoch: [94][  210/  211]    Overall Loss 0.038294    Objective Loss 0.038294    Top1 100.000000    Top5 100.000000    LR 0.100000    Time 0.657123    
2024-01-15 16:46:48,489 - Epoch: [94][  211/  211]    Overall Loss 0.038164    Objective Loss 0.038164    Top1 99.798387    Top5 100.000000    LR 0.100000    Time 0.657219    
2024-01-15 16:46:49,328 - --- validate (epoch=94)-----------
2024-01-15 16:46:49,329 - 6000 samples (256 per mini-batch)
2024-01-15 16:46:56,413 - Epoch: [94][   10/   24]    Loss 0.048976    Top1 98.476562    Top5 100.000000    
2024-01-15 16:46:58,830 - Epoch: [94][   20/   24]    Loss 0.047292    Top1 98.417969    Top5 100.000000    
2024-01-15 16:46:59,638 - Epoch: [94][   24/   24]    Loss 0.045967    Top1 98.450000    Top5 100.000000    
2024-01-15 16:47:00,388 - ==> Top1: 98.450    Top5: 100.000    Loss: 0.046

2024-01-15 16:47:00,389 - ==> Confusion:
[[601   0   1   1   0   0   1   1   0   0]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   2 569   5   0   0   1   7   2   0]
 [  0   1   0 579   0   1   0   1   1   0]
 [  0   1   0   0 551   1   0   3   1   8]
 [  1   1   0   1   0 513   1   0   1   0]
 [  4   1   0   0   1   5 619   0   1   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  1   0   0   8   1   5   2   0 566   1]
 [  0   1   0   0   3   2   0   8   3 598]]

2024-01-15 16:47:00,391 - ==> Best [Top1: 98.933   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 75]
2024-01-15 16:47:00,391 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:47:00,396 - 

2024-01-15 16:47:00,397 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:47:09,960 - Epoch: [95][   10/  211]    Overall Loss 0.036310    Objective Loss 0.036310                                        LR 0.100000    Time 0.956247    
2024-01-15 16:47:16,027 - Epoch: [95][   20/  211]    Overall Loss 0.034361    Objective Loss 0.034361                                        LR 0.100000    Time 0.781351    
2024-01-15 16:47:22,409 - Epoch: [95][   30/  211]    Overall Loss 0.035624    Objective Loss 0.035624                                        LR 0.100000    Time 0.733573    
2024-01-15 16:47:28,141 - Epoch: [95][   40/  211]    Overall Loss 0.035933    Objective Loss 0.035933                                        LR 0.100000    Time 0.693465    
2024-01-15 16:47:33,885 - Epoch: [95][   50/  211]    Overall Loss 0.035273    Objective Loss 0.035273                                        LR 0.100000    Time 0.669630    
2024-01-15 16:47:39,625 - Epoch: [95][   60/  211]    Overall Loss 0.035740    Objective Loss 0.035740                                        LR 0.100000    Time 0.653690    
2024-01-15 16:47:45,414 - Epoch: [95][   70/  211]    Overall Loss 0.035545    Objective Loss 0.035545                                        LR 0.100000    Time 0.642990    
2024-01-15 16:47:51,045 - Epoch: [95][   80/  211]    Overall Loss 0.037318    Objective Loss 0.037318                                        LR 0.100000    Time 0.632987    
2024-01-15 16:47:56,690 - Epoch: [95][   90/  211]    Overall Loss 0.037717    Objective Loss 0.037717                                        LR 0.100000    Time 0.625363    
2024-01-15 16:48:03,543 - Epoch: [95][  100/  211]    Overall Loss 0.040636    Objective Loss 0.040636                                        LR 0.100000    Time 0.631350    
2024-01-15 16:48:09,481 - Epoch: [95][  110/  211]    Overall Loss 0.040557    Objective Loss 0.040557                                        LR 0.100000    Time 0.627919    
2024-01-15 16:48:15,726 - Epoch: [95][  120/  211]    Overall Loss 0.040090    Objective Loss 0.040090                                        LR 0.100000    Time 0.627615    
2024-01-15 16:48:21,991 - Epoch: [95][  130/  211]    Overall Loss 0.039622    Objective Loss 0.039622                                        LR 0.100000    Time 0.627517    
2024-01-15 16:48:28,480 - Epoch: [95][  140/  211]    Overall Loss 0.039586    Objective Loss 0.039586                                        LR 0.100000    Time 0.629034    
2024-01-15 16:48:34,988 - Epoch: [95][  150/  211]    Overall Loss 0.039225    Objective Loss 0.039225                                        LR 0.100000    Time 0.630467    
2024-01-15 16:48:41,704 - Epoch: [95][  160/  211]    Overall Loss 0.039208    Objective Loss 0.039208                                        LR 0.100000    Time 0.633034    
2024-01-15 16:48:47,664 - Epoch: [95][  170/  211]    Overall Loss 0.039080    Objective Loss 0.039080                                        LR 0.100000    Time 0.630845    
2024-01-15 16:48:53,531 - Epoch: [95][  180/  211]    Overall Loss 0.038739    Objective Loss 0.038739                                        LR 0.100000    Time 0.628388    
2024-01-15 16:48:59,848 - Epoch: [95][  190/  211]    Overall Loss 0.038417    Objective Loss 0.038417                                        LR 0.100000    Time 0.628555    
2024-01-15 16:49:05,851 - Epoch: [95][  200/  211]    Overall Loss 0.038551    Objective Loss 0.038551                                        LR 0.100000    Time 0.627136    
2024-01-15 16:49:11,851 - Epoch: [95][  210/  211]    Overall Loss 0.038199    Objective Loss 0.038199    Top1 98.828125    Top5 100.000000    LR 0.100000    Time 0.625838    
2024-01-15 16:49:12,548 - Epoch: [95][  211/  211]    Overall Loss 0.038320    Objective Loss 0.038320    Top1 98.387097    Top5 100.000000    LR 0.100000    Time 0.626171    
2024-01-15 16:49:13,329 - --- validate (epoch=95)-----------
2024-01-15 16:49:13,331 - 6000 samples (256 per mini-batch)
2024-01-15 16:49:20,718 - Epoch: [95][   10/   24]    Loss 0.049423    Top1 98.789062    Top5 99.960938    
2024-01-15 16:49:23,179 - Epoch: [95][   20/   24]    Loss 0.043469    Top1 98.867188    Top5 99.980469    
2024-01-15 16:49:23,959 - Epoch: [95][   24/   24]    Loss 0.039854    Top1 98.950000    Top5 99.983333    
2024-01-15 16:49:24,854 - ==> Top1: 98.950    Top5: 99.983    Loss: 0.040

2024-01-15 16:49:24,856 - ==> Confusion:
[[601   0   1   0   0   0   2   0   0   1]
 [  0 683   1   0   0   1   1   2   0   0]
 [  0   0 580   0   0   0   0   2   3   1]
 [  0   0   4 574   0   1   0   2   2   0]
 [  0   0   0   0 553   0   0   0   0  12]
 [  0   0   0   1   0 512   2   0   1   2]
 [  3   1   0   0   2   1 624   0   0   0]
 [  0   1   1   0   1   0   0 620   0   2]
 [  0   0   1   1   0   1   1   0 578   2]
 [  1   0   0   0   0   0   0   0   2 612]]

2024-01-15 16:49:24,860 - ==> Best [Top1: 98.950   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 95]
2024-01-15 16:49:24,861 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:49:24,871 - 

2024-01-15 16:49:24,872 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:49:35,680 - Epoch: [96][   10/  211]    Overall Loss 0.036586    Objective Loss 0.036586                                        LR 0.100000    Time 1.080752    
2024-01-15 16:49:42,321 - Epoch: [96][   20/  211]    Overall Loss 0.039520    Objective Loss 0.039520                                        LR 0.100000    Time 0.872350    
2024-01-15 16:49:48,582 - Epoch: [96][   30/  211]    Overall Loss 0.040192    Objective Loss 0.040192                                        LR 0.100000    Time 0.790163    
2024-01-15 16:49:54,658 - Epoch: [96][   40/  211]    Overall Loss 0.038899    Objective Loss 0.038899                                        LR 0.100000    Time 0.744452    
2024-01-15 16:50:00,388 - Epoch: [96][   50/  211]    Overall Loss 0.039101    Objective Loss 0.039101                                        LR 0.100000    Time 0.710106    
2024-01-15 16:50:06,168 - Epoch: [96][   60/  211]    Overall Loss 0.038803    Objective Loss 0.038803                                        LR 0.100000    Time 0.688074    
2024-01-15 16:50:11,822 - Epoch: [96][   70/  211]    Overall Loss 0.038709    Objective Loss 0.038709                                        LR 0.100000    Time 0.670531    
2024-01-15 16:50:17,445 - Epoch: [96][   80/  211]    Overall Loss 0.038355    Objective Loss 0.038355                                        LR 0.100000    Time 0.656997    
2024-01-15 16:50:23,328 - Epoch: [96][   90/  211]    Overall Loss 0.037658    Objective Loss 0.037658                                        LR 0.100000    Time 0.649353    
2024-01-15 16:50:30,599 - Epoch: [96][  100/  211]    Overall Loss 0.038271    Objective Loss 0.038271                                        LR 0.100000    Time 0.657110    
2024-01-15 16:50:36,665 - Epoch: [96][  110/  211]    Overall Loss 0.038665    Objective Loss 0.038665                                        LR 0.100000    Time 0.652506    
2024-01-15 16:50:42,474 - Epoch: [96][  120/  211]    Overall Loss 0.039214    Objective Loss 0.039214                                        LR 0.100000    Time 0.646512    
2024-01-15 16:50:48,163 - Epoch: [96][  130/  211]    Overall Loss 0.039714    Objective Loss 0.039714                                        LR 0.100000    Time 0.640537    
2024-01-15 16:50:53,919 - Epoch: [96][  140/  211]    Overall Loss 0.039573    Objective Loss 0.039573                                        LR 0.100000    Time 0.635894    
2024-01-15 16:50:59,678 - Epoch: [96][  150/  211]    Overall Loss 0.039114    Objective Loss 0.039114                                        LR 0.100000    Time 0.631885    
2024-01-15 16:51:05,362 - Epoch: [96][  160/  211]    Overall Loss 0.039018    Objective Loss 0.039018                                        LR 0.100000    Time 0.627910    
2024-01-15 16:51:11,007 - Epoch: [96][  170/  211]    Overall Loss 0.039498    Objective Loss 0.039498                                        LR 0.100000    Time 0.624171    
2024-01-15 16:51:16,704 - Epoch: [96][  180/  211]    Overall Loss 0.039148    Objective Loss 0.039148                                        LR 0.100000    Time 0.621145    
2024-01-15 16:51:22,482 - Epoch: [96][  190/  211]    Overall Loss 0.039312    Objective Loss 0.039312                                        LR 0.100000    Time 0.618855    
2024-01-15 16:51:28,975 - Epoch: [96][  200/  211]    Overall Loss 0.038884    Objective Loss 0.038884                                        LR 0.100000    Time 0.620365    
2024-01-15 16:51:34,810 - Epoch: [96][  210/  211]    Overall Loss 0.039214    Objective Loss 0.039214    Top1 99.609375    Top5 100.000000    LR 0.100000    Time 0.618591    
2024-01-15 16:51:35,414 - Epoch: [96][  211/  211]    Overall Loss 0.039287    Objective Loss 0.039287    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.618520    
2024-01-15 16:51:36,593 - --- validate (epoch=96)-----------
2024-01-15 16:51:36,594 - 6000 samples (256 per mini-batch)
2024-01-15 16:51:44,799 - Epoch: [96][   10/   24]    Loss 0.041979    Top1 98.906250    Top5 100.000000    
2024-01-15 16:51:46,973 - Epoch: [96][   20/   24]    Loss 0.040139    Top1 98.847656    Top5 100.000000    
2024-01-15 16:51:47,738 - Epoch: [96][   24/   24]    Loss 0.042079    Top1 98.900000    Top5 99.983333    
2024-01-15 16:51:48,505 - ==> Top1: 98.900    Top5: 99.983    Loss: 0.042

2024-01-15 16:51:48,507 - ==> Confusion:
[[601   0   1   0   0   1   1   1   0   0]
 [  0 683   0   0   1   0   1   3   0   0]
 [  0   0 583   0   0   0   0   3   0   0]
 [  0   0   5 572   1   1   0   3   1   0]
 [  0   0   1   0 560   0   0   0   0   4]
 [  0   0   0   1   0 514   1   0   2   0]
 [  1   0   0   0   1   2 626   0   1   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   0   1   2   1   2   1 577   0]
 [  2   1   0   1   9   2   0   3   3 594]]

2024-01-15 16:51:48,510 - ==> Best [Top1: 98.950   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 95]
2024-01-15 16:51:48,510 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:51:48,517 - 

2024-01-15 16:51:48,517 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:51:58,883 - Epoch: [97][   10/  211]    Overall Loss 0.043523    Objective Loss 0.043523                                        LR 0.100000    Time 1.036230    
2024-01-15 16:52:05,454 - Epoch: [97][   20/  211]    Overall Loss 0.041670    Objective Loss 0.041670                                        LR 0.100000    Time 0.846448    
2024-01-15 16:52:11,927 - Epoch: [97][   30/  211]    Overall Loss 0.038493    Objective Loss 0.038493                                        LR 0.100000    Time 0.779894    
2024-01-15 16:52:19,339 - Epoch: [97][   40/  211]    Overall Loss 0.038155    Objective Loss 0.038155                                        LR 0.100000    Time 0.770184    
2024-01-15 16:52:25,338 - Epoch: [97][   50/  211]    Overall Loss 0.038044    Objective Loss 0.038044                                        LR 0.100000    Time 0.736105    
2024-01-15 16:52:32,224 - Epoch: [97][   60/  211]    Overall Loss 0.040786    Objective Loss 0.040786                                        LR 0.100000    Time 0.728155    
2024-01-15 16:52:37,972 - Epoch: [97][   70/  211]    Overall Loss 0.041150    Objective Loss 0.041150                                        LR 0.100000    Time 0.706229    
2024-01-15 16:52:43,983 - Epoch: [97][   80/  211]    Overall Loss 0.040779    Objective Loss 0.040779                                        LR 0.100000    Time 0.693064    
2024-01-15 16:52:49,881 - Epoch: [97][   90/  211]    Overall Loss 0.040681    Objective Loss 0.040681                                        LR 0.100000    Time 0.681582    
2024-01-15 16:52:55,604 - Epoch: [97][  100/  211]    Overall Loss 0.040368    Objective Loss 0.040368                                        LR 0.100000    Time 0.670645    
2024-01-15 16:53:01,278 - Epoch: [97][  110/  211]    Overall Loss 0.039869    Objective Loss 0.039869                                        LR 0.100000    Time 0.661253    
2024-01-15 16:53:07,030 - Epoch: [97][  120/  211]    Overall Loss 0.039367    Objective Loss 0.039367                                        LR 0.100000    Time 0.654073    
2024-01-15 16:53:12,791 - Epoch: [97][  130/  211]    Overall Loss 0.038734    Objective Loss 0.038734                                        LR 0.100000    Time 0.648063    
2024-01-15 16:53:18,669 - Epoch: [97][  140/  211]    Overall Loss 0.038001    Objective Loss 0.038001                                        LR 0.100000    Time 0.643747    
2024-01-15 16:53:24,474 - Epoch: [97][  150/  211]    Overall Loss 0.038402    Objective Loss 0.038402                                        LR 0.100000    Time 0.639525    
2024-01-15 16:53:30,262 - Epoch: [97][  160/  211]    Overall Loss 0.038423    Objective Loss 0.038423                                        LR 0.100000    Time 0.635723    
2024-01-15 16:53:36,067 - Epoch: [97][  170/  211]    Overall Loss 0.038546    Objective Loss 0.038546                                        LR 0.100000    Time 0.632470    
2024-01-15 16:53:41,946 - Epoch: [97][  180/  211]    Overall Loss 0.038247    Objective Loss 0.038247                                        LR 0.100000    Time 0.629986    
2024-01-15 16:53:47,723 - Epoch: [97][  190/  211]    Overall Loss 0.038272    Objective Loss 0.038272                                        LR 0.100000    Time 0.627225    
2024-01-15 16:53:53,470 - Epoch: [97][  200/  211]    Overall Loss 0.038117    Objective Loss 0.038117                                        LR 0.100000    Time 0.624590    
2024-01-15 16:53:59,179 - Epoch: [97][  210/  211]    Overall Loss 0.037925    Objective Loss 0.037925    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.622024    
2024-01-15 16:53:59,747 - Epoch: [97][  211/  211]    Overall Loss 0.038048    Objective Loss 0.038048    Top1 98.588710    Top5 100.000000    LR 0.100000    Time 0.621768    
2024-01-15 16:54:00,574 - --- validate (epoch=97)-----------
2024-01-15 16:54:00,575 - 6000 samples (256 per mini-batch)
2024-01-15 16:54:07,193 - Epoch: [97][   10/   24]    Loss 0.042342    Top1 98.515625    Top5 100.000000    
2024-01-15 16:54:09,308 - Epoch: [97][   20/   24]    Loss 0.043827    Top1 98.496094    Top5 99.980469    
2024-01-15 16:54:10,047 - Epoch: [97][   24/   24]    Loss 0.041985    Top1 98.550000    Top5 99.983333    
2024-01-15 16:54:10,808 - ==> Top1: 98.550    Top5: 99.983    Loss: 0.042

2024-01-15 16:54:10,809 - ==> Confusion:
[[601   0   1   0   0   0   1   1   0   1]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   1 578   0   1   0   0   5   1   0]
 [  1   2   5 568   0   2   0   5   0   0]
 [  0   2   1   0 547   0   1   1   0  13]
 [  0   1   0   2   0 502   6   1   2   4]
 [  3   3   0   0   0   0 623   0   2   0]
 [  0   0   0   0   1   0   0 624   0   0]
 [  2   1   1   1   2   0   0   1 574   2]
 [  0   1   0   0   1   1   0   2   2 608]]

2024-01-15 16:54:10,811 - ==> Best [Top1: 98.950   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 95]
2024-01-15 16:54:10,811 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:54:10,816 - 

2024-01-15 16:54:10,816 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:54:19,745 - Epoch: [98][   10/  211]    Overall Loss 0.033562    Objective Loss 0.033562                                        LR 0.100000    Time 0.892804    
2024-01-15 16:54:25,421 - Epoch: [98][   20/  211]    Overall Loss 0.037759    Objective Loss 0.037759                                        LR 0.100000    Time 0.730128    
2024-01-15 16:54:31,129 - Epoch: [98][   30/  211]    Overall Loss 0.037205    Objective Loss 0.037205                                        LR 0.100000    Time 0.677008    
2024-01-15 16:54:36,763 - Epoch: [98][   40/  211]    Overall Loss 0.036917    Objective Loss 0.036917                                        LR 0.100000    Time 0.648587    
2024-01-15 16:54:42,564 - Epoch: [98][   50/  211]    Overall Loss 0.038140    Objective Loss 0.038140                                        LR 0.100000    Time 0.634867    
2024-01-15 16:54:48,430 - Epoch: [98][   60/  211]    Overall Loss 0.037358    Objective Loss 0.037358                                        LR 0.100000    Time 0.626810    
2024-01-15 16:54:54,415 - Epoch: [98][   70/  211]    Overall Loss 0.037394    Objective Loss 0.037394                                        LR 0.100000    Time 0.622745    
2024-01-15 16:55:00,506 - Epoch: [98][   80/  211]    Overall Loss 0.038516    Objective Loss 0.038516                                        LR 0.100000    Time 0.621013    
2024-01-15 16:55:06,192 - Epoch: [98][   90/  211]    Overall Loss 0.038088    Objective Loss 0.038088                                        LR 0.100000    Time 0.615180    
2024-01-15 16:55:12,053 - Epoch: [98][  100/  211]    Overall Loss 0.040012    Objective Loss 0.040012                                        LR 0.100000    Time 0.612260    
2024-01-15 16:55:17,793 - Epoch: [98][  110/  211]    Overall Loss 0.039764    Objective Loss 0.039764                                        LR 0.100000    Time 0.608772    
2024-01-15 16:55:23,529 - Epoch: [98][  120/  211]    Overall Loss 0.039199    Objective Loss 0.039199                                        LR 0.100000    Time 0.605832    
2024-01-15 16:55:29,208 - Epoch: [98][  130/  211]    Overall Loss 0.038799    Objective Loss 0.038799                                        LR 0.100000    Time 0.602910    
2024-01-15 16:55:35,004 - Epoch: [98][  140/  211]    Overall Loss 0.038271    Objective Loss 0.038271                                        LR 0.100000    Time 0.601238    
2024-01-15 16:55:40,771 - Epoch: [98][  150/  211]    Overall Loss 0.038285    Objective Loss 0.038285                                        LR 0.100000    Time 0.599593    
2024-01-15 16:55:46,742 - Epoch: [98][  160/  211]    Overall Loss 0.038211    Objective Loss 0.038211                                        LR 0.100000    Time 0.599426    
2024-01-15 16:55:52,426 - Epoch: [98][  170/  211]    Overall Loss 0.038336    Objective Loss 0.038336                                        LR 0.100000    Time 0.597596    
2024-01-15 16:55:58,103 - Epoch: [98][  180/  211]    Overall Loss 0.038893    Objective Loss 0.038893                                        LR 0.100000    Time 0.595931    
2024-01-15 16:56:04,191 - Epoch: [98][  190/  211]    Overall Loss 0.038639    Objective Loss 0.038639                                        LR 0.100000    Time 0.596603    
2024-01-15 16:56:12,039 - Epoch: [98][  200/  211]    Overall Loss 0.038621    Objective Loss 0.038621                                        LR 0.100000    Time 0.605993    
2024-01-15 16:56:18,553 - Epoch: [98][  210/  211]    Overall Loss 0.038511    Objective Loss 0.038511    Top1 99.218750    Top5 100.000000    LR 0.100000    Time 0.608130    
2024-01-15 16:56:19,169 - Epoch: [98][  211/  211]    Overall Loss 0.038684    Objective Loss 0.038684    Top1 98.588710    Top5 99.798387    LR 0.100000    Time 0.608156    
2024-01-15 16:56:20,853 - --- validate (epoch=98)-----------
2024-01-15 16:56:20,855 - 6000 samples (256 per mini-batch)
2024-01-15 16:56:31,703 - Epoch: [98][   10/   24]    Loss 0.047665    Top1 98.789062    Top5 99.960938    
2024-01-15 16:56:34,109 - Epoch: [98][   20/   24]    Loss 0.051350    Top1 98.535156    Top5 99.980469    
2024-01-15 16:56:34,971 - Epoch: [98][   24/   24]    Loss 0.049293    Top1 98.583333    Top5 99.983333    
2024-01-15 16:56:35,820 - ==> Top1: 98.583    Top5: 99.983    Loss: 0.049

2024-01-15 16:56:35,822 - ==> Confusion:
[[603   0   0   0   0   0   1   0   0   1]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   3 578   1   0   0   0   4   0   0]
 [  0   0   2 575   0   3   0   3   0   0]
 [  0   1   0   0 550   0   1   3   0  10]
 [  0   0   0   1   1 516   0   0   0   0]
 [  3   2   0   0   2   6 618   0   0   0]
 [  0   4   2   0   0   0   0 619   0   0]
 [  2   0   0   5   3   5   1   1 565   2]
 [  0   2   0   1   2   0   0   5   2 603]]

2024-01-15 16:56:35,826 - ==> Best [Top1: 98.950   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 95]
2024-01-15 16:56:35,826 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:56:35,835 - 

2024-01-15 16:56:35,835 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:56:46,612 - Epoch: [99][   10/  211]    Overall Loss 0.045315    Objective Loss 0.045315                                        LR 0.100000    Time 1.077640    
2024-01-15 16:56:52,322 - Epoch: [99][   20/  211]    Overall Loss 0.045439    Objective Loss 0.045439                                        LR 0.100000    Time 0.824261    
2024-01-15 16:56:58,196 - Epoch: [99][   30/  211]    Overall Loss 0.042042    Objective Loss 0.042042                                        LR 0.100000    Time 0.745279    
2024-01-15 16:57:03,967 - Epoch: [99][   40/  211]    Overall Loss 0.040135    Objective Loss 0.040135                                        LR 0.100000    Time 0.703211    
2024-01-15 16:57:09,734 - Epoch: [99][   50/  211]    Overall Loss 0.040615    Objective Loss 0.040615                                        LR 0.100000    Time 0.677872    
2024-01-15 16:57:15,452 - Epoch: [99][   60/  211]    Overall Loss 0.038979    Objective Loss 0.038979                                        LR 0.100000    Time 0.660169    
2024-01-15 16:57:21,081 - Epoch: [99][   70/  211]    Overall Loss 0.038343    Objective Loss 0.038343                                        LR 0.100000    Time 0.646278    
2024-01-15 16:57:26,711 - Epoch: [99][   80/  211]    Overall Loss 0.038296    Objective Loss 0.038296                                        LR 0.100000    Time 0.635858    
2024-01-15 16:57:32,554 - Epoch: [99][   90/  211]    Overall Loss 0.038130    Objective Loss 0.038130                                        LR 0.100000    Time 0.630123    
2024-01-15 16:57:38,193 - Epoch: [99][  100/  211]    Overall Loss 0.038362    Objective Loss 0.038362                                        LR 0.100000    Time 0.623482    
2024-01-15 16:57:43,904 - Epoch: [99][  110/  211]    Overall Loss 0.037543    Objective Loss 0.037543                                        LR 0.100000    Time 0.618716    
2024-01-15 16:57:49,811 - Epoch: [99][  120/  211]    Overall Loss 0.036800    Objective Loss 0.036800                                        LR 0.100000    Time 0.616367    
2024-01-15 16:57:55,600 - Epoch: [99][  130/  211]    Overall Loss 0.036734    Objective Loss 0.036734                                        LR 0.100000    Time 0.613482    
2024-01-15 16:58:01,596 - Epoch: [99][  140/  211]    Overall Loss 0.036771    Objective Loss 0.036771                                        LR 0.100000    Time 0.612479    
2024-01-15 16:58:07,414 - Epoch: [99][  150/  211]    Overall Loss 0.037114    Objective Loss 0.037114                                        LR 0.100000    Time 0.610371    
2024-01-15 16:58:13,651 - Epoch: [99][  160/  211]    Overall Loss 0.037131    Objective Loss 0.037131                                        LR 0.100000    Time 0.611164    
2024-01-15 16:58:19,479 - Epoch: [99][  170/  211]    Overall Loss 0.036956    Objective Loss 0.036956                                        LR 0.100000    Time 0.609491    
2024-01-15 16:58:26,300 - Epoch: [99][  180/  211]    Overall Loss 0.037060    Objective Loss 0.037060                                        LR 0.100000    Time 0.613512    
2024-01-15 16:58:33,633 - Epoch: [99][  190/  211]    Overall Loss 0.037076    Objective Loss 0.037076                                        LR 0.100000    Time 0.619811    
2024-01-15 16:58:39,450 - Epoch: [99][  200/  211]    Overall Loss 0.037111    Objective Loss 0.037111                                        LR 0.100000    Time 0.617896    
2024-01-15 16:58:45,879 - Epoch: [99][  210/  211]    Overall Loss 0.037338    Objective Loss 0.037338    Top1 98.437500    Top5 100.000000    LR 0.100000    Time 0.619080    
2024-01-15 16:58:46,555 - Epoch: [99][  211/  211]    Overall Loss 0.037328    Objective Loss 0.037328    Top1 98.790323    Top5 100.000000    LR 0.100000    Time 0.619342    
2024-01-15 16:58:47,341 - --- validate (epoch=99)-----------
2024-01-15 16:58:47,342 - 6000 samples (256 per mini-batch)
2024-01-15 16:58:53,886 - Epoch: [99][   10/   24]    Loss 0.036080    Top1 98.867188    Top5 99.960938    
2024-01-15 16:58:55,995 - Epoch: [99][   20/   24]    Loss 0.036763    Top1 98.925781    Top5 99.980469    
2024-01-15 16:58:56,749 - Epoch: [99][   24/   24]    Loss 0.035338    Top1 98.933333    Top5 99.983333    
2024-01-15 16:58:57,405 - ==> Top1: 98.933    Top5: 99.983    Loss: 0.035

2024-01-15 16:58:57,406 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 681   1   1   0   1   0   4   0   0]
 [  1   0 578   0   0   0   0   5   2   0]
 [  2   0   1 576   1   3   0   0   0   0]
 [  0   1   0   0 557   0   0   2   0   5]
 [  0   0   0   0   1 513   2   0   1   1]
 [  3   2   0   0   2   0 623   0   1   0]
 [  1   1   0   0   0   0   0 623   0   0]
 [  2   0   0   0   1   1   1   1 576   2]
 [  0   1   0   0   3   0   0   2   3 606]]

2024-01-15 16:58:57,408 - ==> Best [Top1: 98.950   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 95]
2024-01-15 16:58:57,409 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 16:58:57,413 - 

2024-01-15 16:58:57,413 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 16:59:06,730 - Epoch: [100][   10/  211]    Overall Loss 0.025960    Objective Loss 0.025960                                        LR 0.010000    Time 0.931600    
2024-01-15 16:59:12,568 - Epoch: [100][   20/  211]    Overall Loss 0.030685    Objective Loss 0.030685                                        LR 0.010000    Time 0.757671    
2024-01-15 16:59:18,239 - Epoch: [100][   30/  211]    Overall Loss 0.030853    Objective Loss 0.030853                                        LR 0.010000    Time 0.694105    
2024-01-15 16:59:23,874 - Epoch: [100][   40/  211]    Overall Loss 0.031135    Objective Loss 0.031135                                        LR 0.010000    Time 0.661460    
2024-01-15 16:59:29,541 - Epoch: [100][   50/  211]    Overall Loss 0.030543    Objective Loss 0.030543                                        LR 0.010000    Time 0.642495    
2024-01-15 16:59:35,225 - Epoch: [100][   60/  211]    Overall Loss 0.030855    Objective Loss 0.030855                                        LR 0.010000    Time 0.630117    
2024-01-15 16:59:40,998 - Epoch: [100][   70/  211]    Overall Loss 0.029692    Objective Loss 0.029692                                        LR 0.010000    Time 0.622563    
2024-01-15 16:59:46,661 - Epoch: [100][   80/  211]    Overall Loss 0.029157    Objective Loss 0.029157                                        LR 0.010000    Time 0.615518    
2024-01-15 16:59:52,456 - Epoch: [100][   90/  211]    Overall Loss 0.028431    Objective Loss 0.028431                                        LR 0.010000    Time 0.611509    
2024-01-15 16:59:58,094 - Epoch: [100][  100/  211]    Overall Loss 0.028499    Objective Loss 0.028499                                        LR 0.010000    Time 0.606725    
2024-01-15 17:00:03,745 - Epoch: [100][  110/  211]    Overall Loss 0.027653    Objective Loss 0.027653                                        LR 0.010000    Time 0.602933    
2024-01-15 17:00:09,458 - Epoch: [100][  120/  211]    Overall Loss 0.026920    Objective Loss 0.026920                                        LR 0.010000    Time 0.600294    
2024-01-15 17:00:17,874 - Epoch: [100][  130/  211]    Overall Loss 0.027107    Objective Loss 0.027107                                        LR 0.010000    Time 0.618636    
2024-01-15 17:00:23,518 - Epoch: [100][  140/  211]    Overall Loss 0.027492    Objective Loss 0.027492                                        LR 0.010000    Time 0.614749    
2024-01-15 17:00:29,185 - Epoch: [100][  150/  211]    Overall Loss 0.027351    Objective Loss 0.027351                                        LR 0.010000    Time 0.611545    
2024-01-15 17:00:34,875 - Epoch: [100][  160/  211]    Overall Loss 0.027534    Objective Loss 0.027534                                        LR 0.010000    Time 0.608880    
2024-01-15 17:00:41,079 - Epoch: [100][  170/  211]    Overall Loss 0.027086    Objective Loss 0.027086                                        LR 0.010000    Time 0.609548    
2024-01-15 17:00:46,937 - Epoch: [100][  180/  211]    Overall Loss 0.026966    Objective Loss 0.026966                                        LR 0.010000    Time 0.608223    
2024-01-15 17:00:52,763 - Epoch: [100][  190/  211]    Overall Loss 0.026963    Objective Loss 0.026963                                        LR 0.010000    Time 0.606869    
2024-01-15 17:00:58,405 - Epoch: [100][  200/  211]    Overall Loss 0.027018    Objective Loss 0.027018                                        LR 0.010000    Time 0.604732    
2024-01-15 17:01:04,081 - Epoch: [100][  210/  211]    Overall Loss 0.027075    Objective Loss 0.027075    Top1 98.828125    Top5 100.000000    LR 0.010000    Time 0.602962    
2024-01-15 17:01:04,653 - Epoch: [100][  211/  211]    Overall Loss 0.027023    Objective Loss 0.027023    Top1 99.193548    Top5 100.000000    LR 0.010000    Time 0.602810    
2024-01-15 17:01:05,966 - --- validate (epoch=100)-----------
2024-01-15 17:01:05,968 - 6000 samples (256 per mini-batch)
2024-01-15 17:01:12,249 - Epoch: [100][   10/   24]    Loss 0.033869    Top1 98.828125    Top5 99.960938    
2024-01-15 17:01:14,377 - Epoch: [100][   20/   24]    Loss 0.032944    Top1 99.003906    Top5 99.980469    
2024-01-15 17:01:15,137 - Epoch: [100][   24/   24]    Loss 0.034729    Top1 98.983333    Top5 99.983333    
2024-01-15 17:01:15,715 - ==> Top1: 98.983    Top5: 99.983    Loss: 0.035

2024-01-15 17:01:15,716 - ==> Confusion:
[[601   0   2   0   0   0   1   0   0   1]
 [  0 685   2   0   0   0   0   1   0   0]
 [  0   0 580   1   0   0   1   3   1   0]
 [  0   0   1 579   0   1   0   1   1   0]
 [  1   0   0   0 558   0   1   0   0   5]
 [  0   0   0   2   0 513   3   0   0   0]
 [  1   1   0   0   1   0 627   0   1   0]
 [  1   1   1   0   0   0   0 622   0   0]
 [  1   0   0   2   2   2   3   1 572   1]
 [  1   1   0   0   4   2   0   2   3 602]]

2024-01-15 17:01:15,718 - ==> Best [Top1: 98.983   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 100]
2024-01-15 17:01:15,718 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 17:01:15,728 - 

2024-01-15 17:01:15,728 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 17:01:23,953 - Epoch: [101][   10/  211]    Overall Loss 0.025671    Objective Loss 0.025671                                        LR 0.010000    Time 0.822430    
2024-01-15 17:01:29,814 - Epoch: [101][   20/  211]    Overall Loss 0.024074    Objective Loss 0.024074                                        LR 0.010000    Time 0.704204    
2024-01-15 17:01:35,463 - Epoch: [101][   30/  211]    Overall Loss 0.026470    Objective Loss 0.026470                                        LR 0.010000    Time 0.657746    
2024-01-15 17:01:41,413 - Epoch: [101][   40/  211]    Overall Loss 0.026217    Objective Loss 0.026217                                        LR 0.010000    Time 0.642020    
2024-01-15 17:01:47,432 - Epoch: [101][   50/  211]    Overall Loss 0.026270    Objective Loss 0.026270                                        LR 0.010000    Time 0.633974    
2024-01-15 17:01:53,206 - Epoch: [101][   60/  211]    Overall Loss 0.026491    Objective Loss 0.026491                                        LR 0.010000    Time 0.624527    
2024-01-15 17:01:58,913 - Epoch: [101][   70/  211]    Overall Loss 0.026295    Objective Loss 0.026295                                        LR 0.010000    Time 0.616809    
2024-01-15 17:02:04,597 - Epoch: [101][   80/  211]    Overall Loss 0.026308    Objective Loss 0.026308                                        LR 0.010000    Time 0.610749    
2024-01-15 17:02:10,282 - Epoch: [101][   90/  211]    Overall Loss 0.026123    Objective Loss 0.026123                                        LR 0.010000    Time 0.606039    
2024-01-15 17:02:15,956 - Epoch: [101][  100/  211]    Overall Loss 0.025822    Objective Loss 0.025822                                        LR 0.010000    Time 0.602170    
2024-01-15 17:02:21,613 - Epoch: [101][  110/  211]    Overall Loss 0.026435    Objective Loss 0.026435                                        LR 0.010000    Time 0.598847    
2024-01-15 17:02:27,269 - Epoch: [101][  120/  211]    Overall Loss 0.026265    Objective Loss 0.026265                                        LR 0.010000    Time 0.596065    
2024-01-15 17:02:32,959 - Epoch: [101][  130/  211]    Overall Loss 0.026126    Objective Loss 0.026126                                        LR 0.010000    Time 0.593979    
2024-01-15 17:02:38,597 - Epoch: [101][  140/  211]    Overall Loss 0.026220    Objective Loss 0.026220                                        LR 0.010000    Time 0.591817    
2024-01-15 17:02:44,302 - Epoch: [101][  150/  211]    Overall Loss 0.026653    Objective Loss 0.026653                                        LR 0.010000    Time 0.590386    
2024-01-15 17:02:49,946 - Epoch: [101][  160/  211]    Overall Loss 0.026631    Objective Loss 0.026631                                        LR 0.010000    Time 0.588755    
2024-01-15 17:02:55,574 - Epoch: [101][  170/  211]    Overall Loss 0.026132    Objective Loss 0.026132                                        LR 0.010000    Time 0.587224    
2024-01-15 17:03:01,342 - Epoch: [101][  180/  211]    Overall Loss 0.025994    Objective Loss 0.025994                                        LR 0.010000    Time 0.586639    
2024-01-15 17:03:06,989 - Epoch: [101][  190/  211]    Overall Loss 0.025737    Objective Loss 0.025737                                        LR 0.010000    Time 0.585478    
2024-01-15 17:03:12,639 - Epoch: [101][  200/  211]    Overall Loss 0.025506    Objective Loss 0.025506                                        LR 0.010000    Time 0.584451    
2024-01-15 17:03:18,292 - Epoch: [101][  210/  211]    Overall Loss 0.025876    Objective Loss 0.025876    Top1 99.218750    Top5 99.609375    LR 0.010000    Time 0.583533    
2024-01-15 17:03:18,850 - Epoch: [101][  211/  211]    Overall Loss 0.025819    Objective Loss 0.025819    Top1 99.596774    Top5 99.798387    LR 0.010000    Time 0.583411    
2024-01-15 17:03:19,675 - --- validate (epoch=101)-----------
2024-01-15 17:03:19,677 - 6000 samples (256 per mini-batch)
2024-01-15 17:03:25,913 - Epoch: [101][   10/   24]    Loss 0.026926    Top1 99.375000    Top5 100.000000    
2024-01-15 17:03:28,024 - Epoch: [101][   20/   24]    Loss 0.027939    Top1 99.296875    Top5 100.000000    
2024-01-15 17:03:28,766 - Epoch: [101][   24/   24]    Loss 0.026301    Top1 99.316667    Top5 100.000000    
2024-01-15 17:03:29,339 - ==> Top1: 99.317    Top5: 100.000    Loss: 0.026

2024-01-15 17:03:29,340 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 685   1   0   1   1   0   0   0   0]
 [  0   0 584   0   0   0   0   1   1   0]
 [  0   0   1 578   0   2   0   0   2   0]
 [  0   0   1   0 557   0   2   0   1   4]
 [  0   1   0   1   0 512   2   0   2   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  0   0   1   0   0   1   1   0 581   0]
 [  1   1   0   0   2   2   0   2   2 605]]

2024-01-15 17:03:29,342 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 17:03:29,343 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 17:03:29,351 - 

2024-01-15 17:03:29,351 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 17:03:37,738 - Epoch: [102][   10/  211]    Overall Loss 0.021869    Objective Loss 0.021869                                        LR 0.010000    Time 0.838607    
2024-01-15 17:03:43,582 - Epoch: [102][   20/  211]    Overall Loss 0.023115    Objective Loss 0.023115                                        LR 0.010000    Time 0.711443    
2024-01-15 17:03:49,213 - Epoch: [102][   30/  211]    Overall Loss 0.021945    Objective Loss 0.021945                                        LR 0.010000    Time 0.661955    
2024-01-15 17:03:54,837 - Epoch: [102][   40/  211]    Overall Loss 0.022749    Objective Loss 0.022749                                        LR 0.010000    Time 0.637020    
2024-01-15 17:04:00,505 - Epoch: [102][   50/  211]    Overall Loss 0.024382    Objective Loss 0.024382                                        LR 0.010000    Time 0.622972    
2024-01-15 17:04:06,169 - Epoch: [102][   60/  211]    Overall Loss 0.023896    Objective Loss 0.023896                                        LR 0.010000    Time 0.613531    
2024-01-15 17:04:11,822 - Epoch: [102][   70/  211]    Overall Loss 0.023430    Objective Loss 0.023430                                        LR 0.010000    Time 0.606632    
2024-01-15 17:04:17,559 - Epoch: [102][   80/  211]    Overall Loss 0.022913    Objective Loss 0.022913                                        LR 0.010000    Time 0.602509    
2024-01-15 17:04:23,198 - Epoch: [102][   90/  211]    Overall Loss 0.022762    Objective Loss 0.022762                                        LR 0.010000    Time 0.598212    
2024-01-15 17:04:28,822 - Epoch: [102][  100/  211]    Overall Loss 0.022884    Objective Loss 0.022884                                        LR 0.010000    Time 0.594623    
2024-01-15 17:04:34,463 - Epoch: [102][  110/  211]    Overall Loss 0.023346    Objective Loss 0.023346                                        LR 0.010000    Time 0.591841    
2024-01-15 17:04:40,087 - Epoch: [102][  120/  211]    Overall Loss 0.024095    Objective Loss 0.024095                                        LR 0.010000    Time 0.589382    
2024-01-15 17:04:45,976 - Epoch: [102][  130/  211]    Overall Loss 0.024048    Objective Loss 0.024048                                        LR 0.010000    Time 0.589334    
2024-01-15 17:04:51,619 - Epoch: [102][  140/  211]    Overall Loss 0.024416    Objective Loss 0.024416                                        LR 0.010000    Time 0.587537    
2024-01-15 17:04:57,276 - Epoch: [102][  150/  211]    Overall Loss 0.024364    Objective Loss 0.024364                                        LR 0.010000    Time 0.586078    
2024-01-15 17:05:02,982 - Epoch: [102][  160/  211]    Overall Loss 0.024340    Objective Loss 0.024340                                        LR 0.010000    Time 0.585107    
2024-01-15 17:05:08,900 - Epoch: [102][  170/  211]    Overall Loss 0.024126    Objective Loss 0.024126                                        LR 0.010000    Time 0.585497    
2024-01-15 17:05:14,710 - Epoch: [102][  180/  211]    Overall Loss 0.024316    Objective Loss 0.024316                                        LR 0.010000    Time 0.585240    
2024-01-15 17:05:20,502 - Epoch: [102][  190/  211]    Overall Loss 0.024445    Objective Loss 0.024445                                        LR 0.010000    Time 0.584916    
2024-01-15 17:05:26,628 - Epoch: [102][  200/  211]    Overall Loss 0.024451    Objective Loss 0.024451                                        LR 0.010000    Time 0.586297    
2024-01-15 17:05:32,398 - Epoch: [102][  210/  211]    Overall Loss 0.024780    Objective Loss 0.024780    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.585851    
2024-01-15 17:05:32,958 - Epoch: [102][  211/  211]    Overall Loss 0.024723    Objective Loss 0.024723    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.585724    
2024-01-15 17:05:33,792 - --- validate (epoch=102)-----------
2024-01-15 17:05:33,793 - 6000 samples (256 per mini-batch)
2024-01-15 17:05:39,149 - Epoch: [102][   10/   24]    Loss 0.021676    Top1 99.414062    Top5 100.000000    
2024-01-15 17:05:41,658 - Epoch: [102][   20/   24]    Loss 0.026454    Top1 99.218750    Top5 100.000000    
2024-01-15 17:05:42,485 - Epoch: [102][   24/   24]    Loss 0.028458    Top1 99.200000    Top5 100.000000    
2024-01-15 17:05:43,156 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.028

2024-01-15 17:05:43,157 - ==> Confusion:
[[600   0   2   0   0   0   1   0   1   1]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   0 580   1   0   0   0   2   2   1]
 [  0   0   0 579   0   1   0   2   1   0]
 [  0   0   0   0 562   0   0   0   0   3]
 [  0   1   0   1   0 512   2   0   2   0]
 [  0   0   0   0   2   2 626   0   1   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   0   2   0   3   0   0 579   0]
 [  1   1   0   0   3   1   0   3   2 604]]

2024-01-15 17:05:43,160 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 17:05:43,160 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 17:05:43,164 - 

2024-01-15 17:05:43,164 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 17:05:51,411 - Epoch: [103][   10/  211]    Overall Loss 0.030280    Objective Loss 0.030280                                        LR 0.010000    Time 0.824582    
2024-01-15 17:05:57,535 - Epoch: [103][   20/  211]    Overall Loss 0.024748    Objective Loss 0.024748                                        LR 0.010000    Time 0.718415    
2024-01-15 17:06:03,435 - Epoch: [103][   30/  211]    Overall Loss 0.025269    Objective Loss 0.025269                                        LR 0.010000    Time 0.675546    
2024-01-15 17:06:09,375 - Epoch: [103][   40/  211]    Overall Loss 0.024483    Objective Loss 0.024483                                        LR 0.010000    Time 0.655122    
2024-01-15 17:06:15,017 - Epoch: [103][   50/  211]    Overall Loss 0.024638    Objective Loss 0.024638                                        LR 0.010000    Time 0.636915    
2024-01-15 17:06:20,755 - Epoch: [103][   60/  211]    Overall Loss 0.024037    Objective Loss 0.024037                                        LR 0.010000    Time 0.626394    
2024-01-15 17:06:26,592 - Epoch: [103][   70/  211]    Overall Loss 0.024673    Objective Loss 0.024673                                        LR 0.010000    Time 0.620245    
2024-01-15 17:06:32,677 - Epoch: [103][   80/  211]    Overall Loss 0.024677    Objective Loss 0.024677                                        LR 0.010000    Time 0.618766    
2024-01-15 17:06:39,247 - Epoch: [103][   90/  211]    Overall Loss 0.024760    Objective Loss 0.024760                                        LR 0.010000    Time 0.622994    
2024-01-15 17:06:46,576 - Epoch: [103][  100/  211]    Overall Loss 0.024672    Objective Loss 0.024672                                        LR 0.010000    Time 0.633945    
2024-01-15 17:06:52,845 - Epoch: [103][  110/  211]    Overall Loss 0.025321    Objective Loss 0.025321                                        LR 0.010000    Time 0.633292    
2024-01-15 17:06:59,074 - Epoch: [103][  120/  211]    Overall Loss 0.025784    Objective Loss 0.025784                                        LR 0.010000    Time 0.632421    
2024-01-15 17:07:05,212 - Epoch: [103][  130/  211]    Overall Loss 0.025548    Objective Loss 0.025548                                        LR 0.010000    Time 0.630971    
2024-01-15 17:07:11,497 - Epoch: [103][  140/  211]    Overall Loss 0.025405    Objective Loss 0.025405                                        LR 0.010000    Time 0.630786    
2024-01-15 17:07:17,947 - Epoch: [103][  150/  211]    Overall Loss 0.025705    Objective Loss 0.025705                                        LR 0.010000    Time 0.631713    
2024-01-15 17:07:24,229 - Epoch: [103][  160/  211]    Overall Loss 0.025669    Objective Loss 0.025669                                        LR 0.010000    Time 0.631485    
2024-01-15 17:07:30,398 - Epoch: [103][  170/  211]    Overall Loss 0.025414    Objective Loss 0.025414                                        LR 0.010000    Time 0.630622    
2024-01-15 17:07:36,528 - Epoch: [103][  180/  211]    Overall Loss 0.025345    Objective Loss 0.025345                                        LR 0.010000    Time 0.629635    
2024-01-15 17:07:43,147 - Epoch: [103][  190/  211]    Overall Loss 0.025231    Objective Loss 0.025231                                        LR 0.010000    Time 0.631315    
2024-01-15 17:07:49,263 - Epoch: [103][  200/  211]    Overall Loss 0.025249    Objective Loss 0.025249                                        LR 0.010000    Time 0.630321    
2024-01-15 17:07:55,521 - Epoch: [103][  210/  211]    Overall Loss 0.025248    Objective Loss 0.025248    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 0.630100    
2024-01-15 17:07:56,112 - Epoch: [103][  211/  211]    Overall Loss 0.025209    Objective Loss 0.025209    Top1 99.798387    Top5 100.000000    LR 0.010000    Time 0.629913    
2024-01-15 17:07:57,454 - --- validate (epoch=103)-----------
2024-01-15 17:07:57,456 - 6000 samples (256 per mini-batch)
2024-01-15 17:08:04,395 - Epoch: [103][   10/   24]    Loss 0.027858    Top1 99.257812    Top5 100.000000    
2024-01-15 17:08:06,525 - Epoch: [103][   20/   24]    Loss 0.029435    Top1 99.082031    Top5 99.980469    
2024-01-15 17:08:07,404 - Epoch: [103][   24/   24]    Loss 0.029010    Top1 99.083333    Top5 99.983333    
2024-01-15 17:08:07,975 - ==> Top1: 99.083    Top5: 99.983    Loss: 0.029

2024-01-15 17:08:07,977 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 685   0   0   1   1   0   1   0   0]
 [  0   1 580   2   0   0   0   2   0   1]
 [  0   0   2 578   0   2   0   0   1   0]
 [  0   1   1   0 553   0   1   1   1   7]
 [  0   0   0   1   0 515   1   1   0   0]
 [  0   1   0   0   2   2 625   0   1   0]
 [  0   1   2   0   0   0   0 621   0   1]
 [  0   0   1   1   1   1   3   0 577   0]
 [  1   2   0   0   1   0   0   2   2 607]]

2024-01-15 17:08:07,980 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 17:08:07,980 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 17:08:07,987 - 

2024-01-15 17:08:07,987 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 17:08:16,822 - Epoch: [104][   10/  211]    Overall Loss 0.027581    Objective Loss 0.027581                                        LR 0.010000    Time 0.883417    
2024-01-15 17:08:22,480 - Epoch: [104][   20/  211]    Overall Loss 0.025357    Objective Loss 0.025357                                        LR 0.010000    Time 0.724588    
2024-01-15 17:08:28,120 - Epoch: [104][   30/  211]    Overall Loss 0.025092    Objective Loss 0.025092                                        LR 0.010000    Time 0.671046    
2024-01-15 17:08:33,999 - Epoch: [104][   40/  211]    Overall Loss 0.024553    Objective Loss 0.024553                                        LR 0.010000    Time 0.650251    
2024-01-15 17:08:39,842 - Epoch: [104][   50/  211]    Overall Loss 0.026087    Objective Loss 0.026087                                        LR 0.010000    Time 0.636939    
2024-01-15 17:08:45,987 - Epoch: [104][   60/  211]    Overall Loss 0.025266    Objective Loss 0.025266                                        LR 0.010000    Time 0.633140    
2024-01-15 17:08:51,630 - Epoch: [104][   70/  211]    Overall Loss 0.025119    Objective Loss 0.025119                                        LR 0.010000    Time 0.623303    
2024-01-15 17:08:57,440 - Epoch: [104][   80/  211]    Overall Loss 0.025469    Objective Loss 0.025469                                        LR 0.010000    Time 0.617994    
2024-01-15 17:09:03,283 - Epoch: [104][   90/  211]    Overall Loss 0.025571    Objective Loss 0.025571                                        LR 0.010000    Time 0.614238    
2024-01-15 17:09:09,136 - Epoch: [104][  100/  211]    Overall Loss 0.025649    Objective Loss 0.025649                                        LR 0.010000    Time 0.611338    
2024-01-15 17:09:14,767 - Epoch: [104][  110/  211]    Overall Loss 0.025132    Objective Loss 0.025132                                        LR 0.010000    Time 0.606946    
2024-01-15 17:09:21,246 - Epoch: [104][  120/  211]    Overall Loss 0.024940    Objective Loss 0.024940                                        LR 0.010000    Time 0.610347    
2024-01-15 17:09:27,047 - Epoch: [104][  130/  211]    Overall Loss 0.025252    Objective Loss 0.025252                                        LR 0.010000    Time 0.608008    
2024-01-15 17:09:32,792 - Epoch: [104][  140/  211]    Overall Loss 0.025479    Objective Loss 0.025479                                        LR 0.010000    Time 0.605602    
2024-01-15 17:09:38,440 - Epoch: [104][  150/  211]    Overall Loss 0.025222    Objective Loss 0.025222                                        LR 0.010000    Time 0.602882    
2024-01-15 17:09:44,655 - Epoch: [104][  160/  211]    Overall Loss 0.025282    Objective Loss 0.025282                                        LR 0.010000    Time 0.604039    
2024-01-15 17:09:50,449 - Epoch: [104][  170/  211]    Overall Loss 0.025371    Objective Loss 0.025371                                        LR 0.010000    Time 0.602581    
2024-01-15 17:09:56,297 - Epoch: [104][  180/  211]    Overall Loss 0.025676    Objective Loss 0.025676                                        LR 0.010000    Time 0.601590    
2024-01-15 17:10:01,941 - Epoch: [104][  190/  211]    Overall Loss 0.026151    Objective Loss 0.026151                                        LR 0.010000    Time 0.599626    
2024-01-15 17:10:07,773 - Epoch: [104][  200/  211]    Overall Loss 0.026098    Objective Loss 0.026098                                        LR 0.010000    Time 0.598802    
2024-01-15 17:10:13,532 - Epoch: [104][  210/  211]    Overall Loss 0.026147    Objective Loss 0.026147    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.597706    
2024-01-15 17:10:14,115 - Epoch: [104][  211/  211]    Overall Loss 0.026047    Objective Loss 0.026047    Top1 99.596774    Top5 100.000000    LR 0.010000    Time 0.597632    
2024-01-15 17:10:15,017 - --- validate (epoch=104)-----------
2024-01-15 17:10:15,019 - 6000 samples (256 per mini-batch)
2024-01-15 17:10:22,463 - Epoch: [104][   10/   24]    Loss 0.025439    Top1 99.257812    Top5 100.000000    
2024-01-15 17:10:24,685 - Epoch: [104][   20/   24]    Loss 0.027423    Top1 99.257812    Top5 100.000000    
2024-01-15 17:10:25,444 - Epoch: [104][   24/   24]    Loss 0.028647    Top1 99.200000    Top5 100.000000    
2024-01-15 17:10:26,245 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.029

2024-01-15 17:10:26,246 - ==> Confusion:
[[602   0   1   0   0   0   1   0   1   0]
 [  0 684   1   0   1   0   1   1   0   0]
 [  0   0 581   1   0   0   0   2   2   0]
 [  0   0   1 577   0   2   0   1   2   0]
 [  0   0   1   0 560   0   0   1   0   3]
 [  1   0   0   1   0 512   1   2   1   0]
 [  0   1   0   0   1   2 627   0   0   0]
 [  0   1   1   0   0   0   0 623   0   0]
 [  0   0   0   1   0   0   0   0 582   1]
 [  0   1   0   0   2   2   0   3   3 604]]

2024-01-15 17:10:26,249 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 17:10:26,249 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 17:10:26,255 - 

2024-01-15 17:10:26,255 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 17:10:37,276 - Epoch: [105][   10/  211]    Overall Loss 0.027778    Objective Loss 0.027778                                        LR 0.010000    Time 1.102036    
2024-01-15 17:10:43,294 - Epoch: [105][   20/  211]    Overall Loss 0.023655    Objective Loss 0.023655                                        LR 0.010000    Time 0.851813    
2024-01-15 17:10:49,176 - Epoch: [105][   30/  211]    Overall Loss 0.024367    Objective Loss 0.024367                                        LR 0.010000    Time 0.763873    
2024-01-15 17:10:55,109 - Epoch: [105][   40/  211]    Overall Loss 0.023071    Objective Loss 0.023071                                        LR 0.010000    Time 0.721202    
2024-01-15 17:11:00,991 - Epoch: [105][   50/  211]    Overall Loss 0.023102    Objective Loss 0.023102                                        LR 0.010000    Time 0.694568    
2024-01-15 17:11:07,052 - Epoch: [105][   60/  211]    Overall Loss 0.023059    Objective Loss 0.023059                                        LR 0.010000    Time 0.679825    
2024-01-15 17:11:13,219 - Epoch: [105][   70/  211]    Overall Loss 0.022644    Objective Loss 0.022644                                        LR 0.010000    Time 0.670777    
2024-01-15 17:11:18,896 - Epoch: [105][   80/  211]    Overall Loss 0.022724    Objective Loss 0.022724                                        LR 0.010000    Time 0.657880    
2024-01-15 17:11:24,551 - Epoch: [105][   90/  211]    Overall Loss 0.023091    Objective Loss 0.023091                                        LR 0.010000    Time 0.647609    
2024-01-15 17:11:30,250 - Epoch: [105][  100/  211]    Overall Loss 0.023444    Objective Loss 0.023444                                        LR 0.010000    Time 0.639829    
2024-01-15 17:11:35,947 - Epoch: [105][  110/  211]    Overall Loss 0.023541    Objective Loss 0.023541                                        LR 0.010000    Time 0.633440    
2024-01-15 17:11:42,228 - Epoch: [105][  120/  211]    Overall Loss 0.024085    Objective Loss 0.024085                                        LR 0.010000    Time 0.632983    
2024-01-15 17:11:48,364 - Epoch: [105][  130/  211]    Overall Loss 0.023913    Objective Loss 0.023913                                        LR 0.010000    Time 0.631482    
2024-01-15 17:11:54,518 - Epoch: [105][  140/  211]    Overall Loss 0.023852    Objective Loss 0.023852                                        LR 0.010000    Time 0.630327    
2024-01-15 17:12:00,162 - Epoch: [105][  150/  211]    Overall Loss 0.023958    Objective Loss 0.023958                                        LR 0.010000    Time 0.625928    
2024-01-15 17:12:05,877 - Epoch: [105][  160/  211]    Overall Loss 0.023870    Objective Loss 0.023870                                        LR 0.010000    Time 0.622520    
2024-01-15 17:12:11,539 - Epoch: [105][  170/  211]    Overall Loss 0.024166    Objective Loss 0.024166                                        LR 0.010000    Time 0.619203    
2024-01-15 17:12:17,191 - Epoch: [105][  180/  211]    Overall Loss 0.024244    Objective Loss 0.024244                                        LR 0.010000    Time 0.616199    
2024-01-15 17:12:22,918 - Epoch: [105][  190/  211]    Overall Loss 0.023868    Objective Loss 0.023868                                        LR 0.010000    Time 0.613906    
2024-01-15 17:12:29,785 - Epoch: [105][  200/  211]    Overall Loss 0.024079    Objective Loss 0.024079                                        LR 0.010000    Time 0.617537    
2024-01-15 17:16:29,431 - Epoch: [105][  210/  211]    Overall Loss 0.023965    Objective Loss 0.023965    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 1.729297    
2024-01-15 17:16:29,964 - Epoch: [105][  211/  211]    Overall Loss 0.024061    Objective Loss 0.024061    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 1.723623    
2024-01-15 17:16:30,791 - --- validate (epoch=105)-----------
2024-01-15 17:16:30,792 - 6000 samples (256 per mini-batch)
2024-01-15 17:20:38,554 - Epoch: [105][   10/   24]    Loss 0.027480    Top1 99.335938    Top5 100.000000    
2024-01-15 17:20:40,764 - Epoch: [105][   20/   24]    Loss 0.028874    Top1 99.277344    Top5 100.000000    
2024-01-15 17:20:41,607 - Epoch: [105][   24/   24]    Loss 0.027544    Top1 99.250000    Top5 100.000000    
2024-01-15 17:20:42,490 - ==> Top1: 99.250    Top5: 100.000    Loss: 0.028

2024-01-15 17:20:42,492 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 684   1   0   0   1   0   2   0   0]
 [  0   0 585   0   0   0   0   1   0   0]
 [  0   0   1 577   0   2   0   2   1   0]
 [  0   0   0   0 560   0   0   2   0   3]
 [  0   0   0   1   0 514   2   0   1   0]
 [  1   0   0   0   1   0 629   0   0   0]
 [  0   1   0   2   0   0   0 622   0   0]
 [  1   0   0   1   2   2   2   0 575   1]
 [  0   1   0   0   2   1   0   3   2 606]]

2024-01-15 17:20:42,496 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 17:20:42,496 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 17:20:42,503 - 

2024-01-15 17:20:42,503 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 17:20:55,159 - Epoch: [106][   10/  211]    Overall Loss 0.024151    Objective Loss 0.024151                                        LR 0.010000    Time 1.265314    
2024-01-15 17:34:19,379 - Epoch: [106][   20/  211]    Overall Loss 0.023832    Objective Loss 0.023832                                        LR 0.010000    Time 40.843505    
2024-01-15 17:34:24,824 - Epoch: [106][   30/  211]    Overall Loss 0.023675    Objective Loss 0.023675                                        LR 0.010000    Time 27.410358    
2024-01-15 17:47:53,746 - Epoch: [106][   40/  211]    Overall Loss 0.022827    Objective Loss 0.022827                                        LR 0.010000    Time 40.780755    
2024-01-15 18:00:13,186 - Epoch: [106][   50/  211]    Overall Loss 0.022403    Objective Loss 0.022403                                        LR 0.010000    Time 47.413379    
2024-01-15 18:00:18,854 - Epoch: [106][   60/  211]    Overall Loss 0.022942    Objective Loss 0.022942                                        LR 0.010000    Time 39.605598    
2024-01-15 18:00:25,843 - Epoch: [106][   70/  211]    Overall Loss 0.023538    Objective Loss 0.023538                                        LR 0.010000    Time 34.047443    
2024-01-15 18:00:31,948 - Epoch: [106][   80/  211]    Overall Loss 0.022964    Objective Loss 0.022964                                        LR 0.010000    Time 29.867790    
2024-01-15 18:00:37,444 - Epoch: [106][   90/  211]    Overall Loss 0.023392    Objective Loss 0.023392                                        LR 0.010000    Time 26.610193    
2024-01-15 18:00:42,945 - Epoch: [106][  100/  211]    Overall Loss 0.023595    Objective Loss 0.023595                                        LR 0.010000    Time 24.004168    
2024-01-15 18:00:48,507 - Epoch: [106][  110/  211]    Overall Loss 0.023174    Objective Loss 0.023174                                        LR 0.010000    Time 21.872527    
2024-01-15 18:00:54,292 - Epoch: [106][  120/  211]    Overall Loss 0.023382    Objective Loss 0.023382                                        LR 0.010000    Time 20.098019    
2024-01-15 18:01:01,084 - Epoch: [106][  130/  211]    Overall Loss 0.023432    Objective Loss 0.023432                                        LR 0.010000    Time 18.604253    
2024-01-15 18:01:07,038 - Epoch: [106][  140/  211]    Overall Loss 0.023097    Objective Loss 0.023097                                        LR 0.010000    Time 17.317892    
2024-01-15 18:01:12,683 - Epoch: [106][  150/  211]    Overall Loss 0.023583    Objective Loss 0.023583                                        LR 0.010000    Time 16.200995    
2024-01-15 18:01:18,302 - Epoch: [106][  160/  211]    Overall Loss 0.023706    Objective Loss 0.023706                                        LR 0.010000    Time 15.223545    
2024-01-15 18:01:24,157 - Epoch: [106][  170/  211]    Overall Loss 0.023435    Objective Loss 0.023435                                        LR 0.010000    Time 14.362480    
2024-01-15 18:01:30,592 - Epoch: [106][  180/  211]    Overall Loss 0.023879    Objective Loss 0.023879                                        LR 0.010000    Time 13.600308    
2024-01-15 18:01:36,525 - Epoch: [106][  190/  211]    Overall Loss 0.023453    Objective Loss 0.023453                                        LR 0.010000    Time 12.915717    
2024-01-15 18:01:42,185 - Epoch: [106][  200/  211]    Overall Loss 0.023564    Objective Loss 0.023564                                        LR 0.010000    Time 12.298226    
2024-01-15 18:01:48,199 - Epoch: [106][  210/  211]    Overall Loss 0.023538    Objective Loss 0.023538    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 11.741230    
2024-01-15 18:01:48,751 - Epoch: [106][  211/  211]    Overall Loss 0.023505    Objective Loss 0.023505    Top1 99.798387    Top5 100.000000    LR 0.010000    Time 11.688199    
2024-01-15 18:01:49,703 - --- validate (epoch=106)-----------
2024-01-15 18:01:49,704 - 6000 samples (256 per mini-batch)
2024-01-15 18:01:56,944 - Epoch: [106][   10/   24]    Loss 0.032836    Top1 99.101562    Top5 100.000000    
2024-01-15 18:01:59,392 - Epoch: [106][   20/   24]    Loss 0.027313    Top1 99.257812    Top5 100.000000    
2024-01-15 18:02:00,189 - Epoch: [106][   24/   24]    Loss 0.026355    Top1 99.266667    Top5 100.000000    
2024-01-15 18:02:01,024 - ==> Top1: 99.267    Top5: 100.000    Loss: 0.026

2024-01-15 18:02:01,026 - ==> Confusion:
[[602   0   2   0   0   0   0   0   0   1]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   1 580   1   0   0   0   2   2   0]
 [  0   0   0 581   1   0   0   0   1   0]
 [  0   0   1   0 558   0   0   0   0   6]
 [  2   0   0   2   0 513   0   0   1   0]
 [  0   0   0   0   2   1 628   0   0   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  1   0   0   1   1   1   1   0 579   0]
 [  0   0   0   0   2   1   0   3   2 607]]

2024-01-15 18:02:01,028 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:02:01,028 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:02:01,033 - 

2024-01-15 18:02:01,034 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:02:10,478 - Epoch: [107][   10/  211]    Overall Loss 0.018243    Objective Loss 0.018243                                        LR 0.010000    Time 0.944395    
2024-01-15 18:02:16,489 - Epoch: [107][   20/  211]    Overall Loss 0.018898    Objective Loss 0.018898                                        LR 0.010000    Time 0.772640    
2024-01-15 18:02:22,702 - Epoch: [107][   30/  211]    Overall Loss 0.019832    Objective Loss 0.019832                                        LR 0.010000    Time 0.722107    
2024-01-15 18:02:28,577 - Epoch: [107][   40/  211]    Overall Loss 0.019706    Objective Loss 0.019706                                        LR 0.010000    Time 0.688426    
2024-01-15 18:02:34,787 - Epoch: [107][   50/  211]    Overall Loss 0.021133    Objective Loss 0.021133                                        LR 0.010000    Time 0.674912    
2024-01-15 18:02:40,950 - Epoch: [107][   60/  211]    Overall Loss 0.022100    Objective Loss 0.022100                                        LR 0.010000    Time 0.665116    
2024-01-15 18:02:46,620 - Epoch: [107][   70/  211]    Overall Loss 0.023333    Objective Loss 0.023333                                        LR 0.010000    Time 0.651089    
2024-01-15 18:02:52,497 - Epoch: [107][   80/  211]    Overall Loss 0.023861    Objective Loss 0.023861                                        LR 0.010000    Time 0.643159    
2024-01-15 18:02:58,559 - Epoch: [107][   90/  211]    Overall Loss 0.024049    Objective Loss 0.024049                                        LR 0.010000    Time 0.639029    
2024-01-15 18:03:04,226 - Epoch: [107][  100/  211]    Overall Loss 0.024683    Objective Loss 0.024683                                        LR 0.010000    Time 0.631785    
2024-01-15 18:03:10,229 - Epoch: [107][  110/  211]    Overall Loss 0.024787    Objective Loss 0.024787                                        LR 0.010000    Time 0.628913    
2024-01-15 18:03:15,955 - Epoch: [107][  120/  211]    Overall Loss 0.025172    Objective Loss 0.025172                                        LR 0.010000    Time 0.624211    
2024-01-15 18:03:21,956 - Epoch: [107][  130/  211]    Overall Loss 0.024714    Objective Loss 0.024714                                        LR 0.010000    Time 0.622349    
2024-01-15 18:03:29,490 - Epoch: [107][  140/  211]    Overall Loss 0.024759    Objective Loss 0.024759                                        LR 0.010000    Time 0.631699    
2024-01-15 18:03:36,323 - Epoch: [107][  150/  211]    Overall Loss 0.024613    Objective Loss 0.024613                                        LR 0.010000    Time 0.635125    
2024-01-15 18:03:42,038 - Epoch: [107][  160/  211]    Overall Loss 0.024835    Objective Loss 0.024835                                        LR 0.010000    Time 0.631139    
2024-01-15 18:03:48,173 - Epoch: [107][  170/  211]    Overall Loss 0.024603    Objective Loss 0.024603                                        LR 0.010000    Time 0.630095    
2024-01-15 18:03:54,007 - Epoch: [107][  180/  211]    Overall Loss 0.024906    Objective Loss 0.024906                                        LR 0.010000    Time 0.627494    
2024-01-15 18:03:59,882 - Epoch: [107][  190/  211]    Overall Loss 0.024919    Objective Loss 0.024919                                        LR 0.010000    Time 0.625379    
2024-01-15 18:04:05,600 - Epoch: [107][  200/  211]    Overall Loss 0.024618    Objective Loss 0.024618                                        LR 0.010000    Time 0.622699    
2024-01-15 18:04:11,405 - Epoch: [107][  210/  211]    Overall Loss 0.024717    Objective Loss 0.024717    Top1 98.828125    Top5 100.000000    LR 0.010000    Time 0.620682    
2024-01-15 18:04:11,973 - Epoch: [107][  211/  211]    Overall Loss 0.024652    Objective Loss 0.024652    Top1 99.193548    Top5 100.000000    LR 0.010000    Time 0.620426    
2024-01-15 18:04:12,811 - --- validate (epoch=107)-----------
2024-01-15 18:04:12,813 - 6000 samples (256 per mini-batch)
2024-01-15 18:04:19,992 - Epoch: [107][   10/   24]    Loss 0.024227    Top1 99.453125    Top5 100.000000    
2024-01-15 18:04:22,123 - Epoch: [107][   20/   24]    Loss 0.030415    Top1 99.101562    Top5 99.960938    
2024-01-15 18:04:22,917 - Epoch: [107][   24/   24]    Loss 0.029887    Top1 99.116667    Top5 99.966667    
2024-01-15 18:04:23,657 - ==> Top1: 99.117    Top5: 99.967    Loss: 0.030

2024-01-15 18:04:23,658 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 686   0   0   1   1   0   0   0   0]
 [  1   0 580   0   0   0   0   3   2   0]
 [  0   0   1 578   0   2   0   1   1   0]
 [  0   0   0   0 559   0   0   0   0   6]
 [  0   0   0   1   0 511   3   0   3   0]
 [  1   0   0   0   1   0 628   0   1   0]
 [  0   3   0   1   0   0   0 621   0   0]
 [  2   0   1   1   1   0   2   0 575   2]
 [  0   1   0   0   4   0   1   2   2 605]]

2024-01-15 18:04:23,660 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:04:23,660 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:04:23,665 - 

2024-01-15 18:04:23,666 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:04:33,019 - Epoch: [108][   10/  211]    Overall Loss 0.027226    Objective Loss 0.027226                                        LR 0.010000    Time 0.935264    
2024-01-15 18:04:38,943 - Epoch: [108][   20/  211]    Overall Loss 0.029785    Objective Loss 0.029785                                        LR 0.010000    Time 0.763761    
2024-01-15 18:04:45,031 - Epoch: [108][   30/  211]    Overall Loss 0.027298    Objective Loss 0.027298                                        LR 0.010000    Time 0.712055    
2024-01-15 18:04:51,073 - Epoch: [108][   40/  211]    Overall Loss 0.026219    Objective Loss 0.026219                                        LR 0.010000    Time 0.685052    
2024-01-15 18:04:56,765 - Epoch: [108][   50/  211]    Overall Loss 0.025084    Objective Loss 0.025084                                        LR 0.010000    Time 0.661862    
2024-01-15 18:05:02,466 - Epoch: [108][   60/  211]    Overall Loss 0.025732    Objective Loss 0.025732                                        LR 0.010000    Time 0.646553    
2024-01-15 18:05:08,262 - Epoch: [108][   70/  211]    Overall Loss 0.025472    Objective Loss 0.025472                                        LR 0.010000    Time 0.636976    
2024-01-15 18:05:15,915 - Epoch: [108][   80/  211]    Overall Loss 0.026448    Objective Loss 0.026448                                        LR 0.010000    Time 0.652999    
2024-01-15 18:05:23,092 - Epoch: [108][   90/  211]    Overall Loss 0.026838    Objective Loss 0.026838                                        LR 0.010000    Time 0.660045    
2024-01-15 18:05:31,669 - Epoch: [108][  100/  211]    Overall Loss 0.026524    Objective Loss 0.026524                                        LR 0.010000    Time 0.679797    
2024-01-15 18:05:37,687 - Epoch: [108][  110/  211]    Overall Loss 0.025877    Objective Loss 0.025877                                        LR 0.010000    Time 0.672696    
2024-01-15 18:05:43,716 - Epoch: [108][  120/  211]    Overall Loss 0.025662    Objective Loss 0.025662                                        LR 0.010000    Time 0.666872    
2024-01-15 18:05:49,884 - Epoch: [108][  130/  211]    Overall Loss 0.025238    Objective Loss 0.025238                                        LR 0.010000    Time 0.663009    
2024-01-15 18:05:56,018 - Epoch: [108][  140/  211]    Overall Loss 0.024972    Objective Loss 0.024972                                        LR 0.010000    Time 0.659460    
2024-01-15 18:06:02,048 - Epoch: [108][  150/  211]    Overall Loss 0.025047    Objective Loss 0.025047                                        LR 0.010000    Time 0.655683    
2024-01-15 18:06:08,936 - Epoch: [108][  160/  211]    Overall Loss 0.024991    Objective Loss 0.024991                                        LR 0.010000    Time 0.657745    
2024-01-15 18:06:15,564 - Epoch: [108][  170/  211]    Overall Loss 0.025155    Objective Loss 0.025155                                        LR 0.010000    Time 0.658019    
2024-01-15 18:06:21,858 - Epoch: [108][  180/  211]    Overall Loss 0.025127    Objective Loss 0.025127                                        LR 0.010000    Time 0.656407    
2024-01-15 18:06:28,771 - Epoch: [108][  190/  211]    Overall Loss 0.024654    Objective Loss 0.024654                                        LR 0.010000    Time 0.658240    
2024-01-15 18:06:34,982 - Epoch: [108][  200/  211]    Overall Loss 0.024659    Objective Loss 0.024659                                        LR 0.010000    Time 0.656363    
2024-01-15 18:06:41,029 - Epoch: [108][  210/  211]    Overall Loss 0.024856    Objective Loss 0.024856    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 0.653900    
2024-01-15 18:06:41,862 - Epoch: [108][  211/  211]    Overall Loss 0.024817    Objective Loss 0.024817    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 0.654747    
2024-01-15 18:06:43,335 - --- validate (epoch=108)-----------
2024-01-15 18:06:43,338 - 6000 samples (256 per mini-batch)
2024-01-15 18:06:51,534 - Epoch: [108][   10/   24]    Loss 0.023173    Top1 99.218750    Top5 100.000000    
2024-01-15 18:06:53,823 - Epoch: [108][   20/   24]    Loss 0.027650    Top1 99.140625    Top5 100.000000    
2024-01-15 18:06:54,644 - Epoch: [108][   24/   24]    Loss 0.026078    Top1 99.133333    Top5 100.000000    
2024-01-15 18:06:55,371 - ==> Top1: 99.133    Top5: 100.000    Loss: 0.026

2024-01-15 18:06:55,372 - ==> Confusion:
[[603   0   1   0   0   0   0   0   0   1]
 [  0 685   0   0   0   1   0   2   0   0]
 [  0   0 581   2   0   0   0   2   1   0]
 [  0   0   1 581   0   1   0   0   0   0]
 [  0   0   0   0 555   0   1   0   1   8]
 [  1   0   0   1   0 512   3   0   0   1]
 [  0   1   0   0   1   2 627   0   0   0]
 [  0   2   1   0   1   0   0 621   0   0]
 [  0   0   0   0   0   1   4   0 578   1]
 [  0   0   0   0   7   0   0   1   2 605]]

2024-01-15 18:06:55,375 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:06:55,375 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:06:55,380 - 

2024-01-15 18:06:55,381 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:07:05,082 - Epoch: [109][   10/  211]    Overall Loss 0.024589    Objective Loss 0.024589                                        LR 0.010000    Time 0.969986    
2024-01-15 18:07:11,326 - Epoch: [109][   20/  211]    Overall Loss 0.024315    Objective Loss 0.024315                                        LR 0.010000    Time 0.797157    
2024-01-15 18:07:17,059 - Epoch: [109][   30/  211]    Overall Loss 0.024365    Objective Loss 0.024365                                        LR 0.010000    Time 0.722480    
2024-01-15 18:07:22,946 - Epoch: [109][   40/  211]    Overall Loss 0.024610    Objective Loss 0.024610                                        LR 0.010000    Time 0.689013    
2024-01-15 18:07:29,074 - Epoch: [109][   50/  211]    Overall Loss 0.024278    Objective Loss 0.024278                                        LR 0.010000    Time 0.673748    
2024-01-15 18:07:34,750 - Epoch: [109][   60/  211]    Overall Loss 0.023183    Objective Loss 0.023183                                        LR 0.010000    Time 0.656041    
2024-01-15 18:07:40,388 - Epoch: [109][   70/  211]    Overall Loss 0.023626    Objective Loss 0.023626                                        LR 0.010000    Time 0.642850    
2024-01-15 18:07:46,045 - Epoch: [109][   80/  211]    Overall Loss 0.024171    Objective Loss 0.024171                                        LR 0.010000    Time 0.633202    
2024-01-15 18:07:51,842 - Epoch: [109][   90/  211]    Overall Loss 0.024298    Objective Loss 0.024298                                        LR 0.010000    Time 0.627251    
2024-01-15 18:07:57,942 - Epoch: [109][  100/  211]    Overall Loss 0.024589    Objective Loss 0.024589                                        LR 0.010000    Time 0.625509    
2024-01-15 18:08:03,797 - Epoch: [109][  110/  211]    Overall Loss 0.024067    Objective Loss 0.024067                                        LR 0.010000    Time 0.621860    
2024-01-15 18:08:10,087 - Epoch: [109][  120/  211]    Overall Loss 0.024027    Objective Loss 0.024027                                        LR 0.010000    Time 0.622392    
2024-01-15 18:08:16,065 - Epoch: [109][  130/  211]    Overall Loss 0.024101    Objective Loss 0.024101                                        LR 0.010000    Time 0.620489    
2024-01-15 18:08:21,972 - Epoch: [109][  140/  211]    Overall Loss 0.024129    Objective Loss 0.024129                                        LR 0.010000    Time 0.618351    
2024-01-15 18:08:28,305 - Epoch: [109][  150/  211]    Overall Loss 0.024133    Objective Loss 0.024133                                        LR 0.010000    Time 0.619333    
2024-01-15 18:08:34,122 - Epoch: [109][  160/  211]    Overall Loss 0.023869    Objective Loss 0.023869                                        LR 0.010000    Time 0.616978    
2024-01-15 18:08:40,419 - Epoch: [109][  170/  211]    Overall Loss 0.024072    Objective Loss 0.024072                                        LR 0.010000    Time 0.617715    
2024-01-15 18:08:46,323 - Epoch: [109][  180/  211]    Overall Loss 0.024358    Objective Loss 0.024358                                        LR 0.010000    Time 0.616193    
2024-01-15 18:08:51,990 - Epoch: [109][  190/  211]    Overall Loss 0.023949    Objective Loss 0.023949                                        LR 0.010000    Time 0.613584    
2024-01-15 18:08:57,680 - Epoch: [109][  200/  211]    Overall Loss 0.023951    Objective Loss 0.023951                                        LR 0.010000    Time 0.611348    
2024-01-15 18:09:03,689 - Epoch: [109][  210/  211]    Overall Loss 0.023905    Objective Loss 0.023905    Top1 98.437500    Top5 100.000000    LR 0.010000    Time 0.610848    
2024-01-15 18:09:04,246 - Epoch: [109][  211/  211]    Overall Loss 0.023867    Objective Loss 0.023867    Top1 98.991935    Top5 100.000000    LR 0.010000    Time 0.610586    
2024-01-15 18:09:05,100 - --- validate (epoch=109)-----------
2024-01-15 18:09:05,101 - 6000 samples (256 per mini-batch)
2024-01-15 18:09:10,958 - Epoch: [109][   10/   24]    Loss 0.030374    Top1 98.789062    Top5 100.000000    
2024-01-15 18:09:13,084 - Epoch: [109][   20/   24]    Loss 0.025256    Top1 99.101562    Top5 100.000000    
2024-01-15 18:09:13,970 - Epoch: [109][   24/   24]    Loss 0.027798    Top1 99.066667    Top5 100.000000    
2024-01-15 18:09:14,674 - ==> Top1: 99.067    Top5: 100.000    Loss: 0.028

2024-01-15 18:09:14,676 - ==> Confusion:
[[603   0   1   0   0   0   0   0   0   1]
 [  0 684   1   0   0   1   0   2   0   0]
 [  0   1 582   1   0   0   0   0   2   0]
 [  0   0   1 580   0   1   0   0   1   0]
 [  0   1   0   0 558   0   1   1   0   4]
 [  1   0   0   2   1 511   2   0   1   0]
 [  2   0   0   0   1   0 628   0   0   0]
 [  0   2   1   0   1   0   0 621   0   0]
 [  2   0   0   2   3   1   1   0 574   1]
 [  2   1   0   0   4   1   0   2   2 603]]

2024-01-15 18:09:14,680 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:09:14,681 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:09:14,686 - 

2024-01-15 18:09:14,687 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:09:23,417 - Epoch: [110][   10/  211]    Overall Loss 0.020755    Objective Loss 0.020755                                        LR 0.010000    Time 0.872930    
2024-01-15 18:09:29,261 - Epoch: [110][   20/  211]    Overall Loss 0.022313    Objective Loss 0.022313                                        LR 0.010000    Time 0.728595    
2024-01-15 18:09:35,344 - Epoch: [110][   30/  211]    Overall Loss 0.023283    Objective Loss 0.023283                                        LR 0.010000    Time 0.688436    
2024-01-15 18:09:41,544 - Epoch: [110][   40/  211]    Overall Loss 0.025722    Objective Loss 0.025722                                        LR 0.010000    Time 0.671302    
2024-01-15 18:09:47,231 - Epoch: [110][   50/  211]    Overall Loss 0.025795    Objective Loss 0.025795                                        LR 0.010000    Time 0.650777    
2024-01-15 18:09:53,443 - Epoch: [110][   60/  211]    Overall Loss 0.025742    Objective Loss 0.025742                                        LR 0.010000    Time 0.645825    
2024-01-15 18:10:00,598 - Epoch: [110][   70/  211]    Overall Loss 0.026160    Objective Loss 0.026160                                        LR 0.010000    Time 0.655750    
2024-01-15 18:10:07,021 - Epoch: [110][   80/  211]    Overall Loss 0.025632    Objective Loss 0.025632                                        LR 0.010000    Time 0.654040    
2024-01-15 18:10:13,254 - Epoch: [110][   90/  211]    Overall Loss 0.025436    Objective Loss 0.025436                                        LR 0.010000    Time 0.650611    
2024-01-15 18:10:19,596 - Epoch: [110][  100/  211]    Overall Loss 0.025348    Objective Loss 0.025348                                        LR 0.010000    Time 0.648952    
2024-01-15 18:10:25,980 - Epoch: [110][  110/  211]    Overall Loss 0.025968    Objective Loss 0.025968                                        LR 0.010000    Time 0.647974    
2024-01-15 18:10:32,553 - Epoch: [110][  120/  211]    Overall Loss 0.026124    Objective Loss 0.026124                                        LR 0.010000    Time 0.648719    
2024-01-15 18:10:38,547 - Epoch: [110][  130/  211]    Overall Loss 0.026081    Objective Loss 0.026081                                        LR 0.010000    Time 0.644918    
2024-01-15 18:10:44,573 - Epoch: [110][  140/  211]    Overall Loss 0.026626    Objective Loss 0.026626                                        LR 0.010000    Time 0.641892    
2024-01-15 18:10:50,520 - Epoch: [110][  150/  211]    Overall Loss 0.026489    Objective Loss 0.026489                                        LR 0.010000    Time 0.638735    
2024-01-15 18:10:56,632 - Epoch: [110][  160/  211]    Overall Loss 0.026541    Objective Loss 0.026541                                        LR 0.010000    Time 0.637013    
2024-01-15 18:11:02,530 - Epoch: [110][  170/  211]    Overall Loss 0.026351    Objective Loss 0.026351                                        LR 0.010000    Time 0.634224    
2024-01-15 18:11:08,845 - Epoch: [110][  180/  211]    Overall Loss 0.026054    Objective Loss 0.026054                                        LR 0.010000    Time 0.634073    
2024-01-15 18:11:15,657 - Epoch: [110][  190/  211]    Overall Loss 0.026239    Objective Loss 0.026239                                        LR 0.010000    Time 0.636544    
2024-01-15 18:11:22,287 - Epoch: [110][  200/  211]    Overall Loss 0.026336    Objective Loss 0.026336                                        LR 0.010000    Time 0.637858    
2024-01-15 18:11:29,608 - Epoch: [110][  210/  211]    Overall Loss 0.026388    Objective Loss 0.026388    Top1 98.437500    Top5 99.609375    LR 0.010000    Time 0.642333    
2024-01-15 18:11:30,238 - Epoch: [110][  211/  211]    Overall Loss 0.026442    Objective Loss 0.026442    Top1 98.185484    Top5 99.798387    LR 0.010000    Time 0.642266    
2024-01-15 18:11:31,317 - --- validate (epoch=110)-----------
2024-01-15 18:11:31,320 - 6000 samples (256 per mini-batch)
2024-01-15 18:11:38,770 - Epoch: [110][   10/   24]    Loss 0.028593    Top1 99.257812    Top5 100.000000    
2024-01-15 18:11:41,309 - Epoch: [110][   20/   24]    Loss 0.028591    Top1 99.101562    Top5 100.000000    
2024-01-15 18:11:42,171 - Epoch: [110][   24/   24]    Loss 0.030497    Top1 99.066667    Top5 100.000000    
2024-01-15 18:11:43,014 - ==> Top1: 99.067    Top5: 100.000    Loss: 0.030

2024-01-15 18:11:43,017 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 683   1   0   1   1   0   2   0   0]
 [  0   1 580   0   0   1   0   2   0   2]
 [  0   0   1 579   0   2   0   0   1   0]
 [  0   0   0   0 556   0   0   2   0   7]
 [  1   0   0   0   0 513   3   0   1   0]
 [  0   1   0   0   2   1 626   0   1   0]
 [  0   2   1   0   0   0   0 621   0   1]
 [  0   0   0   2   0   1   2   0 579   0]
 [  1   1   0   0   2   3   0   2   3 603]]

2024-01-15 18:11:43,020 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:11:43,021 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:11:43,027 - 

2024-01-15 18:11:43,028 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:11:53,129 - Epoch: [111][   10/  211]    Overall Loss 0.025139    Objective Loss 0.025139                                        LR 0.010000    Time 1.009887    
2024-01-15 18:11:59,464 - Epoch: [111][   20/  211]    Overall Loss 0.025355    Objective Loss 0.025355                                        LR 0.010000    Time 0.821594    
2024-01-15 18:12:05,602 - Epoch: [111][   30/  211]    Overall Loss 0.025291    Objective Loss 0.025291                                        LR 0.010000    Time 0.752308    
2024-01-15 18:12:11,633 - Epoch: [111][   40/  211]    Overall Loss 0.024841    Objective Loss 0.024841                                        LR 0.010000    Time 0.714987    
2024-01-15 18:12:17,786 - Epoch: [111][   50/  211]    Overall Loss 0.024538    Objective Loss 0.024538                                        LR 0.010000    Time 0.694992    
2024-01-15 18:12:23,850 - Epoch: [111][   60/  211]    Overall Loss 0.024009    Objective Loss 0.024009                                        LR 0.010000    Time 0.680221    
2024-01-15 18:12:30,124 - Epoch: [111][   70/  211]    Overall Loss 0.024190    Objective Loss 0.024190                                        LR 0.010000    Time 0.672641    
2024-01-15 18:12:36,985 - Epoch: [111][   80/  211]    Overall Loss 0.023662    Objective Loss 0.023662                                        LR 0.010000    Time 0.674302    
2024-01-15 18:12:42,926 - Epoch: [111][   90/  211]    Overall Loss 0.024193    Objective Loss 0.024193                                        LR 0.010000    Time 0.665385    
2024-01-15 18:12:48,841 - Epoch: [111][  100/  211]    Overall Loss 0.023691    Objective Loss 0.023691                                        LR 0.010000    Time 0.657987    
2024-01-15 18:12:55,392 - Epoch: [111][  110/  211]    Overall Loss 0.024026    Objective Loss 0.024026                                        LR 0.010000    Time 0.657714    
2024-01-15 18:13:01,328 - Epoch: [111][  120/  211]    Overall Loss 0.023879    Objective Loss 0.023879                                        LR 0.010000    Time 0.652362    
2024-01-15 18:13:07,856 - Epoch: [111][  130/  211]    Overall Loss 0.023764    Objective Loss 0.023764                                        LR 0.010000    Time 0.652389    
2024-01-15 18:13:14,268 - Epoch: [111][  140/  211]    Overall Loss 0.024065    Objective Loss 0.024065                                        LR 0.010000    Time 0.651579    
2024-01-15 18:13:20,447 - Epoch: [111][  150/  211]    Overall Loss 0.024273    Objective Loss 0.024273                                        LR 0.010000    Time 0.649320    
2024-01-15 18:13:26,127 - Epoch: [111][  160/  211]    Overall Loss 0.024252    Objective Loss 0.024252                                        LR 0.010000    Time 0.644234    
2024-01-15 18:13:32,714 - Epoch: [111][  170/  211]    Overall Loss 0.024296    Objective Loss 0.024296                                        LR 0.010000    Time 0.645076    
2024-01-15 18:13:38,408 - Epoch: [111][  180/  211]    Overall Loss 0.024521    Objective Loss 0.024521                                        LR 0.010000    Time 0.640867    
2024-01-15 18:13:44,199 - Epoch: [111][  190/  211]    Overall Loss 0.024526    Objective Loss 0.024526                                        LR 0.010000    Time 0.637586    
2024-01-15 18:13:49,853 - Epoch: [111][  200/  211]    Overall Loss 0.024425    Objective Loss 0.024425                                        LR 0.010000    Time 0.633963    
2024-01-15 18:13:55,826 - Epoch: [111][  210/  211]    Overall Loss 0.024207    Objective Loss 0.024207    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 0.632209    
2024-01-15 18:13:56,393 - Epoch: [111][  211/  211]    Overall Loss 0.024218    Objective Loss 0.024218    Top1 99.596774    Top5 100.000000    LR 0.010000    Time 0.631899    
2024-01-15 18:13:57,228 - --- validate (epoch=111)-----------
2024-01-15 18:13:57,229 - 6000 samples (256 per mini-batch)
2024-01-15 18:14:05,416 - Epoch: [111][   10/   24]    Loss 0.036941    Top1 98.906250    Top5 100.000000    
2024-01-15 18:14:07,955 - Epoch: [111][   20/   24]    Loss 0.031477    Top1 99.062500    Top5 100.000000    
2024-01-15 18:14:08,836 - Epoch: [111][   24/   24]    Loss 0.029956    Top1 99.116667    Top5 100.000000    
2024-01-15 18:14:09,645 - ==> Top1: 99.117    Top5: 100.000    Loss: 0.030

2024-01-15 18:14:09,646 - ==> Confusion:
[[601   0   2   0   0   0   1   0   0   1]
 [  0 685   1   0   1   1   0   0   0   0]
 [  0   1 582   0   0   0   0   2   0   1]
 [  0   0   1 578   0   2   0   2   0   0]
 [  0   0   1   0 557   0   1   0   0   6]
 [  1   1   0   0   0 513   2   0   1   0]
 [  2   0   0   0   1   0 626   0   2   0]
 [  0   3   1   0   0   0   0 621   0   0]
 [  1   0   0   2   0   1   0   0 579   1]
 [  1   1   0   0   2   2   0   2   2 605]]

2024-01-15 18:14:09,649 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:14:09,650 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:14:09,658 - 

2024-01-15 18:14:09,658 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:14:20,275 - Epoch: [112][   10/  211]    Overall Loss 0.024161    Objective Loss 0.024161                                        LR 0.010000    Time 1.061603    
2024-01-15 18:14:26,375 - Epoch: [112][   20/  211]    Overall Loss 0.025894    Objective Loss 0.025894                                        LR 0.010000    Time 0.835722    
2024-01-15 18:14:32,623 - Epoch: [112][   30/  211]    Overall Loss 0.025531    Objective Loss 0.025531                                        LR 0.010000    Time 0.765382    
2024-01-15 18:14:38,566 - Epoch: [112][   40/  211]    Overall Loss 0.025625    Objective Loss 0.025625                                        LR 0.010000    Time 0.722563    
2024-01-15 18:14:44,504 - Epoch: [112][   50/  211]    Overall Loss 0.025017    Objective Loss 0.025017                                        LR 0.010000    Time 0.696789    
2024-01-15 18:14:50,671 - Epoch: [112][   60/  211]    Overall Loss 0.024764    Objective Loss 0.024764                                        LR 0.010000    Time 0.683420    
2024-01-15 18:14:56,965 - Epoch: [112][   70/  211]    Overall Loss 0.024070    Objective Loss 0.024070                                        LR 0.010000    Time 0.675682    
2024-01-15 18:15:03,777 - Epoch: [112][   80/  211]    Overall Loss 0.024110    Objective Loss 0.024110                                        LR 0.010000    Time 0.676351    
2024-01-15 18:15:10,327 - Epoch: [112][   90/  211]    Overall Loss 0.024008    Objective Loss 0.024008                                        LR 0.010000    Time 0.673957    
2024-01-15 18:15:16,265 - Epoch: [112][  100/  211]    Overall Loss 0.023633    Objective Loss 0.023633                                        LR 0.010000    Time 0.665924    
2024-01-15 18:15:22,471 - Epoch: [112][  110/  211]    Overall Loss 0.024025    Objective Loss 0.024025                                        LR 0.010000    Time 0.661795    
2024-01-15 18:15:30,301 - Epoch: [112][  120/  211]    Overall Loss 0.023880    Objective Loss 0.023880                                        LR 0.010000    Time 0.671856    
2024-01-15 18:15:39,139 - Epoch: [112][  130/  211]    Overall Loss 0.023897    Objective Loss 0.023897                                        LR 0.010000    Time 0.688143    
2024-01-15 18:15:46,151 - Epoch: [112][  140/  211]    Overall Loss 0.024051    Objective Loss 0.024051                                        LR 0.010000    Time 0.689067    
2024-01-15 18:15:52,427 - Epoch: [112][  150/  211]    Overall Loss 0.024118    Objective Loss 0.024118                                        LR 0.010000    Time 0.684962    
2024-01-15 18:15:58,486 - Epoch: [112][  160/  211]    Overall Loss 0.024402    Objective Loss 0.024402                                        LR 0.010000    Time 0.680017    
2024-01-15 18:16:04,465 - Epoch: [112][  170/  211]    Overall Loss 0.024461    Objective Loss 0.024461                                        LR 0.010000    Time 0.675181    
2024-01-15 18:16:10,605 - Epoch: [112][  180/  211]    Overall Loss 0.024494    Objective Loss 0.024494                                        LR 0.010000    Time 0.671777    
2024-01-15 18:16:16,656 - Epoch: [112][  190/  211]    Overall Loss 0.024744    Objective Loss 0.024744                                        LR 0.010000    Time 0.668256    
2024-01-15 18:16:22,622 - Epoch: [112][  200/  211]    Overall Loss 0.024590    Objective Loss 0.024590                                        LR 0.010000    Time 0.664669    
2024-01-15 18:16:29,045 - Epoch: [112][  210/  211]    Overall Loss 0.024564    Objective Loss 0.024564    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 0.663599    
2024-01-15 18:16:29,724 - Epoch: [112][  211/  211]    Overall Loss 0.024684    Objective Loss 0.024684    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.663671    
2024-01-15 18:16:31,005 - --- validate (epoch=112)-----------
2024-01-15 18:16:31,007 - 6000 samples (256 per mini-batch)
2024-01-15 18:16:38,634 - Epoch: [112][   10/   24]    Loss 0.032613    Top1 99.062500    Top5 100.000000    
2024-01-15 18:16:40,964 - Epoch: [112][   20/   24]    Loss 0.030532    Top1 99.101562    Top5 100.000000    
2024-01-15 18:16:41,815 - Epoch: [112][   24/   24]    Loss 0.029314    Top1 99.166667    Top5 100.000000    
2024-01-15 18:16:42,643 - ==> Top1: 99.167    Top5: 100.000    Loss: 0.029

2024-01-15 18:16:42,644 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   0 585   0   0   0   0   1   0   0]
 [  0   0   2 578   0   1   0   0   2   0]
 [  0   0   1   0 557   0   0   1   0   6]
 [  0   1   1   0   0 510   5   0   0   1]
 [  2   1   0   0   1   0 627   0   0   0]
 [  0   1   1   0   0   0   0 623   0   0]
 [  0   0   1   1   0   1   3   0 577   1]
 [  2   1   0   0   3   1   0   2   2 604]]

2024-01-15 18:16:42,647 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:16:42,648 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:16:42,654 - 

2024-01-15 18:16:42,654 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:16:52,586 - Epoch: [113][   10/  211]    Overall Loss 0.024145    Objective Loss 0.024145                                        LR 0.010000    Time 0.993104    
2024-01-15 18:16:58,544 - Epoch: [113][   20/  211]    Overall Loss 0.025510    Objective Loss 0.025510                                        LR 0.010000    Time 0.794377    
2024-01-15 18:17:04,910 - Epoch: [113][   30/  211]    Overall Loss 0.027454    Objective Loss 0.027454                                        LR 0.010000    Time 0.741764    
2024-01-15 18:17:11,084 - Epoch: [113][   40/  211]    Overall Loss 0.025186    Objective Loss 0.025186                                        LR 0.010000    Time 0.710617    
2024-01-15 18:17:17,480 - Epoch: [113][   50/  211]    Overall Loss 0.025175    Objective Loss 0.025175                                        LR 0.010000    Time 0.696394    
2024-01-15 18:17:24,152 - Epoch: [113][   60/  211]    Overall Loss 0.025165    Objective Loss 0.025165                                        LR 0.010000    Time 0.691506    
2024-01-15 18:17:30,716 - Epoch: [113][   70/  211]    Overall Loss 0.023882    Objective Loss 0.023882                                        LR 0.010000    Time 0.686460    
2024-01-15 18:17:36,881 - Epoch: [113][   80/  211]    Overall Loss 0.024055    Objective Loss 0.024055                                        LR 0.010000    Time 0.677697    
2024-01-15 18:17:43,001 - Epoch: [113][   90/  211]    Overall Loss 0.024422    Objective Loss 0.024422                                        LR 0.010000    Time 0.670386    
2024-01-15 18:17:49,320 - Epoch: [113][  100/  211]    Overall Loss 0.024480    Objective Loss 0.024480                                        LR 0.010000    Time 0.666522    
2024-01-15 18:17:55,361 - Epoch: [113][  110/  211]    Overall Loss 0.024695    Objective Loss 0.024695                                        LR 0.010000    Time 0.660832    
2024-01-15 18:18:02,020 - Epoch: [113][  120/  211]    Overall Loss 0.024494    Objective Loss 0.024494                                        LR 0.010000    Time 0.661246    
2024-01-15 18:18:09,370 - Epoch: [113][  130/  211]    Overall Loss 0.024944    Objective Loss 0.024944                                        LR 0.010000    Time 0.666901    
2024-01-15 18:18:15,765 - Epoch: [113][  140/  211]    Overall Loss 0.025539    Objective Loss 0.025539                                        LR 0.010000    Time 0.664930    
2024-01-15 18:18:22,458 - Epoch: [113][  150/  211]    Overall Loss 0.024975    Objective Loss 0.024975                                        LR 0.010000    Time 0.665205    
2024-01-15 18:18:29,209 - Epoch: [113][  160/  211]    Overall Loss 0.024738    Objective Loss 0.024738                                        LR 0.010000    Time 0.665810    
2024-01-15 18:18:35,575 - Epoch: [113][  170/  211]    Overall Loss 0.025715    Objective Loss 0.025715                                        LR 0.010000    Time 0.664087    
2024-01-15 18:18:41,886 - Epoch: [113][  180/  211]    Overall Loss 0.025542    Objective Loss 0.025542                                        LR 0.010000    Time 0.662246    
2024-01-15 18:18:48,101 - Epoch: [113][  190/  211]    Overall Loss 0.025552    Objective Loss 0.025552                                        LR 0.010000    Time 0.660094    
2024-01-15 18:18:54,635 - Epoch: [113][  200/  211]    Overall Loss 0.025650    Objective Loss 0.025650                                        LR 0.010000    Time 0.659750    
2024-01-15 18:19:01,326 - Epoch: [113][  210/  211]    Overall Loss 0.025321    Objective Loss 0.025321    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.660188    
2024-01-15 18:19:01,913 - Epoch: [113][  211/  211]    Overall Loss 0.025319    Objective Loss 0.025319    Top1 99.193548    Top5 100.000000    LR 0.010000    Time 0.659842    
2024-01-15 18:19:02,932 - --- validate (epoch=113)-----------
2024-01-15 18:19:02,935 - 6000 samples (256 per mini-batch)
2024-01-15 18:19:09,967 - Epoch: [113][   10/   24]    Loss 0.034741    Top1 99.023438    Top5 100.000000    
2024-01-15 18:19:12,246 - Epoch: [113][   20/   24]    Loss 0.033885    Top1 98.945312    Top5 100.000000    
2024-01-15 18:19:13,109 - Epoch: [113][   24/   24]    Loss 0.030612    Top1 99.000000    Top5 100.000000    
2024-01-15 18:19:13,802 - ==> Top1: 99.000    Top5: 100.000    Loss: 0.031

2024-01-15 18:19:13,804 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 686   0   0   0   0   1   1   0   0]
 [  0   0 578   2   0   0   0   4   2   0]
 [  0   0   2 578   0   1   0   1   1   0]
 [  0   0   1   0 551   0   2   2   0   9]
 [  0   0   0   1   0 514   3   0   0   0]
 [  0   2   0   0   1   1 626   0   1   0]
 [  0   3   2   1   0   0   0 619   0   0]
 [  0   0   0   2   1   1   1   0 579   0]
 [  0   1   0   0   2   0   0   3   2 607]]

2024-01-15 18:19:13,806 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:19:13,807 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:19:13,813 - 

2024-01-15 18:19:13,813 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:19:23,305 - Epoch: [114][   10/  211]    Overall Loss 0.026344    Objective Loss 0.026344                                        LR 0.010000    Time 0.949033    
2024-01-15 18:19:29,408 - Epoch: [114][   20/  211]    Overall Loss 0.026312    Objective Loss 0.026312                                        LR 0.010000    Time 0.779554    
2024-01-15 18:19:35,303 - Epoch: [114][   30/  211]    Overall Loss 0.024603    Objective Loss 0.024603                                        LR 0.010000    Time 0.716184    
2024-01-15 18:19:41,414 - Epoch: [114][   40/  211]    Overall Loss 0.027193    Objective Loss 0.027193                                        LR 0.010000    Time 0.689899    
2024-01-15 18:19:47,395 - Epoch: [114][   50/  211]    Overall Loss 0.027008    Objective Loss 0.027008                                        LR 0.010000    Time 0.671522    
2024-01-15 18:19:53,348 - Epoch: [114][   60/  211]    Overall Loss 0.026818    Objective Loss 0.026818                                        LR 0.010000    Time 0.658788    
2024-01-15 18:19:59,279 - Epoch: [114][   70/  211]    Overall Loss 0.026076    Objective Loss 0.026076                                        LR 0.010000    Time 0.649400    
2024-01-15 18:20:05,195 - Epoch: [114][   80/  211]    Overall Loss 0.025430    Objective Loss 0.025430                                        LR 0.010000    Time 0.642147    
2024-01-15 18:20:11,075 - Epoch: [114][   90/  211]    Overall Loss 0.024557    Objective Loss 0.024557                                        LR 0.010000    Time 0.636134    
2024-01-15 18:20:17,001 - Epoch: [114][  100/  211]    Overall Loss 0.024262    Objective Loss 0.024262                                        LR 0.010000    Time 0.631764    
2024-01-15 18:20:23,065 - Epoch: [114][  110/  211]    Overall Loss 0.024022    Objective Loss 0.024022                                        LR 0.010000    Time 0.629452    
2024-01-15 18:20:29,301 - Epoch: [114][  120/  211]    Overall Loss 0.024034    Objective Loss 0.024034                                        LR 0.010000    Time 0.628961    
2024-01-15 18:20:35,305 - Epoch: [114][  130/  211]    Overall Loss 0.023888    Objective Loss 0.023888                                        LR 0.010000    Time 0.626754    
2024-01-15 18:20:41,628 - Epoch: [114][  140/  211]    Overall Loss 0.023676    Objective Loss 0.023676                                        LR 0.010000    Time 0.627141    
2024-01-15 18:20:48,113 - Epoch: [114][  150/  211]    Overall Loss 0.024106    Objective Loss 0.024106                                        LR 0.010000    Time 0.628553    
2024-01-15 18:20:54,691 - Epoch: [114][  160/  211]    Overall Loss 0.024191    Objective Loss 0.024191                                        LR 0.010000    Time 0.630374    
2024-01-15 18:21:01,288 - Epoch: [114][  170/  211]    Overall Loss 0.024415    Objective Loss 0.024415                                        LR 0.010000    Time 0.632066    
2024-01-15 18:21:07,218 - Epoch: [114][  180/  211]    Overall Loss 0.024267    Objective Loss 0.024267                                        LR 0.010000    Time 0.629884    
2024-01-15 18:21:13,113 - Epoch: [114][  190/  211]    Overall Loss 0.024200    Objective Loss 0.024200                                        LR 0.010000    Time 0.627755    
2024-01-15 18:21:19,220 - Epoch: [114][  200/  211]    Overall Loss 0.024127    Objective Loss 0.024127                                        LR 0.010000    Time 0.626901    
2024-01-15 18:21:25,307 - Epoch: [114][  210/  211]    Overall Loss 0.024129    Objective Loss 0.024129    Top1 98.828125    Top5 100.000000    LR 0.010000    Time 0.626028    
2024-01-15 18:21:25,903 - Epoch: [114][  211/  211]    Overall Loss 0.024072    Objective Loss 0.024072    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.625880    
2024-01-15 18:21:26,832 - --- validate (epoch=114)-----------
2024-01-15 18:21:26,834 - 6000 samples (256 per mini-batch)
2024-01-15 18:21:34,457 - Epoch: [114][   10/   24]    Loss 0.031987    Top1 99.179688    Top5 100.000000    
2024-01-15 18:21:37,534 - Epoch: [114][   20/   24]    Loss 0.030844    Top1 99.238281    Top5 100.000000    
2024-01-15 18:21:38,452 - Epoch: [114][   24/   24]    Loss 0.029520    Top1 99.200000    Top5 100.000000    
2024-01-15 18:21:39,282 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.030

2024-01-15 18:21:39,284 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  1   0 583   0   0   0   0   2   0   0]
 [  0   0   3 576   0   1   0   2   1   0]
 [  0   0   0   0 562   0   0   0   0   3]
 [  1   0   0   1   0 513   2   0   1   0]
 [  2   1   0   0   1   0 627   0   0   0]
 [  0   1   1   0   0   0   0 623   0   0]
 [  0   0   2   0   0   1   2   0 579   0]
 [  0   1   0   0   7   1   0   4   2 600]]

2024-01-15 18:21:39,288 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:21:39,288 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:21:39,295 - 

2024-01-15 18:21:39,295 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:21:49,712 - Epoch: [115][   10/  211]    Overall Loss 0.022193    Objective Loss 0.022193                                        LR 0.010000    Time 1.041590    
2024-01-15 18:21:56,115 - Epoch: [115][   20/  211]    Overall Loss 0.024836    Objective Loss 0.024836                                        LR 0.010000    Time 0.840851    
2024-01-15 18:22:02,080 - Epoch: [115][   30/  211]    Overall Loss 0.023697    Objective Loss 0.023697                                        LR 0.010000    Time 0.759357    
2024-01-15 18:22:08,003 - Epoch: [115][   40/  211]    Overall Loss 0.023984    Objective Loss 0.023984                                        LR 0.010000    Time 0.717562    
2024-01-15 18:22:14,073 - Epoch: [115][   50/  211]    Overall Loss 0.024666    Objective Loss 0.024666                                        LR 0.010000    Time 0.695440    
2024-01-15 18:22:19,983 - Epoch: [115][   60/  211]    Overall Loss 0.024033    Objective Loss 0.024033                                        LR 0.010000    Time 0.678009    
2024-01-15 18:22:25,750 - Epoch: [115][   70/  211]    Overall Loss 0.023533    Objective Loss 0.023533                                        LR 0.010000    Time 0.663501    
2024-01-15 18:22:31,874 - Epoch: [115][   80/  211]    Overall Loss 0.024025    Objective Loss 0.024025                                        LR 0.010000    Time 0.657087    
2024-01-15 18:22:37,813 - Epoch: [115][   90/  211]    Overall Loss 0.024222    Objective Loss 0.024222                                        LR 0.010000    Time 0.650049    
2024-01-15 18:22:43,578 - Epoch: [115][  100/  211]    Overall Loss 0.024306    Objective Loss 0.024306                                        LR 0.010000    Time 0.642684    
2024-01-15 18:22:49,396 - Epoch: [115][  110/  211]    Overall Loss 0.024517    Objective Loss 0.024517                                        LR 0.010000    Time 0.637138    
2024-01-15 18:22:55,758 - Epoch: [115][  120/  211]    Overall Loss 0.024456    Objective Loss 0.024456                                        LR 0.010000    Time 0.637046    
2024-01-15 18:23:01,418 - Epoch: [115][  130/  211]    Overall Loss 0.024514    Objective Loss 0.024514                                        LR 0.010000    Time 0.631580    
2024-01-15 18:23:07,775 - Epoch: [115][  140/  211]    Overall Loss 0.024254    Objective Loss 0.024254                                        LR 0.010000    Time 0.631862    
2024-01-15 18:23:13,747 - Epoch: [115][  150/  211]    Overall Loss 0.024028    Objective Loss 0.024028                                        LR 0.010000    Time 0.629537    
2024-01-15 18:23:20,176 - Epoch: [115][  160/  211]    Overall Loss 0.023880    Objective Loss 0.023880                                        LR 0.010000    Time 0.630370    
2024-01-15 18:23:26,384 - Epoch: [115][  170/  211]    Overall Loss 0.023829    Objective Loss 0.023829                                        LR 0.010000    Time 0.629794    
2024-01-15 18:23:32,914 - Epoch: [115][  180/  211]    Overall Loss 0.023999    Objective Loss 0.023999                                        LR 0.010000    Time 0.631081    
2024-01-15 18:23:39,222 - Epoch: [115][  190/  211]    Overall Loss 0.023842    Objective Loss 0.023842                                        LR 0.010000    Time 0.631059    
2024-01-15 18:23:45,148 - Epoch: [115][  200/  211]    Overall Loss 0.023601    Objective Loss 0.023601                                        LR 0.010000    Time 0.629133    
2024-01-15 18:23:51,122 - Epoch: [115][  210/  211]    Overall Loss 0.023665    Objective Loss 0.023665    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.627617    
2024-01-15 18:23:51,715 - Epoch: [115][  211/  211]    Overall Loss 0.023636    Objective Loss 0.023636    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.627450    
2024-01-15 18:23:52,517 - --- validate (epoch=115)-----------
2024-01-15 18:23:52,518 - 6000 samples (256 per mini-batch)
2024-01-15 18:23:59,416 - Epoch: [115][   10/   24]    Loss 0.027667    Top1 99.101562    Top5 100.000000    
2024-01-15 18:24:01,550 - Epoch: [115][   20/   24]    Loss 0.028739    Top1 99.121094    Top5 99.980469    
2024-01-15 18:24:02,298 - Epoch: [115][   24/   24]    Loss 0.028794    Top1 99.133333    Top5 99.983333    
2024-01-15 18:24:02,951 - ==> Top1: 99.133    Top5: 99.983    Loss: 0.029

2024-01-15 18:24:02,952 - ==> Confusion:
[[602   0   1   1   0   0   0   0   0   1]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 584   1   0   0   1   0   0   0]
 [  0   0   0 580   0   1   0   0   2   0]
 [  0   0   0   0 558   0   1   2   0   4]
 [  0   0   0   1   0 512   4   0   1   0]
 [  3   1   0   0   2   1 624   0   0   0]
 [  1   3   0   1   0   0   0 620   0   0]
 [  0   0   0   0   1   2   2   0 578   1]
 [  1   1   0   0   3   1   0   2   3 604]]

2024-01-15 18:24:02,954 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:24:02,955 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:24:02,959 - 

2024-01-15 18:24:02,959 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:24:11,893 - Epoch: [116][   10/  211]    Overall Loss 0.024497    Objective Loss 0.024497                                        LR 0.010000    Time 0.893339    
2024-01-15 18:24:17,680 - Epoch: [116][   20/  211]    Overall Loss 0.023016    Objective Loss 0.023016                                        LR 0.010000    Time 0.735897    
2024-01-15 18:24:23,611 - Epoch: [116][   30/  211]    Overall Loss 0.023133    Objective Loss 0.023133                                        LR 0.010000    Time 0.688249    
2024-01-15 18:24:29,470 - Epoch: [116][   40/  211]    Overall Loss 0.022081    Objective Loss 0.022081                                        LR 0.010000    Time 0.662631    
2024-01-15 18:24:35,217 - Epoch: [116][   50/  211]    Overall Loss 0.022700    Objective Loss 0.022700                                        LR 0.010000    Time 0.645016    
2024-01-15 18:24:40,851 - Epoch: [116][   60/  211]    Overall Loss 0.022462    Objective Loss 0.022462                                        LR 0.010000    Time 0.631403    
2024-01-15 18:24:46,506 - Epoch: [116][   70/  211]    Overall Loss 0.022588    Objective Loss 0.022588                                        LR 0.010000    Time 0.621965    
2024-01-15 18:24:52,143 - Epoch: [116][   80/  211]    Overall Loss 0.022831    Objective Loss 0.022831                                        LR 0.010000    Time 0.614683    
2024-01-15 18:24:57,949 - Epoch: [116][   90/  211]    Overall Loss 0.023870    Objective Loss 0.023870                                        LR 0.010000    Time 0.610884    
2024-01-15 18:25:03,728 - Epoch: [116][  100/  211]    Overall Loss 0.023357    Objective Loss 0.023357                                        LR 0.010000    Time 0.607565    
2024-01-15 18:25:09,556 - Epoch: [116][  110/  211]    Overall Loss 0.023137    Objective Loss 0.023137                                        LR 0.010000    Time 0.605305    
2024-01-15 18:25:15,512 - Epoch: [116][  120/  211]    Overall Loss 0.023352    Objective Loss 0.023352                                        LR 0.010000    Time 0.604490    
2024-01-15 18:25:21,518 - Epoch: [116][  130/  211]    Overall Loss 0.023358    Objective Loss 0.023358                                        LR 0.010000    Time 0.604178    
2024-01-15 18:25:27,279 - Epoch: [116][  140/  211]    Overall Loss 0.023323    Objective Loss 0.023323                                        LR 0.010000    Time 0.602164    
2024-01-15 18:25:33,636 - Epoch: [116][  150/  211]    Overall Loss 0.023324    Objective Loss 0.023324                                        LR 0.010000    Time 0.604394    
2024-01-15 18:25:39,342 - Epoch: [116][  160/  211]    Overall Loss 0.023170    Objective Loss 0.023170                                        LR 0.010000    Time 0.602272    
2024-01-15 18:25:45,213 - Epoch: [116][  170/  211]    Overall Loss 0.023068    Objective Loss 0.023068                                        LR 0.010000    Time 0.601376    
2024-01-15 18:25:50,876 - Epoch: [116][  180/  211]    Overall Loss 0.023108    Objective Loss 0.023108                                        LR 0.010000    Time 0.599420    
2024-01-15 18:25:56,565 - Epoch: [116][  190/  211]    Overall Loss 0.023116    Objective Loss 0.023116                                        LR 0.010000    Time 0.597810    
2024-01-15 18:26:02,452 - Epoch: [116][  200/  211]    Overall Loss 0.023187    Objective Loss 0.023187                                        LR 0.010000    Time 0.597349    
2024-01-15 18:26:08,205 - Epoch: [116][  210/  211]    Overall Loss 0.023069    Objective Loss 0.023069    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 0.596292    
2024-01-15 18:26:08,887 - Epoch: [116][  211/  211]    Overall Loss 0.023086    Objective Loss 0.023086    Top1 99.596774    Top5 100.000000    LR 0.010000    Time 0.596697    
2024-01-15 18:26:09,724 - --- validate (epoch=116)-----------
2024-01-15 18:26:09,725 - 6000 samples (256 per mini-batch)
2024-01-15 18:26:16,531 - Epoch: [116][   10/   24]    Loss 0.023120    Top1 99.375000    Top5 100.000000    
2024-01-15 18:26:18,772 - Epoch: [116][   20/   24]    Loss 0.027701    Top1 99.218750    Top5 100.000000    
2024-01-15 18:26:19,570 - Epoch: [116][   24/   24]    Loss 0.028850    Top1 99.233333    Top5 100.000000    
2024-01-15 18:26:20,143 - ==> Top1: 99.233    Top5: 100.000    Loss: 0.029

2024-01-15 18:26:20,144 - ==> Confusion:
[[603   0   0   0   0   0   1   0   1   0]
 [  0 684   1   1   1   0   0   1   0   0]
 [  0   0 585   0   0   0   0   1   0   0]
 [  0   0   2 579   0   1   0   1   0   0]
 [  0   0   0   0 558   0   0   2   0   5]
 [  0   0   0   1   0 511   5   0   1   0]
 [  0   0   0   0   2   0 629   0   0   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   1   1   0   0   2   0 580   0]
 [  1   1   0   0   4   2   0   2   4 601]]

2024-01-15 18:26:20,146 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:26:20,146 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:26:20,150 - 

2024-01-15 18:26:20,150 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:26:28,632 - Epoch: [117][   10/  211]    Overall Loss 0.026665    Objective Loss 0.026665                                        LR 0.010000    Time 0.848101    
2024-01-15 18:26:34,408 - Epoch: [117][   20/  211]    Overall Loss 0.024457    Objective Loss 0.024457                                        LR 0.010000    Time 0.712762    
2024-01-15 18:26:40,065 - Epoch: [117][   30/  211]    Overall Loss 0.026585    Objective Loss 0.026585                                        LR 0.010000    Time 0.663702    
2024-01-15 18:26:45,804 - Epoch: [117][   40/  211]    Overall Loss 0.026363    Objective Loss 0.026363                                        LR 0.010000    Time 0.641259    
2024-01-15 18:26:51,453 - Epoch: [117][   50/  211]    Overall Loss 0.025692    Objective Loss 0.025692                                        LR 0.010000    Time 0.625955    
2024-01-15 18:26:57,354 - Epoch: [117][   60/  211]    Overall Loss 0.025791    Objective Loss 0.025791                                        LR 0.010000    Time 0.619972    
2024-01-15 18:27:03,148 - Epoch: [117][   70/  211]    Overall Loss 0.025334    Objective Loss 0.025334                                        LR 0.010000    Time 0.614162    
2024-01-15 18:27:08,814 - Epoch: [117][   80/  211]    Overall Loss 0.025715    Objective Loss 0.025715                                        LR 0.010000    Time 0.608207    
2024-01-15 18:27:14,444 - Epoch: [117][   90/  211]    Overall Loss 0.025425    Objective Loss 0.025425                                        LR 0.010000    Time 0.603183    
2024-01-15 18:27:20,079 - Epoch: [117][  100/  211]    Overall Loss 0.025586    Objective Loss 0.025586                                        LR 0.010000    Time 0.599203    
2024-01-15 18:27:25,733 - Epoch: [117][  110/  211]    Overall Loss 0.024831    Objective Loss 0.024831                                        LR 0.010000    Time 0.596126    
2024-01-15 18:27:31,572 - Epoch: [117][  120/  211]    Overall Loss 0.024658    Objective Loss 0.024658                                        LR 0.010000    Time 0.595103    
2024-01-15 18:27:37,214 - Epoch: [117][  130/  211]    Overall Loss 0.024904    Objective Loss 0.024904                                        LR 0.010000    Time 0.592711    
2024-01-15 18:27:42,889 - Epoch: [117][  140/  211]    Overall Loss 0.025092    Objective Loss 0.025092                                        LR 0.010000    Time 0.590906    
2024-01-15 18:27:48,524 - Epoch: [117][  150/  211]    Overall Loss 0.025285    Objective Loss 0.025285                                        LR 0.010000    Time 0.589075    
2024-01-15 18:27:54,158 - Epoch: [117][  160/  211]    Overall Loss 0.025066    Objective Loss 0.025066                                        LR 0.010000    Time 0.587468    
2024-01-15 18:27:59,810 - Epoch: [117][  170/  211]    Overall Loss 0.025062    Objective Loss 0.025062                                        LR 0.010000    Time 0.586147    
2024-01-15 18:28:05,577 - Epoch: [117][  180/  211]    Overall Loss 0.025070    Objective Loss 0.025070                                        LR 0.010000    Time 0.585622    
2024-01-15 18:28:11,219 - Epoch: [117][  190/  211]    Overall Loss 0.024821    Objective Loss 0.024821                                        LR 0.010000    Time 0.584487    
2024-01-15 18:28:16,875 - Epoch: [117][  200/  211]    Overall Loss 0.024625    Objective Loss 0.024625                                        LR 0.010000    Time 0.583540    
2024-01-15 18:28:22,568 - Epoch: [117][  210/  211]    Overall Loss 0.024478    Objective Loss 0.024478    Top1 98.437500    Top5 100.000000    LR 0.010000    Time 0.582855    
2024-01-15 18:28:23,155 - Epoch: [117][  211/  211]    Overall Loss 0.024545    Objective Loss 0.024545    Top1 98.588710    Top5 100.000000    LR 0.010000    Time 0.582870    
2024-01-15 18:28:23,738 - --- validate (epoch=117)-----------
2024-01-15 18:28:23,739 - 6000 samples (256 per mini-batch)
2024-01-15 18:28:29,952 - Epoch: [117][   10/   24]    Loss 0.031357    Top1 99.140625    Top5 100.000000    
2024-01-15 18:28:32,061 - Epoch: [117][   20/   24]    Loss 0.028109    Top1 99.218750    Top5 100.000000    
2024-01-15 18:28:32,817 - Epoch: [117][   24/   24]    Loss 0.029491    Top1 99.200000    Top5 100.000000    
2024-01-15 18:28:33,560 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.029

2024-01-15 18:28:33,561 - ==> Confusion:
[[605   0   0   0   0   0   0   0   0   0]
 [  0 684   2   0   0   1   0   1   0   0]
 [  0   1 580   0   0   0   1   3   1   0]
 [  0   0   0 578   0   2   0   1   2   0]
 [  1   0   1   0 557   0   0   2   1   3]
 [  0   0   0   1   1 512   2   0   2   0]
 [  2   0   0   0   1   0 628   0   0   0]
 [  0   3   0   0   0   0   0 622   0   0]
 [  1   0   0   1   2   0   1   0 579   0]
 [  0   0   0   0   5   0   0   1   2 607]]

2024-01-15 18:28:33,564 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:28:33,564 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:28:33,569 - 

2024-01-15 18:28:33,569 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:28:42,455 - Epoch: [118][   10/  211]    Overall Loss 0.017091    Objective Loss 0.017091                                        LR 0.010000    Time 0.888551    
2024-01-15 18:28:48,091 - Epoch: [118][   20/  211]    Overall Loss 0.017821    Objective Loss 0.017821                                        LR 0.010000    Time 0.725982    
2024-01-15 18:28:53,834 - Epoch: [118][   30/  211]    Overall Loss 0.019815    Objective Loss 0.019815                                        LR 0.010000    Time 0.675405    
2024-01-15 18:28:59,669 - Epoch: [118][   40/  211]    Overall Loss 0.020950    Objective Loss 0.020950                                        LR 0.010000    Time 0.652404    
2024-01-15 18:29:05,493 - Epoch: [118][   50/  211]    Overall Loss 0.022782    Objective Loss 0.022782                                        LR 0.010000    Time 0.638375    
2024-01-15 18:29:11,132 - Epoch: [118][   60/  211]    Overall Loss 0.023224    Objective Loss 0.023224                                        LR 0.010000    Time 0.625956    
2024-01-15 18:29:16,764 - Epoch: [118][   70/  211]    Overall Loss 0.024424    Objective Loss 0.024424                                        LR 0.010000    Time 0.616976    
2024-01-15 18:29:22,467 - Epoch: [118][   80/  211]    Overall Loss 0.024234    Objective Loss 0.024234                                        LR 0.010000    Time 0.611137    
2024-01-15 18:29:28,219 - Epoch: [118][   90/  211]    Overall Loss 0.025054    Objective Loss 0.025054                                        LR 0.010000    Time 0.607127    
2024-01-15 18:29:33,860 - Epoch: [118][  100/  211]    Overall Loss 0.025060    Objective Loss 0.025060                                        LR 0.010000    Time 0.602819    
2024-01-15 18:29:39,514 - Epoch: [118][  110/  211]    Overall Loss 0.024880    Objective Loss 0.024880                                        LR 0.010000    Time 0.599411    
2024-01-15 18:29:47,118 - Epoch: [118][  120/  211]    Overall Loss 0.024810    Objective Loss 0.024810                                        LR 0.010000    Time 0.612811    
2024-01-15 18:29:53,198 - Epoch: [118][  130/  211]    Overall Loss 0.025291    Objective Loss 0.025291                                        LR 0.010000    Time 0.612431    
2024-01-15 18:29:59,852 - Epoch: [118][  140/  211]    Overall Loss 0.026217    Objective Loss 0.026217                                        LR 0.010000    Time 0.616209    
2024-01-15 18:30:06,047 - Epoch: [118][  150/  211]    Overall Loss 0.026083    Objective Loss 0.026083                                        LR 0.010000    Time 0.616417    
2024-01-15 18:30:11,767 - Epoch: [118][  160/  211]    Overall Loss 0.025791    Objective Loss 0.025791                                        LR 0.010000    Time 0.613636    
2024-01-15 18:30:17,461 - Epoch: [118][  170/  211]    Overall Loss 0.025369    Objective Loss 0.025369                                        LR 0.010000    Time 0.611034    
2024-01-15 18:30:24,018 - Epoch: [118][  180/  211]    Overall Loss 0.024905    Objective Loss 0.024905                                        LR 0.010000    Time 0.613502    
2024-01-15 18:30:30,973 - Epoch: [118][  190/  211]    Overall Loss 0.024439    Objective Loss 0.024439                                        LR 0.010000    Time 0.617800    
2024-01-15 18:30:37,255 - Epoch: [118][  200/  211]    Overall Loss 0.024227    Objective Loss 0.024227                                        LR 0.010000    Time 0.618308    
2024-01-15 18:30:43,764 - Epoch: [118][  210/  211]    Overall Loss 0.024274    Objective Loss 0.024274    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 0.619851    
2024-01-15 18:30:44,400 - Epoch: [118][  211/  211]    Overall Loss 0.024202    Objective Loss 0.024202    Top1 99.798387    Top5 100.000000    LR 0.010000    Time 0.619923    
2024-01-15 18:30:45,656 - --- validate (epoch=118)-----------
2024-01-15 18:30:45,658 - 6000 samples (256 per mini-batch)
2024-01-15 18:30:53,124 - Epoch: [118][   10/   24]    Loss 0.027195    Top1 99.101562    Top5 100.000000    
2024-01-15 18:30:55,229 - Epoch: [118][   20/   24]    Loss 0.028194    Top1 99.121094    Top5 100.000000    
2024-01-15 18:30:56,162 - Epoch: [118][   24/   24]    Loss 0.028762    Top1 99.100000    Top5 100.000000    
2024-01-15 18:30:57,120 - ==> Top1: 99.100    Top5: 100.000    Loss: 0.029

2024-01-15 18:30:57,122 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 685   1   0   1   1   0   0   0   0]
 [  0   0 578   2   0   0   0   2   3   1]
 [  0   0   1 580   0   1   0   0   1   0]
 [  0   1   0   0 557   0   0   0   1   6]
 [  0   0   0   1   0 514   2   0   1   0]
 [  1   1   0   0   2   1 626   0   0   0]
 [  0   3   1   0   0   0   0 621   0   0]
 [  0   0   0   1   0   1   2   0 578   2]
 [  1   1   1   1   2   0   0   2   2 605]]

2024-01-15 18:30:57,125 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:30:57,125 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:30:57,132 - 

2024-01-15 18:30:57,132 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:31:07,053 - Epoch: [119][   10/  211]    Overall Loss 0.023253    Objective Loss 0.023253                                        LR 0.010000    Time 0.991976    
2024-01-15 18:31:13,074 - Epoch: [119][   20/  211]    Overall Loss 0.024063    Objective Loss 0.024063                                        LR 0.010000    Time 0.796977    
2024-01-15 18:31:19,289 - Epoch: [119][   30/  211]    Overall Loss 0.023680    Objective Loss 0.023680                                        LR 0.010000    Time 0.738460    
2024-01-15 18:31:25,139 - Epoch: [119][   40/  211]    Overall Loss 0.023952    Objective Loss 0.023952                                        LR 0.010000    Time 0.700060    
2024-01-15 18:31:30,932 - Epoch: [119][   50/  211]    Overall Loss 0.022815    Objective Loss 0.022815                                        LR 0.010000    Time 0.675873    
2024-01-15 18:31:37,298 - Epoch: [119][   60/  211]    Overall Loss 0.023238    Objective Loss 0.023238                                        LR 0.010000    Time 0.669292    
2024-01-15 18:31:43,712 - Epoch: [119][   70/  211]    Overall Loss 0.023374    Objective Loss 0.023374                                        LR 0.010000    Time 0.665281    
2024-01-15 18:31:49,879 - Epoch: [119][   80/  211]    Overall Loss 0.022867    Objective Loss 0.022867                                        LR 0.010000    Time 0.659200    
2024-01-15 18:31:56,382 - Epoch: [119][   90/  211]    Overall Loss 0.023372    Objective Loss 0.023372                                        LR 0.010000    Time 0.658191    
2024-01-15 18:32:03,061 - Epoch: [119][  100/  211]    Overall Loss 0.023104    Objective Loss 0.023104                                        LR 0.010000    Time 0.659128    
2024-01-15 18:32:09,742 - Epoch: [119][  110/  211]    Overall Loss 0.023454    Objective Loss 0.023454                                        LR 0.010000    Time 0.659909    
2024-01-15 18:32:16,256 - Epoch: [119][  120/  211]    Overall Loss 0.022957    Objective Loss 0.022957                                        LR 0.010000    Time 0.659190    
2024-01-15 18:32:22,879 - Epoch: [119][  130/  211]    Overall Loss 0.023250    Objective Loss 0.023250                                        LR 0.010000    Time 0.659410    
2024-01-15 18:32:29,278 - Epoch: [119][  140/  211]    Overall Loss 0.023444    Objective Loss 0.023444                                        LR 0.010000    Time 0.658008    
2024-01-15 18:32:35,575 - Epoch: [119][  150/  211]    Overall Loss 0.023451    Objective Loss 0.023451                                        LR 0.010000    Time 0.656101    
2024-01-15 18:32:41,931 - Epoch: [119][  160/  211]    Overall Loss 0.023596    Objective Loss 0.023596                                        LR 0.010000    Time 0.654814    
2024-01-15 18:32:48,889 - Epoch: [119][  170/  211]    Overall Loss 0.023600    Objective Loss 0.023600                                        LR 0.010000    Time 0.657214    
2024-01-15 18:32:55,084 - Epoch: [119][  180/  211]    Overall Loss 0.024054    Objective Loss 0.024054                                        LR 0.010000    Time 0.655103    
2024-01-15 18:33:01,417 - Epoch: [119][  190/  211]    Overall Loss 0.024010    Objective Loss 0.024010                                        LR 0.010000    Time 0.653949    
2024-01-15 18:33:07,559 - Epoch: [119][  200/  211]    Overall Loss 0.023948    Objective Loss 0.023948                                        LR 0.010000    Time 0.651953    
2024-01-15 18:33:13,875 - Epoch: [119][  210/  211]    Overall Loss 0.024044    Objective Loss 0.024044    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 0.650972    
2024-01-15 18:33:14,503 - Epoch: [119][  211/  211]    Overall Loss 0.023981    Objective Loss 0.023981    Top1 99.798387    Top5 100.000000    LR 0.010000    Time 0.650855    
2024-01-15 18:33:15,599 - --- validate (epoch=119)-----------
2024-01-15 18:33:15,601 - 6000 samples (256 per mini-batch)
2024-01-15 18:33:22,834 - Epoch: [119][   10/   24]    Loss 0.025804    Top1 99.257812    Top5 100.000000    
2024-01-15 18:33:25,021 - Epoch: [119][   20/   24]    Loss 0.025725    Top1 99.238281    Top5 100.000000    
2024-01-15 18:33:25,859 - Epoch: [119][   24/   24]    Loss 0.027181    Top1 99.200000    Top5 100.000000    
2024-01-15 18:33:26,736 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.027

2024-01-15 18:33:26,737 - ==> Confusion:
[[601   0   1   0   0   0   2   0   0   1]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 582   1   0   0   0   3   0   0]
 [  0   0   2 575   0   3   0   2   1   0]
 [  0   0   0   0 560   0   1   1   0   3]
 [  1   1   0   1   0 511   3   0   1   0]
 [  1   0   0   0   2   0 628   0   0   0]
 [  0   3   1   0   1   0   0 620   0   0]
 [  1   0   1   1   0   0   1   0 580   0]
 [  0   1   0   0   2   1   0   1   2 608]]

2024-01-15 18:33:26,741 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:33:26,742 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:33:26,747 - 

2024-01-15 18:33:26,748 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:33:36,716 - Epoch: [120][   10/  211]    Overall Loss 0.021507    Objective Loss 0.021507                                        LR 0.010000    Time 0.996741    
2024-01-15 18:33:43,132 - Epoch: [120][   20/  211]    Overall Loss 0.024290    Objective Loss 0.024290                                        LR 0.010000    Time 0.819072    
2024-01-15 18:33:49,471 - Epoch: [120][   30/  211]    Overall Loss 0.024215    Objective Loss 0.024215                                        LR 0.010000    Time 0.757322    
2024-01-15 18:33:55,429 - Epoch: [120][   40/  211]    Overall Loss 0.024725    Objective Loss 0.024725                                        LR 0.010000    Time 0.716895    
2024-01-15 18:34:02,185 - Epoch: [120][   50/  211]    Overall Loss 0.024576    Objective Loss 0.024576                                        LR 0.010000    Time 0.708605    
2024-01-15 18:34:08,260 - Epoch: [120][   60/  211]    Overall Loss 0.024427    Objective Loss 0.024427                                        LR 0.010000    Time 0.691728    
2024-01-15 18:34:14,319 - Epoch: [120][   70/  211]    Overall Loss 0.024981    Objective Loss 0.024981                                        LR 0.010000    Time 0.679438    
2024-01-15 18:34:20,759 - Epoch: [120][   80/  211]    Overall Loss 0.024610    Objective Loss 0.024610                                        LR 0.010000    Time 0.674978    
2024-01-15 18:34:26,426 - Epoch: [120][   90/  211]    Overall Loss 0.025464    Objective Loss 0.025464                                        LR 0.010000    Time 0.662943    
2024-01-15 18:34:32,632 - Epoch: [120][  100/  211]    Overall Loss 0.025179    Objective Loss 0.025179                                        LR 0.010000    Time 0.658697    
2024-01-15 18:34:38,716 - Epoch: [120][  110/  211]    Overall Loss 0.024903    Objective Loss 0.024903                                        LR 0.010000    Time 0.654108    
2024-01-15 18:34:45,136 - Epoch: [120][  120/  211]    Overall Loss 0.024683    Objective Loss 0.024683                                        LR 0.010000    Time 0.653088    
2024-01-15 18:34:51,704 - Epoch: [120][  130/  211]    Overall Loss 0.024880    Objective Loss 0.024880                                        LR 0.010000    Time 0.653360    
2024-01-15 18:34:57,718 - Epoch: [120][  140/  211]    Overall Loss 0.024800    Objective Loss 0.024800                                        LR 0.010000    Time 0.649643    
2024-01-15 18:35:04,131 - Epoch: [120][  150/  211]    Overall Loss 0.024242    Objective Loss 0.024242                                        LR 0.010000    Time 0.649068    
2024-01-15 18:35:10,169 - Epoch: [120][  160/  211]    Overall Loss 0.024068    Objective Loss 0.024068                                        LR 0.010000    Time 0.646231    
2024-01-15 18:35:16,349 - Epoch: [120][  170/  211]    Overall Loss 0.024469    Objective Loss 0.024469                                        LR 0.010000    Time 0.644554    
2024-01-15 18:35:22,560 - Epoch: [120][  180/  211]    Overall Loss 0.024526    Objective Loss 0.024526                                        LR 0.010000    Time 0.643237    
2024-01-15 18:35:28,996 - Epoch: [120][  190/  211]    Overall Loss 0.024357    Objective Loss 0.024357                                        LR 0.010000    Time 0.643244    
2024-01-15 18:35:35,162 - Epoch: [120][  200/  211]    Overall Loss 0.024692    Objective Loss 0.024692                                        LR 0.010000    Time 0.641903    
2024-01-15 18:35:41,569 - Epoch: [120][  210/  211]    Overall Loss 0.024572    Objective Loss 0.024572    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.641836    
2024-01-15 18:35:42,236 - Epoch: [120][  211/  211]    Overall Loss 0.024602    Objective Loss 0.024602    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.641951    
2024-01-15 18:35:43,176 - --- validate (epoch=120)-----------
2024-01-15 18:35:43,177 - 6000 samples (256 per mini-batch)
2024-01-15 18:35:50,956 - Epoch: [120][   10/   24]    Loss 0.027503    Top1 99.257812    Top5 100.000000    
2024-01-15 18:35:53,176 - Epoch: [120][   20/   24]    Loss 0.027116    Top1 99.179688    Top5 100.000000    
2024-01-15 18:35:53,964 - Epoch: [120][   24/   24]    Loss 0.027202    Top1 99.166667    Top5 100.000000    
2024-01-15 18:35:54,787 - ==> Top1: 99.167    Top5: 100.000    Loss: 0.027

2024-01-15 18:35:54,788 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 682   2   1   0   1   0   2   0   0]
 [  0   0 583   1   0   0   0   1   0   1]
 [  0   0   3 576   0   1   0   1   2   0]
 [  0   0   1   0 556   0   0   1   1   6]
 [  2   0   0   0   0 511   3   0   2   0]
 [  0   2   0   0   1   0 627   0   1   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   0   0   1   0   1   0 581   1]
 [  0   1   0   0   4   0   0   1   2 607]]

2024-01-15 18:35:54,790 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:35:54,790 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:35:54,795 - 

2024-01-15 18:35:54,795 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:36:05,292 - Epoch: [121][   10/  211]    Overall Loss 0.020791    Objective Loss 0.020791                                        LR 0.010000    Time 1.049568    
2024-01-15 18:36:11,330 - Epoch: [121][   20/  211]    Overall Loss 0.022054    Objective Loss 0.022054                                        LR 0.010000    Time 0.826658    
2024-01-15 18:36:17,278 - Epoch: [121][   30/  211]    Overall Loss 0.023699    Objective Loss 0.023699                                        LR 0.010000    Time 0.749311    
2024-01-15 18:36:23,274 - Epoch: [121][   40/  211]    Overall Loss 0.023424    Objective Loss 0.023424                                        LR 0.010000    Time 0.711860    
2024-01-15 18:36:30,415 - Epoch: [121][   50/  211]    Overall Loss 0.022430    Objective Loss 0.022430                                        LR 0.010000    Time 0.712268    
2024-01-15 18:36:36,641 - Epoch: [121][   60/  211]    Overall Loss 0.023717    Objective Loss 0.023717                                        LR 0.010000    Time 0.697300    
2024-01-15 18:36:43,682 - Epoch: [121][   70/  211]    Overall Loss 0.024242    Objective Loss 0.024242                                        LR 0.010000    Time 0.698246    
2024-01-15 18:36:49,871 - Epoch: [121][   80/  211]    Overall Loss 0.024200    Objective Loss 0.024200                                        LR 0.010000    Time 0.688320    
2024-01-15 18:36:56,077 - Epoch: [121][   90/  211]    Overall Loss 0.024446    Objective Loss 0.024446                                        LR 0.010000    Time 0.680715    
2024-01-15 18:37:02,453 - Epoch: [121][  100/  211]    Overall Loss 0.024464    Objective Loss 0.024464                                        LR 0.010000    Time 0.676394    
2024-01-15 18:37:08,516 - Epoch: [121][  110/  211]    Overall Loss 0.024563    Objective Loss 0.024563                                        LR 0.010000    Time 0.670011    
2024-01-15 18:37:14,642 - Epoch: [121][  120/  211]    Overall Loss 0.024061    Objective Loss 0.024061                                        LR 0.010000    Time 0.665215    
2024-01-15 18:37:20,488 - Epoch: [121][  130/  211]    Overall Loss 0.023722    Objective Loss 0.023722                                        LR 0.010000    Time 0.659001    
2024-01-15 18:37:26,760 - Epoch: [121][  140/  211]    Overall Loss 0.024085    Objective Loss 0.024085                                        LR 0.010000    Time 0.656723    
2024-01-15 18:37:32,812 - Epoch: [121][  150/  211]    Overall Loss 0.023706    Objective Loss 0.023706                                        LR 0.010000    Time 0.653281    
2024-01-15 18:37:38,460 - Epoch: [121][  160/  211]    Overall Loss 0.023919    Objective Loss 0.023919                                        LR 0.010000    Time 0.647747    
2024-01-15 18:37:44,113 - Epoch: [121][  170/  211]    Overall Loss 0.023703    Objective Loss 0.023703                                        LR 0.010000    Time 0.642892    
2024-01-15 18:37:49,773 - Epoch: [121][  180/  211]    Overall Loss 0.023902    Objective Loss 0.023902                                        LR 0.010000    Time 0.638615    
2024-01-15 18:37:55,416 - Epoch: [121][  190/  211]    Overall Loss 0.024053    Objective Loss 0.024053                                        LR 0.010000    Time 0.634697    
2024-01-15 18:38:01,067 - Epoch: [121][  200/  211]    Overall Loss 0.023908    Objective Loss 0.023908                                        LR 0.010000    Time 0.631215    
2024-01-15 18:38:06,720 - Epoch: [121][  210/  211]    Overall Loss 0.023681    Objective Loss 0.023681    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 0.628071    
2024-01-15 18:38:07,306 - Epoch: [121][  211/  211]    Overall Loss 0.023714    Objective Loss 0.023714    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.627871    
2024-01-15 18:38:08,042 - --- validate (epoch=121)-----------
2024-01-15 18:38:08,043 - 6000 samples (256 per mini-batch)
2024-01-15 18:38:14,732 - Epoch: [121][   10/   24]    Loss 0.030237    Top1 99.179688    Top5 100.000000    
2024-01-15 18:38:16,999 - Epoch: [121][   20/   24]    Loss 0.031603    Top1 99.140625    Top5 100.000000    
2024-01-15 18:38:17,764 - Epoch: [121][   24/   24]    Loss 0.030826    Top1 99.116667    Top5 100.000000    
2024-01-15 18:38:18,515 - ==> Top1: 99.117    Top5: 100.000    Loss: 0.031

2024-01-15 18:38:18,516 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 582   1   0   0   0   3   0   0]
 [  1   0   3 576   0   2   0   0   1   0]
 [  0   0   1   0 555   0   0   1   0   8]
 [  0   0   0   1   0 511   4   0   2   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  0   1   1   1   1   1   2   0 577   0]
 [  0   2   0   1   3   1   0   2   1 605]]

2024-01-15 18:38:18,518 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:38:18,518 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:38:18,522 - 

2024-01-15 18:38:18,523 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:38:27,796 - Epoch: [122][   10/  211]    Overall Loss 0.020179    Objective Loss 0.020179                                        LR 0.010000    Time 0.927296    
2024-01-15 18:38:33,804 - Epoch: [122][   20/  211]    Overall Loss 0.023298    Objective Loss 0.023298                                        LR 0.010000    Time 0.763955    
2024-01-15 18:38:39,444 - Epoch: [122][   30/  211]    Overall Loss 0.023698    Objective Loss 0.023698                                        LR 0.010000    Time 0.697266    
2024-01-15 18:38:45,108 - Epoch: [122][   40/  211]    Overall Loss 0.021941    Objective Loss 0.021941                                        LR 0.010000    Time 0.664530    
2024-01-15 18:38:50,839 - Epoch: [122][   50/  211]    Overall Loss 0.021297    Objective Loss 0.021297                                        LR 0.010000    Time 0.646221    
2024-01-15 18:38:56,497 - Epoch: [122][   60/  211]    Overall Loss 0.022257    Objective Loss 0.022257                                        LR 0.010000    Time 0.632810    
2024-01-15 18:39:02,182 - Epoch: [122][   70/  211]    Overall Loss 0.022373    Objective Loss 0.022373                                        LR 0.010000    Time 0.623611    
2024-01-15 18:39:07,832 - Epoch: [122][   80/  211]    Overall Loss 0.022664    Objective Loss 0.022664                                        LR 0.010000    Time 0.616267    
2024-01-15 18:39:13,465 - Epoch: [122][   90/  211]    Overall Loss 0.022709    Objective Loss 0.022709                                        LR 0.010000    Time 0.610382    
2024-01-15 18:39:19,088 - Epoch: [122][  100/  211]    Overall Loss 0.022881    Objective Loss 0.022881                                        LR 0.010000    Time 0.605566    
2024-01-15 18:39:24,729 - Epoch: [122][  110/  211]    Overall Loss 0.022987    Objective Loss 0.022987                                        LR 0.010000    Time 0.601788    
2024-01-15 18:39:30,627 - Epoch: [122][  120/  211]    Overall Loss 0.022836    Objective Loss 0.022836                                        LR 0.010000    Time 0.600783    
2024-01-15 18:39:36,285 - Epoch: [122][  130/  211]    Overall Loss 0.022807    Objective Loss 0.022807                                        LR 0.010000    Time 0.598084    
2024-01-15 18:39:41,912 - Epoch: [122][  140/  211]    Overall Loss 0.022558    Objective Loss 0.022558                                        LR 0.010000    Time 0.595545    
2024-01-15 18:39:47,535 - Epoch: [122][  150/  211]    Overall Loss 0.023014    Objective Loss 0.023014                                        LR 0.010000    Time 0.593324    
2024-01-15 18:39:53,169 - Epoch: [122][  160/  211]    Overall Loss 0.023089    Objective Loss 0.023089                                        LR 0.010000    Time 0.591448    
2024-01-15 18:39:58,797 - Epoch: [122][  170/  211]    Overall Loss 0.022975    Objective Loss 0.022975                                        LR 0.010000    Time 0.589760    
2024-01-15 18:40:04,454 - Epoch: [122][  180/  211]    Overall Loss 0.022896    Objective Loss 0.022896                                        LR 0.010000    Time 0.588425    
2024-01-15 18:40:10,086 - Epoch: [122][  190/  211]    Overall Loss 0.022507    Objective Loss 0.022507                                        LR 0.010000    Time 0.587092    
2024-01-15 18:40:15,717 - Epoch: [122][  200/  211]    Overall Loss 0.022776    Objective Loss 0.022776                                        LR 0.010000    Time 0.585886    
2024-01-15 18:40:21,346 - Epoch: [122][  210/  211]    Overall Loss 0.022904    Objective Loss 0.022904    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.584788    
2024-01-15 18:40:21,913 - Epoch: [122][  211/  211]    Overall Loss 0.023124    Objective Loss 0.023124    Top1 98.387097    Top5 100.000000    LR 0.010000    Time 0.584702    
2024-01-15 18:40:22,717 - --- validate (epoch=122)-----------
2024-01-15 18:40:22,717 - 6000 samples (256 per mini-batch)
2024-01-15 18:40:28,327 - Epoch: [122][   10/   24]    Loss 0.029445    Top1 98.945312    Top5 100.000000    
2024-01-15 18:40:30,919 - Epoch: [122][   20/   24]    Loss 0.025656    Top1 99.218750    Top5 100.000000    
2024-01-15 18:40:31,704 - Epoch: [122][   24/   24]    Loss 0.024677    Top1 99.200000    Top5 100.000000    
2024-01-15 18:40:32,461 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.025

2024-01-15 18:40:32,463 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   0 582   1   0   0   0   3   0   0]
 [  0   0   1 577   0   2   0   1   2   0]
 [  0   0   0   0 559   0   0   1   0   5]
 [  1   0   0   1   0 512   3   0   1   0]
 [  1   2   0   0   1   0 626   0   1   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   1   2   0   2   0   0 579   0]
 [  0   1   0   0   3   2   0   2   2 605]]

2024-01-15 18:40:32,464 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:40:32,465 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:40:32,469 - 

2024-01-15 18:40:32,470 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:40:41,591 - Epoch: [123][   10/  211]    Overall Loss 0.027071    Objective Loss 0.027071                                        LR 0.010000    Time 0.912019    
2024-01-15 18:40:47,829 - Epoch: [123][   20/  211]    Overall Loss 0.025666    Objective Loss 0.025666                                        LR 0.010000    Time 0.767745    
2024-01-15 18:40:54,170 - Epoch: [123][   30/  211]    Overall Loss 0.023517    Objective Loss 0.023517                                        LR 0.010000    Time 0.723049    
2024-01-15 18:41:00,485 - Epoch: [123][   40/  211]    Overall Loss 0.025806    Objective Loss 0.025806                                        LR 0.010000    Time 0.700118    
2024-01-15 18:41:06,160 - Epoch: [123][   50/  211]    Overall Loss 0.025349    Objective Loss 0.025349                                        LR 0.010000    Time 0.673584    
2024-01-15 18:41:11,842 - Epoch: [123][   60/  211]    Overall Loss 0.025570    Objective Loss 0.025570                                        LR 0.010000    Time 0.656015    
2024-01-15 18:41:17,603 - Epoch: [123][   70/  211]    Overall Loss 0.024754    Objective Loss 0.024754                                        LR 0.010000    Time 0.644574    
2024-01-15 18:41:23,398 - Epoch: [123][   80/  211]    Overall Loss 0.024766    Objective Loss 0.024766                                        LR 0.010000    Time 0.636418    
2024-01-15 18:41:29,607 - Epoch: [123][   90/  211]    Overall Loss 0.024863    Objective Loss 0.024863                                        LR 0.010000    Time 0.634676    
2024-01-15 18:41:37,825 - Epoch: [123][  100/  211]    Overall Loss 0.024206    Objective Loss 0.024206                                        LR 0.010000    Time 0.653343    
2024-01-15 18:41:44,862 - Epoch: [123][  110/  211]    Overall Loss 0.024068    Objective Loss 0.024068                                        LR 0.010000    Time 0.657905    
2024-01-15 18:41:50,643 - Epoch: [123][  120/  211]    Overall Loss 0.024234    Objective Loss 0.024234                                        LR 0.010000    Time 0.651243    
2024-01-15 18:41:57,025 - Epoch: [123][  130/  211]    Overall Loss 0.024155    Objective Loss 0.024155                                        LR 0.010000    Time 0.650230    
2024-01-15 18:42:03,256 - Epoch: [123][  140/  211]    Overall Loss 0.023884    Objective Loss 0.023884                                        LR 0.010000    Time 0.648285    
2024-01-15 18:42:09,100 - Epoch: [123][  150/  211]    Overall Loss 0.024605    Objective Loss 0.024605                                        LR 0.010000    Time 0.644014    
2024-01-15 18:42:14,752 - Epoch: [123][  160/  211]    Overall Loss 0.024278    Objective Loss 0.024278                                        LR 0.010000    Time 0.639087    
2024-01-15 18:42:20,498 - Epoch: [123][  170/  211]    Overall Loss 0.024378    Objective Loss 0.024378                                        LR 0.010000    Time 0.635290    
2024-01-15 18:42:26,409 - Epoch: [123][  180/  211]    Overall Loss 0.024497    Objective Loss 0.024497                                        LR 0.010000    Time 0.632829    
2024-01-15 18:42:32,966 - Epoch: [123][  190/  211]    Overall Loss 0.024461    Objective Loss 0.024461                                        LR 0.010000    Time 0.634022    
2024-01-15 18:42:38,813 - Epoch: [123][  200/  211]    Overall Loss 0.024365    Objective Loss 0.024365                                        LR 0.010000    Time 0.631553    
2024-01-15 18:42:44,558 - Epoch: [123][  210/  211]    Overall Loss 0.024065    Objective Loss 0.024065    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 0.628829    
2024-01-15 18:42:45,136 - Epoch: [123][  211/  211]    Overall Loss 0.024045    Objective Loss 0.024045    Top1 99.596774    Top5 100.000000    LR 0.010000    Time 0.628588    
2024-01-15 18:42:46,112 - --- validate (epoch=123)-----------
2024-01-15 18:42:46,114 - 6000 samples (256 per mini-batch)
2024-01-15 18:42:52,974 - Epoch: [123][   10/   24]    Loss 0.022771    Top1 99.296875    Top5 99.960938    
2024-01-15 18:42:55,224 - Epoch: [123][   20/   24]    Loss 0.027796    Top1 99.199219    Top5 99.980469    
2024-01-15 18:42:55,993 - Epoch: [123][   24/   24]    Loss 0.027420    Top1 99.233333    Top5 99.983333    
2024-01-15 18:42:56,820 - ==> Top1: 99.233    Top5: 99.983    Loss: 0.027

2024-01-15 18:42:56,822 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   0   1   0   0   0   1   0   0]
 [  0   0 583   1   0   0   0   0   2   0]
 [  0   0   1 578   0   2   0   1   1   0]
 [  0   0   1   0 558   0   0   0   0   6]
 [  1   0   0   3   0 510   3   0   1   0]
 [  2   0   0   0   1   0 626   0   2   0]
 [  0   1   0   0   0   1   0 622   0   1]
 [  1   0   0   0   2   0   1   0 580   0]
 [  0   1   0   0   1   1   0   2   2 608]]

2024-01-15 18:42:56,824 - ==> Best [Top1: 99.317   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 101]
2024-01-15 18:42:56,824 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:42:56,829 - 

2024-01-15 18:42:56,829 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:43:06,378 - Epoch: [124][   10/  211]    Overall Loss 0.024933    Objective Loss 0.024933                                        LR 0.010000    Time 0.954817    
2024-01-15 18:43:12,291 - Epoch: [124][   20/  211]    Overall Loss 0.023505    Objective Loss 0.023505                                        LR 0.010000    Time 0.772934    
2024-01-15 18:43:18,212 - Epoch: [124][   30/  211]    Overall Loss 0.026650    Objective Loss 0.026650                                        LR 0.010000    Time 0.712586    
2024-01-15 18:43:24,225 - Epoch: [124][   40/  211]    Overall Loss 0.024467    Objective Loss 0.024467                                        LR 0.010000    Time 0.684736    
2024-01-15 18:43:30,413 - Epoch: [124][   50/  211]    Overall Loss 0.023209    Objective Loss 0.023209                                        LR 0.010000    Time 0.671522    
2024-01-15 18:43:36,188 - Epoch: [124][   60/  211]    Overall Loss 0.024190    Objective Loss 0.024190                                        LR 0.010000    Time 0.655833    
2024-01-15 18:43:42,121 - Epoch: [124][   70/  211]    Overall Loss 0.024111    Objective Loss 0.024111                                        LR 0.010000    Time 0.646882    
2024-01-15 18:43:47,851 - Epoch: [124][   80/  211]    Overall Loss 0.023443    Objective Loss 0.023443                                        LR 0.010000    Time 0.637628    
2024-01-15 18:43:53,558 - Epoch: [124][   90/  211]    Overall Loss 0.023262    Objective Loss 0.023262                                        LR 0.010000    Time 0.630176    
2024-01-15 18:43:59,433 - Epoch: [124][  100/  211]    Overall Loss 0.023646    Objective Loss 0.023646                                        LR 0.010000    Time 0.625902    
2024-01-15 18:44:05,259 - Epoch: [124][  110/  211]    Overall Loss 0.024104    Objective Loss 0.024104                                        LR 0.010000    Time 0.621960    
2024-01-15 18:44:11,083 - Epoch: [124][  120/  211]    Overall Loss 0.024768    Objective Loss 0.024768                                        LR 0.010000    Time 0.618645    
2024-01-15 18:44:16,867 - Epoch: [124][  130/  211]    Overall Loss 0.025086    Objective Loss 0.025086                                        LR 0.010000    Time 0.615548    
2024-01-15 18:44:22,694 - Epoch: [124][  140/  211]    Overall Loss 0.025476    Objective Loss 0.025476                                        LR 0.010000    Time 0.613187    
2024-01-15 18:44:28,788 - Epoch: [124][  150/  211]    Overall Loss 0.025058    Objective Loss 0.025058                                        LR 0.010000    Time 0.612923    
2024-01-15 18:44:34,868 - Epoch: [124][  160/  211]    Overall Loss 0.024983    Objective Loss 0.024983                                        LR 0.010000    Time 0.612605    
2024-01-15 18:44:40,693 - Epoch: [124][  170/  211]    Overall Loss 0.024994    Objective Loss 0.024994                                        LR 0.010000    Time 0.610825    
2024-01-15 18:44:46,684 - Epoch: [124][  180/  211]    Overall Loss 0.024843    Objective Loss 0.024843                                        LR 0.010000    Time 0.610163    
2024-01-15 18:44:52,675 - Epoch: [124][  190/  211]    Overall Loss 0.024837    Objective Loss 0.024837                                        LR 0.010000    Time 0.609562    
2024-01-15 18:44:58,603 - Epoch: [124][  200/  211]    Overall Loss 0.024613    Objective Loss 0.024613                                        LR 0.010000    Time 0.608720    
2024-01-15 18:45:04,494 - Epoch: [124][  210/  211]    Overall Loss 0.024548    Objective Loss 0.024548    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.607780    
2024-01-15 18:45:05,047 - Epoch: [124][  211/  211]    Overall Loss 0.024538    Objective Loss 0.024538    Top1 99.193548    Top5 100.000000    LR 0.010000    Time 0.607517    
2024-01-15 18:45:05,681 - --- validate (epoch=124)-----------
2024-01-15 18:45:05,681 - 6000 samples (256 per mini-batch)
2024-01-15 18:45:10,996 - Epoch: [124][   10/   24]    Loss 0.026834    Top1 99.375000    Top5 100.000000    
2024-01-15 18:45:13,252 - Epoch: [124][   20/   24]    Loss 0.025101    Top1 99.355469    Top5 100.000000    
2024-01-15 18:45:13,998 - Epoch: [124][   24/   24]    Loss 0.025417    Top1 99.333333    Top5 100.000000    
2024-01-15 18:45:14,557 - ==> Top1: 99.333    Top5: 100.000    Loss: 0.025

2024-01-15 18:45:14,559 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 684   1   1   1   1   0   0   0   0]
 [  0   0 584   0   0   0   1   1   0   0]
 [  0   0   2 578   0   2   0   0   1   0]
 [  0   0   0   0 561   0   0   0   0   4]
 [  0   0   0   1   0 514   3   0   0   0]
 [  1   0   0   0   1   0 629   0   0   0]
 [  0   1   0   1   0   0   0 623   0   0]
 [  0   0   0   0   0   1   4   0 579   0]
 [  0   1   0   0   3   0   0   3   2 606]]

2024-01-15 18:45:14,560 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 18:45:14,561 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:45:14,571 - 

2024-01-15 18:45:14,571 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:45:22,881 - Epoch: [125][   10/  211]    Overall Loss 0.026646    Objective Loss 0.026646                                        LR 0.010000    Time 0.830971    
2024-01-15 18:45:28,959 - Epoch: [125][   20/  211]    Overall Loss 0.022843    Objective Loss 0.022843                                        LR 0.010000    Time 0.719257    
2024-01-15 18:45:34,628 - Epoch: [125][   30/  211]    Overall Loss 0.023437    Objective Loss 0.023437                                        LR 0.010000    Time 0.668407    
2024-01-15 18:45:40,269 - Epoch: [125][   40/  211]    Overall Loss 0.022210    Objective Loss 0.022210                                        LR 0.010000    Time 0.642331    
2024-01-15 18:45:45,906 - Epoch: [125][   50/  211]    Overall Loss 0.021844    Objective Loss 0.021844                                        LR 0.010000    Time 0.626582    
2024-01-15 18:45:51,542 - Epoch: [125][   60/  211]    Overall Loss 0.021910    Objective Loss 0.021910                                        LR 0.010000    Time 0.616074    
2024-01-15 18:45:57,181 - Epoch: [125][   70/  211]    Overall Loss 0.022083    Objective Loss 0.022083                                        LR 0.010000    Time 0.608605    
2024-01-15 18:46:02,892 - Epoch: [125][   80/  211]    Overall Loss 0.023042    Objective Loss 0.023042                                        LR 0.010000    Time 0.603903    
2024-01-15 18:46:08,619 - Epoch: [125][   90/  211]    Overall Loss 0.023270    Objective Loss 0.023270                                        LR 0.010000    Time 0.600424    
2024-01-15 18:46:14,400 - Epoch: [125][  100/  211]    Overall Loss 0.023322    Objective Loss 0.023322                                        LR 0.010000    Time 0.598180    
2024-01-15 18:46:20,455 - Epoch: [125][  110/  211]    Overall Loss 0.023136    Objective Loss 0.023136                                        LR 0.010000    Time 0.598816    
2024-01-15 18:46:28,506 - Epoch: [125][  120/  211]    Overall Loss 0.023094    Objective Loss 0.023094                                        LR 0.010000    Time 0.615963    
2024-01-15 18:46:37,499 - Epoch: [125][  130/  211]    Overall Loss 0.023586    Objective Loss 0.023586                                        LR 0.010000    Time 0.637706    
2024-01-15 18:46:45,679 - Epoch: [125][  140/  211]    Overall Loss 0.023591    Objective Loss 0.023591                                        LR 0.010000    Time 0.650561    
2024-01-15 18:46:53,760 - Epoch: [125][  150/  211]    Overall Loss 0.023330    Objective Loss 0.023330                                        LR 0.010000    Time 0.661039    
2024-01-15 18:47:03,087 - Epoch: [125][  160/  211]    Overall Loss 0.023189    Objective Loss 0.023189                                        LR 0.010000    Time 0.677992    
2024-01-15 18:47:09,581 - Epoch: [125][  170/  211]    Overall Loss 0.023337    Objective Loss 0.023337                                        LR 0.010000    Time 0.676301    
2024-01-15 18:47:17,228 - Epoch: [125][  180/  211]    Overall Loss 0.023593    Objective Loss 0.023593                                        LR 0.010000    Time 0.681204    
2024-01-15 18:47:23,774 - Epoch: [125][  190/  211]    Overall Loss 0.023540    Objective Loss 0.023540                                        LR 0.010000    Time 0.679791    
2024-01-15 18:47:30,252 - Epoch: [125][  200/  211]    Overall Loss 0.023268    Objective Loss 0.023268                                        LR 0.010000    Time 0.678188    
2024-01-15 18:47:36,555 - Epoch: [125][  210/  211]    Overall Loss 0.023481    Objective Loss 0.023481    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 0.675903    
2024-01-15 18:47:37,189 - Epoch: [125][  211/  211]    Overall Loss 0.023654    Objective Loss 0.023654    Top1 98.387097    Top5 100.000000    LR 0.010000    Time 0.675698    
2024-01-15 18:47:38,538 - --- validate (epoch=125)-----------
2024-01-15 18:47:38,541 - 6000 samples (256 per mini-batch)
2024-01-15 18:47:45,375 - Epoch: [125][   10/   24]    Loss 0.033243    Top1 99.101562    Top5 100.000000    
2024-01-15 18:47:47,564 - Epoch: [125][   20/   24]    Loss 0.030472    Top1 99.121094    Top5 100.000000    
2024-01-15 18:47:48,357 - Epoch: [125][   24/   24]    Loss 0.027953    Top1 99.216667    Top5 100.000000    
2024-01-15 18:47:49,108 - ==> Top1: 99.217    Top5: 100.000    Loss: 0.028

2024-01-15 18:47:49,109 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 685   0   0   0   1   1   1   0   0]
 [  0   0 584   1   0   0   0   0   0   1]
 [  0   0   0 575   0   3   0   2   3   0]
 [  0   1   0   0 556   0   1   1   0   6]
 [  0   0   0   3   0 512   3   0   0   0]
 [  1   1   0   0   1   0 627   0   1   0]
 [  0   1   0   1   0   0   0 623   0   0]
 [  0   0   0   1   1   1   1   1 579   0]
 [  2   1   0   0   0   1   0   1   2 608]]

2024-01-15 18:47:49,111 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 18:47:49,112 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:47:49,117 - 

2024-01-15 18:47:49,117 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:47:59,052 - Epoch: [126][   10/  211]    Overall Loss 0.022924    Objective Loss 0.022924                                        LR 0.010000    Time 0.993384    
2024-01-15 18:48:04,958 - Epoch: [126][   20/  211]    Overall Loss 0.022078    Objective Loss 0.022078                                        LR 0.010000    Time 0.791918    
2024-01-15 18:48:11,520 - Epoch: [126][   30/  211]    Overall Loss 0.022249    Objective Loss 0.022249                                        LR 0.010000    Time 0.746630    
2024-01-15 18:48:17,595 - Epoch: [126][   40/  211]    Overall Loss 0.022743    Objective Loss 0.022743                                        LR 0.010000    Time 0.711811    
2024-01-15 18:48:24,292 - Epoch: [126][   50/  211]    Overall Loss 0.021270    Objective Loss 0.021270                                        LR 0.010000    Time 0.703356    
2024-01-15 18:48:30,548 - Epoch: [126][   60/  211]    Overall Loss 0.021902    Objective Loss 0.021902                                        LR 0.010000    Time 0.690387    
2024-01-15 18:48:36,354 - Epoch: [126][   70/  211]    Overall Loss 0.022786    Objective Loss 0.022786                                        LR 0.010000    Time 0.674684    
2024-01-15 18:48:42,227 - Epoch: [126][   80/  211]    Overall Loss 0.022220    Objective Loss 0.022220                                        LR 0.010000    Time 0.663743    
2024-01-15 18:48:48,271 - Epoch: [126][   90/  211]    Overall Loss 0.021918    Objective Loss 0.021918                                        LR 0.010000    Time 0.657137    
2024-01-15 18:48:54,193 - Epoch: [126][  100/  211]    Overall Loss 0.022350    Objective Loss 0.022350                                        LR 0.010000    Time 0.650625    
2024-01-15 18:49:00,231 - Epoch: [126][  110/  211]    Overall Loss 0.022133    Objective Loss 0.022133                                        LR 0.010000    Time 0.646351    
2024-01-15 18:49:06,157 - Epoch: [126][  120/  211]    Overall Loss 0.022018    Objective Loss 0.022018                                        LR 0.010000    Time 0.641844    
2024-01-15 18:49:11,965 - Epoch: [126][  130/  211]    Overall Loss 0.022420    Objective Loss 0.022420                                        LR 0.010000    Time 0.637129    
2024-01-15 18:49:17,913 - Epoch: [126][  140/  211]    Overall Loss 0.022944    Objective Loss 0.022944                                        LR 0.010000    Time 0.634098    
2024-01-15 18:49:23,975 - Epoch: [126][  150/  211]    Overall Loss 0.023176    Objective Loss 0.023176                                        LR 0.010000    Time 0.632230    
2024-01-15 18:49:30,168 - Epoch: [126][  160/  211]    Overall Loss 0.022744    Objective Loss 0.022744                                        LR 0.010000    Time 0.631408    
2024-01-15 18:49:36,236 - Epoch: [126][  170/  211]    Overall Loss 0.022876    Objective Loss 0.022876                                        LR 0.010000    Time 0.629953    
2024-01-15 18:49:42,119 - Epoch: [126][  180/  211]    Overall Loss 0.023155    Objective Loss 0.023155                                        LR 0.010000    Time 0.627635    
2024-01-15 18:49:48,429 - Epoch: [126][  190/  211]    Overall Loss 0.023618    Objective Loss 0.023618                                        LR 0.010000    Time 0.627804    
2024-01-15 18:49:54,422 - Epoch: [126][  200/  211]    Overall Loss 0.023397    Objective Loss 0.023397                                        LR 0.010000    Time 0.626365    
2024-01-15 18:50:00,485 - Epoch: [126][  210/  211]    Overall Loss 0.023402    Objective Loss 0.023402    Top1 98.828125    Top5 100.000000    LR 0.010000    Time 0.625396    
2024-01-15 18:50:01,130 - Epoch: [126][  211/  211]    Overall Loss 0.023361    Objective Loss 0.023361    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.625487    
2024-01-15 18:50:02,025 - --- validate (epoch=126)-----------
2024-01-15 18:50:02,027 - 6000 samples (256 per mini-batch)
2024-01-15 18:50:08,987 - Epoch: [126][   10/   24]    Loss 0.030506    Top1 99.101562    Top5 100.000000    
2024-01-15 18:50:11,154 - Epoch: [126][   20/   24]    Loss 0.027103    Top1 99.218750    Top5 100.000000    
2024-01-15 18:50:11,920 - Epoch: [126][   24/   24]    Loss 0.025329    Top1 99.300000    Top5 100.000000    
2024-01-15 18:50:12,667 - ==> Top1: 99.300    Top5: 100.000    Loss: 0.025

2024-01-15 18:50:12,668 - ==> Confusion:
[[601   0   1   0   0   0   3   0   0   0]
 [  0 686   0   0   1   1   0   0   0   0]
 [  0   0 580   2   0   1   0   1   2   0]
 [  1   0   0 579   0   1   0   2   0   0]
 [  0   0   0   0 557   0   1   0   0   7]
 [  0   0   0   0   0 516   2   0   0   0]
 [  1   0   0   0   1   0 628   0   1   0]
 [  0   0   1   0   0   0   0 624   0   0]
 [  1   0   0   0   2   1   2   0 578   0]
 [  0   0   1   0   2   0   0   1   2 609]]

2024-01-15 18:50:12,670 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 18:50:12,670 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:50:12,674 - 

2024-01-15 18:50:12,675 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:50:22,476 - Epoch: [127][   10/  211]    Overall Loss 0.021760    Objective Loss 0.021760                                        LR 0.010000    Time 0.979922    
2024-01-15 18:50:29,037 - Epoch: [127][   20/  211]    Overall Loss 0.022786    Objective Loss 0.022786                                        LR 0.010000    Time 0.817930    
2024-01-15 18:50:34,839 - Epoch: [127][   30/  211]    Overall Loss 0.022780    Objective Loss 0.022780                                        LR 0.010000    Time 0.738666    
2024-01-15 18:50:40,592 - Epoch: [127][   40/  211]    Overall Loss 0.023029    Objective Loss 0.023029                                        LR 0.010000    Time 0.697803    
2024-01-15 18:50:46,508 - Epoch: [127][   50/  211]    Overall Loss 0.022463    Objective Loss 0.022463                                        LR 0.010000    Time 0.676542    
2024-01-15 18:50:52,399 - Epoch: [127][   60/  211]    Overall Loss 0.021814    Objective Loss 0.021814                                        LR 0.010000    Time 0.661946    
2024-01-15 18:50:59,163 - Epoch: [127][   70/  211]    Overall Loss 0.021617    Objective Loss 0.021617                                        LR 0.010000    Time 0.663980    
2024-01-15 18:51:05,374 - Epoch: [127][   80/  211]    Overall Loss 0.021755    Objective Loss 0.021755                                        LR 0.010000    Time 0.658610    
2024-01-15 18:51:11,072 - Epoch: [127][   90/  211]    Overall Loss 0.022824    Objective Loss 0.022824                                        LR 0.010000    Time 0.648735    
2024-01-15 18:51:16,741 - Epoch: [127][  100/  211]    Overall Loss 0.022874    Objective Loss 0.022874                                        LR 0.010000    Time 0.640543    
2024-01-15 18:51:22,381 - Epoch: [127][  110/  211]    Overall Loss 0.022141    Objective Loss 0.022141                                        LR 0.010000    Time 0.633575    
2024-01-15 18:51:28,025 - Epoch: [127][  120/  211]    Overall Loss 0.022066    Objective Loss 0.022066                                        LR 0.010000    Time 0.627803    
2024-01-15 18:51:33,809 - Epoch: [127][  130/  211]    Overall Loss 0.022326    Objective Loss 0.022326                                        LR 0.010000    Time 0.624000    
2024-01-15 18:51:39,474 - Epoch: [127][  140/  211]    Overall Loss 0.023283    Objective Loss 0.023283                                        LR 0.010000    Time 0.619886    
2024-01-15 18:51:46,140 - Epoch: [127][  150/  211]    Overall Loss 0.023521    Objective Loss 0.023521                                        LR 0.010000    Time 0.622990    
2024-01-15 18:51:52,053 - Epoch: [127][  160/  211]    Overall Loss 0.023150    Objective Loss 0.023150                                        LR 0.010000    Time 0.621002    
2024-01-15 18:51:57,747 - Epoch: [127][  170/  211]    Overall Loss 0.022884    Objective Loss 0.022884                                        LR 0.010000    Time 0.617966    
2024-01-15 18:52:03,533 - Epoch: [127][  180/  211]    Overall Loss 0.022658    Objective Loss 0.022658                                        LR 0.010000    Time 0.615772    
2024-01-15 18:52:09,570 - Epoch: [127][  190/  211]    Overall Loss 0.022597    Objective Loss 0.022597                                        LR 0.010000    Time 0.615130    
2024-01-15 18:52:15,321 - Epoch: [127][  200/  211]    Overall Loss 0.022874    Objective Loss 0.022874                                        LR 0.010000    Time 0.613119    
2024-01-15 18:52:21,118 - Epoch: [127][  210/  211]    Overall Loss 0.023008    Objective Loss 0.023008    Top1 98.828125    Top5 100.000000    LR 0.010000    Time 0.611525    
2024-01-15 18:52:21,684 - Epoch: [127][  211/  211]    Overall Loss 0.023094    Objective Loss 0.023094    Top1 98.588710    Top5 100.000000    LR 0.010000    Time 0.611305    
2024-01-15 18:52:22,596 - --- validate (epoch=127)-----------
2024-01-15 18:52:22,598 - 6000 samples (256 per mini-batch)
2024-01-15 18:52:30,154 - Epoch: [127][   10/   24]    Loss 0.029051    Top1 99.414062    Top5 100.000000    
2024-01-15 18:52:32,325 - Epoch: [127][   20/   24]    Loss 0.028101    Top1 99.238281    Top5 100.000000    
2024-01-15 18:52:33,075 - Epoch: [127][   24/   24]    Loss 0.026570    Top1 99.283333    Top5 100.000000    
2024-01-15 18:52:33,783 - ==> Top1: 99.283    Top5: 100.000    Loss: 0.027

2024-01-15 18:52:33,785 - ==> Confusion:
[[603   0   0   0   0   0   0   0   0   2]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 578   2   0   1   1   3   1   0]
 [  0   0   0 581   0   1   0   0   1   0]
 [  0   0   0   0 559   0   0   0   0   6]
 [  0   1   0   2   0 513   1   0   0   1]
 [  0   0   0   0   1   1 628   0   1   0]
 [  0   1   1   1   1   0   0 620   0   1]
 [  0   0   0   0   1   1   1   0 581   0]
 [  0   1   0   0   2   1   0   1   3 607]]

2024-01-15 18:52:33,787 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 18:52:33,787 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:52:33,792 - 

2024-01-15 18:52:33,792 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:52:43,133 - Epoch: [128][   10/  211]    Overall Loss 0.022411    Objective Loss 0.022411                                        LR 0.010000    Time 0.933993    
2024-01-15 18:52:48,908 - Epoch: [128][   20/  211]    Overall Loss 0.024646    Objective Loss 0.024646                                        LR 0.010000    Time 0.755624    
2024-01-15 18:52:54,543 - Epoch: [128][   30/  211]    Overall Loss 0.023291    Objective Loss 0.023291                                        LR 0.010000    Time 0.691581    
2024-01-15 18:53:00,335 - Epoch: [128][   40/  211]    Overall Loss 0.024011    Objective Loss 0.024011                                        LR 0.010000    Time 0.663462    
2024-01-15 18:53:06,006 - Epoch: [128][   50/  211]    Overall Loss 0.023139    Objective Loss 0.023139                                        LR 0.010000    Time 0.644157    
2024-01-15 18:53:11,788 - Epoch: [128][   60/  211]    Overall Loss 0.023508    Objective Loss 0.023508                                        LR 0.010000    Time 0.633155    
2024-01-15 18:53:17,453 - Epoch: [128][   70/  211]    Overall Loss 0.023902    Objective Loss 0.023902                                        LR 0.010000    Time 0.623620    
2024-01-15 18:53:23,129 - Epoch: [128][   80/  211]    Overall Loss 0.024196    Objective Loss 0.024196                                        LR 0.010000    Time 0.616589    
2024-01-15 18:53:29,231 - Epoch: [128][   90/  211]    Overall Loss 0.023947    Objective Loss 0.023947                                        LR 0.010000    Time 0.615871    
2024-01-15 18:53:35,117 - Epoch: [128][  100/  211]    Overall Loss 0.023391    Objective Loss 0.023391                                        LR 0.010000    Time 0.613124    
2024-01-15 18:53:41,321 - Epoch: [128][  110/  211]    Overall Loss 0.022787    Objective Loss 0.022787                                        LR 0.010000    Time 0.613776    
2024-01-15 18:53:47,236 - Epoch: [128][  120/  211]    Overall Loss 0.022408    Objective Loss 0.022408                                        LR 0.010000    Time 0.611916    
2024-01-15 18:53:52,964 - Epoch: [128][  130/  211]    Overall Loss 0.022209    Objective Loss 0.022209                                        LR 0.010000    Time 0.608892    
2024-01-15 18:53:58,668 - Epoch: [128][  140/  211]    Overall Loss 0.022560    Objective Loss 0.022560                                        LR 0.010000    Time 0.606141    
2024-01-15 18:54:04,412 - Epoch: [128][  150/  211]    Overall Loss 0.023248    Objective Loss 0.023248                                        LR 0.010000    Time 0.604019    
2024-01-15 18:54:10,121 - Epoch: [128][  160/  211]    Overall Loss 0.023423    Objective Loss 0.023423                                        LR 0.010000    Time 0.601943    
2024-01-15 18:54:16,011 - Epoch: [128][  170/  211]    Overall Loss 0.023714    Objective Loss 0.023714                                        LR 0.010000    Time 0.601173    
2024-01-15 18:54:22,077 - Epoch: [128][  180/  211]    Overall Loss 0.023543    Objective Loss 0.023543                                        LR 0.010000    Time 0.601466    
2024-01-15 18:54:27,761 - Epoch: [128][  190/  211]    Overall Loss 0.023338    Objective Loss 0.023338                                        LR 0.010000    Time 0.599724    
2024-01-15 18:54:33,802 - Epoch: [128][  200/  211]    Overall Loss 0.023470    Objective Loss 0.023470                                        LR 0.010000    Time 0.599935    
2024-01-15 18:54:39,633 - Epoch: [128][  210/  211]    Overall Loss 0.023525    Objective Loss 0.023525    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 0.599125    
2024-01-15 18:54:40,240 - Epoch: [128][  211/  211]    Overall Loss 0.023455    Objective Loss 0.023455    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 0.599157    
2024-01-15 18:54:41,284 - --- validate (epoch=128)-----------
2024-01-15 18:54:41,286 - 6000 samples (256 per mini-batch)
2024-01-15 18:54:49,069 - Epoch: [128][   10/   24]    Loss 0.034614    Top1 98.945312    Top5 100.000000    
2024-01-15 18:54:51,820 - Epoch: [128][   20/   24]    Loss 0.028137    Top1 99.179688    Top5 100.000000    
2024-01-15 18:54:52,599 - Epoch: [128][   24/   24]    Loss 0.026906    Top1 99.233333    Top5 100.000000    
2024-01-15 18:54:53,401 - ==> Top1: 99.233    Top5: 100.000    Loss: 0.027

2024-01-15 18:54:53,403 - ==> Confusion:
[[602   0   1   0   0   0   1   0   1   0]
 [  0 685   0   0   1   1   0   1   0   0]
 [  0   0 580   3   0   0   0   2   1   0]
 [  0   0   2 577   0   2   0   0   2   0]
 [  0   0   0   0 558   0   1   0   0   6]
 [  0   0   0   2   0 514   2   0   0   0]
 [  0   0   0   0   1   0 629   0   1   0]
 [  0   1   1   1   0   0   0 622   0   0]
 [  0   0   0   2   1   1   1   0 579   0]
 [  1   1   0   0   1   0   0   3   1 608]]

2024-01-15 18:54:53,405 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 18:54:53,405 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:54:53,411 - 

2024-01-15 18:54:53,411 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:55:03,340 - Epoch: [129][   10/  211]    Overall Loss 0.021043    Objective Loss 0.021043                                        LR 0.010000    Time 0.992788    
2024-01-15 18:55:09,166 - Epoch: [129][   20/  211]    Overall Loss 0.024218    Objective Loss 0.024218                                        LR 0.010000    Time 0.787636    
2024-01-15 18:55:15,035 - Epoch: [129][   30/  211]    Overall Loss 0.022925    Objective Loss 0.022925                                        LR 0.010000    Time 0.720688    
2024-01-15 18:55:20,812 - Epoch: [129][   40/  211]    Overall Loss 0.023649    Objective Loss 0.023649                                        LR 0.010000    Time 0.684916    
2024-01-15 18:55:26,771 - Epoch: [129][   50/  211]    Overall Loss 0.023182    Objective Loss 0.023182                                        LR 0.010000    Time 0.667088    
2024-01-15 18:55:32,923 - Epoch: [129][   60/  211]    Overall Loss 0.024014    Objective Loss 0.024014                                        LR 0.010000    Time 0.658417    
2024-01-15 18:55:38,767 - Epoch: [129][   70/  211]    Overall Loss 0.024092    Objective Loss 0.024092                                        LR 0.010000    Time 0.647823    
2024-01-15 18:55:44,422 - Epoch: [129][   80/  211]    Overall Loss 0.024748    Objective Loss 0.024748                                        LR 0.010000    Time 0.637514    
2024-01-15 18:55:50,359 - Epoch: [129][   90/  211]    Overall Loss 0.024015    Objective Loss 0.024015                                        LR 0.010000    Time 0.632639    
2024-01-15 18:55:56,008 - Epoch: [129][  100/  211]    Overall Loss 0.023965    Objective Loss 0.023965                                        LR 0.010000    Time 0.625853    
2024-01-15 18:56:01,939 - Epoch: [129][  110/  211]    Overall Loss 0.024004    Objective Loss 0.024004                                        LR 0.010000    Time 0.622869    
2024-01-15 18:56:07,865 - Epoch: [129][  120/  211]    Overall Loss 0.023988    Objective Loss 0.023988                                        LR 0.010000    Time 0.620338    
2024-01-15 18:56:13,547 - Epoch: [129][  130/  211]    Overall Loss 0.023674    Objective Loss 0.023674                                        LR 0.010000    Time 0.616322    
2024-01-15 18:56:19,203 - Epoch: [129][  140/  211]    Overall Loss 0.023200    Objective Loss 0.023200                                        LR 0.010000    Time 0.612689    
2024-01-15 18:56:25,020 - Epoch: [129][  150/  211]    Overall Loss 0.022978    Objective Loss 0.022978                                        LR 0.010000    Time 0.610619    
2024-01-15 18:56:30,981 - Epoch: [129][  160/  211]    Overall Loss 0.023076    Objective Loss 0.023076                                        LR 0.010000    Time 0.609707    
2024-01-15 18:56:36,985 - Epoch: [129][  170/  211]    Overall Loss 0.023137    Objective Loss 0.023137                                        LR 0.010000    Time 0.609140    
2024-01-15 18:56:43,036 - Epoch: [129][  180/  211]    Overall Loss 0.023253    Objective Loss 0.023253                                        LR 0.010000    Time 0.608909    
2024-01-15 18:56:48,950 - Epoch: [129][  190/  211]    Overall Loss 0.023730    Objective Loss 0.023730                                        LR 0.010000    Time 0.607975    
2024-01-15 18:56:55,448 - Epoch: [129][  200/  211]    Overall Loss 0.023718    Objective Loss 0.023718                                        LR 0.010000    Time 0.610056    
2024-01-15 18:57:01,496 - Epoch: [129][  210/  211]    Overall Loss 0.023477    Objective Loss 0.023477    Top1 100.000000    Top5 100.000000    LR 0.010000    Time 0.609802    
2024-01-15 18:57:02,069 - Epoch: [129][  211/  211]    Overall Loss 0.023444    Objective Loss 0.023444    Top1 99.798387    Top5 100.000000    LR 0.010000    Time 0.609625    
2024-01-15 18:57:02,966 - --- validate (epoch=129)-----------
2024-01-15 18:57:02,967 - 6000 samples (256 per mini-batch)
2024-01-15 18:57:09,927 - Epoch: [129][   10/   24]    Loss 0.030236    Top1 99.101562    Top5 100.000000    
2024-01-15 18:57:12,039 - Epoch: [129][   20/   24]    Loss 0.026634    Top1 99.257812    Top5 100.000000    
2024-01-15 18:57:12,819 - Epoch: [129][   24/   24]    Loss 0.027158    Top1 99.200000    Top5 100.000000    
2024-01-15 18:57:13,445 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.027

2024-01-15 18:57:13,446 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   0 582   1   0   0   1   2   0   0]
 [  0   0   2 578   0   2   0   0   1   0]
 [  0   1   1   0 554   0   0   1   0   8]
 [  1   0   0   0   0 514   3   0   0   0]
 [  1   2   0   0   2   0 625   0   1   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   0   1   2   1   0   0 578   2]
 [  0   1   0   0   5   0   0   1   1 607]]

2024-01-15 18:57:13,448 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 18:57:13,449 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:57:13,453 - 

2024-01-15 18:57:13,453 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:57:22,481 - Epoch: [130][   10/  211]    Overall Loss 0.023353    Objective Loss 0.023353                                        LR 0.010000    Time 0.902760    
2024-01-15 18:57:29,023 - Epoch: [130][   20/  211]    Overall Loss 0.023464    Objective Loss 0.023464                                        LR 0.010000    Time 0.778338    
2024-01-15 18:57:35,038 - Epoch: [130][   30/  211]    Overall Loss 0.023623    Objective Loss 0.023623                                        LR 0.010000    Time 0.719375    
2024-01-15 18:57:40,839 - Epoch: [130][   40/  211]    Overall Loss 0.024583    Objective Loss 0.024583                                        LR 0.010000    Time 0.684533    
2024-01-15 18:57:46,610 - Epoch: [130][   50/  211]    Overall Loss 0.024472    Objective Loss 0.024472                                        LR 0.010000    Time 0.663028    
2024-01-15 18:57:52,429 - Epoch: [130][   60/  211]    Overall Loss 0.023833    Objective Loss 0.023833                                        LR 0.010000    Time 0.649480    
2024-01-15 18:57:58,294 - Epoch: [130][   70/  211]    Overall Loss 0.024108    Objective Loss 0.024108                                        LR 0.010000    Time 0.640470    
2024-01-15 18:58:04,198 - Epoch: [130][   80/  211]    Overall Loss 0.022997    Objective Loss 0.022997                                        LR 0.010000    Time 0.634189    
2024-01-15 18:58:10,027 - Epoch: [130][   90/  211]    Overall Loss 0.022275    Objective Loss 0.022275                                        LR 0.010000    Time 0.628480    
2024-01-15 18:58:15,937 - Epoch: [130][  100/  211]    Overall Loss 0.022095    Objective Loss 0.022095                                        LR 0.010000    Time 0.624721    
2024-01-15 18:58:22,795 - Epoch: [130][  110/  211]    Overall Loss 0.022268    Objective Loss 0.022268                                        LR 0.010000    Time 0.630258    
2024-01-15 18:58:29,034 - Epoch: [130][  120/  211]    Overall Loss 0.022469    Objective Loss 0.022469                                        LR 0.010000    Time 0.629715    
2024-01-15 18:58:34,949 - Epoch: [130][  130/  211]    Overall Loss 0.022506    Objective Loss 0.022506                                        LR 0.010000    Time 0.626759    
2024-01-15 18:58:40,727 - Epoch: [130][  140/  211]    Overall Loss 0.022440    Objective Loss 0.022440                                        LR 0.010000    Time 0.623252    
2024-01-15 18:58:46,396 - Epoch: [130][  150/  211]    Overall Loss 0.023565    Objective Loss 0.023565                                        LR 0.010000    Time 0.619495    
2024-01-15 18:58:52,136 - Epoch: [130][  160/  211]    Overall Loss 0.023486    Objective Loss 0.023486                                        LR 0.010000    Time 0.616645    
2024-01-15 18:58:57,821 - Epoch: [130][  170/  211]    Overall Loss 0.023413    Objective Loss 0.023413                                        LR 0.010000    Time 0.613811    
2024-01-15 18:59:03,577 - Epoch: [130][  180/  211]    Overall Loss 0.023898    Objective Loss 0.023898                                        LR 0.010000    Time 0.611685    
2024-01-15 18:59:09,284 - Epoch: [130][  190/  211]    Overall Loss 0.023745    Objective Loss 0.023745                                        LR 0.010000    Time 0.609520    
2024-01-15 18:59:15,173 - Epoch: [130][  200/  211]    Overall Loss 0.023565    Objective Loss 0.023565                                        LR 0.010000    Time 0.608480    
2024-01-15 18:59:20,925 - Epoch: [130][  210/  211]    Overall Loss 0.023613    Objective Loss 0.023613    Top1 98.437500    Top5 100.000000    LR 0.010000    Time 0.606892    
2024-01-15 18:59:21,574 - Epoch: [130][  211/  211]    Overall Loss 0.023600    Objective Loss 0.023600    Top1 98.588710    Top5 100.000000    LR 0.010000    Time 0.607091    
2024-01-15 18:59:22,446 - --- validate (epoch=130)-----------
2024-01-15 18:59:22,448 - 6000 samples (256 per mini-batch)
2024-01-15 18:59:29,628 - Epoch: [130][   10/   24]    Loss 0.028687    Top1 99.062500    Top5 100.000000    
2024-01-15 18:59:31,834 - Epoch: [130][   20/   24]    Loss 0.028681    Top1 99.101562    Top5 100.000000    
2024-01-15 18:59:32,599 - Epoch: [130][   24/   24]    Loss 0.028216    Top1 99.083333    Top5 100.000000    
2024-01-15 18:59:33,432 - ==> Top1: 99.083    Top5: 100.000    Loss: 0.028

2024-01-15 18:59:33,434 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   1 584   0   0   0   0   1   0   0]
 [  0   1   1 578   0   1   0   1   1   0]
 [  0   1   0   0 555   0   0   1   1   7]
 [  1   0   0   3   0 510   3   0   1   0]
 [  0   0   0   0   2   0 629   0   0   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  0   0   0   1   0   2   4   0 576   1]
 [  0   2   0   0   6   2   0   1   3 601]]

2024-01-15 18:59:33,437 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 18:59:33,437 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 18:59:33,441 - 

2024-01-15 18:59:33,442 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 18:59:42,381 - Epoch: [131][   10/  211]    Overall Loss 0.016919    Objective Loss 0.016919                                        LR 0.010000    Time 0.893830    
2024-01-15 18:59:48,173 - Epoch: [131][   20/  211]    Overall Loss 0.018289    Objective Loss 0.018289                                        LR 0.010000    Time 0.736426    
2024-01-15 18:59:53,977 - Epoch: [131][   30/  211]    Overall Loss 0.017555    Objective Loss 0.017555                                        LR 0.010000    Time 0.684388    
2024-01-15 18:59:59,743 - Epoch: [131][   40/  211]    Overall Loss 0.019068    Objective Loss 0.019068                                        LR 0.010000    Time 0.657422    
2024-01-15 19:00:05,812 - Epoch: [131][   50/  211]    Overall Loss 0.021050    Objective Loss 0.021050                                        LR 0.010000    Time 0.647276    
2024-01-15 19:00:11,581 - Epoch: [131][   60/  211]    Overall Loss 0.022742    Objective Loss 0.022742                                        LR 0.010000    Time 0.635536    
2024-01-15 19:00:17,369 - Epoch: [131][   70/  211]    Overall Loss 0.023167    Objective Loss 0.023167                                        LR 0.010000    Time 0.627414    
2024-01-15 19:00:23,077 - Epoch: [131][   80/  211]    Overall Loss 0.022973    Objective Loss 0.022973                                        LR 0.010000    Time 0.620310    
2024-01-15 19:00:29,416 - Epoch: [131][   90/  211]    Overall Loss 0.023808    Objective Loss 0.023808                                        LR 0.010000    Time 0.621769    
2024-01-15 19:00:35,148 - Epoch: [131][  100/  211]    Overall Loss 0.024627    Objective Loss 0.024627                                        LR 0.010000    Time 0.616900    
2024-01-15 19:00:40,904 - Epoch: [131][  110/  211]    Overall Loss 0.024430    Objective Loss 0.024430                                        LR 0.010000    Time 0.613141    
2024-01-15 19:00:46,652 - Epoch: [131][  120/  211]    Overall Loss 0.024418    Objective Loss 0.024418                                        LR 0.010000    Time 0.609925    
2024-01-15 19:00:52,677 - Epoch: [131][  130/  211]    Overall Loss 0.024119    Objective Loss 0.024119                                        LR 0.010000    Time 0.609343    
2024-01-15 19:00:58,427 - Epoch: [131][  140/  211]    Overall Loss 0.024371    Objective Loss 0.024371                                        LR 0.010000    Time 0.606871    
2024-01-15 19:01:04,152 - Epoch: [131][  150/  211]    Overall Loss 0.024171    Objective Loss 0.024171                                        LR 0.010000    Time 0.604572    
2024-01-15 19:01:09,909 - Epoch: [131][  160/  211]    Overall Loss 0.024173    Objective Loss 0.024173                                        LR 0.010000    Time 0.602760    
2024-01-15 19:01:15,568 - Epoch: [131][  170/  211]    Overall Loss 0.023666    Objective Loss 0.023666                                        LR 0.010000    Time 0.600591    
2024-01-15 19:01:21,409 - Epoch: [131][  180/  211]    Overall Loss 0.023505    Objective Loss 0.023505                                        LR 0.010000    Time 0.599666    
2024-01-15 19:01:27,113 - Epoch: [131][  190/  211]    Overall Loss 0.023382    Objective Loss 0.023382                                        LR 0.010000    Time 0.598122    
2024-01-15 19:01:33,188 - Epoch: [131][  200/  211]    Overall Loss 0.023494    Objective Loss 0.023494                                        LR 0.010000    Time 0.598583    
2024-01-15 19:01:38,867 - Epoch: [131][  210/  211]    Overall Loss 0.023159    Objective Loss 0.023159    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.597119    
2024-01-15 19:01:39,459 - Epoch: [131][  211/  211]    Overall Loss 0.023143    Objective Loss 0.023143    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.597092    
2024-01-15 19:01:40,338 - --- validate (epoch=131)-----------
2024-01-15 19:01:40,338 - 6000 samples (256 per mini-batch)
2024-01-15 19:01:46,439 - Epoch: [131][   10/   24]    Loss 0.024154    Top1 99.296875    Top5 100.000000    
2024-01-15 19:01:48,571 - Epoch: [131][   20/   24]    Loss 0.029714    Top1 99.160156    Top5 100.000000    
2024-01-15 19:01:49,327 - Epoch: [131][   24/   24]    Loss 0.028695    Top1 99.200000    Top5 100.000000    
2024-01-15 19:01:49,913 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.029

2024-01-15 19:01:49,914 - ==> Confusion:
[[603   0   0   0   0   0   1   0   0   1]
 [  0 686   0   0   0   0   1   1   0   0]
 [  0   0 582   1   0   0   0   1   2   0]
 [  0   0   2 578   0   2   0   0   1   0]
 [  0   0   0   0 559   0   0   0   0   6]
 [  0   0   0   1   0 510   5   0   2   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   4   0   0   0   0   0 621   0   0]
 [  0   0   0   1   0   1   1   2 578   1]
 [  1   1   0   1   1   2   0   2   2 605]]

2024-01-15 19:01:49,916 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 19:01:49,916 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:01:49,920 - 

2024-01-15 19:01:49,920 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:01:58,459 - Epoch: [132][   10/  211]    Overall Loss 0.023295    Objective Loss 0.023295                                        LR 0.010000    Time 0.853811    
2024-01-15 19:02:04,171 - Epoch: [132][   20/  211]    Overall Loss 0.022865    Objective Loss 0.022865                                        LR 0.010000    Time 0.712413    
2024-01-15 19:02:09,854 - Epoch: [132][   30/  211]    Overall Loss 0.021454    Objective Loss 0.021454                                        LR 0.010000    Time 0.664342    
2024-01-15 19:02:15,582 - Epoch: [132][   40/  211]    Overall Loss 0.020827    Objective Loss 0.020827                                        LR 0.010000    Time 0.641414    
2024-01-15 19:02:21,488 - Epoch: [132][   50/  211]    Overall Loss 0.022604    Objective Loss 0.022604                                        LR 0.010000    Time 0.631213    
2024-01-15 19:02:27,227 - Epoch: [132][   60/  211]    Overall Loss 0.022667    Objective Loss 0.022667                                        LR 0.010000    Time 0.621637    
2024-01-15 19:02:33,298 - Epoch: [132][   70/  211]    Overall Loss 0.022839    Objective Loss 0.022839                                        LR 0.010000    Time 0.619536    
2024-01-15 19:02:38,989 - Epoch: [132][   80/  211]    Overall Loss 0.022656    Objective Loss 0.022656                                        LR 0.010000    Time 0.613229    
2024-01-15 19:02:44,683 - Epoch: [132][   90/  211]    Overall Loss 0.022663    Objective Loss 0.022663                                        LR 0.010000    Time 0.608350    
2024-01-15 19:02:50,380 - Epoch: [132][  100/  211]    Overall Loss 0.022669    Objective Loss 0.022669                                        LR 0.010000    Time 0.604477    
2024-01-15 19:02:56,078 - Epoch: [132][  110/  211]    Overall Loss 0.023191    Objective Loss 0.023191                                        LR 0.010000    Time 0.601312    
2024-01-15 19:03:01,843 - Epoch: [132][  120/  211]    Overall Loss 0.023153    Objective Loss 0.023153                                        LR 0.010000    Time 0.599238    
2024-01-15 19:03:07,490 - Epoch: [132][  130/  211]    Overall Loss 0.023489    Objective Loss 0.023489                                        LR 0.010000    Time 0.596573    
2024-01-15 19:03:13,140 - Epoch: [132][  140/  211]    Overall Loss 0.023842    Objective Loss 0.023842                                        LR 0.010000    Time 0.594307    
2024-01-15 19:03:18,914 - Epoch: [132][  150/  211]    Overall Loss 0.023823    Objective Loss 0.023823                                        LR 0.010000    Time 0.593175    
2024-01-15 19:03:24,638 - Epoch: [132][  160/  211]    Overall Loss 0.023746    Objective Loss 0.023746                                        LR 0.010000    Time 0.591865    
2024-01-15 19:03:30,497 - Epoch: [132][  170/  211]    Overall Loss 0.023456    Objective Loss 0.023456                                        LR 0.010000    Time 0.591507    
2024-01-15 19:03:36,220 - Epoch: [132][  180/  211]    Overall Loss 0.023568    Objective Loss 0.023568                                        LR 0.010000    Time 0.590437    
2024-01-15 19:03:41,970 - Epoch: [132][  190/  211]    Overall Loss 0.023405    Objective Loss 0.023405                                        LR 0.010000    Time 0.589616    
2024-01-15 19:03:48,038 - Epoch: [132][  200/  211]    Overall Loss 0.023479    Objective Loss 0.023479                                        LR 0.010000    Time 0.590474    
2024-01-15 19:03:53,885 - Epoch: [132][  210/  211]    Overall Loss 0.023640    Objective Loss 0.023640    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.590190    
2024-01-15 19:03:54,549 - Epoch: [132][  211/  211]    Overall Loss 0.023720    Objective Loss 0.023720    Top1 98.991935    Top5 100.000000    LR 0.010000    Time 0.590532    
2024-01-15 19:03:55,163 - --- validate (epoch=132)-----------
2024-01-15 19:03:55,164 - 6000 samples (256 per mini-batch)
2024-01-15 19:04:00,460 - Epoch: [132][   10/   24]    Loss 0.028259    Top1 99.257812    Top5 100.000000    
2024-01-15 19:04:02,631 - Epoch: [132][   20/   24]    Loss 0.027836    Top1 99.160156    Top5 100.000000    
2024-01-15 19:04:03,424 - Epoch: [132][   24/   24]    Loss 0.026080    Top1 99.233333    Top5 100.000000    
2024-01-15 19:04:04,045 - ==> Top1: 99.233    Top5: 100.000    Loss: 0.026

2024-01-15 19:04:04,047 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 685   1   0   1   0   0   1   0   0]
 [  0   0 582   0   0   0   0   4   0   0]
 [  0   0   2 579   0   1   0   0   1   0]
 [  0   0   1   0 561   0   0   0   0   3]
 [  0   0   0   2   0 514   2   0   0   0]
 [  0   1   0   0   1   0 629   0   0   0]
 [  0   1   0   1   0   0   0 623   0   0]
 [  0   0   0   0   2   0   3   0 578   1]
 [  0   0   0   1   5   1   0   5   2 601]]

2024-01-15 19:04:04,050 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 19:04:04,050 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:04:04,056 - 

2024-01-15 19:04:04,056 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:04:12,518 - Epoch: [133][   10/  211]    Overall Loss 0.025679    Objective Loss 0.025679                                        LR 0.010000    Time 0.846109    
2024-01-15 19:04:18,589 - Epoch: [133][   20/  211]    Overall Loss 0.026182    Objective Loss 0.026182                                        LR 0.010000    Time 0.726535    
2024-01-15 19:04:24,419 - Epoch: [133][   30/  211]    Overall Loss 0.023108    Objective Loss 0.023108                                        LR 0.010000    Time 0.678637    
2024-01-15 19:04:30,328 - Epoch: [133][   40/  211]    Overall Loss 0.021782    Objective Loss 0.021782                                        LR 0.010000    Time 0.656660    
2024-01-15 19:04:35,982 - Epoch: [133][   50/  211]    Overall Loss 0.022237    Objective Loss 0.022237                                        LR 0.010000    Time 0.638390    
2024-01-15 19:04:41,619 - Epoch: [133][   60/  211]    Overall Loss 0.022000    Objective Loss 0.022000                                        LR 0.010000    Time 0.625933    
2024-01-15 19:04:47,264 - Epoch: [133][   70/  211]    Overall Loss 0.021954    Objective Loss 0.021954                                        LR 0.010000    Time 0.617146    
2024-01-15 19:04:53,139 - Epoch: [133][   80/  211]    Overall Loss 0.021431    Objective Loss 0.021431                                        LR 0.010000    Time 0.613419    
2024-01-15 19:04:58,798 - Epoch: [133][   90/  211]    Overall Loss 0.021345    Objective Loss 0.021345                                        LR 0.010000    Time 0.608130    
2024-01-15 19:05:04,453 - Epoch: [133][  100/  211]    Overall Loss 0.022238    Objective Loss 0.022238                                        LR 0.010000    Time 0.603867    
2024-01-15 19:05:10,094 - Epoch: [133][  110/  211]    Overall Loss 0.021838    Objective Loss 0.021838                                        LR 0.010000    Time 0.600240    
2024-01-15 19:05:15,726 - Epoch: [133][  120/  211]    Overall Loss 0.021698    Objective Loss 0.021698                                        LR 0.010000    Time 0.597153    
2024-01-15 19:05:21,357 - Epoch: [133][  130/  211]    Overall Loss 0.021535    Objective Loss 0.021535                                        LR 0.010000    Time 0.594521    
2024-01-15 19:05:26,997 - Epoch: [133][  140/  211]    Overall Loss 0.022286    Objective Loss 0.022286                                        LR 0.010000    Time 0.592339    
2024-01-15 19:05:32,807 - Epoch: [133][  150/  211]    Overall Loss 0.022356    Objective Loss 0.022356                                        LR 0.010000    Time 0.591571    
2024-01-15 19:05:38,449 - Epoch: [133][  160/  211]    Overall Loss 0.022416    Objective Loss 0.022416                                        LR 0.010000    Time 0.589857    
2024-01-15 19:05:44,107 - Epoch: [133][  170/  211]    Overall Loss 0.022453    Objective Loss 0.022453                                        LR 0.010000    Time 0.588435    
2024-01-15 19:05:49,735 - Epoch: [133][  180/  211]    Overall Loss 0.022791    Objective Loss 0.022791                                        LR 0.010000    Time 0.587008    
2024-01-15 19:05:55,368 - Epoch: [133][  190/  211]    Overall Loss 0.023024    Objective Loss 0.023024                                        LR 0.010000    Time 0.585754    
2024-01-15 19:06:01,021 - Epoch: [133][  200/  211]    Overall Loss 0.023241    Objective Loss 0.023241                                        LR 0.010000    Time 0.584723    
2024-01-15 19:06:06,678 - Epoch: [133][  210/  211]    Overall Loss 0.023289    Objective Loss 0.023289    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.583815    
2024-01-15 19:06:07,238 - Epoch: [133][  211/  211]    Overall Loss 0.023253    Objective Loss 0.023253    Top1 99.395161    Top5 100.000000    LR 0.010000    Time 0.583697    
2024-01-15 19:06:07,841 - --- validate (epoch=133)-----------
2024-01-15 19:06:07,842 - 6000 samples (256 per mini-batch)
2024-01-15 19:06:13,174 - Epoch: [133][   10/   24]    Loss 0.019752    Top1 99.453125    Top5 100.000000    
2024-01-15 19:06:15,288 - Epoch: [133][   20/   24]    Loss 0.026079    Top1 99.218750    Top5 100.000000    
2024-01-15 19:06:16,054 - Epoch: [133][   24/   24]    Loss 0.024629    Top1 99.283333    Top5 100.000000    
2024-01-15 19:06:16,599 - ==> Top1: 99.283    Top5: 100.000    Loss: 0.025

2024-01-15 19:06:16,600 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 687   0   0   1   0   0   0   0   0]
 [  0   0 581   0   0   0   0   4   1   0]
 [  0   0   4 577   0   1   0   0   1   0]
 [  0   0   0   0 560   0   0   1   0   4]
 [  1   1   0   1   0 513   2   0   0   0]
 [  0   0   0   0   1   0 627   0   3   0]
 [  0   0   1   0   0   0   0 624   0   0]
 [  0   0   0   0   0   2   1   0 581   0]
 [  1   1   0   0   2   2   0   2   2 605]]

2024-01-15 19:06:16,603 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 19:06:16,603 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:06:16,607 - 

2024-01-15 19:06:16,607 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:06:24,942 - Epoch: [134][   10/  211]    Overall Loss 0.018304    Objective Loss 0.018304                                        LR 0.010000    Time 0.833480    
2024-01-15 19:06:30,779 - Epoch: [134][   20/  211]    Overall Loss 0.020045    Objective Loss 0.020045                                        LR 0.010000    Time 0.708500    
2024-01-15 19:06:36,422 - Epoch: [134][   30/  211]    Overall Loss 0.020239    Objective Loss 0.020239                                        LR 0.010000    Time 0.660382    
2024-01-15 19:06:42,063 - Epoch: [134][   40/  211]    Overall Loss 0.022584    Objective Loss 0.022584                                        LR 0.010000    Time 0.636295    
2024-01-15 19:06:47,722 - Epoch: [134][   50/  211]    Overall Loss 0.022793    Objective Loss 0.022793                                        LR 0.010000    Time 0.622218    
2024-01-15 19:06:53,354 - Epoch: [134][   60/  211]    Overall Loss 0.023915    Objective Loss 0.023915                                        LR 0.010000    Time 0.612367    
2024-01-15 19:06:59,135 - Epoch: [134][   70/  211]    Overall Loss 0.024064    Objective Loss 0.024064                                        LR 0.010000    Time 0.607463    
2024-01-15 19:07:04,959 - Epoch: [134][   80/  211]    Overall Loss 0.024628    Objective Loss 0.024628                                        LR 0.010000    Time 0.604314    
2024-01-15 19:07:10,675 - Epoch: [134][   90/  211]    Overall Loss 0.025226    Objective Loss 0.025226                                        LR 0.010000    Time 0.600664    
2024-01-15 19:07:16,334 - Epoch: [134][  100/  211]    Overall Loss 0.024597    Objective Loss 0.024597                                        LR 0.010000    Time 0.597186    
2024-01-15 19:07:21,970 - Epoch: [134][  110/  211]    Overall Loss 0.024048    Objective Loss 0.024048                                        LR 0.010000    Time 0.594120    
2024-01-15 19:07:27,654 - Epoch: [134][  120/  211]    Overall Loss 0.023629    Objective Loss 0.023629                                        LR 0.010000    Time 0.591979    
2024-01-15 19:07:33,687 - Epoch: [134][  130/  211]    Overall Loss 0.023563    Objective Loss 0.023563                                        LR 0.010000    Time 0.592783    
2024-01-15 19:07:39,494 - Epoch: [134][  140/  211]    Overall Loss 0.023710    Objective Loss 0.023710                                        LR 0.010000    Time 0.591897    
2024-01-15 19:07:45,197 - Epoch: [134][  150/  211]    Overall Loss 0.023379    Objective Loss 0.023379                                        LR 0.010000    Time 0.590451    
2024-01-15 19:07:50,969 - Epoch: [134][  160/  211]    Overall Loss 0.023135    Objective Loss 0.023135                                        LR 0.010000    Time 0.589619    
2024-01-15 19:07:56,841 - Epoch: [134][  170/  211]    Overall Loss 0.023625    Objective Loss 0.023625                                        LR 0.010000    Time 0.589466    
2024-01-15 19:08:02,593 - Epoch: [134][  180/  211]    Overall Loss 0.023520    Objective Loss 0.023520                                        LR 0.010000    Time 0.588669    
2024-01-15 19:08:08,320 - Epoch: [134][  190/  211]    Overall Loss 0.023611    Objective Loss 0.023611                                        LR 0.010000    Time 0.587826    
2024-01-15 19:08:14,157 - Epoch: [134][  200/  211]    Overall Loss 0.024011    Objective Loss 0.024011                                        LR 0.010000    Time 0.587611    
2024-01-15 19:08:19,834 - Epoch: [134][  210/  211]    Overall Loss 0.023773    Objective Loss 0.023773    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.586659    
2024-01-15 19:08:20,445 - Epoch: [134][  211/  211]    Overall Loss 0.023890    Objective Loss 0.023890    Top1 98.991935    Top5 100.000000    LR 0.010000    Time 0.586773    
2024-01-15 19:08:21,023 - --- validate (epoch=134)-----------
2024-01-15 19:08:21,024 - 6000 samples (256 per mini-batch)
2024-01-15 19:08:28,323 - Epoch: [134][   10/   24]    Loss 0.020820    Top1 99.414062    Top5 100.000000    
2024-01-15 19:08:30,817 - Epoch: [134][   20/   24]    Loss 0.025808    Top1 99.218750    Top5 100.000000    
2024-01-15 19:08:31,687 - Epoch: [134][   24/   24]    Loss 0.028199    Top1 99.133333    Top5 100.000000    
2024-01-15 19:08:32,239 - ==> Top1: 99.133    Top5: 100.000    Loss: 0.028

2024-01-15 19:08:32,241 - ==> Confusion:
[[602   0   1   1   0   0   1   0   0   0]
 [  0 683   1   0   0   1   1   2   0   0]
 [  0   0 580   1   0   0   1   4   0   0]
 [  0   0   3 578   0   1   0   0   1   0]
 [  0   0   0   0 559   0   0   1   0   5]
 [  0   0   0   0   0 514   3   0   0   1]
 [  0   1   0   0   2   1 627   0   0   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  0   0   1   2   1   0   2   0 578   0]
 [  0   1   0   0   5   1   0   1   3 604]]

2024-01-15 19:08:32,243 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 19:08:32,243 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:08:32,248 - 

2024-01-15 19:08:32,248 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:08:41,635 - Epoch: [135][   10/  211]    Overall Loss 0.023885    Objective Loss 0.023885                                        LR 0.010000    Time 0.938603    
2024-01-15 19:08:47,319 - Epoch: [135][   20/  211]    Overall Loss 0.022669    Objective Loss 0.022669                                        LR 0.010000    Time 0.753318    
2024-01-15 19:08:53,060 - Epoch: [135][   30/  211]    Overall Loss 0.024169    Objective Loss 0.024169                                        LR 0.010000    Time 0.693540    
2024-01-15 19:08:59,374 - Epoch: [135][   40/  211]    Overall Loss 0.024307    Objective Loss 0.024307                                        LR 0.010000    Time 0.677984    
2024-01-15 19:09:05,934 - Epoch: [135][   50/  211]    Overall Loss 0.024166    Objective Loss 0.024166                                        LR 0.010000    Time 0.673561    
2024-01-15 19:09:11,795 - Epoch: [135][   60/  211]    Overall Loss 0.023422    Objective Loss 0.023422                                        LR 0.010000    Time 0.658948    
2024-01-15 19:09:17,585 - Epoch: [135][   70/  211]    Overall Loss 0.022852    Objective Loss 0.022852                                        LR 0.010000    Time 0.647512    
2024-01-15 19:09:23,342 - Epoch: [135][   80/  211]    Overall Loss 0.022763    Objective Loss 0.022763                                        LR 0.010000    Time 0.638509    
2024-01-15 19:09:29,352 - Epoch: [135][   90/  211]    Overall Loss 0.022624    Objective Loss 0.022624                                        LR 0.010000    Time 0.634327    
2024-01-15 19:09:35,128 - Epoch: [135][  100/  211]    Overall Loss 0.023339    Objective Loss 0.023339                                        LR 0.010000    Time 0.628643    
2024-01-15 19:09:40,837 - Epoch: [135][  110/  211]    Overall Loss 0.023408    Objective Loss 0.023408                                        LR 0.010000    Time 0.623382    
2024-01-15 19:09:46,623 - Epoch: [135][  120/  211]    Overall Loss 0.023639    Objective Loss 0.023639                                        LR 0.010000    Time 0.619640    
2024-01-15 19:09:52,316 - Epoch: [135][  130/  211]    Overall Loss 0.023839    Objective Loss 0.023839                                        LR 0.010000    Time 0.615763    
2024-01-15 19:09:58,096 - Epoch: [135][  140/  211]    Overall Loss 0.023844    Objective Loss 0.023844                                        LR 0.010000    Time 0.613052    
2024-01-15 19:10:03,888 - Epoch: [135][  150/  211]    Overall Loss 0.023409    Objective Loss 0.023409                                        LR 0.010000    Time 0.610791    
2024-01-15 19:10:09,744 - Epoch: [135][  160/  211]    Overall Loss 0.023031    Objective Loss 0.023031                                        LR 0.010000    Time 0.609207    
2024-01-15 19:10:15,560 - Epoch: [135][  170/  211]    Overall Loss 0.023475    Objective Loss 0.023475                                        LR 0.010000    Time 0.607579    
2024-01-15 19:10:21,620 - Epoch: [135][  180/  211]    Overall Loss 0.023276    Objective Loss 0.023276                                        LR 0.010000    Time 0.607484    
2024-01-15 19:10:27,701 - Epoch: [135][  190/  211]    Overall Loss 0.023311    Objective Loss 0.023311                                        LR 0.010000    Time 0.607507    
2024-01-15 19:10:34,493 - Epoch: [135][  200/  211]    Overall Loss 0.023199    Objective Loss 0.023199                                        LR 0.010000    Time 0.611077    
2024-01-15 19:10:40,775 - Epoch: [135][  210/  211]    Overall Loss 0.023435    Objective Loss 0.023435    Top1 99.218750    Top5 100.000000    LR 0.010000    Time 0.611885    
2024-01-15 19:10:41,342 - Epoch: [135][  211/  211]    Overall Loss 0.023386    Objective Loss 0.023386    Top1 99.596774    Top5 100.000000    LR 0.010000    Time 0.611669    
2024-01-15 19:10:42,223 - --- validate (epoch=135)-----------
2024-01-15 19:10:42,225 - 6000 samples (256 per mini-batch)
2024-01-15 19:10:48,516 - Epoch: [135][   10/   24]    Loss 0.028607    Top1 99.218750    Top5 100.000000    
2024-01-15 19:10:50,676 - Epoch: [135][   20/   24]    Loss 0.026567    Top1 99.296875    Top5 100.000000    
2024-01-15 19:10:51,456 - Epoch: [135][   24/   24]    Loss 0.026072    Top1 99.316667    Top5 100.000000    
2024-01-15 19:10:52,025 - ==> Top1: 99.317    Top5: 100.000    Loss: 0.026

2024-01-15 19:10:52,026 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 684   0   0   1   1   1   1   0   0]
 [  0   1 582   0   1   0   0   1   0   1]
 [  0   0   0 580   0   1   0   0   1   1]
 [  0   0   0   0 557   0   1   1   0   6]
 [  0   0   0   1   0 514   2   0   1   0]
 [  0   0   0   0   1   1 628   0   1   0]
 [  0   0   1   0   0   0   0 624   0   0]
 [  0   0   0   0   1   0   3   0 580   0]
 [  0   1   0   0   4   0   0   1   2 607]]

2024-01-15 19:10:52,028 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 19:10:52,028 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:10:52,033 - 

2024-01-15 19:10:52,034 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:11:00,581 - Epoch: [136][   10/  211]    Overall Loss 0.018769    Objective Loss 0.018769                                        LR 0.010000    Time 0.854677    
2024-01-15 19:11:07,463 - Epoch: [136][   20/  211]    Overall Loss 0.025286    Objective Loss 0.025286                                        LR 0.010000    Time 0.771370    
2024-01-15 19:11:14,201 - Epoch: [136][   30/  211]    Overall Loss 0.026662    Objective Loss 0.026662                                        LR 0.010000    Time 0.738779    
2024-01-15 19:11:20,026 - Epoch: [136][   40/  211]    Overall Loss 0.024723    Objective Loss 0.024723                                        LR 0.010000    Time 0.699666    
2024-01-15 19:11:25,901 - Epoch: [136][   50/  211]    Overall Loss 0.024634    Objective Loss 0.024634                                        LR 0.010000    Time 0.677199    
2024-01-15 19:11:31,935 - Epoch: [136][   60/  211]    Overall Loss 0.024215    Objective Loss 0.024215                                        LR 0.010000    Time 0.664872    
2024-01-15 19:11:37,837 - Epoch: [136][   70/  211]    Overall Loss 0.023506    Objective Loss 0.023506                                        LR 0.010000    Time 0.654176    
2024-01-15 19:11:43,599 - Epoch: [136][   80/  211]    Overall Loss 0.025463    Objective Loss 0.025463                                        LR 0.010000    Time 0.644425    
2024-01-15 19:11:49,387 - Epoch: [136][   90/  211]    Overall Loss 0.025412    Objective Loss 0.025412                                        LR 0.010000    Time 0.637116    
2024-01-15 19:11:55,073 - Epoch: [136][  100/  211]    Overall Loss 0.025408    Objective Loss 0.025408                                        LR 0.010000    Time 0.630251    
2024-01-15 19:12:00,761 - Epoch: [136][  110/  211]    Overall Loss 0.025191    Objective Loss 0.025191                                        LR 0.010000    Time 0.624664    
2024-01-15 19:12:06,575 - Epoch: [136][  120/  211]    Overall Loss 0.024617    Objective Loss 0.024617                                        LR 0.010000    Time 0.621050    
2024-01-15 19:12:12,266 - Epoch: [136][  130/  211]    Overall Loss 0.024917    Objective Loss 0.024917                                        LR 0.010000    Time 0.617043    
2024-01-15 19:12:17,935 - Epoch: [136][  140/  211]    Overall Loss 0.025015    Objective Loss 0.025015                                        LR 0.010000    Time 0.613454    
2024-01-15 19:12:23,624 - Epoch: [136][  150/  211]    Overall Loss 0.024629    Objective Loss 0.024629                                        LR 0.010000    Time 0.610476    
2024-01-15 19:12:29,547 - Epoch: [136][  160/  211]    Overall Loss 0.024274    Objective Loss 0.024274                                        LR 0.010000    Time 0.609337    
2024-01-15 19:12:35,254 - Epoch: [136][  170/  211]    Overall Loss 0.024309    Objective Loss 0.024309                                        LR 0.010000    Time 0.607059    
2024-01-15 19:12:40,994 - Epoch: [136][  180/  211]    Overall Loss 0.023880    Objective Loss 0.023880                                        LR 0.010000    Time 0.605208    
2024-01-15 19:12:46,894 - Epoch: [136][  190/  211]    Overall Loss 0.023838    Objective Loss 0.023838                                        LR 0.010000    Time 0.604390    
2024-01-15 19:12:52,567 - Epoch: [136][  200/  211]    Overall Loss 0.023705    Objective Loss 0.023705                                        LR 0.010000    Time 0.602530    
2024-01-15 19:12:58,279 - Epoch: [136][  210/  211]    Overall Loss 0.023800    Objective Loss 0.023800    Top1 98.828125    Top5 100.000000    LR 0.010000    Time 0.601038    
2024-01-15 19:12:58,846 - Epoch: [136][  211/  211]    Overall Loss 0.023842    Objective Loss 0.023842    Top1 98.991935    Top5 100.000000    LR 0.010000    Time 0.600874    
2024-01-15 19:12:59,777 - --- validate (epoch=136)-----------
2024-01-15 19:12:59,779 - 6000 samples (256 per mini-batch)
2024-01-15 19:13:05,970 - Epoch: [136][   10/   24]    Loss 0.021539    Top1 99.296875    Top5 100.000000    
2024-01-15 19:13:08,107 - Epoch: [136][   20/   24]    Loss 0.025688    Top1 99.257812    Top5 100.000000    
2024-01-15 19:13:08,852 - Epoch: [136][   24/   24]    Loss 0.028092    Top1 99.150000    Top5 100.000000    
2024-01-15 19:13:09,424 - ==> Top1: 99.150    Top5: 100.000    Loss: 0.028

2024-01-15 19:13:09,425 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 583   1   0   0   0   1   1   0]
 [  0   0   1 579   0   2   0   0   1   0]
 [  0   0   1   0 553   0   1   1   0   9]
 [  0   0   0   1   0 515   2   0   0   0]
 [  0   0   0   0   2   0 629   0   0   0]
 [  0   2   2   0   1   0   0 620   0   0]
 [  0   0   0   0   0   0   4   0 579   1]
 [  2   1   0   1   3   1   0   2   3 602]]

2024-01-15 19:13:09,427 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 19:13:09,428 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:13:09,433 - 

2024-01-15 19:13:09,433 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:13:18,179 - Epoch: [137][   10/  211]    Overall Loss 0.023852    Objective Loss 0.023852                                        LR 0.010000    Time 0.874578    
2024-01-15 19:13:23,957 - Epoch: [137][   20/  211]    Overall Loss 0.025658    Objective Loss 0.025658                                        LR 0.010000    Time 0.726080    
2024-01-15 19:13:30,304 - Epoch: [137][   30/  211]    Overall Loss 0.025836    Objective Loss 0.025836                                        LR 0.010000    Time 0.695544    
2024-01-15 19:13:36,296 - Epoch: [137][   40/  211]    Overall Loss 0.024634    Objective Loss 0.024634                                        LR 0.010000    Time 0.671431    
2024-01-15 19:13:41,989 - Epoch: [137][   50/  211]    Overall Loss 0.024329    Objective Loss 0.024329                                        LR 0.010000    Time 0.650974    
2024-01-15 19:13:47,686 - Epoch: [137][   60/  211]    Overall Loss 0.023255    Objective Loss 0.023255                                        LR 0.010000    Time 0.637403    
2024-01-15 19:13:53,376 - Epoch: [137][   70/  211]    Overall Loss 0.023918    Objective Loss 0.023918                                        LR 0.010000    Time 0.627625    
2024-01-15 19:13:59,135 - Epoch: [137][   80/  211]    Overall Loss 0.023538    Objective Loss 0.023538                                        LR 0.010000    Time 0.621143    
2024-01-15 19:14:04,860 - Epoch: [137][   90/  211]    Overall Loss 0.023711    Objective Loss 0.023711                                        LR 0.010000    Time 0.615726    
2024-01-15 19:14:10,668 - Epoch: [137][  100/  211]    Overall Loss 0.023789    Objective Loss 0.023789                                        LR 0.010000    Time 0.612230    
2024-01-15 19:14:16,361 - Epoch: [137][  110/  211]    Overall Loss 0.023824    Objective Loss 0.023824                                        LR 0.010000    Time 0.608309    
2024-01-15 19:14:22,222 - Epoch: [137][  120/  211]    Overall Loss 0.023345    Objective Loss 0.023345                                        LR 0.010000    Time 0.606452    
2024-01-15 19:14:28,386 - Epoch: [137][  130/  211]    Overall Loss 0.022829    Objective Loss 0.022829                                        LR 0.010000    Time 0.607200    
2024-01-15 19:14:34,383 - Epoch: [137][  140/  211]    Overall Loss 0.022680    Objective Loss 0.022680                                        LR 0.010000    Time 0.606658    
2024-01-15 19:14:40,261 - Epoch: [137][  150/  211]    Overall Loss 0.022990    Objective Loss 0.022990                                        LR 0.010000    Time 0.605395    
2024-01-15 19:14:46,016 - Epoch: [137][  160/  211]    Overall Loss 0.023028    Objective Loss 0.023028                                        LR 0.010000    Time 0.603522    
2024-01-15 19:14:51,845 - Epoch: [137][  170/  211]    Overall Loss 0.023485    Objective Loss 0.023485                                        LR 0.010000    Time 0.602298    
2024-01-15 19:14:57,770 - Epoch: [137][  180/  211]    Overall Loss 0.023072    Objective Loss 0.023072                                        LR 0.010000    Time 0.601752    
2024-01-15 19:15:03,641 - Epoch: [137][  190/  211]    Overall Loss 0.022928    Objective Loss 0.022928                                        LR 0.010000    Time 0.600972    
2024-01-15 19:15:09,290 - Epoch: [137][  200/  211]    Overall Loss 0.022694    Objective Loss 0.022694                                        LR 0.010000    Time 0.599165    
2024-01-15 19:15:14,913 - Epoch: [137][  210/  211]    Overall Loss 0.022504    Objective Loss 0.022504    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 0.597406    
2024-01-15 19:15:15,448 - Epoch: [137][  211/  211]    Overall Loss 0.022660    Objective Loss 0.022660    Top1 99.193548    Top5 100.000000    LR 0.010000    Time 0.597111    
2024-01-15 19:15:16,395 - --- validate (epoch=137)-----------
2024-01-15 19:15:16,397 - 6000 samples (256 per mini-batch)
2024-01-15 19:15:23,257 - Epoch: [137][   10/   24]    Loss 0.022551    Top1 99.375000    Top5 100.000000    
2024-01-15 19:15:25,368 - Epoch: [137][   20/   24]    Loss 0.030023    Top1 99.121094    Top5 100.000000    
2024-01-15 19:15:26,106 - Epoch: [137][   24/   24]    Loss 0.030309    Top1 99.116667    Top5 100.000000    
2024-01-15 19:15:26,814 - ==> Top1: 99.117    Top5: 100.000    Loss: 0.030

2024-01-15 19:15:26,815 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 685   1   0   0   0   1   1   0   0]
 [  0   1 581   0   0   0   0   2   2   0]
 [  0   0   3 575   0   2   0   2   1   0]
 [  0   0   0   0 558   0   1   1   0   5]
 [  0   2   0   0   0 513   2   0   1   0]
 [  2   1   0   0   2   0 626   0   0   0]
 [  0   3   1   0   2   0   0 619   0   0]
 [  0   0   0   2   0   0   1   0 581   0]
 [  0   2   0   0   1   0   0   2   4 606]]

2024-01-15 19:15:26,817 - ==> Best [Top1: 99.333   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 124]
2024-01-15 19:15:26,817 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:15:26,821 - 

2024-01-15 19:15:26,821 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:15:35,696 - Epoch: [138][   10/  211]    Overall Loss 0.020546    Objective Loss 0.020546                                        LR 0.010000    Time 0.887457    
2024-01-15 19:15:41,389 - Epoch: [138][   20/  211]    Overall Loss 0.022272    Objective Loss 0.022272                                        LR 0.010000    Time 0.728282    
2024-01-15 19:15:47,028 - Epoch: [138][   30/  211]    Overall Loss 0.022747    Objective Loss 0.022747                                        LR 0.010000    Time 0.673483    
2024-01-15 19:15:52,659 - Epoch: [138][   40/  211]    Overall Loss 0.022199    Objective Loss 0.022199                                        LR 0.010000    Time 0.645874    
2024-01-15 19:15:58,284 - Epoch: [138][   50/  211]    Overall Loss 0.022219    Objective Loss 0.022219                                        LR 0.010000    Time 0.629198    
2024-01-15 19:16:04,055 - Epoch: [138][   60/  211]    Overall Loss 0.021671    Objective Loss 0.021671                                        LR 0.010000    Time 0.620499    
2024-01-15 19:16:09,740 - Epoch: [138][   70/  211]    Overall Loss 0.022641    Objective Loss 0.022641                                        LR 0.010000    Time 0.613055    
2024-01-15 19:16:15,384 - Epoch: [138][   80/  211]    Overall Loss 0.022166    Objective Loss 0.022166                                        LR 0.010000    Time 0.606968    
2024-01-15 19:16:21,027 - Epoch: [138][   90/  211]    Overall Loss 0.022302    Objective Loss 0.022302                                        LR 0.010000    Time 0.602214    
2024-01-15 19:16:26,941 - Epoch: [138][  100/  211]    Overall Loss 0.022242    Objective Loss 0.022242                                        LR 0.010000    Time 0.601110    
2024-01-15 19:16:34,237 - Epoch: [138][  110/  211]    Overall Loss 0.022577    Objective Loss 0.022577                                        LR 0.010000    Time 0.612782    
2024-01-15 19:16:40,089 - Epoch: [138][  120/  211]    Overall Loss 0.023165    Objective Loss 0.023165                                        LR 0.010000    Time 0.610471    
2024-01-15 19:16:46,016 - Epoch: [138][  130/  211]    Overall Loss 0.023052    Objective Loss 0.023052                                        LR 0.010000    Time 0.609075    
2024-01-15 19:16:52,012 - Epoch: [138][  140/  211]    Overall Loss 0.022901    Objective Loss 0.022901                                        LR 0.010000    Time 0.608363    
2024-01-15 19:16:57,758 - Epoch: [138][  150/  211]    Overall Loss 0.022709    Objective Loss 0.022709                                        LR 0.010000    Time 0.606108    
2024-01-15 19:17:03,608 - Epoch: [138][  160/  211]    Overall Loss 0.022908    Objective Loss 0.022908                                        LR 0.010000    Time 0.604778    
2024-01-15 19:17:09,382 - Epoch: [138][  170/  211]    Overall Loss 0.022718    Objective Loss 0.022718                                        LR 0.010000    Time 0.603162    
2024-01-15 19:17:15,071 - Epoch: [138][  180/  211]    Overall Loss 0.022828    Objective Loss 0.022828                                        LR 0.010000    Time 0.601252    
2024-01-15 19:17:20,813 - Epoch: [138][  190/  211]    Overall Loss 0.022837    Objective Loss 0.022837                                        LR 0.010000    Time 0.599826    
2024-01-15 19:17:26,678 - Epoch: [138][  200/  211]    Overall Loss 0.022815    Objective Loss 0.022815                                        LR 0.010000    Time 0.599150    
2024-01-15 19:17:32,619 - Epoch: [138][  210/  211]    Overall Loss 0.022748    Objective Loss 0.022748    Top1 99.609375    Top5 100.000000    LR 0.010000    Time 0.598907    
2024-01-15 19:17:33,302 - Epoch: [138][  211/  211]    Overall Loss 0.022730    Objective Loss 0.022730    Top1 99.596774    Top5 100.000000    LR 0.010000    Time 0.599299    
2024-01-15 19:17:34,135 - --- validate (epoch=138)-----------
2024-01-15 19:17:34,136 - 6000 samples (256 per mini-batch)
2024-01-15 19:17:41,005 - Epoch: [138][   10/   24]    Loss 0.024588    Top1 99.375000    Top5 100.000000    
2024-01-15 19:17:43,213 - Epoch: [138][   20/   24]    Loss 0.025747    Top1 99.335938    Top5 100.000000    
2024-01-15 19:17:44,003 - Epoch: [138][   24/   24]    Loss 0.025528    Top1 99.350000    Top5 100.000000    
2024-01-15 19:17:44,827 - ==> Top1: 99.350    Top5: 100.000    Loss: 0.026

2024-01-15 19:17:44,828 - ==> Confusion:
[[604   0   1   0   0   0   0   0   0   0]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 584   0   0   0   0   1   1   0]
 [  0   0   2 580   0   1   0   0   0   0]
 [  0   1   2   0 558   0   0   0   0   4]
 [  2   0   0   1   0 511   4   0   0   0]
 [  0   0   0   0   1   1 628   0   1   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   1   2   0   1   1   0 579   0]
 [  1   1   0   0   2   1   0   2   2 606]]

2024-01-15 19:17:44,830 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:17:44,830 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:17:44,837 - 

2024-01-15 19:17:44,838 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:17:53,679 - Epoch: [139][   10/  211]    Overall Loss 0.014779    Objective Loss 0.014779                                        LR 0.010000    Time 0.884070    
2024-01-15 19:17:59,347 - Epoch: [139][   20/  211]    Overall Loss 0.018516    Objective Loss 0.018516                                        LR 0.010000    Time 0.725329    
2024-01-15 19:18:05,221 - Epoch: [139][   30/  211]    Overall Loss 0.020076    Objective Loss 0.020076                                        LR 0.010000    Time 0.679340    
2024-01-15 19:18:10,902 - Epoch: [139][   40/  211]    Overall Loss 0.020589    Objective Loss 0.020589                                        LR 0.010000    Time 0.651516    
2024-01-15 19:18:16,668 - Epoch: [139][   50/  211]    Overall Loss 0.020563    Objective Loss 0.020563                                        LR 0.010000    Time 0.636511    
2024-01-15 19:18:22,529 - Epoch: [139][   60/  211]    Overall Loss 0.020879    Objective Loss 0.020879                                        LR 0.010000    Time 0.628082    
2024-01-15 19:18:28,309 - Epoch: [139][   70/  211]    Overall Loss 0.021652    Objective Loss 0.021652                                        LR 0.010000    Time 0.620897    
2024-01-15 19:18:34,181 - Epoch: [139][   80/  211]    Overall Loss 0.021645    Objective Loss 0.021645                                        LR 0.010000    Time 0.616665    
2024-01-15 19:18:39,868 - Epoch: [139][   90/  211]    Overall Loss 0.021744    Objective Loss 0.021744                                        LR 0.010000    Time 0.611326    
2024-01-15 19:18:45,609 - Epoch: [139][  100/  211]    Overall Loss 0.021955    Objective Loss 0.021955                                        LR 0.010000    Time 0.607591    
2024-01-15 19:18:51,287 - Epoch: [139][  110/  211]    Overall Loss 0.021632    Objective Loss 0.021632                                        LR 0.010000    Time 0.603960    
2024-01-15 19:18:56,926 - Epoch: [139][  120/  211]    Overall Loss 0.021870    Objective Loss 0.021870                                        LR 0.010000    Time 0.600622    
2024-01-15 19:19:02,594 - Epoch: [139][  130/  211]    Overall Loss 0.022173    Objective Loss 0.022173                                        LR 0.010000    Time 0.598007    
2024-01-15 19:19:08,355 - Epoch: [139][  140/  211]    Overall Loss 0.021947    Objective Loss 0.021947                                        LR 0.010000    Time 0.596439    
2024-01-15 19:19:13,997 - Epoch: [139][  150/  211]    Overall Loss 0.022240    Objective Loss 0.022240                                        LR 0.010000    Time 0.594282    
2024-01-15 19:19:19,671 - Epoch: [139][  160/  211]    Overall Loss 0.022163    Objective Loss 0.022163                                        LR 0.010000    Time 0.592595    
2024-01-15 19:19:25,412 - Epoch: [139][  170/  211]    Overall Loss 0.021962    Objective Loss 0.021962                                        LR 0.010000    Time 0.591505    
2024-01-15 19:19:31,223 - Epoch: [139][  180/  211]    Overall Loss 0.021930    Objective Loss 0.021930                                        LR 0.010000    Time 0.590915    
2024-01-15 19:19:36,903 - Epoch: [139][  190/  211]    Overall Loss 0.022188    Objective Loss 0.022188                                        LR 0.010000    Time 0.589705    
2024-01-15 19:19:42,694 - Epoch: [139][  200/  211]    Overall Loss 0.022168    Objective Loss 0.022168                                        LR 0.010000    Time 0.589170    
2024-01-15 19:19:48,358 - Epoch: [139][  210/  211]    Overall Loss 0.022371    Objective Loss 0.022371    Top1 98.828125    Top5 100.000000    LR 0.010000    Time 0.588081    
2024-01-15 19:19:48,934 - Epoch: [139][  211/  211]    Overall Loss 0.022400    Objective Loss 0.022400    Top1 98.991935    Top5 100.000000    LR 0.010000    Time 0.588020    
2024-01-15 19:19:49,532 - --- validate (epoch=139)-----------
2024-01-15 19:19:49,533 - 6000 samples (256 per mini-batch)
2024-01-15 19:19:54,832 - Epoch: [139][   10/   24]    Loss 0.031206    Top1 99.296875    Top5 99.960938    
2024-01-15 19:19:57,018 - Epoch: [139][   20/   24]    Loss 0.027470    Top1 99.316406    Top5 99.960938    
2024-01-15 19:19:57,781 - Epoch: [139][   24/   24]    Loss 0.027392    Top1 99.316667    Top5 99.966667    
2024-01-15 19:19:58,354 - ==> Top1: 99.317    Top5: 99.967    Loss: 0.027

2024-01-15 19:19:58,355 - ==> Confusion:
[[605   0   0   0   0   0   0   0   0   0]
 [  0 687   0   0   0   0   0   1   0   0]
 [  1   0 580   0   0   0   0   4   1   0]
 [  0   0   0 581   0   1   0   0   1   0]
 [  0   0   0   0 560   0   0   0   0   5]
 [  0   0   0   1   1 512   2   0   2   0]
 [  2   2   0   0   1   0 626   0   0   0]
 [  1   1   0   0   0   0   0 623   0   0]
 [  0   0   0   1   1   1   0   0 581   0]
 [  1   1   0   0   3   0   0   3   3 604]]

2024-01-15 19:19:58,357 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:19:58,357 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:19:58,361 - 

2024-01-15 19:19:58,362 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:20:06,632 - Epoch: [140][   10/  211]    Overall Loss 0.022062    Objective Loss 0.022062                                        LR 0.001000    Time 0.826985    
2024-01-15 19:20:12,422 - Epoch: [140][   20/  211]    Overall Loss 0.020624    Objective Loss 0.020624                                        LR 0.001000    Time 0.702912    
2024-01-15 19:20:18,063 - Epoch: [140][   30/  211]    Overall Loss 0.019420    Objective Loss 0.019420                                        LR 0.001000    Time 0.656632    
2024-01-15 19:20:23,743 - Epoch: [140][   40/  211]    Overall Loss 0.020087    Objective Loss 0.020087                                        LR 0.001000    Time 0.634466    
2024-01-15 19:20:29,819 - Epoch: [140][   50/  211]    Overall Loss 0.020515    Objective Loss 0.020515                                        LR 0.001000    Time 0.629051    
2024-01-15 19:20:35,500 - Epoch: [140][   60/  211]    Overall Loss 0.020556    Objective Loss 0.020556                                        LR 0.001000    Time 0.618871    
2024-01-15 19:20:41,244 - Epoch: [140][   70/  211]    Overall Loss 0.021323    Objective Loss 0.021323                                        LR 0.001000    Time 0.612508    
2024-01-15 19:20:46,886 - Epoch: [140][   80/  211]    Overall Loss 0.021216    Objective Loss 0.021216                                        LR 0.001000    Time 0.606453    
2024-01-15 19:20:52,587 - Epoch: [140][   90/  211]    Overall Loss 0.021316    Objective Loss 0.021316                                        LR 0.001000    Time 0.602406    
2024-01-15 19:20:58,244 - Epoch: [140][  100/  211]    Overall Loss 0.020878    Objective Loss 0.020878                                        LR 0.001000    Time 0.598725    
2024-01-15 19:21:03,900 - Epoch: [140][  110/  211]    Overall Loss 0.020996    Objective Loss 0.020996                                        LR 0.001000    Time 0.595712    
2024-01-15 19:21:09,776 - Epoch: [140][  120/  211]    Overall Loss 0.021192    Objective Loss 0.021192                                        LR 0.001000    Time 0.595030    
2024-01-15 19:21:15,444 - Epoch: [140][  130/  211]    Overall Loss 0.021338    Objective Loss 0.021338                                        LR 0.001000    Time 0.592849    
2024-01-15 19:21:21,091 - Epoch: [140][  140/  211]    Overall Loss 0.021419    Objective Loss 0.021419                                        LR 0.001000    Time 0.590829    
2024-01-15 19:21:26,840 - Epoch: [140][  150/  211]    Overall Loss 0.021263    Objective Loss 0.021263                                        LR 0.001000    Time 0.589762    
2024-01-15 19:21:32,807 - Epoch: [140][  160/  211]    Overall Loss 0.021465    Objective Loss 0.021465                                        LR 0.001000    Time 0.590188    
2024-01-15 19:21:38,733 - Epoch: [140][  170/  211]    Overall Loss 0.021034    Objective Loss 0.021034                                        LR 0.001000    Time 0.590326    
2024-01-15 19:21:44,504 - Epoch: [140][  180/  211]    Overall Loss 0.020919    Objective Loss 0.020919                                        LR 0.001000    Time 0.589581    
2024-01-15 19:21:50,171 - Epoch: [140][  190/  211]    Overall Loss 0.021014    Objective Loss 0.021014                                        LR 0.001000    Time 0.588372    
2024-01-15 19:21:55,886 - Epoch: [140][  200/  211]    Overall Loss 0.020881    Objective Loss 0.020881                                        LR 0.001000    Time 0.587525    
2024-01-15 19:22:02,873 - Epoch: [140][  210/  211]    Overall Loss 0.020906    Objective Loss 0.020906    Top1 99.218750    Top5 100.000000    LR 0.001000    Time 0.592805    
2024-01-15 19:22:03,525 - Epoch: [140][  211/  211]    Overall Loss 0.021028    Objective Loss 0.021028    Top1 98.588710    Top5 100.000000    LR 0.001000    Time 0.593085    
2024-01-15 19:22:04,415 - --- validate (epoch=140)-----------
2024-01-15 19:22:04,416 - 6000 samples (256 per mini-batch)
2024-01-15 19:22:12,024 - Epoch: [140][   10/   24]    Loss 0.026706    Top1 99.140625    Top5 100.000000    
2024-01-15 19:22:14,185 - Epoch: [140][   20/   24]    Loss 0.025887    Top1 99.199219    Top5 100.000000    
2024-01-15 19:22:14,973 - Epoch: [140][   24/   24]    Loss 0.025953    Top1 99.200000    Top5 100.000000    
2024-01-15 19:22:15,662 - ==> Top1: 99.200    Top5: 100.000    Loss: 0.026

2024-01-15 19:22:15,663 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 683   0   0   1   1   1   2   0   0]
 [  0   0 581   1   0   0   0   3   1   0]
 [  0   0   0 579   0   2   0   0   2   0]
 [  0   0   0   0 559   0   1   1   0   4]
 [  0   0   0   1   0 514   2   0   1   0]
 [  0   1   0   0   1   1 627   0   1   0]
 [  1   2   0   0   1   0   0 621   0   0]
 [  0   0   1   0   0   0   1   0 581   1]
 [  0   1   0   0   6   0   0   2   1 605]]

2024-01-15 19:22:15,665 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:22:15,665 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:22:15,669 - 

2024-01-15 19:22:15,669 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:22:24,651 - Epoch: [141][   10/  211]    Overall Loss 0.021627    Objective Loss 0.021627                                        LR 0.001000    Time 0.898049    
2024-01-15 19:22:30,945 - Epoch: [141][   20/  211]    Overall Loss 0.021368    Objective Loss 0.021368                                        LR 0.001000    Time 0.763684    
2024-01-15 19:22:36,733 - Epoch: [141][   30/  211]    Overall Loss 0.022809    Objective Loss 0.022809                                        LR 0.001000    Time 0.701991    
2024-01-15 19:22:42,482 - Epoch: [141][   40/  211]    Overall Loss 0.025363    Objective Loss 0.025363                                        LR 0.001000    Time 0.670192    
2024-01-15 19:22:49,837 - Epoch: [141][   50/  211]    Overall Loss 0.025456    Objective Loss 0.025456                                        LR 0.001000    Time 0.683210    
2024-01-15 19:22:56,234 - Epoch: [141][   60/  211]    Overall Loss 0.025851    Objective Loss 0.025851                                        LR 0.001000    Time 0.675908    
2024-01-15 19:23:02,502 - Epoch: [141][   70/  211]    Overall Loss 0.025483    Objective Loss 0.025483                                        LR 0.001000    Time 0.668880    
2024-01-15 19:23:08,753 - Epoch: [141][   80/  211]    Overall Loss 0.024471    Objective Loss 0.024471                                        LR 0.001000    Time 0.663395    
2024-01-15 19:23:14,622 - Epoch: [141][   90/  211]    Overall Loss 0.023826    Objective Loss 0.023826                                        LR 0.001000    Time 0.654848    
2024-01-15 19:23:20,652 - Epoch: [141][  100/  211]    Overall Loss 0.023720    Objective Loss 0.023720                                        LR 0.001000    Time 0.649650    
2024-01-15 19:23:26,492 - Epoch: [141][  110/  211]    Overall Loss 0.023613    Objective Loss 0.023613                                        LR 0.001000    Time 0.643675    
2024-01-15 19:23:32,245 - Epoch: [141][  120/  211]    Overall Loss 0.023230    Objective Loss 0.023230                                        LR 0.001000    Time 0.637973    
2024-01-15 19:23:37,955 - Epoch: [141][  130/  211]    Overall Loss 0.022783    Objective Loss 0.022783                                        LR 0.001000    Time 0.632813    
2024-01-15 19:23:44,378 - Epoch: [141][  140/  211]    Overall Loss 0.023203    Objective Loss 0.023203                                        LR 0.001000    Time 0.633484    
2024-01-15 19:23:50,542 - Epoch: [141][  150/  211]    Overall Loss 0.023138    Objective Loss 0.023138                                        LR 0.001000    Time 0.632333    
2024-01-15 19:23:56,710 - Epoch: [141][  160/  211]    Overall Loss 0.023062    Objective Loss 0.023062                                        LR 0.001000    Time 0.631355    
2024-01-15 19:24:02,434 - Epoch: [141][  170/  211]    Overall Loss 0.022770    Objective Loss 0.022770                                        LR 0.001000    Time 0.627875    
2024-01-15 19:24:08,273 - Epoch: [141][  180/  211]    Overall Loss 0.022490    Objective Loss 0.022490                                        LR 0.001000    Time 0.625430    
2024-01-15 19:24:14,028 - Epoch: [141][  190/  211]    Overall Loss 0.022121    Objective Loss 0.022121                                        LR 0.001000    Time 0.622794    
2024-01-15 19:24:20,388 - Epoch: [141][  200/  211]    Overall Loss 0.022303    Objective Loss 0.022303                                        LR 0.001000    Time 0.623446    
2024-01-15 19:24:27,552 - Epoch: [141][  210/  211]    Overall Loss 0.022389    Objective Loss 0.022389    Top1 99.218750    Top5 100.000000    LR 0.001000    Time 0.627863    
2024-01-15 19:24:28,334 - Epoch: [141][  211/  211]    Overall Loss 0.022431    Objective Loss 0.022431    Top1 98.790323    Top5 100.000000    LR 0.001000    Time 0.628591    
2024-01-15 19:24:29,363 - --- validate (epoch=141)-----------
2024-01-15 19:24:29,364 - 6000 samples (256 per mini-batch)
2024-01-15 19:24:36,568 - Epoch: [141][   10/   24]    Loss 0.026605    Top1 99.296875    Top5 100.000000    
2024-01-15 19:24:38,774 - Epoch: [141][   20/   24]    Loss 0.025992    Top1 99.316406    Top5 100.000000    
2024-01-15 19:24:39,555 - Epoch: [141][   24/   24]    Loss 0.028495    Top1 99.283333    Top5 100.000000    
2024-01-15 19:24:40,386 - ==> Top1: 99.283    Top5: 100.000    Loss: 0.028

2024-01-15 19:24:40,386 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   1 582   0   0   0   0   2   0   1]
 [  0   0   3 578   0   2   0   0   0   0]
 [  0   0   1   0 558   0   0   1   0   5]
 [  0   1   0   1   0 512   2   1   1   0]
 [  1   1   0   0   0   0 628   0   1   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  0   0   2   2   1   0   1   0 577   1]
 [  0   1   0   0   0   1   0   1   3 609]]

2024-01-15 19:24:40,389 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:24:40,389 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:24:40,393 - 

2024-01-15 19:24:40,394 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:24:49,999 - Epoch: [142][   10/  211]    Overall Loss 0.024613    Objective Loss 0.024613                                        LR 0.001000    Time 0.960421    
2024-01-15 19:24:56,479 - Epoch: [142][   20/  211]    Overall Loss 0.024314    Objective Loss 0.024314                                        LR 0.001000    Time 0.804100    
2024-01-15 19:25:02,498 - Epoch: [142][   30/  211]    Overall Loss 0.022976    Objective Loss 0.022976                                        LR 0.001000    Time 0.736672    
2024-01-15 19:25:08,258 - Epoch: [142][   40/  211]    Overall Loss 0.022472    Objective Loss 0.022472                                        LR 0.001000    Time 0.696470    
2024-01-15 19:25:13,929 - Epoch: [142][   50/  211]    Overall Loss 0.022358    Objective Loss 0.022358                                        LR 0.001000    Time 0.670595    
2024-01-15 19:25:19,574 - Epoch: [142][   60/  211]    Overall Loss 0.022044    Objective Loss 0.022044                                        LR 0.001000    Time 0.652908    
2024-01-15 19:25:26,001 - Epoch: [142][   70/  211]    Overall Loss 0.021790    Objective Loss 0.021790                                        LR 0.001000    Time 0.651432    
2024-01-15 19:25:32,155 - Epoch: [142][   80/  211]    Overall Loss 0.021670    Objective Loss 0.021670                                        LR 0.001000    Time 0.646905    
2024-01-15 19:25:38,268 - Epoch: [142][   90/  211]    Overall Loss 0.022814    Objective Loss 0.022814                                        LR 0.001000    Time 0.642933    
2024-01-15 19:25:44,044 - Epoch: [142][  100/  211]    Overall Loss 0.022396    Objective Loss 0.022396                                        LR 0.001000    Time 0.636391    
2024-01-15 19:25:49,940 - Epoch: [142][  110/  211]    Overall Loss 0.021857    Objective Loss 0.021857                                        LR 0.001000    Time 0.632129    
2024-01-15 19:25:55,650 - Epoch: [142][  120/  211]    Overall Loss 0.021800    Objective Loss 0.021800                                        LR 0.001000    Time 0.627022    
2024-01-15 19:26:01,968 - Epoch: [142][  130/  211]    Overall Loss 0.021673    Objective Loss 0.021673                                        LR 0.001000    Time 0.627387    
2024-01-15 19:26:07,859 - Epoch: [142][  140/  211]    Overall Loss 0.021454    Objective Loss 0.021454                                        LR 0.001000    Time 0.624642    
2024-01-15 19:26:13,543 - Epoch: [142][  150/  211]    Overall Loss 0.021609    Objective Loss 0.021609                                        LR 0.001000    Time 0.620882    
2024-01-15 19:26:19,210 - Epoch: [142][  160/  211]    Overall Loss 0.021583    Objective Loss 0.021583                                        LR 0.001000    Time 0.617490    
2024-01-15 19:26:24,935 - Epoch: [142][  170/  211]    Overall Loss 0.021576    Objective Loss 0.021576                                        LR 0.001000    Time 0.614839    
2024-01-15 19:26:30,961 - Epoch: [142][  180/  211]    Overall Loss 0.021800    Objective Loss 0.021800                                        LR 0.001000    Time 0.614154    
2024-01-15 19:26:36,690 - Epoch: [142][  190/  211]    Overall Loss 0.021731    Objective Loss 0.021731                                        LR 0.001000    Time 0.611972    
2024-01-15 19:26:42,417 - Epoch: [142][  200/  211]    Overall Loss 0.021723    Objective Loss 0.021723                                        LR 0.001000    Time 0.610002    
2024-01-15 19:26:48,186 - Epoch: [142][  210/  211]    Overall Loss 0.021693    Objective Loss 0.021693    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.608421    
2024-01-15 19:26:48,924 - Epoch: [142][  211/  211]    Overall Loss 0.021652    Objective Loss 0.021652    Top1 99.798387    Top5 100.000000    LR 0.001000    Time 0.609030    
2024-01-15 19:26:49,954 - --- validate (epoch=142)-----------
2024-01-15 19:26:49,956 - 6000 samples (256 per mini-batch)
2024-01-15 19:26:57,038 - Epoch: [142][   10/   24]    Loss 0.025208    Top1 99.257812    Top5 100.000000    
2024-01-15 19:26:59,197 - Epoch: [142][   20/   24]    Loss 0.026131    Top1 99.238281    Top5 100.000000    
2024-01-15 19:26:59,943 - Epoch: [142][   24/   24]    Loss 0.029685    Top1 99.183333    Top5 100.000000    
2024-01-15 19:27:00,600 - ==> Top1: 99.183    Top5: 100.000    Loss: 0.030

2024-01-15 19:27:00,601 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 683   0   1   0   1   1   2   0   0]
 [  0   0 580   0   0   0   0   4   2   0]
 [  0   0   1 580   0   1   0   1   0   0]
 [  0   1   0   0 554   0   0   2   0   8]
 [  2   0   0   1   0 513   2   0   0   0]
 [  0   1   0   0   1   0 628   0   1   0]
 [  1   1   1   0   0   0   0 621   0   1]
 [  0   0   0   1   1   0   1   0 581   0]
 [  0   1   0   0   3   0   0   1   2 608]]

2024-01-15 19:27:00,604 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:27:00,604 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:27:00,609 - 

2024-01-15 19:27:00,609 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:27:09,261 - Epoch: [143][   10/  211]    Overall Loss 0.027128    Objective Loss 0.027128                                        LR 0.001000    Time 0.865116    
2024-01-15 19:27:14,972 - Epoch: [143][   20/  211]    Overall Loss 0.025248    Objective Loss 0.025248                                        LR 0.001000    Time 0.718056    
2024-01-15 19:27:20,668 - Epoch: [143][   30/  211]    Overall Loss 0.025888    Objective Loss 0.025888                                        LR 0.001000    Time 0.668547    
2024-01-15 19:27:26,342 - Epoch: [143][   40/  211]    Overall Loss 0.026498    Objective Loss 0.026498                                        LR 0.001000    Time 0.643230    
2024-01-15 19:27:32,469 - Epoch: [143][   50/  211]    Overall Loss 0.025476    Objective Loss 0.025476                                        LR 0.001000    Time 0.637109    
2024-01-15 19:27:38,352 - Epoch: [143][   60/  211]    Overall Loss 0.024476    Objective Loss 0.024476                                        LR 0.001000    Time 0.628948    
2024-01-15 19:27:44,041 - Epoch: [143][   70/  211]    Overall Loss 0.024087    Objective Loss 0.024087                                        LR 0.001000    Time 0.620355    
2024-01-15 19:27:49,750 - Epoch: [143][   80/  211]    Overall Loss 0.024660    Objective Loss 0.024660                                        LR 0.001000    Time 0.614156    
2024-01-15 19:27:55,441 - Epoch: [143][   90/  211]    Overall Loss 0.024271    Objective Loss 0.024271                                        LR 0.001000    Time 0.609141    
2024-01-15 19:28:01,229 - Epoch: [143][  100/  211]    Overall Loss 0.024129    Objective Loss 0.024129                                        LR 0.001000    Time 0.606098    
2024-01-15 19:28:06,909 - Epoch: [143][  110/  211]    Overall Loss 0.023838    Objective Loss 0.023838                                        LR 0.001000    Time 0.602631    
2024-01-15 19:28:12,663 - Epoch: [143][  120/  211]    Overall Loss 0.023301    Objective Loss 0.023301                                        LR 0.001000    Time 0.600346    
2024-01-15 19:28:18,661 - Epoch: [143][  130/  211]    Overall Loss 0.023712    Objective Loss 0.023712                                        LR 0.001000    Time 0.600297    
2024-01-15 19:28:24,474 - Epoch: [143][  140/  211]    Overall Loss 0.023314    Objective Loss 0.023314                                        LR 0.001000    Time 0.598930    
2024-01-15 19:28:30,561 - Epoch: [143][  150/  211]    Overall Loss 0.023601    Objective Loss 0.023601                                        LR 0.001000    Time 0.599574    
2024-01-15 19:28:38,035 - Epoch: [143][  160/  211]    Overall Loss 0.023483    Objective Loss 0.023483                                        LR 0.001000    Time 0.608796    
2024-01-15 19:28:44,768 - Epoch: [143][  170/  211]    Overall Loss 0.023300    Objective Loss 0.023300                                        LR 0.001000    Time 0.612573    
2024-01-15 19:28:50,982 - Epoch: [143][  180/  211]    Overall Loss 0.023263    Objective Loss 0.023263                                        LR 0.001000    Time 0.613052    
2024-01-15 19:28:56,702 - Epoch: [143][  190/  211]    Overall Loss 0.023128    Objective Loss 0.023128                                        LR 0.001000    Time 0.610886    
2024-01-15 19:29:02,435 - Epoch: [143][  200/  211]    Overall Loss 0.022848    Objective Loss 0.022848                                        LR 0.001000    Time 0.609002    
2024-01-15 19:29:08,208 - Epoch: [143][  210/  211]    Overall Loss 0.022582    Objective Loss 0.022582    Top1 99.609375    Top5 100.000000    LR 0.001000    Time 0.607488    
2024-01-15 19:29:08,786 - Epoch: [143][  211/  211]    Overall Loss 0.022671    Objective Loss 0.022671    Top1 98.991935    Top5 100.000000    LR 0.001000    Time 0.607344    
2024-01-15 19:29:09,651 - --- validate (epoch=143)-----------
2024-01-15 19:29:09,653 - 6000 samples (256 per mini-batch)
2024-01-15 19:29:16,495 - Epoch: [143][   10/   24]    Loss 0.024637    Top1 99.179688    Top5 100.000000    
2024-01-15 19:29:18,679 - Epoch: [143][   20/   24]    Loss 0.024951    Top1 99.238281    Top5 100.000000    
2024-01-15 19:29:19,440 - Epoch: [143][   24/   24]    Loss 0.024827    Top1 99.233333    Top5 100.000000    
2024-01-15 19:29:20,196 - ==> Top1: 99.233    Top5: 100.000    Loss: 0.025

2024-01-15 19:29:20,197 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 584   0   0   0   0   0   1   1]
 [  0   0   1 579   0   1   0   1   1   0]
 [  0   1   0   0 556   0   0   0   1   7]
 [  1   1   0   2   0 512   2   0   0   0]
 [  1   1   0   0   0   0 629   0   0   0]
 [  1   2   0   1   0   0   0 621   0   0]
 [  0   0   0   0   1   1   1   0 581   0]
 [  1   1   0   0   3   1   0   2   4 603]]

2024-01-15 19:29:20,200 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:29:20,200 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:29:20,204 - 

2024-01-15 19:29:20,204 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:29:29,321 - Epoch: [144][   10/  211]    Overall Loss 0.022798    Objective Loss 0.022798                                        LR 0.001000    Time 0.911647    
2024-01-15 19:29:35,205 - Epoch: [144][   20/  211]    Overall Loss 0.023271    Objective Loss 0.023271                                        LR 0.001000    Time 0.749938    
2024-01-15 19:29:41,577 - Epoch: [144][   30/  211]    Overall Loss 0.024838    Objective Loss 0.024838                                        LR 0.001000    Time 0.712318    
2024-01-15 19:29:48,349 - Epoch: [144][   40/  211]    Overall Loss 0.023664    Objective Loss 0.023664                                        LR 0.001000    Time 0.703490    
2024-01-15 19:29:54,694 - Epoch: [144][   50/  211]    Overall Loss 0.021836    Objective Loss 0.021836                                        LR 0.001000    Time 0.689660    
2024-01-15 19:30:01,299 - Epoch: [144][   60/  211]    Overall Loss 0.021680    Objective Loss 0.021680                                        LR 0.001000    Time 0.684782    
2024-01-15 19:30:07,841 - Epoch: [144][   70/  211]    Overall Loss 0.021483    Objective Loss 0.021483                                        LR 0.001000    Time 0.680390    
2024-01-15 19:30:14,116 - Epoch: [144][   80/  211]    Overall Loss 0.021810    Objective Loss 0.021810                                        LR 0.001000    Time 0.673751    
2024-01-15 19:30:21,535 - Epoch: [144][   90/  211]    Overall Loss 0.021483    Objective Loss 0.021483                                        LR 0.001000    Time 0.681304    
2024-01-15 19:30:28,461 - Epoch: [144][  100/  211]    Overall Loss 0.022525    Objective Loss 0.022525                                        LR 0.001000    Time 0.682430    
2024-01-15 19:30:35,171 - Epoch: [144][  110/  211]    Overall Loss 0.023080    Objective Loss 0.023080                                        LR 0.001000    Time 0.681372    
2024-01-15 19:30:41,515 - Epoch: [144][  120/  211]    Overall Loss 0.022916    Objective Loss 0.022916                                        LR 0.001000    Time 0.677444    
2024-01-15 19:30:47,835 - Epoch: [144][  130/  211]    Overall Loss 0.022691    Objective Loss 0.022691                                        LR 0.001000    Time 0.673939    
2024-01-15 19:30:53,532 - Epoch: [144][  140/  211]    Overall Loss 0.022742    Objective Loss 0.022742                                        LR 0.001000    Time 0.666485    
2024-01-15 19:30:59,183 - Epoch: [144][  150/  211]    Overall Loss 0.022294    Objective Loss 0.022294                                        LR 0.001000    Time 0.659727    
2024-01-15 19:31:04,865 - Epoch: [144][  160/  211]    Overall Loss 0.022115    Objective Loss 0.022115                                        LR 0.001000    Time 0.653998    
2024-01-15 19:31:10,526 - Epoch: [144][  170/  211]    Overall Loss 0.022101    Objective Loss 0.022101                                        LR 0.001000    Time 0.648821    
2024-01-15 19:31:16,233 - Epoch: [144][  180/  211]    Overall Loss 0.021818    Objective Loss 0.021818                                        LR 0.001000    Time 0.644477    
2024-01-15 19:31:21,886 - Epoch: [144][  190/  211]    Overall Loss 0.021903    Objective Loss 0.021903                                        LR 0.001000    Time 0.640306    
2024-01-15 19:31:27,530 - Epoch: [144][  200/  211]    Overall Loss 0.021858    Objective Loss 0.021858                                        LR 0.001000    Time 0.636505    
2024-01-15 19:31:33,366 - Epoch: [144][  210/  211]    Overall Loss 0.021631    Objective Loss 0.021631    Top1 99.218750    Top5 100.000000    LR 0.001000    Time 0.633981    
2024-01-15 19:31:33,925 - Epoch: [144][  211/  211]    Overall Loss 0.021584    Objective Loss 0.021584    Top1 99.395161    Top5 100.000000    LR 0.001000    Time 0.633625    
2024-01-15 19:31:34,922 - --- validate (epoch=144)-----------
2024-01-15 19:31:34,923 - 6000 samples (256 per mini-batch)
2024-01-15 19:31:41,830 - Epoch: [144][   10/   24]    Loss 0.025773    Top1 99.140625    Top5 100.000000    
2024-01-15 19:31:43,986 - Epoch: [144][   20/   24]    Loss 0.026884    Top1 99.179688    Top5 99.980469    
2024-01-15 19:31:44,740 - Epoch: [144][   24/   24]    Loss 0.027604    Top1 99.200000    Top5 99.983333    
2024-01-15 19:31:45,561 - ==> Top1: 99.200    Top5: 99.983    Loss: 0.028

2024-01-15 19:31:45,562 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 687   1   0   0   0   0   0   0   0]
 [  0   0 578   0   0   0   3   2   3   0]
 [  0   0   1 577   0   3   0   1   1   0]
 [  0   1   0   0 558   0   1   0   0   5]
 [  1   0   0   1   0 514   2   0   0   0]
 [  0   1   0   0   2   0 628   0   0   0]
 [  0   2   0   0   0   0   0 622   0   1]
 [  1   0   0   2   1   0   1   0 579   0]
 [  0   1   0   0   3   2   0   2   2 605]]

2024-01-15 19:31:45,565 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:31:45,565 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:31:45,571 - 

2024-01-15 19:31:45,571 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:31:54,496 - Epoch: [145][   10/  211]    Overall Loss 0.023875    Objective Loss 0.023875                                        LR 0.001000    Time 0.892297    
2024-01-15 19:32:00,163 - Epoch: [145][   20/  211]    Overall Loss 0.022104    Objective Loss 0.022104                                        LR 0.001000    Time 0.729402    
2024-01-15 19:32:05,995 - Epoch: [145][   30/  211]    Overall Loss 0.021709    Objective Loss 0.021709                                        LR 0.001000    Time 0.680670    
2024-01-15 19:32:11,811 - Epoch: [145][   40/  211]    Overall Loss 0.020736    Objective Loss 0.020736                                        LR 0.001000    Time 0.655874    
2024-01-15 19:32:17,462 - Epoch: [145][   50/  211]    Overall Loss 0.022127    Objective Loss 0.022127                                        LR 0.001000    Time 0.637716    
2024-01-15 19:32:23,268 - Epoch: [145][   60/  211]    Overall Loss 0.022814    Objective Loss 0.022814                                        LR 0.001000    Time 0.628159    
2024-01-15 19:32:29,744 - Epoch: [145][   70/  211]    Overall Loss 0.022258    Objective Loss 0.022258                                        LR 0.001000    Time 0.630913    
2024-01-15 19:32:35,646 - Epoch: [145][   80/  211]    Overall Loss 0.022613    Objective Loss 0.022613                                        LR 0.001000    Time 0.625767    
2024-01-15 19:32:43,322 - Epoch: [145][   90/  211]    Overall Loss 0.022756    Objective Loss 0.022756                                        LR 0.001000    Time 0.641459    
2024-01-15 19:32:49,497 - Epoch: [145][  100/  211]    Overall Loss 0.022673    Objective Loss 0.022673                                        LR 0.001000    Time 0.639045    
2024-01-15 19:32:55,426 - Epoch: [145][  110/  211]    Overall Loss 0.022329    Objective Loss 0.022329                                        LR 0.001000    Time 0.634828    
2024-01-15 19:33:01,287 - Epoch: [145][  120/  211]    Overall Loss 0.021795    Objective Loss 0.021795                                        LR 0.001000    Time 0.630764    
2024-01-15 19:33:07,532 - Epoch: [145][  130/  211]    Overall Loss 0.021882    Objective Loss 0.021882                                        LR 0.001000    Time 0.630268    
2024-01-15 19:33:14,103 - Epoch: [145][  140/  211]    Overall Loss 0.021368    Objective Loss 0.021368                                        LR 0.001000    Time 0.632163    
2024-01-15 19:33:21,002 - Epoch: [145][  150/  211]    Overall Loss 0.021391    Objective Loss 0.021391                                        LR 0.001000    Time 0.635970    
2024-01-15 19:33:27,247 - Epoch: [145][  160/  211]    Overall Loss 0.021327    Objective Loss 0.021327                                        LR 0.001000    Time 0.635249    
2024-01-15 19:33:34,597 - Epoch: [145][  170/  211]    Overall Loss 0.021205    Objective Loss 0.021205                                        LR 0.001000    Time 0.641104    
2024-01-15 19:33:41,174 - Epoch: [145][  180/  211]    Overall Loss 0.021704    Objective Loss 0.021704                                        LR 0.001000    Time 0.642020    
2024-01-15 19:33:47,259 - Epoch: [145][  190/  211]    Overall Loss 0.021874    Objective Loss 0.021874                                        LR 0.001000    Time 0.640249    
2024-01-15 19:33:53,307 - Epoch: [145][  200/  211]    Overall Loss 0.022294    Objective Loss 0.022294                                        LR 0.001000    Time 0.638468    
2024-01-15 19:34:01,039 - Epoch: [145][  210/  211]    Overall Loss 0.022357    Objective Loss 0.022357    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.644874    
2024-01-15 19:34:01,795 - Epoch: [145][  211/  211]    Overall Loss 0.022363    Objective Loss 0.022363    Top1 99.798387    Top5 100.000000    LR 0.001000    Time 0.645397    
2024-01-15 19:34:03,043 - --- validate (epoch=145)-----------
2024-01-15 19:34:03,045 - 6000 samples (256 per mini-batch)
2024-01-15 19:34:11,336 - Epoch: [145][   10/   24]    Loss 0.031384    Top1 99.101562    Top5 100.000000    
2024-01-15 19:34:13,770 - Epoch: [145][   20/   24]    Loss 0.025747    Top1 99.238281    Top5 100.000000    
2024-01-15 19:34:14,782 - Epoch: [145][   24/   24]    Loss 0.028621    Top1 99.166667    Top5 100.000000    
2024-01-15 19:34:15,670 - ==> Top1: 99.167    Top5: 100.000    Loss: 0.029

2024-01-15 19:34:15,672 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   0 581   1   0   0   0   2   2   0]
 [  0   0   2 577   0   2   0   1   1   0]
 [  0   1   0   0 558   0   1   0   1   4]
 [  1   0   0   2   0 510   3   0   2   0]
 [  1   0   0   0   1   1 627   0   1   0]
 [  0   2   2   0   1   0   0 620   0   0]
 [  1   0   0   3   0   2   1   0 577   0]
 [  0   1   0   0   0   0   0   0   2 612]]

2024-01-15 19:34:15,675 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:34:15,675 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:34:15,681 - 

2024-01-15 19:34:15,682 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:34:27,294 - Epoch: [146][   10/  211]    Overall Loss 0.018731    Objective Loss 0.018731                                        LR 0.001000    Time 1.161146    
2024-01-15 19:34:34,433 - Epoch: [146][   20/  211]    Overall Loss 0.020794    Objective Loss 0.020794                                        LR 0.001000    Time 0.937429    
2024-01-15 19:34:41,319 - Epoch: [146][   30/  211]    Overall Loss 0.020662    Objective Loss 0.020662                                        LR 0.001000    Time 0.854418    
2024-01-15 19:34:47,875 - Epoch: [146][   40/  211]    Overall Loss 0.020208    Objective Loss 0.020208                                        LR 0.001000    Time 0.804681    
2024-01-15 19:34:54,788 - Epoch: [146][   50/  211]    Overall Loss 0.021729    Objective Loss 0.021729                                        LR 0.001000    Time 0.781962    
2024-01-15 19:35:01,493 - Epoch: [146][   60/  211]    Overall Loss 0.022117    Objective Loss 0.022117                                        LR 0.001000    Time 0.763358    
2024-01-15 19:35:08,205 - Epoch: [146][   70/  211]    Overall Loss 0.021457    Objective Loss 0.021457                                        LR 0.001000    Time 0.750167    
2024-01-15 19:35:14,650 - Epoch: [146][   80/  211]    Overall Loss 0.023109    Objective Loss 0.023109                                        LR 0.001000    Time 0.736927    
2024-01-15 19:35:21,057 - Epoch: [146][   90/  211]    Overall Loss 0.023180    Objective Loss 0.023180                                        LR 0.001000    Time 0.726216    
2024-01-15 19:35:27,594 - Epoch: [146][  100/  211]    Overall Loss 0.023683    Objective Loss 0.023683                                        LR 0.001000    Time 0.718950    
2024-01-15 19:35:34,034 - Epoch: [146][  110/  211]    Overall Loss 0.023647    Objective Loss 0.023647                                        LR 0.001000    Time 0.712120    
2024-01-15 19:35:40,569 - Epoch: [146][  120/  211]    Overall Loss 0.024154    Objective Loss 0.024154                                        LR 0.001000    Time 0.707227    
2024-01-15 19:35:48,208 - Epoch: [146][  130/  211]    Overall Loss 0.024389    Objective Loss 0.024389                                        LR 0.001000    Time 0.711562    
2024-01-15 19:35:55,137 - Epoch: [146][  140/  211]    Overall Loss 0.024116    Objective Loss 0.024116                                        LR 0.001000    Time 0.710220    
2024-01-15 19:36:01,196 - Epoch: [146][  150/  211]    Overall Loss 0.023706    Objective Loss 0.023706                                        LR 0.001000    Time 0.703255    
2024-01-15 19:36:07,602 - Epoch: [146][  160/  211]    Overall Loss 0.023396    Objective Loss 0.023396                                        LR 0.001000    Time 0.699330    
2024-01-15 19:36:14,155 - Epoch: [146][  170/  211]    Overall Loss 0.023162    Objective Loss 0.023162                                        LR 0.001000    Time 0.696730    
2024-01-15 19:36:19,877 - Epoch: [146][  180/  211]    Overall Loss 0.023355    Objective Loss 0.023355                                        LR 0.001000    Time 0.689808    
2024-01-15 19:36:25,758 - Epoch: [146][  190/  211]    Overall Loss 0.023113    Objective Loss 0.023113                                        LR 0.001000    Time 0.684453    
2024-01-15 19:36:32,903 - Epoch: [146][  200/  211]    Overall Loss 0.023139    Objective Loss 0.023139                                        LR 0.001000    Time 0.685949    
2024-01-15 19:36:39,459 - Epoch: [146][  210/  211]    Overall Loss 0.023199    Objective Loss 0.023199    Top1 99.609375    Top5 100.000000    LR 0.001000    Time 0.684498    
2024-01-15 19:36:40,304 - Epoch: [146][  211/  211]    Overall Loss 0.023209    Objective Loss 0.023209    Top1 99.193548    Top5 100.000000    LR 0.001000    Time 0.685253    
2024-01-15 19:36:41,713 - --- validate (epoch=146)-----------
2024-01-15 19:36:41,714 - 6000 samples (256 per mini-batch)
2024-01-15 19:36:50,393 - Epoch: [146][   10/   24]    Loss 0.023970    Top1 99.492188    Top5 100.000000    
2024-01-15 19:36:52,769 - Epoch: [146][   20/   24]    Loss 0.026021    Top1 99.238281    Top5 100.000000    
2024-01-15 19:36:53,796 - Epoch: [146][   24/   24]    Loss 0.025645    Top1 99.250000    Top5 100.000000    
2024-01-15 19:36:54,767 - ==> Top1: 99.250    Top5: 100.000    Loss: 0.026

2024-01-15 19:36:54,769 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   0   0   0   1   1   0   0   0]
 [  0   0 581   1   0   0   0   3   1   0]
 [  0   0   1 579   0   2   0   0   1   0]
 [  0   0   0   0 558   0   2   0   0   5]
 [  0   0   0   2   0 514   2   0   0   0]
 [  0   0   0   0   1   1 628   0   1   0]
 [  0   3   1   1   0   0   0 620   0   0]
 [  0   0   0   1   1   0   1   0 579   2]
 [  0   1   0   0   2   0   0   2   3 607]]

2024-01-15 19:36:54,772 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:36:54,773 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:36:54,779 - 

2024-01-15 19:36:54,780 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:37:08,435 - Epoch: [147][   10/  211]    Overall Loss 0.031106    Objective Loss 0.031106                                        LR 0.001000    Time 1.365362    
2024-01-15 19:37:14,838 - Epoch: [147][   20/  211]    Overall Loss 0.024047    Objective Loss 0.024047                                        LR 0.001000    Time 1.002717    
2024-01-15 19:37:21,334 - Epoch: [147][   30/  211]    Overall Loss 0.022094    Objective Loss 0.022094                                        LR 0.001000    Time 0.884971    
2024-01-15 19:37:28,858 - Epoch: [147][   40/  211]    Overall Loss 0.020664    Objective Loss 0.020664                                        LR 0.001000    Time 0.851798    
2024-01-15 19:37:35,312 - Epoch: [147][   50/  211]    Overall Loss 0.019683    Objective Loss 0.019683                                        LR 0.001000    Time 0.810460    
2024-01-15 19:37:41,812 - Epoch: [147][   60/  211]    Overall Loss 0.019540    Objective Loss 0.019540                                        LR 0.001000    Time 0.783698    
2024-01-15 19:37:48,264 - Epoch: [147][   70/  211]    Overall Loss 0.020449    Objective Loss 0.020449                                        LR 0.001000    Time 0.763900    
2024-01-15 19:37:54,891 - Epoch: [147][   80/  211]    Overall Loss 0.020341    Objective Loss 0.020341                                        LR 0.001000    Time 0.751230    
2024-01-15 19:38:01,281 - Epoch: [147][   90/  211]    Overall Loss 0.020941    Objective Loss 0.020941                                        LR 0.001000    Time 0.738747    
2024-01-15 19:38:07,474 - Epoch: [147][  100/  211]    Overall Loss 0.020515    Objective Loss 0.020515                                        LR 0.001000    Time 0.726788    
2024-01-15 19:38:13,897 - Epoch: [147][  110/  211]    Overall Loss 0.020783    Objective Loss 0.020783                                        LR 0.001000    Time 0.719097    
2024-01-15 19:38:20,981 - Epoch: [147][  120/  211]    Overall Loss 0.021418    Objective Loss 0.021418                                        LR 0.001000    Time 0.718187    
2024-01-15 19:38:27,959 - Epoch: [147][  130/  211]    Overall Loss 0.021121    Objective Loss 0.021121                                        LR 0.001000    Time 0.716605    
2024-01-15 19:38:34,516 - Epoch: [147][  140/  211]    Overall Loss 0.021210    Objective Loss 0.021210                                        LR 0.001000    Time 0.712240    
2024-01-15 19:38:41,546 - Epoch: [147][  150/  211]    Overall Loss 0.021221    Objective Loss 0.021221                                        LR 0.001000    Time 0.711617    
2024-01-15 19:38:47,675 - Epoch: [147][  160/  211]    Overall Loss 0.021657    Objective Loss 0.021657                                        LR 0.001000    Time 0.705437    
2024-01-15 19:38:54,557 - Epoch: [147][  170/  211]    Overall Loss 0.021644    Objective Loss 0.021644                                        LR 0.001000    Time 0.704411    
2024-01-15 19:39:01,514 - Epoch: [147][  180/  211]    Overall Loss 0.021280    Objective Loss 0.021280                                        LR 0.001000    Time 0.703915    
2024-01-15 19:39:07,631 - Epoch: [147][  190/  211]    Overall Loss 0.021447    Objective Loss 0.021447                                        LR 0.001000    Time 0.699047    
2024-01-15 19:39:14,570 - Epoch: [147][  200/  211]    Overall Loss 0.021488    Objective Loss 0.021488                                        LR 0.001000    Time 0.698776    
2024-01-15 19:39:20,714 - Epoch: [147][  210/  211]    Overall Loss 0.021576    Objective Loss 0.021576    Top1 99.609375    Top5 100.000000    LR 0.001000    Time 0.694753    
2024-01-15 19:39:21,368 - Epoch: [147][  211/  211]    Overall Loss 0.021542    Objective Loss 0.021542    Top1 99.395161    Top5 100.000000    LR 0.001000    Time 0.694556    
2024-01-15 19:39:22,269 - --- validate (epoch=147)-----------
2024-01-15 19:39:22,272 - 6000 samples (256 per mini-batch)
2024-01-15 19:39:31,652 - Epoch: [147][   10/   24]    Loss 0.027997    Top1 99.218750    Top5 100.000000    
2024-01-15 19:39:33,915 - Epoch: [147][   20/   24]    Loss 0.025883    Top1 99.316406    Top5 100.000000    
2024-01-15 19:39:34,730 - Epoch: [147][   24/   24]    Loss 0.026171    Top1 99.316667    Top5 100.000000    
2024-01-15 19:39:35,755 - ==> Top1: 99.317    Top5: 100.000    Loss: 0.026

2024-01-15 19:39:35,757 - ==> Confusion:
[[602   0   1   0   0   1   1   0   0   0]
 [  0 685   0   0   1   1   0   1   0   0]
 [  0   0 584   0   0   0   0   1   1   0]
 [  0   0   0 578   0   1   0   2   2   0]
 [  0   1   0   0 558   0   0   0   0   6]
 [  1   0   0   1   0 514   2   0   0   0]
 [  0   0   0   0   0   0 629   0   2   0]
 [  0   0   0   1   0   0   0 624   0   0]
 [  1   0   0   0   0   1   2   0 579   1]
 [  0   1   0   0   2   1   0   2   3 606]]

2024-01-15 19:39:35,762 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:39:35,762 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:39:35,770 - 

2024-01-15 19:39:35,771 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:39:47,644 - Epoch: [148][   10/  211]    Overall Loss 0.022339    Objective Loss 0.022339                                        LR 0.001000    Time 1.187248    
2024-01-15 19:39:53,955 - Epoch: [148][   20/  211]    Overall Loss 0.023370    Objective Loss 0.023370                                        LR 0.001000    Time 0.909070    
2024-01-15 19:40:00,167 - Epoch: [148][   30/  211]    Overall Loss 0.022644    Objective Loss 0.022644                                        LR 0.001000    Time 0.813059    
2024-01-15 19:40:06,186 - Epoch: [148][   40/  211]    Overall Loss 0.022637    Objective Loss 0.022637                                        LR 0.001000    Time 0.760242    
2024-01-15 19:40:12,594 - Epoch: [148][   50/  211]    Overall Loss 0.023337    Objective Loss 0.023337                                        LR 0.001000    Time 0.736314    
2024-01-15 19:40:19,000 - Epoch: [148][   60/  211]    Overall Loss 0.023207    Objective Loss 0.023207                                        LR 0.001000    Time 0.720326    
2024-01-15 19:40:25,241 - Epoch: [148][   70/  211]    Overall Loss 0.023566    Objective Loss 0.023566                                        LR 0.001000    Time 0.706564    
2024-01-15 19:40:32,745 - Epoch: [148][   80/  211]    Overall Loss 0.022562    Objective Loss 0.022562                                        LR 0.001000    Time 0.712035    
2024-01-15 19:40:38,857 - Epoch: [148][   90/  211]    Overall Loss 0.022469    Objective Loss 0.022469                                        LR 0.001000    Time 0.700809    
2024-01-15 19:40:45,149 - Epoch: [148][  100/  211]    Overall Loss 0.022226    Objective Loss 0.022226                                        LR 0.001000    Time 0.693636    
2024-01-15 19:40:50,825 - Epoch: [148][  110/  211]    Overall Loss 0.021983    Objective Loss 0.021983                                        LR 0.001000    Time 0.682173    
2024-01-15 19:40:56,601 - Epoch: [148][  120/  211]    Overall Loss 0.021887    Objective Loss 0.021887                                        LR 0.001000    Time 0.673449    
2024-01-15 19:41:02,263 - Epoch: [148][  130/  211]    Overall Loss 0.022074    Objective Loss 0.022074                                        LR 0.001000    Time 0.665192    
2024-01-15 19:41:09,418 - Epoch: [148][  140/  211]    Overall Loss 0.022206    Objective Loss 0.022206                                        LR 0.001000    Time 0.668782    
2024-01-15 19:41:15,514 - Epoch: [148][  150/  211]    Overall Loss 0.022261    Objective Loss 0.022261                                        LR 0.001000    Time 0.664819    
2024-01-15 19:41:21,599 - Epoch: [148][  160/  211]    Overall Loss 0.021939    Objective Loss 0.021939                                        LR 0.001000    Time 0.661292    
2024-01-15 19:41:27,259 - Epoch: [148][  170/  211]    Overall Loss 0.021805    Objective Loss 0.021805                                        LR 0.001000    Time 0.655683    
2024-01-15 19:41:33,040 - Epoch: [148][  180/  211]    Overall Loss 0.021622    Objective Loss 0.021622                                        LR 0.001000    Time 0.651368    
2024-01-15 19:41:38,806 - Epoch: [148][  190/  211]    Overall Loss 0.021088    Objective Loss 0.021088                                        LR 0.001000    Time 0.647428    
2024-01-15 19:41:44,886 - Epoch: [148][  200/  211]    Overall Loss 0.020912    Objective Loss 0.020912                                        LR 0.001000    Time 0.645449    
2024-01-15 19:41:50,765 - Epoch: [148][  210/  211]    Overall Loss 0.021128    Objective Loss 0.021128    Top1 98.437500    Top5 100.000000    LR 0.001000    Time 0.642705    
2024-01-15 19:41:51,389 - Epoch: [148][  211/  211]    Overall Loss 0.021108    Objective Loss 0.021108    Top1 98.991935    Top5 100.000000    LR 0.001000    Time 0.642612    
2024-01-15 19:41:52,207 - --- validate (epoch=148)-----------
2024-01-15 19:41:52,209 - 6000 samples (256 per mini-batch)
2024-01-15 19:42:00,660 - Epoch: [148][   10/   24]    Loss 0.029032    Top1 99.140625    Top5 100.000000    
2024-01-15 19:42:03,129 - Epoch: [148][   20/   24]    Loss 0.027743    Top1 99.160156    Top5 100.000000    
2024-01-15 19:42:04,066 - Epoch: [148][   24/   24]    Loss 0.028724    Top1 99.150000    Top5 100.000000    
2024-01-15 19:42:04,920 - ==> Top1: 99.150    Top5: 100.000    Loss: 0.029

2024-01-15 19:42:04,922 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 684   2   0   0   0   0   2   0   0]
 [  0   0 581   1   0   0   1   2   1   0]
 [  0   0   1 577   0   2   0   1   2   0]
 [  0   0   0   0 560   0   0   1   0   4]
 [  1   0   0   1   0 513   3   0   0   0]
 [  1   0   0   0   1   0 629   0   0   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  1   0   0   1   1   2   4   1 574   0]
 [  1   1   0   0   2   2   0   2   2 605]]

2024-01-15 19:42:04,925 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:42:04,926 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:42:04,932 - 

2024-01-15 19:42:04,933 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:42:16,354 - Epoch: [149][   10/  211]    Overall Loss 0.022706    Objective Loss 0.022706                                        LR 0.001000    Time 1.141942    
2024-01-15 19:42:22,677 - Epoch: [149][   20/  211]    Overall Loss 0.023178    Objective Loss 0.023178                                        LR 0.001000    Time 0.887054    
2024-01-15 19:42:28,546 - Epoch: [149][   30/  211]    Overall Loss 0.021233    Objective Loss 0.021233                                        LR 0.001000    Time 0.786980    
2024-01-15 19:42:34,380 - Epoch: [149][   40/  211]    Overall Loss 0.023631    Objective Loss 0.023631                                        LR 0.001000    Time 0.736036    
2024-01-15 19:42:41,613 - Epoch: [149][   50/  211]    Overall Loss 0.022680    Objective Loss 0.022680                                        LR 0.001000    Time 0.733448    
2024-01-15 19:42:48,026 - Epoch: [149][   60/  211]    Overall Loss 0.022265    Objective Loss 0.022265                                        LR 0.001000    Time 0.718074    
2024-01-15 19:42:54,675 - Epoch: [149][   70/  211]    Overall Loss 0.021439    Objective Loss 0.021439                                        LR 0.001000    Time 0.710422    
2024-01-15 19:43:01,151 - Epoch: [149][   80/  211]    Overall Loss 0.020908    Objective Loss 0.020908                                        LR 0.001000    Time 0.702525    
2024-01-15 19:43:07,543 - Epoch: [149][   90/  211]    Overall Loss 0.021371    Objective Loss 0.021371                                        LR 0.001000    Time 0.695469    
2024-01-15 19:43:13,687 - Epoch: [149][  100/  211]    Overall Loss 0.021046    Objective Loss 0.021046                                        LR 0.001000    Time 0.687344    
2024-01-15 19:43:20,859 - Epoch: [149][  110/  211]    Overall Loss 0.021542    Objective Loss 0.021542                                        LR 0.001000    Time 0.690038    
2024-01-15 19:43:27,420 - Epoch: [149][  120/  211]    Overall Loss 0.021424    Objective Loss 0.021424                                        LR 0.001000    Time 0.687203    
2024-01-15 19:43:34,028 - Epoch: [149][  130/  211]    Overall Loss 0.021677    Objective Loss 0.021677                                        LR 0.001000    Time 0.685141    
2024-01-15 19:43:40,435 - Epoch: [149][  140/  211]    Overall Loss 0.021329    Objective Loss 0.021329                                        LR 0.001000    Time 0.681936    
2024-01-15 19:43:46,777 - Epoch: [149][  150/  211]    Overall Loss 0.021736    Objective Loss 0.021736                                        LR 0.001000    Time 0.678743    
2024-01-15 19:43:53,567 - Epoch: [149][  160/  211]    Overall Loss 0.021874    Objective Loss 0.021874                                        LR 0.001000    Time 0.678753    
2024-01-15 19:44:00,874 - Epoch: [149][  170/  211]    Overall Loss 0.022054    Objective Loss 0.022054                                        LR 0.001000    Time 0.681791    
2024-01-15 19:44:07,468 - Epoch: [149][  180/  211]    Overall Loss 0.022238    Objective Loss 0.022238                                        LR 0.001000    Time 0.680539    
2024-01-15 19:44:13,809 - Epoch: [149][  190/  211]    Overall Loss 0.022017    Objective Loss 0.022017                                        LR 0.001000    Time 0.678092    
2024-01-15 19:44:19,916 - Epoch: [149][  200/  211]    Overall Loss 0.022355    Objective Loss 0.022355                                        LR 0.001000    Time 0.674714    
2024-01-15 19:44:26,064 - Epoch: [149][  210/  211]    Overall Loss 0.022319    Objective Loss 0.022319    Top1 99.218750    Top5 100.000000    LR 0.001000    Time 0.671855    
2024-01-15 19:44:26,683 - Epoch: [149][  211/  211]    Overall Loss 0.022368    Objective Loss 0.022368    Top1 99.395161    Top5 100.000000    LR 0.001000    Time 0.671602    
2024-01-15 19:44:27,794 - --- validate (epoch=149)-----------
2024-01-15 19:44:27,796 - 6000 samples (256 per mini-batch)
2024-01-15 19:44:35,640 - Epoch: [149][   10/   24]    Loss 0.029926    Top1 99.062500    Top5 100.000000    
2024-01-15 19:44:38,125 - Epoch: [149][   20/   24]    Loss 0.025652    Top1 99.316406    Top5 100.000000    
2024-01-15 19:44:39,008 - Epoch: [149][   24/   24]    Loss 0.025006    Top1 99.283333    Top5 100.000000    
2024-01-15 19:44:39,755 - ==> Top1: 99.283    Top5: 100.000    Loss: 0.025

2024-01-15 19:44:39,757 - ==> Confusion:
[[604   0   1   0   0   0   0   0   0   0]
 [  0 686   0   0   0   0   1   1   0   0]
 [  0   0 579   1   0   0   0   3   2   1]
 [  0   0   2 577   0   1   0   1   2   0]
 [  0   0   0   0 559   0   0   1   1   4]
 [  0   0   0   1   0 516   1   0   0   0]
 [  0   0   0   0   1   0 629   0   1   0]
 [  0   1   1   1   0   0   0 622   0   0]
 [  0   0   0   1   0   1   2   0 579   1]
 [  1   1   0   0   3   0   0   1   3 606]]

2024-01-15 19:44:39,759 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:44:39,760 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:44:39,767 - 

2024-01-15 19:44:39,768 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:44:50,119 - Epoch: [150][   10/  211]    Overall Loss 0.019936    Objective Loss 0.019936                                        LR 0.001000    Time 1.035009    
2024-01-15 19:44:56,234 - Epoch: [150][   20/  211]    Overall Loss 0.022706    Objective Loss 0.022706                                        LR 0.001000    Time 0.823188    
2024-01-15 19:45:02,689 - Epoch: [150][   30/  211]    Overall Loss 0.020666    Objective Loss 0.020666                                        LR 0.001000    Time 0.763882    
2024-01-15 19:45:09,332 - Epoch: [150][   40/  211]    Overall Loss 0.019707    Objective Loss 0.019707                                        LR 0.001000    Time 0.738962    
2024-01-15 19:45:15,562 - Epoch: [150][   50/  211]    Overall Loss 0.021419    Objective Loss 0.021419                                        LR 0.001000    Time 0.715717    
2024-01-15 19:45:22,052 - Epoch: [150][   60/  211]    Overall Loss 0.020563    Objective Loss 0.020563                                        LR 0.001000    Time 0.704544    
2024-01-15 19:45:29,019 - Epoch: [150][   70/  211]    Overall Loss 0.021107    Objective Loss 0.021107                                        LR 0.001000    Time 0.703367    
2024-01-15 19:45:35,722 - Epoch: [150][   80/  211]    Overall Loss 0.022101    Objective Loss 0.022101                                        LR 0.001000    Time 0.699195    
2024-01-15 19:45:42,698 - Epoch: [150][   90/  211]    Overall Loss 0.022171    Objective Loss 0.022171                                        LR 0.001000    Time 0.698989    
2024-01-15 19:45:48,954 - Epoch: [150][  100/  211]    Overall Loss 0.022676    Objective Loss 0.022676                                        LR 0.001000    Time 0.691643    
2024-01-15 19:45:55,774 - Epoch: [150][  110/  211]    Overall Loss 0.022222    Objective Loss 0.022222                                        LR 0.001000    Time 0.690729    
2024-01-15 19:46:02,629 - Epoch: [150][  120/  211]    Overall Loss 0.021934    Objective Loss 0.021934                                        LR 0.001000    Time 0.690281    
2024-01-15 19:46:10,787 - Epoch: [150][  130/  211]    Overall Loss 0.022170    Objective Loss 0.022170                                        LR 0.001000    Time 0.699921    
2024-01-15 19:46:17,371 - Epoch: [150][  140/  211]    Overall Loss 0.022450    Objective Loss 0.022450                                        LR 0.001000    Time 0.696944    
2024-01-15 19:46:24,890 - Epoch: [150][  150/  211]    Overall Loss 0.021943    Objective Loss 0.021943                                        LR 0.001000    Time 0.700590    
2024-01-15 19:46:31,607 - Epoch: [150][  160/  211]    Overall Loss 0.021974    Objective Loss 0.021974                                        LR 0.001000    Time 0.698777    
2024-01-15 19:46:38,059 - Epoch: [150][  170/  211]    Overall Loss 0.021881    Objective Loss 0.021881                                        LR 0.001000    Time 0.695620    
2024-01-15 19:46:43,866 - Epoch: [150][  180/  211]    Overall Loss 0.021785    Objective Loss 0.021785                                        LR 0.001000    Time 0.689231    
2024-01-15 19:46:51,126 - Epoch: [150][  190/  211]    Overall Loss 0.021947    Objective Loss 0.021947                                        LR 0.001000    Time 0.691155    
2024-01-15 19:46:57,452 - Epoch: [150][  200/  211]    Overall Loss 0.022203    Objective Loss 0.022203                                        LR 0.001000    Time 0.688221    
2024-01-15 19:47:03,937 - Epoch: [150][  210/  211]    Overall Loss 0.022200    Objective Loss 0.022200    Top1 98.828125    Top5 100.000000    LR 0.001000    Time 0.686324    
2024-01-15 19:47:04,590 - Epoch: [150][  211/  211]    Overall Loss 0.022208    Objective Loss 0.022208    Top1 99.193548    Top5 100.000000    LR 0.001000    Time 0.686160    
2024-01-15 19:47:05,818 - --- validate (epoch=150)-----------
2024-01-15 19:47:05,820 - 6000 samples (256 per mini-batch)
2024-01-15 19:47:13,956 - Epoch: [150][   10/   24]    Loss 0.029089    Top1 99.218750    Top5 100.000000    
2024-01-15 19:47:16,383 - Epoch: [150][   20/   24]    Loss 0.025995    Top1 99.257812    Top5 100.000000    
2024-01-15 19:47:17,212 - Epoch: [150][   24/   24]    Loss 0.025605    Top1 99.283333    Top5 100.000000    
2024-01-15 19:47:18,164 - ==> Top1: 99.283    Top5: 100.000    Loss: 0.026

2024-01-15 19:47:18,167 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   1 585   0   0   0   0   0   0   0]
 [  0   0   2 579   0   1   0   0   1   0]
 [  0   1   1   0 555   0   1   0   1   6]
 [  0   1   0   0   0 515   1   0   1   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   2   3   0   0   0   0 620   0   0]
 [  1   0   0   0   1   2   0   0 579   1]
 [  0   0   0   0   5   2   0   2   2 604]]

2024-01-15 19:47:18,170 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:47:18,170 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:47:18,176 - 

2024-01-15 19:47:18,176 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:47:27,939 - Epoch: [151][   10/  211]    Overall Loss 0.020186    Objective Loss 0.020186                                        LR 0.001000    Time 0.976151    
2024-01-15 19:47:34,260 - Epoch: [151][   20/  211]    Overall Loss 0.021690    Objective Loss 0.021690                                        LR 0.001000    Time 0.803740    
2024-01-15 19:47:41,062 - Epoch: [151][   30/  211]    Overall Loss 0.021488    Objective Loss 0.021488                                        LR 0.001000    Time 0.762465    
2024-01-15 19:47:47,034 - Epoch: [151][   40/  211]    Overall Loss 0.023081    Objective Loss 0.023081                                        LR 0.001000    Time 0.721049    
2024-01-15 19:47:53,198 - Epoch: [151][   50/  211]    Overall Loss 0.022541    Objective Loss 0.022541                                        LR 0.001000    Time 0.700108    
2024-01-15 19:47:59,000 - Epoch: [151][   60/  211]    Overall Loss 0.021728    Objective Loss 0.021728                                        LR 0.001000    Time 0.680097    
2024-01-15 19:48:05,175 - Epoch: [151][   70/  211]    Overall Loss 0.021587    Objective Loss 0.021587                                        LR 0.001000    Time 0.671148    
2024-01-15 19:48:10,948 - Epoch: [151][   80/  211]    Overall Loss 0.020744    Objective Loss 0.020744                                        LR 0.001000    Time 0.659399    
2024-01-15 19:48:16,766 - Epoch: [151][   90/  211]    Overall Loss 0.020880    Objective Loss 0.020880                                        LR 0.001000    Time 0.650755    
2024-01-15 19:48:22,777 - Epoch: [151][  100/  211]    Overall Loss 0.020614    Objective Loss 0.020614                                        LR 0.001000    Time 0.645781    
2024-01-15 19:48:28,929 - Epoch: [151][  110/  211]    Overall Loss 0.021389    Objective Loss 0.021389                                        LR 0.001000    Time 0.642988    
2024-01-15 19:48:34,783 - Epoch: [151][  120/  211]    Overall Loss 0.021874    Objective Loss 0.021874                                        LR 0.001000    Time 0.638150    
2024-01-15 19:48:40,749 - Epoch: [151][  130/  211]    Overall Loss 0.022146    Objective Loss 0.022146                                        LR 0.001000    Time 0.634946    
2024-01-15 19:48:46,527 - Epoch: [151][  140/  211]    Overall Loss 0.022504    Objective Loss 0.022504                                        LR 0.001000    Time 0.630853    
2024-01-15 19:48:52,320 - Epoch: [151][  150/  211]    Overall Loss 0.022688    Objective Loss 0.022688                                        LR 0.001000    Time 0.627405    
2024-01-15 19:48:58,025 - Epoch: [151][  160/  211]    Overall Loss 0.022406    Objective Loss 0.022406                                        LR 0.001000    Time 0.623839    
2024-01-15 19:49:04,017 - Epoch: [151][  170/  211]    Overall Loss 0.022318    Objective Loss 0.022318                                        LR 0.001000    Time 0.622387    
2024-01-15 19:49:10,071 - Epoch: [151][  180/  211]    Overall Loss 0.022277    Objective Loss 0.022277                                        LR 0.001000    Time 0.621433    
2024-01-15 19:49:15,956 - Epoch: [151][  190/  211]    Overall Loss 0.022375    Objective Loss 0.022375                                        LR 0.001000    Time 0.619684    
2024-01-15 19:49:21,873 - Epoch: [151][  200/  211]    Overall Loss 0.022631    Objective Loss 0.022631                                        LR 0.001000    Time 0.618279    
2024-01-15 19:49:27,704 - Epoch: [151][  210/  211]    Overall Loss 0.022678    Objective Loss 0.022678    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.616594    
2024-01-15 19:49:28,433 - Epoch: [151][  211/  211]    Overall Loss 0.022627    Objective Loss 0.022627    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.617118    
2024-01-15 19:49:29,331 - --- validate (epoch=151)-----------
2024-01-15 19:49:29,333 - 6000 samples (256 per mini-batch)
2024-01-15 19:49:36,133 - Epoch: [151][   10/   24]    Loss 0.025651    Top1 99.453125    Top5 100.000000    
2024-01-15 19:49:38,438 - Epoch: [151][   20/   24]    Loss 0.027416    Top1 99.179688    Top5 100.000000    
2024-01-15 19:49:39,248 - Epoch: [151][   24/   24]    Loss 0.026011    Top1 99.250000    Top5 100.000000    
2024-01-15 19:49:39,995 - ==> Top1: 99.250    Top5: 100.000    Loss: 0.026

2024-01-15 19:49:39,997 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 687   0   1   0   0   0   0   0   0]
 [  0   1 580   0   0   0   0   4   1   0]
 [  0   0   2 579   0   2   0   0   0   0]
 [  0   0   0   0 558   0   0   1   0   6]
 [  0   0   0   1   0 516   1   0   0   0]
 [  1   1   0   0   2   0 627   0   0   0]
 [  0   2   0   1   2   0   0 620   0   0]
 [  0   0   1   0   2   1   2   0 578   0]
 [  0   1   0   0   2   1   0   1   3 607]]

2024-01-15 19:49:39,999 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:49:39,999 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:49:40,005 - 

2024-01-15 19:49:40,005 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:49:49,279 - Epoch: [152][   10/  211]    Overall Loss 0.026974    Objective Loss 0.026974                                        LR 0.001000    Time 0.927333    
2024-01-15 19:49:55,689 - Epoch: [152][   20/  211]    Overall Loss 0.025131    Objective Loss 0.025131                                        LR 0.001000    Time 0.784089    
2024-01-15 19:50:01,529 - Epoch: [152][   30/  211]    Overall Loss 0.023009    Objective Loss 0.023009                                        LR 0.001000    Time 0.717318    
2024-01-15 19:50:07,382 - Epoch: [152][   40/  211]    Overall Loss 0.024109    Objective Loss 0.024109                                        LR 0.001000    Time 0.684287    
2024-01-15 19:50:13,526 - Epoch: [152][   50/  211]    Overall Loss 0.022153    Objective Loss 0.022153                                        LR 0.001000    Time 0.670279    
2024-01-15 19:50:19,594 - Epoch: [152][   60/  211]    Overall Loss 0.022284    Objective Loss 0.022284                                        LR 0.001000    Time 0.659683    
2024-01-15 19:50:25,409 - Epoch: [152][   70/  211]    Overall Loss 0.022310    Objective Loss 0.022310                                        LR 0.001000    Time 0.648482    
2024-01-15 19:50:31,240 - Epoch: [152][   80/  211]    Overall Loss 0.023484    Objective Loss 0.023484                                        LR 0.001000    Time 0.640287    
2024-01-15 19:50:37,591 - Epoch: [152][   90/  211]    Overall Loss 0.023691    Objective Loss 0.023691                                        LR 0.001000    Time 0.639700    
2024-01-15 19:50:43,791 - Epoch: [152][  100/  211]    Overall Loss 0.023164    Objective Loss 0.023164                                        LR 0.001000    Time 0.637718    
2024-01-15 19:50:49,582 - Epoch: [152][  110/  211]    Overall Loss 0.023414    Objective Loss 0.023414                                        LR 0.001000    Time 0.632378    
2024-01-15 19:50:55,554 - Epoch: [152][  120/  211]    Overall Loss 0.023143    Objective Loss 0.023143                                        LR 0.001000    Time 0.629435    
2024-01-15 19:51:01,680 - Epoch: [152][  130/  211]    Overall Loss 0.023360    Objective Loss 0.023360                                        LR 0.001000    Time 0.628128    
2024-01-15 19:51:09,194 - Epoch: [152][  140/  211]    Overall Loss 0.022968    Objective Loss 0.022968                                        LR 0.001000    Time 0.636921    
2024-01-15 19:51:15,061 - Epoch: [152][  150/  211]    Overall Loss 0.022855    Objective Loss 0.022855                                        LR 0.001000    Time 0.633547    
2024-01-15 19:51:20,859 - Epoch: [152][  160/  211]    Overall Loss 0.022917    Objective Loss 0.022917                                        LR 0.001000    Time 0.630185    
2024-01-15 19:51:26,849 - Epoch: [152][  170/  211]    Overall Loss 0.022838    Objective Loss 0.022838                                        LR 0.001000    Time 0.628343    
2024-01-15 19:51:33,233 - Epoch: [152][  180/  211]    Overall Loss 0.023437    Objective Loss 0.023437                                        LR 0.001000    Time 0.628895    
2024-01-15 19:51:39,964 - Epoch: [152][  190/  211]    Overall Loss 0.022938    Objective Loss 0.022938                                        LR 0.001000    Time 0.631210    
2024-01-15 19:51:45,951 - Epoch: [152][  200/  211]    Overall Loss 0.022536    Objective Loss 0.022536                                        LR 0.001000    Time 0.629579    
2024-01-15 19:51:52,896 - Epoch: [152][  210/  211]    Overall Loss 0.022471    Objective Loss 0.022471    Top1 98.828125    Top5 100.000000    LR 0.001000    Time 0.632668    
2024-01-15 19:51:53,553 - Epoch: [152][  211/  211]    Overall Loss 0.022582    Objective Loss 0.022582    Top1 98.588710    Top5 100.000000    LR 0.001000    Time 0.632779    
2024-01-15 19:51:54,566 - --- validate (epoch=152)-----------
2024-01-15 19:51:54,568 - 6000 samples (256 per mini-batch)
2024-01-15 19:52:01,625 - Epoch: [152][   10/   24]    Loss 0.030010    Top1 99.335938    Top5 100.000000    
2024-01-15 19:52:03,758 - Epoch: [152][   20/   24]    Loss 0.028795    Top1 99.218750    Top5 100.000000    
2024-01-15 19:52:04,550 - Epoch: [152][   24/   24]    Loss 0.027182    Top1 99.266667    Top5 100.000000    
2024-01-15 19:52:05,323 - ==> Top1: 99.267    Top5: 100.000    Loss: 0.027

2024-01-15 19:52:05,324 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 685   0   1   0   1   1   0   0   0]
 [  0   0 583   0   0   0   1   2   0   0]
 [  0   0   0 580   0   2   0   0   1   0]
 [  0   1   0   0 558   0   1   0   0   5]
 [  0   0   0   1   0 512   4   0   0   1]
 [  1   1   0   0   1   0 627   0   1   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  0   1   0   1   1   0   2   0 579   0]
 [  0   0   0   0   2   0   0   2   3 608]]

2024-01-15 19:52:05,326 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:52:05,326 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:52:05,331 - 

2024-01-15 19:52:05,331 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:52:16,374 - Epoch: [153][   10/  211]    Overall Loss 0.028407    Objective Loss 0.028407                                        LR 0.001000    Time 1.104225    
2024-01-15 19:52:22,288 - Epoch: [153][   20/  211]    Overall Loss 0.024223    Objective Loss 0.024223                                        LR 0.001000    Time 0.847729    
2024-01-15 19:52:28,566 - Epoch: [153][   30/  211]    Overall Loss 0.024152    Objective Loss 0.024152                                        LR 0.001000    Time 0.774361    
2024-01-15 19:52:34,530 - Epoch: [153][   40/  211]    Overall Loss 0.022788    Objective Loss 0.022788                                        LR 0.001000    Time 0.729805    
2024-01-15 19:52:41,472 - Epoch: [153][   50/  211]    Overall Loss 0.023632    Objective Loss 0.023632                                        LR 0.001000    Time 0.722670    
2024-01-15 19:52:47,813 - Epoch: [153][   60/  211]    Overall Loss 0.023861    Objective Loss 0.023861                                        LR 0.001000    Time 0.707880    
2024-01-15 19:52:53,752 - Epoch: [153][   70/  211]    Overall Loss 0.023905    Objective Loss 0.023905                                        LR 0.001000    Time 0.691583    
2024-01-15 19:52:59,753 - Epoch: [153][   80/  211]    Overall Loss 0.023642    Objective Loss 0.023642                                        LR 0.001000    Time 0.680119    
2024-01-15 19:53:05,628 - Epoch: [153][   90/  211]    Overall Loss 0.023612    Objective Loss 0.023612                                        LR 0.001000    Time 0.669813    
2024-01-15 19:53:11,296 - Epoch: [153][  100/  211]    Overall Loss 0.023459    Objective Loss 0.023459                                        LR 0.001000    Time 0.659505    
2024-01-15 19:53:16,938 - Epoch: [153][  110/  211]    Overall Loss 0.023659    Objective Loss 0.023659                                        LR 0.001000    Time 0.650832    
2024-01-15 19:53:22,660 - Epoch: [153][  120/  211]    Overall Loss 0.023378    Objective Loss 0.023378                                        LR 0.001000    Time 0.644266    
2024-01-15 19:53:28,607 - Epoch: [153][  130/  211]    Overall Loss 0.023795    Objective Loss 0.023795                                        LR 0.001000    Time 0.640445    
2024-01-15 19:53:34,463 - Epoch: [153][  140/  211]    Overall Loss 0.023618    Objective Loss 0.023618                                        LR 0.001000    Time 0.636516    
2024-01-15 19:53:40,168 - Epoch: [153][  150/  211]    Overall Loss 0.023556    Objective Loss 0.023556                                        LR 0.001000    Time 0.632093    
2024-01-15 19:53:45,918 - Epoch: [153][  160/  211]    Overall Loss 0.023661    Objective Loss 0.023661                                        LR 0.001000    Time 0.628512    
2024-01-15 19:53:51,854 - Epoch: [153][  170/  211]    Overall Loss 0.023470    Objective Loss 0.023470                                        LR 0.001000    Time 0.626452    
2024-01-15 19:53:57,494 - Epoch: [153][  180/  211]    Overall Loss 0.023675    Objective Loss 0.023675                                        LR 0.001000    Time 0.622977    
2024-01-15 19:54:03,158 - Epoch: [153][  190/  211]    Overall Loss 0.023471    Objective Loss 0.023471                                        LR 0.001000    Time 0.619993    
2024-01-15 19:54:08,867 - Epoch: [153][  200/  211]    Overall Loss 0.023126    Objective Loss 0.023126                                        LR 0.001000    Time 0.617537    
2024-01-15 19:54:14,741 - Epoch: [153][  210/  211]    Overall Loss 0.023167    Objective Loss 0.023167    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.616099    
2024-01-15 19:54:15,329 - Epoch: [153][  211/  211]    Overall Loss 0.023183    Objective Loss 0.023183    Top1 99.798387    Top5 100.000000    LR 0.001000    Time 0.615963    
2024-01-15 19:54:16,091 - --- validate (epoch=153)-----------
2024-01-15 19:54:16,092 - 6000 samples (256 per mini-batch)
2024-01-15 19:54:22,871 - Epoch: [153][   10/   24]    Loss 0.036169    Top1 98.867188    Top5 100.000000    
2024-01-15 19:54:25,010 - Epoch: [153][   20/   24]    Loss 0.032739    Top1 99.042969    Top5 100.000000    
2024-01-15 19:54:25,808 - Epoch: [153][   24/   24]    Loss 0.031060    Top1 99.050000    Top5 100.000000    
2024-01-15 19:54:26,479 - ==> Top1: 99.050    Top5: 100.000    Loss: 0.031

2024-01-15 19:54:26,480 - ==> Confusion:
[[601   0   1   0   0   1   2   0   0   0]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   0 580   0   0   0   1   3   1   1]
 [  0   0   2 577   0   1   0   0   2   1]
 [  0   0   1   0 558   0   0   1   1   4]
 [  1   0   0   2   0 510   4   0   1   0]
 [  0   0   0   0   1   0 628   0   1   1]
 [  0   3   2   0   0   0   0 620   0   0]
 [  1   0   0   1   0   2   1   0 578   1]
 [  0   1   0   1   3   2   0   3   2 603]]

2024-01-15 19:54:26,482 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:54:26,482 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:54:26,490 - 

2024-01-15 19:54:26,490 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:54:35,168 - Epoch: [154][   10/  211]    Overall Loss 0.021101    Objective Loss 0.021101                                        LR 0.001000    Time 0.867710    
2024-01-15 19:54:40,823 - Epoch: [154][   20/  211]    Overall Loss 0.022552    Objective Loss 0.022552                                        LR 0.001000    Time 0.716566    
2024-01-15 19:54:46,467 - Epoch: [154][   30/  211]    Overall Loss 0.022271    Objective Loss 0.022271                                        LR 0.001000    Time 0.665812    
2024-01-15 19:54:52,194 - Epoch: [154][   40/  211]    Overall Loss 0.021763    Objective Loss 0.021763                                        LR 0.001000    Time 0.642513    
2024-01-15 19:54:58,082 - Epoch: [154][   50/  211]    Overall Loss 0.021759    Objective Loss 0.021759                                        LR 0.001000    Time 0.631744    
2024-01-15 19:55:03,750 - Epoch: [154][   60/  211]    Overall Loss 0.022698    Objective Loss 0.022698                                        LR 0.001000    Time 0.620912    
2024-01-15 19:55:09,419 - Epoch: [154][   70/  211]    Overall Loss 0.023240    Objective Loss 0.023240                                        LR 0.001000    Time 0.613184    
2024-01-15 19:55:15,218 - Epoch: [154][   80/  211]    Overall Loss 0.022665    Objective Loss 0.022665                                        LR 0.001000    Time 0.609000    
2024-01-15 19:55:20,958 - Epoch: [154][   90/  211]    Overall Loss 0.022381    Objective Loss 0.022381                                        LR 0.001000    Time 0.605105    
2024-01-15 19:55:26,645 - Epoch: [154][  100/  211]    Overall Loss 0.022228    Objective Loss 0.022228                                        LR 0.001000    Time 0.601455    
2024-01-15 19:55:32,487 - Epoch: [154][  110/  211]    Overall Loss 0.022502    Objective Loss 0.022502                                        LR 0.001000    Time 0.599880    
2024-01-15 19:55:39,458 - Epoch: [154][  120/  211]    Overall Loss 0.022333    Objective Loss 0.022333                                        LR 0.001000    Time 0.607965    
2024-01-15 19:55:45,292 - Epoch: [154][  130/  211]    Overall Loss 0.022110    Objective Loss 0.022110                                        LR 0.001000    Time 0.606073    
2024-01-15 19:55:51,052 - Epoch: [154][  140/  211]    Overall Loss 0.022040    Objective Loss 0.022040                                        LR 0.001000    Time 0.603919    
2024-01-15 19:55:56,766 - Epoch: [154][  150/  211]    Overall Loss 0.021894    Objective Loss 0.021894                                        LR 0.001000    Time 0.601746    
2024-01-15 19:56:02,410 - Epoch: [154][  160/  211]    Overall Loss 0.021696    Objective Loss 0.021696                                        LR 0.001000    Time 0.599408    
2024-01-15 19:56:08,094 - Epoch: [154][  170/  211]    Overall Loss 0.021790    Objective Loss 0.021790                                        LR 0.001000    Time 0.597575    
2024-01-15 19:56:13,757 - Epoch: [154][  180/  211]    Overall Loss 0.021807    Objective Loss 0.021807                                        LR 0.001000    Time 0.595834    
2024-01-15 19:56:19,451 - Epoch: [154][  190/  211]    Overall Loss 0.022075    Objective Loss 0.022075                                        LR 0.001000    Time 0.594441    
2024-01-15 19:56:25,232 - Epoch: [154][  200/  211]    Overall Loss 0.021851    Objective Loss 0.021851                                        LR 0.001000    Time 0.593619    
2024-01-15 19:56:31,368 - Epoch: [154][  210/  211]    Overall Loss 0.022217    Objective Loss 0.022217    Top1 99.609375    Top5 100.000000    LR 0.001000    Time 0.594566    
2024-01-15 19:56:31,930 - Epoch: [154][  211/  211]    Overall Loss 0.022202    Objective Loss 0.022202    Top1 99.596774    Top5 100.000000    LR 0.001000    Time 0.594407    
2024-01-15 19:56:32,730 - --- validate (epoch=154)-----------
2024-01-15 19:56:32,732 - 6000 samples (256 per mini-batch)
2024-01-15 19:56:39,790 - Epoch: [154][   10/   24]    Loss 0.020544    Top1 99.492188    Top5 100.000000    
2024-01-15 19:56:41,921 - Epoch: [154][   20/   24]    Loss 0.024164    Top1 99.394531    Top5 100.000000    
2024-01-15 19:56:42,733 - Epoch: [154][   24/   24]    Loss 0.025885    Top1 99.316667    Top5 100.000000    
2024-01-15 19:56:43,462 - ==> Top1: 99.317    Top5: 100.000    Loss: 0.026

2024-01-15 19:56:43,463 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 685   0   0   0   0   0   3   0   0]
 [  0   0 585   0   0   0   0   1   0   0]
 [  0   0   3 578   0   1   0   0   1   0]
 [  0   1   1   0 559   0   0   0   0   4]
 [  0   1   0   1   0 513   2   0   1   0]
 [  0   1   0   0   2   0 628   0   0   0]
 [  0   2   0   1   1   0   0 621   0   0]
 [  1   0   0   0   0   0   0   0 583   0]
 [  1   0   0   0   4   2   0   2   2 604]]

2024-01-15 19:56:43,466 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:56:43,466 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:56:43,470 - 

2024-01-15 19:56:43,470 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:56:52,215 - Epoch: [155][   10/  211]    Overall Loss 0.025155    Objective Loss 0.025155                                        LR 0.001000    Time 0.874369    
2024-01-15 19:56:57,945 - Epoch: [155][   20/  211]    Overall Loss 0.026756    Objective Loss 0.026756                                        LR 0.001000    Time 0.723636    
2024-01-15 19:57:03,628 - Epoch: [155][   30/  211]    Overall Loss 0.025928    Objective Loss 0.025928                                        LR 0.001000    Time 0.671817    
2024-01-15 19:57:09,507 - Epoch: [155][   40/  211]    Overall Loss 0.023660    Objective Loss 0.023660                                        LR 0.001000    Time 0.650496    
2024-01-15 19:57:15,469 - Epoch: [155][   50/  211]    Overall Loss 0.023526    Objective Loss 0.023526                                        LR 0.001000    Time 0.639480    
2024-01-15 19:57:21,424 - Epoch: [155][   60/  211]    Overall Loss 0.023506    Objective Loss 0.023506                                        LR 0.001000    Time 0.632129    
2024-01-15 19:57:27,254 - Epoch: [155][   70/  211]    Overall Loss 0.022924    Objective Loss 0.022924                                        LR 0.001000    Time 0.625095    
2024-01-15 19:57:33,130 - Epoch: [155][   80/  211]    Overall Loss 0.023517    Objective Loss 0.023517                                        LR 0.001000    Time 0.620391    
2024-01-15 19:57:38,883 - Epoch: [155][   90/  211]    Overall Loss 0.023786    Objective Loss 0.023786                                        LR 0.001000    Time 0.615374    
2024-01-15 19:57:44,549 - Epoch: [155][  100/  211]    Overall Loss 0.023147    Objective Loss 0.023147                                        LR 0.001000    Time 0.610488    
2024-01-15 19:57:50,919 - Epoch: [155][  110/  211]    Overall Loss 0.023650    Objective Loss 0.023650                                        LR 0.001000    Time 0.612888    
2024-01-15 19:57:56,572 - Epoch: [155][  120/  211]    Overall Loss 0.023597    Objective Loss 0.023597                                        LR 0.001000    Time 0.608916    
2024-01-15 19:58:02,202 - Epoch: [155][  130/  211]    Overall Loss 0.023475    Objective Loss 0.023475                                        LR 0.001000    Time 0.605380    
2024-01-15 19:58:07,867 - Epoch: [155][  140/  211]    Overall Loss 0.023115    Objective Loss 0.023115                                        LR 0.001000    Time 0.602593    
2024-01-15 19:58:13,556 - Epoch: [155][  150/  211]    Overall Loss 0.022566    Objective Loss 0.022566                                        LR 0.001000    Time 0.600341    
2024-01-15 19:58:19,191 - Epoch: [155][  160/  211]    Overall Loss 0.022094    Objective Loss 0.022094                                        LR 0.001000    Time 0.598035    
2024-01-15 19:58:24,972 - Epoch: [155][  170/  211]    Overall Loss 0.021829    Objective Loss 0.021829                                        LR 0.001000    Time 0.596855    
2024-01-15 19:58:30,891 - Epoch: [155][  180/  211]    Overall Loss 0.022010    Objective Loss 0.022010                                        LR 0.001000    Time 0.596573    
2024-01-15 19:58:36,537 - Epoch: [155][  190/  211]    Overall Loss 0.021722    Objective Loss 0.021722                                        LR 0.001000    Time 0.594890    
2024-01-15 19:58:42,296 - Epoch: [155][  200/  211]    Overall Loss 0.021572    Objective Loss 0.021572                                        LR 0.001000    Time 0.593934    
2024-01-15 19:58:47,936 - Epoch: [155][  210/  211]    Overall Loss 0.021807    Objective Loss 0.021807    Top1 98.828125    Top5 100.000000    LR 0.001000    Time 0.592503    
2024-01-15 19:58:48,588 - Epoch: [155][  211/  211]    Overall Loss 0.021744    Objective Loss 0.021744    Top1 99.395161    Top5 100.000000    LR 0.001000    Time 0.592782    
2024-01-15 19:58:49,494 - --- validate (epoch=155)-----------
2024-01-15 19:58:49,496 - 6000 samples (256 per mini-batch)
2024-01-15 19:58:56,325 - Epoch: [155][   10/   24]    Loss 0.025569    Top1 99.218750    Top5 100.000000    
2024-01-15 19:58:58,433 - Epoch: [155][   20/   24]    Loss 0.027191    Top1 99.257812    Top5 100.000000    
2024-01-15 19:58:59,177 - Epoch: [155][   24/   24]    Loss 0.026241    Top1 99.266667    Top5 100.000000    
2024-01-15 19:58:59,717 - ==> Top1: 99.267    Top5: 100.000    Loss: 0.026

2024-01-15 19:58:59,718 - ==> Confusion:
[[603   0   0   0   0   0   1   0   0   1]
 [  0 685   1   0   1   0   1   0   0   0]
 [  0   0 581   2   0   0   0   2   1   0]
 [  0   0   2 577   0   3   0   0   1   0]
 [  0   1   0   0 560   0   0   0   0   4]
 [  0   0   0   1   0 515   2   0   0   0]
 [  0   1   0   0   0   0 629   0   1   0]
 [  0   1   0   1   0   0   0 623   0   0]
 [  0   0   0   2   0   2   2   0 578   0]
 [  0   1   0   0   2   1   0   3   3 605]]

2024-01-15 19:58:59,720 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 19:58:59,720 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 19:58:59,724 - 

2024-01-15 19:58:59,724 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 19:59:08,092 - Epoch: [156][   10/  211]    Overall Loss 0.020028    Objective Loss 0.020028                                        LR 0.001000    Time 0.836688    
2024-01-15 19:59:13,741 - Epoch: [156][   20/  211]    Overall Loss 0.023674    Objective Loss 0.023674                                        LR 0.001000    Time 0.700754    
2024-01-15 19:59:19,377 - Epoch: [156][   30/  211]    Overall Loss 0.025669    Objective Loss 0.025669                                        LR 0.001000    Time 0.655011    
2024-01-15 19:59:25,017 - Epoch: [156][   40/  211]    Overall Loss 0.024936    Objective Loss 0.024936                                        LR 0.001000    Time 0.632243    
2024-01-15 19:59:30,789 - Epoch: [156][   50/  211]    Overall Loss 0.023967    Objective Loss 0.023967                                        LR 0.001000    Time 0.621147    
2024-01-15 19:59:36,444 - Epoch: [156][   60/  211]    Overall Loss 0.022760    Objective Loss 0.022760                                        LR 0.001000    Time 0.611673    
2024-01-15 19:59:42,197 - Epoch: [156][   70/  211]    Overall Loss 0.022289    Objective Loss 0.022289                                        LR 0.001000    Time 0.606471    
2024-01-15 19:59:47,839 - Epoch: [156][   80/  211]    Overall Loss 0.023094    Objective Loss 0.023094                                        LR 0.001000    Time 0.601174    
2024-01-15 19:59:53,475 - Epoch: [156][   90/  211]    Overall Loss 0.022997    Objective Loss 0.022997                                        LR 0.001000    Time 0.596994    
2024-01-15 19:59:59,113 - Epoch: [156][  100/  211]    Overall Loss 0.023388    Objective Loss 0.023388                                        LR 0.001000    Time 0.593660    
2024-01-15 20:00:04,740 - Epoch: [156][  110/  211]    Overall Loss 0.022609    Objective Loss 0.022609                                        LR 0.001000    Time 0.590848    
2024-01-15 20:00:10,371 - Epoch: [156][  120/  211]    Overall Loss 0.022231    Objective Loss 0.022231                                        LR 0.001000    Time 0.588527    
2024-01-15 20:00:16,034 - Epoch: [156][  130/  211]    Overall Loss 0.022138    Objective Loss 0.022138                                        LR 0.001000    Time 0.586810    
2024-01-15 20:00:21,718 - Epoch: [156][  140/  211]    Overall Loss 0.022042    Objective Loss 0.022042                                        LR 0.001000    Time 0.585488    
2024-01-15 20:00:27,401 - Epoch: [156][  150/  211]    Overall Loss 0.021792    Objective Loss 0.021792                                        LR 0.001000    Time 0.584332    
2024-01-15 20:00:33,258 - Epoch: [156][  160/  211]    Overall Loss 0.022095    Objective Loss 0.022095                                        LR 0.001000    Time 0.584412    
2024-01-15 20:00:38,902 - Epoch: [156][  170/  211]    Overall Loss 0.022210    Objective Loss 0.022210                                        LR 0.001000    Time 0.583230    
2024-01-15 20:00:44,554 - Epoch: [156][  180/  211]    Overall Loss 0.022436    Objective Loss 0.022436                                        LR 0.001000    Time 0.582224    
2024-01-15 20:00:50,181 - Epoch: [156][  190/  211]    Overall Loss 0.022113    Objective Loss 0.022113                                        LR 0.001000    Time 0.581191    
2024-01-15 20:00:55,846 - Epoch: [156][  200/  211]    Overall Loss 0.022209    Objective Loss 0.022209                                        LR 0.001000    Time 0.580453    
2024-01-15 20:01:01,471 - Epoch: [156][  210/  211]    Overall Loss 0.022169    Objective Loss 0.022169    Top1 98.437500    Top5 100.000000    LR 0.001000    Time 0.579590    
2024-01-15 20:01:02,038 - Epoch: [156][  211/  211]    Overall Loss 0.022197    Objective Loss 0.022197    Top1 98.991935    Top5 100.000000    LR 0.001000    Time 0.579528    
2024-01-15 20:01:02,592 - --- validate (epoch=156)-----------
2024-01-15 20:01:02,592 - 6000 samples (256 per mini-batch)
2024-01-15 20:01:07,831 - Epoch: [156][   10/   24]    Loss 0.028265    Top1 99.335938    Top5 99.960938    
2024-01-15 20:01:10,826 - Epoch: [156][   20/   24]    Loss 0.026522    Top1 99.277344    Top5 99.980469    
2024-01-15 20:01:11,960 - Epoch: [156][   24/   24]    Loss 0.025872    Top1 99.300000    Top5 99.983333    
2024-01-15 20:01:14,136 - ==> Top1: 99.300    Top5: 99.983    Loss: 0.026

2024-01-15 20:01:14,140 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 684   1   0   1   1   1   0   0   0]
 [  0   0 584   0   0   0   0   1   1   0]
 [  0   0   1 578   0   1   0   1   2   0]
 [  0   0   0   0 561   0   0   0   0   4]
 [  1   0   0   1   0 514   2   0   0   0]
 [  1   1   0   0   1   0 627   0   1   0]
 [  0   2   0   2   0   0   0 621   0   0]
 [  0   0   0   1   0   1   1   0 580   1]
 [  0   1   0   0   1   1   0   3   3 606]]

2024-01-15 20:01:14,144 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 20:01:14,144 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:01:14,152 - 

2024-01-15 20:01:14,152 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:01:25,489 - Epoch: [157][   10/  211]    Overall Loss 0.022599    Objective Loss 0.022599                                        LR 0.001000    Time 1.133349    
2024-01-15 20:01:31,489 - Epoch: [157][   20/  211]    Overall Loss 0.020471    Objective Loss 0.020471                                        LR 0.001000    Time 0.866600    
2024-01-15 20:01:38,817 - Epoch: [157][   30/  211]    Overall Loss 0.022861    Objective Loss 0.022861                                        LR 0.001000    Time 0.821935    
2024-01-15 20:01:44,952 - Epoch: [157][   40/  211]    Overall Loss 0.023385    Objective Loss 0.023385                                        LR 0.001000    Time 0.769800    
2024-01-15 20:01:50,729 - Epoch: [157][   50/  211]    Overall Loss 0.022072    Objective Loss 0.022072                                        LR 0.001000    Time 0.731354    
2024-01-15 20:01:57,315 - Epoch: [157][   60/  211]    Overall Loss 0.021655    Objective Loss 0.021655                                        LR 0.001000    Time 0.719217    
2024-01-15 20:02:03,832 - Epoch: [157][   70/  211]    Overall Loss 0.022320    Objective Loss 0.022320                                        LR 0.001000    Time 0.709537    
2024-01-15 20:02:10,457 - Epoch: [157][   80/  211]    Overall Loss 0.021844    Objective Loss 0.021844                                        LR 0.001000    Time 0.703631    
2024-01-15 20:02:18,232 - Epoch: [157][   90/  211]    Overall Loss 0.022127    Objective Loss 0.022127                                        LR 0.001000    Time 0.711729    
2024-01-15 20:02:25,259 - Epoch: [157][  100/  211]    Overall Loss 0.022745    Objective Loss 0.022745                                        LR 0.001000    Time 0.710680    
2024-01-15 20:02:32,282 - Epoch: [157][  110/  211]    Overall Loss 0.022814    Objective Loss 0.022814                                        LR 0.001000    Time 0.709902    
2024-01-15 20:02:39,018 - Epoch: [157][  120/  211]    Overall Loss 0.023062    Objective Loss 0.023062                                        LR 0.001000    Time 0.706861    
2024-01-15 20:02:45,799 - Epoch: [157][  130/  211]    Overall Loss 0.023061    Objective Loss 0.023061                                        LR 0.001000    Time 0.704635    
2024-01-15 20:02:52,010 - Epoch: [157][  140/  211]    Overall Loss 0.023026    Objective Loss 0.023026                                        LR 0.001000    Time 0.698660    
2024-01-15 20:02:57,888 - Epoch: [157][  150/  211]    Overall Loss 0.023021    Objective Loss 0.023021                                        LR 0.001000    Time 0.691257    
2024-01-15 20:03:04,834 - Epoch: [157][  160/  211]    Overall Loss 0.022784    Objective Loss 0.022784                                        LR 0.001000    Time 0.691458    
2024-01-15 20:03:11,339 - Epoch: [157][  170/  211]    Overall Loss 0.022816    Objective Loss 0.022816                                        LR 0.001000    Time 0.689043    
2024-01-15 20:03:18,476 - Epoch: [157][  180/  211]    Overall Loss 0.022844    Objective Loss 0.022844                                        LR 0.001000    Time 0.690402    
2024-01-15 20:03:25,290 - Epoch: [157][  190/  211]    Overall Loss 0.022554    Objective Loss 0.022554                                        LR 0.001000    Time 0.689919    
2024-01-15 20:03:32,119 - Epoch: [157][  200/  211]    Overall Loss 0.022458    Objective Loss 0.022458                                        LR 0.001000    Time 0.689541    
2024-01-15 20:03:38,893 - Epoch: [157][  210/  211]    Overall Loss 0.022602    Objective Loss 0.022602    Top1 99.218750    Top5 100.000000    LR 0.001000    Time 0.688955    
2024-01-15 20:03:39,678 - Epoch: [157][  211/  211]    Overall Loss 0.022627    Objective Loss 0.022627    Top1 99.193548    Top5 100.000000    LR 0.001000    Time 0.689406    
2024-01-15 20:03:41,487 - --- validate (epoch=157)-----------
2024-01-15 20:03:41,491 - 6000 samples (256 per mini-batch)
2024-01-15 20:03:49,356 - Epoch: [157][   10/   24]    Loss 0.035131    Top1 98.867188    Top5 100.000000    
2024-01-15 20:03:51,601 - Epoch: [157][   20/   24]    Loss 0.031926    Top1 98.984375    Top5 100.000000    
2024-01-15 20:03:52,404 - Epoch: [157][   24/   24]    Loss 0.031086    Top1 99.016667    Top5 100.000000    
2024-01-15 20:03:53,141 - ==> Top1: 99.017    Top5: 100.000    Loss: 0.031

2024-01-15 20:03:53,144 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 684   1   0   1   1   1   0   0   0]
 [  0   0 581   0   1   0   1   3   0   0]
 [  0   0   2 577   0   2   0   1   1   0]
 [  0   0   1   0 555   0   1   1   1   6]
 [  1   1   0   1   0 512   2   0   1   0]
 [  1   0   0   0   2   0 628   0   0   0]
 [  0   3   0   2   0   0   0 619   0   1]
 [  1   0   0   0   0   1   1   1 580   0]
 [  0   2   0   0   5   2   0   2   2 602]]

2024-01-15 20:03:53,149 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 20:03:53,149 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:03:53,158 - 

2024-01-15 20:03:53,159 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:04:04,380 - Epoch: [158][   10/  211]    Overall Loss 0.024819    Objective Loss 0.024819                                        LR 0.001000    Time 1.121972    
2024-01-15 20:04:10,655 - Epoch: [158][   20/  211]    Overall Loss 0.027874    Objective Loss 0.027874                                        LR 0.001000    Time 0.874487    
2024-01-15 20:04:17,293 - Epoch: [158][   30/  211]    Overall Loss 0.027203    Objective Loss 0.027203                                        LR 0.001000    Time 0.804168    
2024-01-15 20:04:24,619 - Epoch: [158][   40/  211]    Overall Loss 0.025408    Objective Loss 0.025408                                        LR 0.001000    Time 0.786212    
2024-01-15 20:04:31,610 - Epoch: [158][   50/  211]    Overall Loss 0.023947    Objective Loss 0.023947                                        LR 0.001000    Time 0.768764    
2024-01-15 20:04:38,404 - Epoch: [158][   60/  211]    Overall Loss 0.025066    Objective Loss 0.025066                                        LR 0.001000    Time 0.753832    
2024-01-15 20:04:44,977 - Epoch: [158][   70/  211]    Overall Loss 0.024420    Objective Loss 0.024420                                        LR 0.001000    Time 0.740020    
2024-01-15 20:04:51,609 - Epoch: [158][   80/  211]    Overall Loss 0.023914    Objective Loss 0.023914                                        LR 0.001000    Time 0.730394    
2024-01-15 20:04:58,491 - Epoch: [158][   90/  211]    Overall Loss 0.023557    Objective Loss 0.023557                                        LR 0.001000    Time 0.725621    
2024-01-15 20:05:05,407 - Epoch: [158][  100/  211]    Overall Loss 0.023562    Objective Loss 0.023562                                        LR 0.001000    Time 0.722184    
2024-01-15 20:05:12,647 - Epoch: [158][  110/  211]    Overall Loss 0.023512    Objective Loss 0.023512                                        LR 0.001000    Time 0.722334    
2024-01-15 20:05:19,793 - Epoch: [158][  120/  211]    Overall Loss 0.023351    Objective Loss 0.023351                                        LR 0.001000    Time 0.721666    
2024-01-15 20:05:26,226 - Epoch: [158][  130/  211]    Overall Loss 0.023343    Objective Loss 0.023343                                        LR 0.001000    Time 0.715626    
2024-01-15 20:05:33,432 - Epoch: [158][  140/  211]    Overall Loss 0.023666    Objective Loss 0.023666                                        LR 0.001000    Time 0.715956    
2024-01-15 20:05:39,587 - Epoch: [158][  150/  211]    Overall Loss 0.023735    Objective Loss 0.023735                                        LR 0.001000    Time 0.709257    
2024-01-15 20:05:46,496 - Epoch: [158][  160/  211]    Overall Loss 0.023610    Objective Loss 0.023610                                        LR 0.001000    Time 0.708099    
2024-01-15 20:05:52,855 - Epoch: [158][  170/  211]    Overall Loss 0.023247    Objective Loss 0.023247                                        LR 0.001000    Time 0.703839    
2024-01-15 20:05:59,301 - Epoch: [158][  180/  211]    Overall Loss 0.023059    Objective Loss 0.023059                                        LR 0.001000    Time 0.700541    
2024-01-15 20:06:05,863 - Epoch: [158][  190/  211]    Overall Loss 0.022542    Objective Loss 0.022542                                        LR 0.001000    Time 0.698198    
2024-01-15 20:06:12,673 - Epoch: [158][  200/  211]    Overall Loss 0.022369    Objective Loss 0.022369                                        LR 0.001000    Time 0.697327    
2024-01-15 20:06:19,666 - Epoch: [158][  210/  211]    Overall Loss 0.022192    Objective Loss 0.022192    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.697413    
2024-01-15 20:06:20,364 - Epoch: [158][  211/  211]    Overall Loss 0.022117    Objective Loss 0.022117    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.697412    
2024-01-15 20:06:21,426 - --- validate (epoch=158)-----------
2024-01-15 20:06:21,428 - 6000 samples (256 per mini-batch)
2024-01-15 20:06:29,554 - Epoch: [158][   10/   24]    Loss 0.027410    Top1 99.179688    Top5 100.000000    
2024-01-15 20:06:31,934 - Epoch: [158][   20/   24]    Loss 0.029113    Top1 99.003906    Top5 100.000000    
2024-01-15 20:06:32,785 - Epoch: [158][   24/   24]    Loss 0.028914    Top1 99.033333    Top5 100.000000    
2024-01-15 20:06:33,694 - ==> Top1: 99.033    Top5: 100.000    Loss: 0.029

2024-01-15 20:06:33,696 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 685   0   0   0   1   1   1   0   0]
 [  0   0 581   0   0   0   0   4   1   0]
 [  0   0   1 577   0   4   0   0   1   0]
 [  0   1   0   0 557   1   0   1   1   4]
 [  1   0   0   1   0 512   3   1   0   0]
 [  1   2   0   0   1   0 626   0   1   0]
 [  0   1   1   0   0   0   0 623   0   0]
 [  1   0   0   1   1   2   2   0 576   1]
 [  2   1   0   0   3   2   0   3   2 602]]

2024-01-15 20:06:33,700 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 20:06:33,701 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:06:33,711 - 

2024-01-15 20:06:33,711 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:06:45,069 - Epoch: [159][   10/  211]    Overall Loss 0.016674    Objective Loss 0.016674                                        LR 0.001000    Time 1.135641    
2024-01-15 20:06:52,408 - Epoch: [159][   20/  211]    Overall Loss 0.019784    Objective Loss 0.019784                                        LR 0.001000    Time 0.934682    
2024-01-15 20:06:58,646 - Epoch: [159][   30/  211]    Overall Loss 0.020514    Objective Loss 0.020514                                        LR 0.001000    Time 0.830956    
2024-01-15 20:07:04,750 - Epoch: [159][   40/  211]    Overall Loss 0.019419    Objective Loss 0.019419                                        LR 0.001000    Time 0.775792    
2024-01-15 20:07:11,448 - Epoch: [159][   50/  211]    Overall Loss 0.019849    Objective Loss 0.019849                                        LR 0.001000    Time 0.753837    
2024-01-15 20:07:17,417 - Epoch: [159][   60/  211]    Overall Loss 0.020585    Objective Loss 0.020585                                        LR 0.001000    Time 0.727645    
2024-01-15 20:07:23,221 - Epoch: [159][   70/  211]    Overall Loss 0.021308    Objective Loss 0.021308                                        LR 0.001000    Time 0.706596    
2024-01-15 20:07:30,188 - Epoch: [159][   80/  211]    Overall Loss 0.021297    Objective Loss 0.021297                                        LR 0.001000    Time 0.705343    
2024-01-15 20:07:36,127 - Epoch: [159][   90/  211]    Overall Loss 0.021495    Objective Loss 0.021495                                        LR 0.001000    Time 0.692948    
2024-01-15 20:07:43,138 - Epoch: [159][  100/  211]    Overall Loss 0.021506    Objective Loss 0.021506                                        LR 0.001000    Time 0.693728    
2024-01-15 20:07:48,922 - Epoch: [159][  110/  211]    Overall Loss 0.022077    Objective Loss 0.022077                                        LR 0.001000    Time 0.683234    
2024-01-15 20:07:56,047 - Epoch: [159][  120/  211]    Overall Loss 0.021681    Objective Loss 0.021681                                        LR 0.001000    Time 0.685658    
2024-01-15 20:08:02,731 - Epoch: [159][  130/  211]    Overall Loss 0.021587    Objective Loss 0.021587                                        LR 0.001000    Time 0.684316    
2024-01-15 20:08:09,836 - Epoch: [159][  140/  211]    Overall Loss 0.021431    Objective Loss 0.021431                                        LR 0.001000    Time 0.686169    
2024-01-15 20:08:16,250 - Epoch: [159][  150/  211]    Overall Loss 0.021520    Objective Loss 0.021520                                        LR 0.001000    Time 0.683155    
2024-01-15 20:08:23,001 - Epoch: [159][  160/  211]    Overall Loss 0.021853    Objective Loss 0.021853                                        LR 0.001000    Time 0.682644    
2024-01-15 20:08:30,580 - Epoch: [159][  170/  211]    Overall Loss 0.021933    Objective Loss 0.021933                                        LR 0.001000    Time 0.687055    
2024-01-15 20:08:37,726 - Epoch: [159][  180/  211]    Overall Loss 0.022072    Objective Loss 0.022072                                        LR 0.001000    Time 0.688576    
2024-01-15 20:08:44,929 - Epoch: [159][  190/  211]    Overall Loss 0.022242    Objective Loss 0.022242                                        LR 0.001000    Time 0.690214    
2024-01-15 20:08:51,957 - Epoch: [159][  200/  211]    Overall Loss 0.022365    Objective Loss 0.022365                                        LR 0.001000    Time 0.690828    
2024-01-15 20:08:58,361 - Epoch: [159][  210/  211]    Overall Loss 0.022207    Objective Loss 0.022207    Top1 99.218750    Top5 100.000000    LR 0.001000    Time 0.688418    
2024-01-15 20:08:59,051 - Epoch: [159][  211/  211]    Overall Loss 0.022302    Objective Loss 0.022302    Top1 99.395161    Top5 99.798387    LR 0.001000    Time 0.688416    
2024-01-15 20:09:00,562 - --- validate (epoch=159)-----------
2024-01-15 20:09:00,566 - 6000 samples (256 per mini-batch)
2024-01-15 20:09:07,925 - Epoch: [159][   10/   24]    Loss 0.030569    Top1 99.140625    Top5 100.000000    
2024-01-15 20:09:10,075 - Epoch: [159][   20/   24]    Loss 0.029404    Top1 99.101562    Top5 100.000000    
2024-01-15 20:09:10,883 - Epoch: [159][   24/   24]    Loss 0.027472    Top1 99.150000    Top5 100.000000    
2024-01-15 20:09:11,574 - ==> Top1: 99.150    Top5: 100.000    Loss: 0.027

2024-01-15 20:09:11,576 - ==> Confusion:
[[602   0   1   0   0   0   1   0   1   0]
 [  0 686   0   0   1   0   0   1   0   0]
 [  0   0 579   0   0   0   0   6   1   0]
 [  0   0   3 577   0   1   0   0   2   0]
 [  0   1   0   0 558   0   0   1   0   5]
 [  0   1   0   1   0 515   1   0   0   0]
 [  1   0   0   0   1   0 628   0   1   0]
 [  1   1   0   0   0   0   0 622   0   1]
 [  0   0   0   2   2   1   2   0 577   0]
 [  0   2   0   0   2   3   0   1   2 605]]

2024-01-15 20:09:11,578 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 20:09:11,579 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:09:11,584 - 

2024-01-15 20:09:11,585 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:09:22,452 - Epoch: [160][   10/  211]    Overall Loss 0.021672    Objective Loss 0.021672                                        LR 0.001000    Time 1.086655    
2024-01-15 20:09:29,428 - Epoch: [160][   20/  211]    Overall Loss 0.021310    Objective Loss 0.021310                                        LR 0.001000    Time 0.892053    
2024-01-15 20:09:35,985 - Epoch: [160][   30/  211]    Overall Loss 0.022530    Objective Loss 0.022530                                        LR 0.001000    Time 0.813197    
2024-01-15 20:09:42,697 - Epoch: [160][   40/  211]    Overall Loss 0.022988    Objective Loss 0.022988                                        LR 0.001000    Time 0.777657    
2024-01-15 20:09:49,121 - Epoch: [160][   50/  211]    Overall Loss 0.022485    Objective Loss 0.022485                                        LR 0.001000    Time 0.750586    
2024-01-15 20:09:55,901 - Epoch: [160][   60/  211]    Overall Loss 0.022397    Objective Loss 0.022397                                        LR 0.001000    Time 0.738476    
2024-01-15 20:10:02,574 - Epoch: [160][   70/  211]    Overall Loss 0.021722    Objective Loss 0.021722                                        LR 0.001000    Time 0.728282    
2024-01-15 20:10:08,987 - Epoch: [160][   80/  211]    Overall Loss 0.021534    Objective Loss 0.021534                                        LR 0.001000    Time 0.717380    
2024-01-15 20:10:15,014 - Epoch: [160][   90/  211]    Overall Loss 0.022489    Objective Loss 0.022489                                        LR 0.001000    Time 0.704625    
2024-01-15 20:10:22,416 - Epoch: [160][  100/  211]    Overall Loss 0.022064    Objective Loss 0.022064                                        LR 0.001000    Time 0.708143    
2024-01-15 20:10:28,654 - Epoch: [160][  110/  211]    Overall Loss 0.021917    Objective Loss 0.021917                                        LR 0.001000    Time 0.700453    
2024-01-15 20:10:35,165 - Epoch: [160][  120/  211]    Overall Loss 0.022241    Objective Loss 0.022241                                        LR 0.001000    Time 0.696329    
2024-01-15 20:10:42,218 - Epoch: [160][  130/  211]    Overall Loss 0.022331    Objective Loss 0.022331                                        LR 0.001000    Time 0.697000    
2024-01-15 20:10:49,510 - Epoch: [160][  140/  211]    Overall Loss 0.022427    Objective Loss 0.022427                                        LR 0.001000    Time 0.699296    
2024-01-15 20:10:55,477 - Epoch: [160][  150/  211]    Overall Loss 0.022790    Objective Loss 0.022790                                        LR 0.001000    Time 0.692444    
2024-01-15 20:11:01,541 - Epoch: [160][  160/  211]    Overall Loss 0.023327    Objective Loss 0.023327                                        LR 0.001000    Time 0.687056    
2024-01-15 20:11:08,500 - Epoch: [160][  170/  211]    Overall Loss 0.022914    Objective Loss 0.022914                                        LR 0.001000    Time 0.687567    
2024-01-15 20:11:15,237 - Epoch: [160][  180/  211]    Overall Loss 0.022481    Objective Loss 0.022481                                        LR 0.001000    Time 0.686778    
2024-01-15 20:11:21,217 - Epoch: [160][  190/  211]    Overall Loss 0.022195    Objective Loss 0.022195                                        LR 0.001000    Time 0.682096    
2024-01-15 20:11:27,107 - Epoch: [160][  200/  211]    Overall Loss 0.022352    Objective Loss 0.022352                                        LR 0.001000    Time 0.677436    
2024-01-15 20:11:33,455 - Epoch: [160][  210/  211]    Overall Loss 0.022550    Objective Loss 0.022550    Top1 99.609375    Top5 100.000000    LR 0.001000    Time 0.675397    
2024-01-15 20:11:34,116 - Epoch: [160][  211/  211]    Overall Loss 0.022543    Objective Loss 0.022543    Top1 99.596774    Top5 100.000000    LR 0.001000    Time 0.675327    
2024-01-15 20:11:35,735 - --- validate (epoch=160)-----------
2024-01-15 20:11:35,738 - 6000 samples (256 per mini-batch)
2024-01-15 20:11:43,256 - Epoch: [160][   10/   24]    Loss 0.032991    Top1 99.023438    Top5 100.000000    
2024-01-15 20:11:45,624 - Epoch: [160][   20/   24]    Loss 0.026564    Top1 99.101562    Top5 100.000000    
2024-01-15 20:11:46,411 - Epoch: [160][   24/   24]    Loss 0.027077    Top1 99.116667    Top5 100.000000    
2024-01-15 20:11:47,219 - ==> Top1: 99.117    Top5: 100.000    Loss: 0.027

2024-01-15 20:11:47,221 - ==> Confusion:
[[601   0   1   0   0   0   1   1   0   1]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 579   1   1   0   0   3   1   1]
 [  1   0   1 578   0   1   0   1   1   0]
 [  0   1   0   0 558   0   1   0   0   5]
 [  0   0   0   0   0 514   2   0   2   0]
 [  1   1   0   0   2   0 627   0   0   0]
 [  0   1   2   0   0   0   0 622   0   0]
 [  0   0   1   0   1   1   3   2 575   1]
 [  0   0   0   0   3   1   0   1   3 607]]

2024-01-15 20:11:47,223 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 138]
2024-01-15 20:11:47,224 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:11:47,229 - 

2024-01-15 20:11:47,230 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:11:58,666 - Epoch: [161][   10/  211]    Overall Loss 0.019863    Objective Loss 0.019863                                        LR 0.001000    Time 1.143515    
2024-01-15 20:12:04,746 - Epoch: [161][   20/  211]    Overall Loss 0.020771    Objective Loss 0.020771                                        LR 0.001000    Time 0.875701    
2024-01-15 20:12:11,269 - Epoch: [161][   30/  211]    Overall Loss 0.021386    Objective Loss 0.021386                                        LR 0.001000    Time 0.801190    
2024-01-15 20:12:17,291 - Epoch: [161][   40/  211]    Overall Loss 0.021018    Objective Loss 0.021018                                        LR 0.001000    Time 0.751427    
2024-01-15 20:12:24,383 - Epoch: [161][   50/  211]    Overall Loss 0.020885    Objective Loss 0.020885                                        LR 0.001000    Time 0.742955    
2024-01-15 20:12:31,629 - Epoch: [161][   60/  211]    Overall Loss 0.021237    Objective Loss 0.021237                                        LR 0.001000    Time 0.739865    
2024-01-15 20:12:37,881 - Epoch: [161][   70/  211]    Overall Loss 0.021330    Objective Loss 0.021330                                        LR 0.001000    Time 0.723471    
2024-01-15 20:12:44,199 - Epoch: [161][   80/  211]    Overall Loss 0.021597    Objective Loss 0.021597                                        LR 0.001000    Time 0.711987    
2024-01-15 20:12:50,760 - Epoch: [161][   90/  211]    Overall Loss 0.021936    Objective Loss 0.021936                                        LR 0.001000    Time 0.705768    
2024-01-15 20:12:57,341 - Epoch: [161][  100/  211]    Overall Loss 0.022295    Objective Loss 0.022295                                        LR 0.001000    Time 0.700986    
2024-01-15 20:13:03,624 - Epoch: [161][  110/  211]    Overall Loss 0.022311    Objective Loss 0.022311                                        LR 0.001000    Time 0.694359    
2024-01-15 20:13:09,957 - Epoch: [161][  120/  211]    Overall Loss 0.022221    Objective Loss 0.022221                                        LR 0.001000    Time 0.689262    
2024-01-15 20:13:16,259 - Epoch: [161][  130/  211]    Overall Loss 0.022146    Objective Loss 0.022146                                        LR 0.001000    Time 0.684703    
2024-01-15 20:13:22,768 - Epoch: [161][  140/  211]    Overall Loss 0.021758    Objective Loss 0.021758                                        LR 0.001000    Time 0.682279    
2024-01-15 20:13:30,096 - Epoch: [161][  150/  211]    Overall Loss 0.021938    Objective Loss 0.021938                                        LR 0.001000    Time 0.685633    
2024-01-15 20:13:36,922 - Epoch: [161][  160/  211]    Overall Loss 0.022035    Objective Loss 0.022035                                        LR 0.001000    Time 0.685434    
2024-01-15 20:13:43,410 - Epoch: [161][  170/  211]    Overall Loss 0.022274    Objective Loss 0.022274                                        LR 0.001000    Time 0.683267    
2024-01-15 20:13:49,519 - Epoch: [161][  180/  211]    Overall Loss 0.022003    Objective Loss 0.022003                                        LR 0.001000    Time 0.679237    
2024-01-15 20:13:56,062 - Epoch: [161][  190/  211]    Overall Loss 0.021855    Objective Loss 0.021855                                        LR 0.001000    Time 0.677915    
2024-01-15 20:14:02,220 - Epoch: [161][  200/  211]    Overall Loss 0.021766    Objective Loss 0.021766                                        LR 0.001000    Time 0.674796    
2024-01-15 20:14:08,783 - Epoch: [161][  210/  211]    Overall Loss 0.021883    Objective Loss 0.021883    Top1 98.828125    Top5 100.000000    LR 0.001000    Time 0.673912    
2024-01-15 20:14:09,393 - Epoch: [161][  211/  211]    Overall Loss 0.022027    Objective Loss 0.022027    Top1 98.790323    Top5 100.000000    LR 0.001000    Time 0.673600    
2024-01-15 20:14:10,293 - --- validate (epoch=161)-----------
2024-01-15 20:14:10,295 - 6000 samples (256 per mini-batch)
2024-01-15 20:14:18,232 - Epoch: [161][   10/   24]    Loss 0.032459    Top1 99.296875    Top5 100.000000    
2024-01-15 20:14:20,617 - Epoch: [161][   20/   24]    Loss 0.028352    Top1 99.257812    Top5 100.000000    
2024-01-15 20:14:21,435 - Epoch: [161][   24/   24]    Loss 0.025647    Top1 99.350000    Top5 100.000000    
2024-01-15 20:14:22,355 - ==> Top1: 99.350    Top5: 100.000    Loss: 0.026

2024-01-15 20:14:22,356 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 581   0   0   0   1   4   0   0]
 [  0   0   1 579   0   2   0   0   1   0]
 [  0   0   0   0 560   0   0   1   0   4]
 [  0   0   0   2   0 511   4   0   1   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   0   1   0   0   0   0 624   0   0]
 [  0   0   0   1   0   1   3   0 579   0]
 [  0   1   0   0   2   0   0   2   2 608]]

2024-01-15 20:14:22,359 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 161]
2024-01-15 20:14:22,359 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:14:22,368 - 

2024-01-15 20:14:22,369 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:14:33,177 - Epoch: [162][   10/  211]    Overall Loss 0.026811    Objective Loss 0.026811                                        LR 0.001000    Time 1.080704    
2024-01-15 20:14:39,255 - Epoch: [162][   20/  211]    Overall Loss 0.023342    Objective Loss 0.023342                                        LR 0.001000    Time 0.844152    
2024-01-15 20:14:45,884 - Epoch: [162][   30/  211]    Overall Loss 0.021959    Objective Loss 0.021959                                        LR 0.001000    Time 0.783678    
2024-01-15 20:14:52,239 - Epoch: [162][   40/  211]    Overall Loss 0.021069    Objective Loss 0.021069                                        LR 0.001000    Time 0.746602    
2024-01-15 20:14:58,723 - Epoch: [162][   50/  211]    Overall Loss 0.021076    Objective Loss 0.021076                                        LR 0.001000    Time 0.726924    
2024-01-15 20:15:05,435 - Epoch: [162][   60/  211]    Overall Loss 0.021325    Objective Loss 0.021325                                        LR 0.001000    Time 0.717600    
2024-01-15 20:15:12,364 - Epoch: [162][   70/  211]    Overall Loss 0.021628    Objective Loss 0.021628                                        LR 0.001000    Time 0.714056    
2024-01-15 20:15:18,636 - Epoch: [162][   80/  211]    Overall Loss 0.022035    Objective Loss 0.022035                                        LR 0.001000    Time 0.703168    
2024-01-15 20:15:25,227 - Epoch: [162][   90/  211]    Overall Loss 0.021611    Objective Loss 0.021611                                        LR 0.001000    Time 0.698255    
2024-01-15 20:15:31,881 - Epoch: [162][  100/  211]    Overall Loss 0.021276    Objective Loss 0.021276                                        LR 0.001000    Time 0.694958    
2024-01-15 20:15:38,203 - Epoch: [162][  110/  211]    Overall Loss 0.021129    Objective Loss 0.021129                                        LR 0.001000    Time 0.689228    
2024-01-15 20:15:44,781 - Epoch: [162][  120/  211]    Overall Loss 0.021687    Objective Loss 0.021687                                        LR 0.001000    Time 0.686596    
2024-01-15 20:15:50,972 - Epoch: [162][  130/  211]    Overall Loss 0.021479    Objective Loss 0.021479                                        LR 0.001000    Time 0.681391    
2024-01-15 20:15:57,327 - Epoch: [162][  140/  211]    Overall Loss 0.022073    Objective Loss 0.022073                                        LR 0.001000    Time 0.678103    
2024-01-15 20:16:03,643 - Epoch: [162][  150/  211]    Overall Loss 0.021980    Objective Loss 0.021980                                        LR 0.001000    Time 0.674988    
2024-01-15 20:16:10,188 - Epoch: [162][  160/  211]    Overall Loss 0.022141    Objective Loss 0.022141                                        LR 0.001000    Time 0.673704    
2024-01-15 20:16:16,082 - Epoch: [162][  170/  211]    Overall Loss 0.022383    Objective Loss 0.022383                                        LR 0.001000    Time 0.668733    
2024-01-15 20:16:23,012 - Epoch: [162][  180/  211]    Overall Loss 0.022202    Objective Loss 0.022202                                        LR 0.001000    Time 0.670076    
2024-01-15 20:16:29,871 - Epoch: [162][  190/  211]    Overall Loss 0.022348    Objective Loss 0.022348                                        LR 0.001000    Time 0.670900    
2024-01-15 20:16:36,856 - Epoch: [162][  200/  211]    Overall Loss 0.022337    Objective Loss 0.022337                                        LR 0.001000    Time 0.672273    
2024-01-15 20:16:43,503 - Epoch: [162][  210/  211]    Overall Loss 0.022352    Objective Loss 0.022352    Top1 99.218750    Top5 100.000000    LR 0.001000    Time 0.671906    
2024-01-15 20:16:44,263 - Epoch: [162][  211/  211]    Overall Loss 0.022299    Objective Loss 0.022299    Top1 99.596774    Top5 100.000000    LR 0.001000    Time 0.672316    
2024-01-15 20:16:45,827 - --- validate (epoch=162)-----------
2024-01-15 20:16:45,829 - 6000 samples (256 per mini-batch)
2024-01-15 20:16:54,382 - Epoch: [162][   10/   24]    Loss 0.026791    Top1 99.335938    Top5 100.000000    
2024-01-15 20:16:56,665 - Epoch: [162][   20/   24]    Loss 0.023892    Top1 99.355469    Top5 100.000000    
2024-01-15 20:16:57,460 - Epoch: [162][   24/   24]    Loss 0.024773    Top1 99.266667    Top5 100.000000    
2024-01-15 20:16:58,369 - ==> Top1: 99.267    Top5: 100.000    Loss: 0.025

2024-01-15 20:16:58,371 - ==> Confusion:
[[600   0   1   0   0   0   2   0   0   2]
 [  0 685   0   0   1   1   1   0   0   0]
 [  0   0 585   0   0   0   0   0   1   0]
 [  0   0   1 578   0   1   0   2   1   0]
 [  0   1   0   0 557   0   0   0   0   7]
 [  1   0   0   1   0 512   3   0   1   0]
 [  2   0   0   0   2   0 627   0   0   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  0   0   0   2   0   0   2   0 580   0]
 [  0   1   0   0   0   0   0   2   2 610]]

2024-01-15 20:16:58,374 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 161]
2024-01-15 20:16:58,374 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:16:58,380 - 

2024-01-15 20:16:58,380 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:17:09,759 - Epoch: [163][   10/  211]    Overall Loss 0.017374    Objective Loss 0.017374                                        LR 0.001000    Time 1.137710    
2024-01-15 20:17:16,155 - Epoch: [163][   20/  211]    Overall Loss 0.022280    Objective Loss 0.022280                                        LR 0.001000    Time 0.888208    
2024-01-15 20:17:22,614 - Epoch: [163][   30/  211]    Overall Loss 0.021910    Objective Loss 0.021910                                        LR 0.001000    Time 0.807414    
2024-01-15 20:17:29,271 - Epoch: [163][   40/  211]    Overall Loss 0.022916    Objective Loss 0.022916                                        LR 0.001000    Time 0.771947    
2024-01-15 20:17:35,628 - Epoch: [163][   50/  211]    Overall Loss 0.021968    Objective Loss 0.021968                                        LR 0.001000    Time 0.744658    
2024-01-15 20:17:41,941 - Epoch: [163][   60/  211]    Overall Loss 0.021224    Objective Loss 0.021224                                        LR 0.001000    Time 0.725751    
2024-01-15 20:17:49,092 - Epoch: [163][   70/  211]    Overall Loss 0.021626    Objective Loss 0.021626                                        LR 0.001000    Time 0.724188    
2024-01-15 20:17:55,366 - Epoch: [163][   80/  211]    Overall Loss 0.022340    Objective Loss 0.022340                                        LR 0.001000    Time 0.712041    
2024-01-15 20:18:01,540 - Epoch: [163][   90/  211]    Overall Loss 0.022122    Objective Loss 0.022122                                        LR 0.001000    Time 0.701506    
2024-01-15 20:18:07,966 - Epoch: [163][  100/  211]    Overall Loss 0.022076    Objective Loss 0.022076                                        LR 0.001000    Time 0.695597    
2024-01-15 20:18:14,626 - Epoch: [163][  110/  211]    Overall Loss 0.021837    Objective Loss 0.021837                                        LR 0.001000    Time 0.692894    
2024-01-15 20:18:20,879 - Epoch: [163][  120/  211]    Overall Loss 0.022030    Objective Loss 0.022030                                        LR 0.001000    Time 0.687252    
2024-01-15 20:18:26,847 - Epoch: [163][  130/  211]    Overall Loss 0.021725    Objective Loss 0.021725                                        LR 0.001000    Time 0.680281    
2024-01-15 20:18:33,613 - Epoch: [163][  140/  211]    Overall Loss 0.021695    Objective Loss 0.021695                                        LR 0.001000    Time 0.680008    
2024-01-15 20:18:39,610 - Epoch: [163][  150/  211]    Overall Loss 0.021579    Objective Loss 0.021579                                        LR 0.001000    Time 0.674628    
2024-01-15 20:18:46,174 - Epoch: [163][  160/  211]    Overall Loss 0.021767    Objective Loss 0.021767                                        LR 0.001000    Time 0.673456    
2024-01-15 20:18:52,467 - Epoch: [163][  170/  211]    Overall Loss 0.021406    Objective Loss 0.021406                                        LR 0.001000    Time 0.670848    
2024-01-15 20:18:59,081 - Epoch: [163][  180/  211]    Overall Loss 0.021672    Objective Loss 0.021672                                        LR 0.001000    Time 0.670314    
2024-01-15 20:19:05,536 - Epoch: [163][  190/  211]    Overall Loss 0.022301    Objective Loss 0.022301                                        LR 0.001000    Time 0.668999    
2024-01-15 20:19:11,967 - Epoch: [163][  200/  211]    Overall Loss 0.021917    Objective Loss 0.021917                                        LR 0.001000    Time 0.667695    
2024-01-15 20:19:18,261 - Epoch: [163][  210/  211]    Overall Loss 0.021742    Objective Loss 0.021742    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.665860    
2024-01-15 20:19:19,067 - Epoch: [163][  211/  211]    Overall Loss 0.021791    Objective Loss 0.021791    Top1 99.395161    Top5 100.000000    LR 0.001000    Time 0.666520    
2024-01-15 20:19:20,034 - --- validate (epoch=163)-----------
2024-01-15 20:19:20,035 - 6000 samples (256 per mini-batch)
2024-01-15 20:19:26,957 - Epoch: [163][   10/   24]    Loss 0.028628    Top1 99.414062    Top5 100.000000    
2024-01-15 20:19:29,145 - Epoch: [163][   20/   24]    Loss 0.024165    Top1 99.394531    Top5 100.000000    
2024-01-15 20:19:29,895 - Epoch: [163][   24/   24]    Loss 0.024893    Top1 99.300000    Top5 100.000000    
2024-01-15 20:19:30,622 - ==> Top1: 99.300    Top5: 100.000    Loss: 0.025

2024-01-15 20:19:30,622 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 687   0   0   0   1   0   0   0   0]
 [  0   1 584   1   0   0   0   0   0   0]
 [  0   0   1 578   0   2   0   0   2   0]
 [  0   0   0   0 558   0   2   0   0   5]
 [  0   0   0   1   0 514   3   0   0   0]
 [  2   2   0   0   1   0 625   0   1   0]
 [  0   3   1   0   0   0   0 621   0   0]
 [  0   1   0   1   1   1   1   0 579   0]
 [  0   1   0   0   1   0   0   3   2 608]]

2024-01-15 20:19:30,624 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 161]
2024-01-15 20:19:30,624 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:19:30,628 - 

2024-01-15 20:19:30,628 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:19:40,086 - Epoch: [164][   10/  211]    Overall Loss 0.016728    Objective Loss 0.016728                                        LR 0.001000    Time 0.945707    
2024-01-15 20:19:46,572 - Epoch: [164][   20/  211]    Overall Loss 0.015667    Objective Loss 0.015667                                        LR 0.001000    Time 0.797071    
2024-01-15 20:19:53,183 - Epoch: [164][   30/  211]    Overall Loss 0.020585    Objective Loss 0.020585                                        LR 0.001000    Time 0.751670    
2024-01-15 20:19:59,152 - Epoch: [164][   40/  211]    Overall Loss 0.021034    Objective Loss 0.021034                                        LR 0.001000    Time 0.712931    
2024-01-15 20:20:04,874 - Epoch: [164][   50/  211]    Overall Loss 0.021816    Objective Loss 0.021816                                        LR 0.001000    Time 0.684784    
2024-01-15 20:20:10,515 - Epoch: [164][   60/  211]    Overall Loss 0.021599    Objective Loss 0.021599                                        LR 0.001000    Time 0.664645    
2024-01-15 20:20:16,146 - Epoch: [164][   70/  211]    Overall Loss 0.020861    Objective Loss 0.020861                                        LR 0.001000    Time 0.650138    
2024-01-15 20:20:21,823 - Epoch: [164][   80/  211]    Overall Loss 0.020970    Objective Loss 0.020970                                        LR 0.001000    Time 0.639822    
2024-01-15 20:20:27,523 - Epoch: [164][   90/  211]    Overall Loss 0.021637    Objective Loss 0.021637                                        LR 0.001000    Time 0.632056    
2024-01-15 20:20:33,428 - Epoch: [164][  100/  211]    Overall Loss 0.021246    Objective Loss 0.021246                                        LR 0.001000    Time 0.627887    
2024-01-15 20:20:39,081 - Epoch: [164][  110/  211]    Overall Loss 0.020984    Objective Loss 0.020984                                        LR 0.001000    Time 0.622192    
2024-01-15 20:20:44,718 - Epoch: [164][  120/  211]    Overall Loss 0.020762    Objective Loss 0.020762                                        LR 0.001000    Time 0.617311    
2024-01-15 20:20:50,369 - Epoch: [164][  130/  211]    Overall Loss 0.020869    Objective Loss 0.020869                                        LR 0.001000    Time 0.613293    
2024-01-15 20:20:56,517 - Epoch: [164][  140/  211]    Overall Loss 0.021207    Objective Loss 0.021207                                        LR 0.001000    Time 0.613396    
2024-01-15 20:21:03,250 - Epoch: [164][  150/  211]    Overall Loss 0.021471    Objective Loss 0.021471                                        LR 0.001000    Time 0.617376    
2024-01-15 20:21:09,752 - Epoch: [164][  160/  211]    Overall Loss 0.021935    Objective Loss 0.021935                                        LR 0.001000    Time 0.619417    
2024-01-15 20:21:16,160 - Epoch: [164][  170/  211]    Overall Loss 0.022170    Objective Loss 0.022170                                        LR 0.001000    Time 0.620665    
2024-01-15 20:21:22,743 - Epoch: [164][  180/  211]    Overall Loss 0.021850    Objective Loss 0.021850                                        LR 0.001000    Time 0.622742    
2024-01-15 20:21:29,364 - Epoch: [164][  190/  211]    Overall Loss 0.021848    Objective Loss 0.021848                                        LR 0.001000    Time 0.624805    
2024-01-15 20:21:36,039 - Epoch: [164][  200/  211]    Overall Loss 0.021897    Objective Loss 0.021897                                        LR 0.001000    Time 0.626923    
2024-01-15 20:21:42,461 - Epoch: [164][  210/  211]    Overall Loss 0.022137    Objective Loss 0.022137    Top1 98.828125    Top5 100.000000    LR 0.001000    Time 0.627644    
2024-01-15 20:21:43,180 - Epoch: [164][  211/  211]    Overall Loss 0.022098    Objective Loss 0.022098    Top1 99.193548    Top5 100.000000    LR 0.001000    Time 0.628071    
2024-01-15 20:21:44,018 - --- validate (epoch=164)-----------
2024-01-15 20:21:44,020 - 6000 samples (256 per mini-batch)
2024-01-15 20:21:51,766 - Epoch: [164][   10/   24]    Loss 0.029161    Top1 99.023438    Top5 100.000000    
2024-01-15 20:21:54,052 - Epoch: [164][   20/   24]    Loss 0.029160    Top1 99.179688    Top5 100.000000    
2024-01-15 20:21:55,026 - Epoch: [164][   24/   24]    Loss 0.029130    Top1 99.133333    Top5 100.000000    
2024-01-15 20:21:55,953 - ==> Top1: 99.133    Top5: 100.000    Loss: 0.029

2024-01-15 20:21:55,954 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 683   1   0   0   1   0   3   0   0]
 [  0   0 580   1   0   0   0   4   1   0]
 [  0   1   1 579   0   1   0   0   1   0]
 [  0   1   0   0 560   0   0   1   0   3]
 [  1   0   0   1   0 512   3   0   1   0]
 [  1   0   0   0   1   1 628   0   0   0]
 [  0   3   0   0   0   0   0 622   0   0]
 [  0   0   1   1   0   0   3   0 578   1]
 [  0   1   0   1   4   1   0   3   2 603]]

2024-01-15 20:21:55,957 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 161]
2024-01-15 20:21:55,957 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:21:55,962 - 

2024-01-15 20:21:55,962 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:22:06,189 - Epoch: [165][   10/  211]    Overall Loss 0.018770    Objective Loss 0.018770                                        LR 0.001000    Time 1.022482    
2024-01-15 20:22:12,362 - Epoch: [165][   20/  211]    Overall Loss 0.021079    Objective Loss 0.021079                                        LR 0.001000    Time 0.819826    
2024-01-15 20:22:19,009 - Epoch: [165][   30/  211]    Overall Loss 0.020667    Objective Loss 0.020667                                        LR 0.001000    Time 0.768082    
2024-01-15 20:22:25,786 - Epoch: [165][   40/  211]    Overall Loss 0.022146    Objective Loss 0.022146                                        LR 0.001000    Time 0.745458    
2024-01-15 20:22:32,693 - Epoch: [165][   50/  211]    Overall Loss 0.022408    Objective Loss 0.022408                                        LR 0.001000    Time 0.734459    
2024-01-15 20:22:39,008 - Epoch: [165][   60/  211]    Overall Loss 0.022205    Objective Loss 0.022205                                        LR 0.001000    Time 0.717270    
2024-01-15 20:22:44,845 - Epoch: [165][   70/  211]    Overall Loss 0.022108    Objective Loss 0.022108                                        LR 0.001000    Time 0.698169    
2024-01-15 20:22:51,781 - Epoch: [165][   80/  211]    Overall Loss 0.021771    Objective Loss 0.021771                                        LR 0.001000    Time 0.697578    
2024-01-15 20:22:58,051 - Epoch: [165][   90/  211]    Overall Loss 0.021834    Objective Loss 0.021834                                        LR 0.001000    Time 0.689707    
2024-01-15 20:23:04,300 - Epoch: [165][  100/  211]    Overall Loss 0.021595    Objective Loss 0.021595                                        LR 0.001000    Time 0.683189    
2024-01-15 20:23:10,638 - Epoch: [165][  110/  211]    Overall Loss 0.021553    Objective Loss 0.021553                                        LR 0.001000    Time 0.678693    
2024-01-15 20:23:16,814 - Epoch: [165][  120/  211]    Overall Loss 0.021557    Objective Loss 0.021557                                        LR 0.001000    Time 0.673589    
2024-01-15 20:23:23,311 - Epoch: [165][  130/  211]    Overall Loss 0.021241    Objective Loss 0.021241                                        LR 0.001000    Time 0.671738    
2024-01-15 20:23:30,148 - Epoch: [165][  140/  211]    Overall Loss 0.021795    Objective Loss 0.021795                                        LR 0.001000    Time 0.672576    
2024-01-15 20:23:36,088 - Epoch: [165][  150/  211]    Overall Loss 0.021909    Objective Loss 0.021909                                        LR 0.001000    Time 0.667326    
2024-01-15 20:23:41,899 - Epoch: [165][  160/  211]    Overall Loss 0.021838    Objective Loss 0.021838                                        LR 0.001000    Time 0.661935    
2024-01-15 20:23:47,549 - Epoch: [165][  170/  211]    Overall Loss 0.021941    Objective Loss 0.021941                                        LR 0.001000    Time 0.656229    
2024-01-15 20:23:53,182 - Epoch: [165][  180/  211]    Overall Loss 0.022106    Objective Loss 0.022106                                        LR 0.001000    Time 0.651059    
2024-01-15 20:23:58,823 - Epoch: [165][  190/  211]    Overall Loss 0.022018    Objective Loss 0.022018                                        LR 0.001000    Time 0.646478    
2024-01-15 20:24:04,459 - Epoch: [165][  200/  211]    Overall Loss 0.021772    Objective Loss 0.021772                                        LR 0.001000    Time 0.642334    
2024-01-15 20:24:10,154 - Epoch: [165][  210/  211]    Overall Loss 0.021772    Objective Loss 0.021772    Top1 99.609375    Top5 100.000000    LR 0.001000    Time 0.638860    
2024-01-15 20:24:10,722 - Epoch: [165][  211/  211]    Overall Loss 0.021786    Objective Loss 0.021786    Top1 99.395161    Top5 100.000000    LR 0.001000    Time 0.638522    
2024-01-15 20:24:11,558 - --- validate (epoch=165)-----------
2024-01-15 20:24:11,559 - 6000 samples (256 per mini-batch)
2024-01-15 20:24:18,537 - Epoch: [165][   10/   24]    Loss 0.037942    Top1 99.023438    Top5 100.000000    
2024-01-15 20:24:20,652 - Epoch: [165][   20/   24]    Loss 0.031567    Top1 99.238281    Top5 100.000000    
2024-01-15 20:24:21,399 - Epoch: [165][   24/   24]    Loss 0.032109    Top1 99.266667    Top5 100.000000    
2024-01-15 20:24:22,103 - ==> Top1: 99.267    Top5: 100.000    Loss: 0.032

2024-01-15 20:24:22,104 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 583   1   0   0   0   2   0   0]
 [  0   0   1 579   0   1   0   0   2   0]
 [  0   0   1   0 554   0   1   2   0   7]
 [  0   0   0   1   2 511   3   0   1   0]
 [  0   1   0   0   2   0 628   0   0   0]
 [  0   0   0   0   0   0   0 625   0   0]
 [  0   0   0   1   0   2   2   0 578   1]
 [  1   1   0   0   3   0   0   0   2 608]]

2024-01-15 20:24:22,106 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 161]
2024-01-15 20:24:22,106 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:24:22,110 - 

2024-01-15 20:24:22,110 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:24:31,344 - Epoch: [166][   10/  211]    Overall Loss 0.018722    Objective Loss 0.018722                                        LR 0.001000    Time 0.923306    
2024-01-15 20:24:37,025 - Epoch: [166][   20/  211]    Overall Loss 0.019044    Objective Loss 0.019044                                        LR 0.001000    Time 0.745630    
2024-01-15 20:24:42,733 - Epoch: [166][   30/  211]    Overall Loss 0.020325    Objective Loss 0.020325                                        LR 0.001000    Time 0.687335    
2024-01-15 20:24:48,375 - Epoch: [166][   40/  211]    Overall Loss 0.020248    Objective Loss 0.020248                                        LR 0.001000    Time 0.656496    
2024-01-15 20:24:54,016 - Epoch: [166][   50/  211]    Overall Loss 0.019421    Objective Loss 0.019421                                        LR 0.001000    Time 0.638012    
2024-01-15 20:24:59,645 - Epoch: [166][   60/  211]    Overall Loss 0.019873    Objective Loss 0.019873                                        LR 0.001000    Time 0.625468    
2024-01-15 20:25:05,505 - Epoch: [166][   70/  211]    Overall Loss 0.020835    Objective Loss 0.020835                                        LR 0.001000    Time 0.619807    
2024-01-15 20:25:11,157 - Epoch: [166][   80/  211]    Overall Loss 0.021819    Objective Loss 0.021819                                        LR 0.001000    Time 0.612961    
2024-01-15 20:25:16,857 - Epoch: [166][   90/  211]    Overall Loss 0.021885    Objective Loss 0.021885                                        LR 0.001000    Time 0.608185    
2024-01-15 20:25:22,532 - Epoch: [166][  100/  211]    Overall Loss 0.022609    Objective Loss 0.022609                                        LR 0.001000    Time 0.604111    
2024-01-15 20:25:28,331 - Epoch: [166][  110/  211]    Overall Loss 0.022087    Objective Loss 0.022087                                        LR 0.001000    Time 0.601873    
2024-01-15 20:25:34,094 - Epoch: [166][  120/  211]    Overall Loss 0.022471    Objective Loss 0.022471                                        LR 0.001000    Time 0.599730    
2024-01-15 20:25:39,735 - Epoch: [166][  130/  211]    Overall Loss 0.022424    Objective Loss 0.022424                                        LR 0.001000    Time 0.596979    
2024-01-15 20:25:46,047 - Epoch: [166][  140/  211]    Overall Loss 0.022400    Objective Loss 0.022400                                        LR 0.001000    Time 0.599413    
2024-01-15 20:25:51,683 - Epoch: [166][  150/  211]    Overall Loss 0.022469    Objective Loss 0.022469                                        LR 0.001000    Time 0.597017    
2024-01-15 20:25:57,372 - Epoch: [166][  160/  211]    Overall Loss 0.022468    Objective Loss 0.022468                                        LR 0.001000    Time 0.595262    
2024-01-15 20:26:03,031 - Epoch: [166][  170/  211]    Overall Loss 0.022488    Objective Loss 0.022488                                        LR 0.001000    Time 0.593528    
2024-01-15 20:26:08,682 - Epoch: [166][  180/  211]    Overall Loss 0.022643    Objective Loss 0.022643                                        LR 0.001000    Time 0.591943    
2024-01-15 20:26:14,318 - Epoch: [166][  190/  211]    Overall Loss 0.022356    Objective Loss 0.022356                                        LR 0.001000    Time 0.590449    
2024-01-15 20:26:19,961 - Epoch: [166][  200/  211]    Overall Loss 0.022684    Objective Loss 0.022684                                        LR 0.001000    Time 0.589140    
2024-01-15 20:26:25,615 - Epoch: [166][  210/  211]    Overall Loss 0.022385    Objective Loss 0.022385    Top1 98.046875    Top5 100.000000    LR 0.001000    Time 0.588006    
2024-01-15 20:26:26,227 - Epoch: [166][  211/  211]    Overall Loss 0.022327    Objective Loss 0.022327    Top1 98.991935    Top5 100.000000    LR 0.001000    Time 0.588116    
2024-01-15 20:26:27,039 - --- validate (epoch=166)-----------
2024-01-15 20:26:27,039 - 6000 samples (256 per mini-batch)
2024-01-15 20:26:33,385 - Epoch: [166][   10/   24]    Loss 0.019797    Top1 99.492188    Top5 100.000000    
2024-01-15 20:26:35,499 - Epoch: [166][   20/   24]    Loss 0.021384    Top1 99.394531    Top5 100.000000    
2024-01-15 20:26:36,242 - Epoch: [166][   24/   24]    Loss 0.023757    Top1 99.283333    Top5 100.000000    
2024-01-15 20:26:36,797 - ==> Top1: 99.283    Top5: 100.000    Loss: 0.024

2024-01-15 20:26:36,798 - ==> Confusion:
[[601   0   0   0   0   0   1   1   1   1]
 [  0 685   0   0   1   0   0   2   0   0]
 [  0   0 582   1   0   0   1   2   0   0]
 [  0   0   0 580   0   1   0   0   2   0]
 [  0   0   0   0 559   0   0   1   0   5]
 [  0   1   0   2   0 512   1   0   2   0]
 [  0   2   0   0   2   0 627   0   0   0]
 [  0   2   2   0   0   0   0 621   0   0]
 [  0   0   1   0   0   0   1   0 581   1]
 [  1   1   0   0   0   0   0   2   2 609]]

2024-01-15 20:26:36,800 - ==> Best [Top1: 99.350   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 161]
2024-01-15 20:26:36,800 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:26:36,804 - 

2024-01-15 20:26:36,805 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:26:44,973 - Epoch: [167][   10/  211]    Overall Loss 0.024305    Objective Loss 0.024305                                        LR 0.001000    Time 0.816798    
2024-01-15 20:26:50,751 - Epoch: [167][   20/  211]    Overall Loss 0.023219    Objective Loss 0.023219                                        LR 0.001000    Time 0.697188    
2024-01-15 20:26:56,556 - Epoch: [167][   30/  211]    Overall Loss 0.023513    Objective Loss 0.023513                                        LR 0.001000    Time 0.658218    
2024-01-15 20:27:02,216 - Epoch: [167][   40/  211]    Overall Loss 0.024457    Objective Loss 0.024457                                        LR 0.001000    Time 0.635149    
2024-01-15 20:27:07,881 - Epoch: [167][   50/  211]    Overall Loss 0.024870    Objective Loss 0.024870                                        LR 0.001000    Time 0.621404    
2024-01-15 20:27:13,516 - Epoch: [167][   60/  211]    Overall Loss 0.024491    Objective Loss 0.024491                                        LR 0.001000    Time 0.611734    
2024-01-15 20:27:19,141 - Epoch: [167][   70/  211]    Overall Loss 0.023124    Objective Loss 0.023124                                        LR 0.001000    Time 0.604691    
2024-01-15 20:27:24,888 - Epoch: [167][   80/  211]    Overall Loss 0.023537    Objective Loss 0.023537                                        LR 0.001000    Time 0.600932    
2024-01-15 20:27:30,633 - Epoch: [167][   90/  211]    Overall Loss 0.024294    Objective Loss 0.024294                                        LR 0.001000    Time 0.597983    
2024-01-15 20:27:36,268 - Epoch: [167][  100/  211]    Overall Loss 0.024072    Objective Loss 0.024072                                        LR 0.001000    Time 0.594524    
2024-01-15 20:27:41,890 - Epoch: [167][  110/  211]    Overall Loss 0.023989    Objective Loss 0.023989                                        LR 0.001000    Time 0.591582    
2024-01-15 20:27:47,529 - Epoch: [167][  120/  211]    Overall Loss 0.023801    Objective Loss 0.023801                                        LR 0.001000    Time 0.589266    
2024-01-15 20:27:53,156 - Epoch: [167][  130/  211]    Overall Loss 0.023817    Objective Loss 0.023817                                        LR 0.001000    Time 0.587216    
2024-01-15 20:27:58,792 - Epoch: [167][  140/  211]    Overall Loss 0.023644    Objective Loss 0.023644                                        LR 0.001000    Time 0.585512    
2024-01-15 20:28:04,430 - Epoch: [167][  150/  211]    Overall Loss 0.023529    Objective Loss 0.023529                                        LR 0.001000    Time 0.584061    
2024-01-15 20:28:10,076 - Epoch: [167][  160/  211]    Overall Loss 0.023583    Objective Loss 0.023583                                        LR 0.001000    Time 0.582840    
2024-01-15 20:28:15,704 - Epoch: [167][  170/  211]    Overall Loss 0.023027    Objective Loss 0.023027                                        LR 0.001000    Time 0.581655    
2024-01-15 20:28:21,339 - Epoch: [167][  180/  211]    Overall Loss 0.023049    Objective Loss 0.023049                                        LR 0.001000    Time 0.580645    
2024-01-15 20:28:27,117 - Epoch: [167][  190/  211]    Overall Loss 0.022881    Objective Loss 0.022881                                        LR 0.001000    Time 0.580492    
2024-01-15 20:28:32,972 - Epoch: [167][  200/  211]    Overall Loss 0.022931    Objective Loss 0.022931                                        LR 0.001000    Time 0.580736    
2024-01-15 20:28:38,607 - Epoch: [167][  210/  211]    Overall Loss 0.022689    Objective Loss 0.022689    Top1 100.000000    Top5 100.000000    LR 0.001000    Time 0.579909    
2024-01-15 20:28:39,185 - Epoch: [167][  211/  211]    Overall Loss 0.022684    Objective Loss 0.022684    Top1 99.798387    Top5 100.000000    LR 0.001000    Time 0.579900    
2024-01-15 20:28:39,753 - --- validate (epoch=167)-----------
2024-01-15 20:28:39,754 - 6000 samples (256 per mini-batch)
2024-01-15 20:28:44,973 - Epoch: [167][   10/   24]    Loss 0.022124    Top1 99.492188    Top5 99.960938    
2024-01-15 20:28:47,093 - Epoch: [167][   20/   24]    Loss 0.026250    Top1 99.355469    Top5 99.980469    
2024-01-15 20:28:47,845 - Epoch: [167][   24/   24]    Loss 0.024707    Top1 99.383333    Top5 99.983333    
2024-01-15 20:28:48,385 - ==> Top1: 99.383    Top5: 99.983    Loss: 0.025

2024-01-15 20:28:48,386 - ==> Confusion:
[[603   0   0   0   0   0   1   0   0   1]
 [  0 685   0   0   0   1   1   1   0   0]
 [  0   0 585   0   0   0   0   1   0   0]
 [  1   0   1 579   0   1   0   0   1   0]
 [  0   0   0   0 561   0   1   0   0   3]
 [  0   1   0   2   0 514   1   0   0   0]
 [  0   1   0   0   1   1 628   0   0   0]
 [  1   2   0   1   0   0   0 621   0   0]
 [  0   0   0   0   0   2   1   0 580   1]
 [  0   0   0   0   2   1   0   2   3 607]]

2024-01-15 20:28:48,388 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:28:48,388 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:28:48,399 - 

2024-01-15 20:28:48,399 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:28:56,613 - Epoch: [168][   10/  211]    Overall Loss 0.016813    Objective Loss 0.016813                                        LR 0.001000    Time 0.821333    
2024-01-15 20:29:02,251 - Epoch: [168][   20/  211]    Overall Loss 0.017246    Objective Loss 0.017246                                        LR 0.001000    Time 0.692506    
2024-01-15 20:29:07,894 - Epoch: [168][   30/  211]    Overall Loss 0.020495    Objective Loss 0.020495                                        LR 0.001000    Time 0.649769    
2024-01-15 20:29:14,979 - Epoch: [168][   40/  211]    Overall Loss 0.021776    Objective Loss 0.021776                                        LR 0.001000    Time 0.664342    
2024-01-15 20:29:22,420 - Epoch: [168][   50/  211]    Overall Loss 0.021799    Objective Loss 0.021799                                        LR 0.001000    Time 0.680091    
2024-01-15 20:29:29,673 - Epoch: [168][   60/  211]    Overall Loss 0.021710    Objective Loss 0.021710                                        LR 0.001000    Time 0.687507    
2024-01-15 20:29:35,436 - Epoch: [168][   70/  211]    Overall Loss 0.022194    Objective Loss 0.022194                                        LR 0.001000    Time 0.671610    
2024-01-15 20:29:41,318 - Epoch: [168][   80/  211]    Overall Loss 0.022268    Objective Loss 0.022268                                        LR 0.001000    Time 0.661173    
2024-01-15 20:29:47,237 - Epoch: [168][   90/  211]    Overall Loss 0.022504    Objective Loss 0.022504                                        LR 0.001000    Time 0.653460    
2024-01-15 20:29:53,034 - Epoch: [168][  100/  211]    Overall Loss 0.022614    Objective Loss 0.022614                                        LR 0.001000    Time 0.646065    
2024-01-15 20:29:58,797 - Epoch: [168][  110/  211]    Overall Loss 0.022058    Objective Loss 0.022058                                        LR 0.001000    Time 0.639720    
2024-01-15 20:30:04,638 - Epoch: [168][  120/  211]    Overall Loss 0.021771    Objective Loss 0.021771                                        LR 0.001000    Time 0.635072    
2024-01-15 20:30:10,463 - Epoch: [168][  130/  211]    Overall Loss 0.021895    Objective Loss 0.021895                                        LR 0.001000    Time 0.631018    
2024-01-15 20:30:16,161 - Epoch: [168][  140/  211]    Overall Loss 0.021815    Objective Loss 0.021815                                        LR 0.001000    Time 0.626638    
2024-01-15 20:30:21,973 - Epoch: [168][  150/  211]    Overall Loss 0.021567    Objective Loss 0.021567                                        LR 0.001000    Time 0.623599    
2024-01-15 20:30:28,002 - Epoch: [168][  160/  211]    Overall Loss 0.021725    Objective Loss 0.021725                                        LR 0.001000    Time 0.622302    
2024-01-15 20:30:34,073 - Epoch: [168][  170/  211]    Overall Loss 0.021614    Objective Loss 0.021614                                        LR 0.001000    Time 0.621397    
2024-01-15 20:30:39,778 - Epoch: [168][  180/  211]    Overall Loss 0.021606    Objective Loss 0.021606                                        LR 0.001000    Time 0.618566    
2024-01-15 20:30:45,582 - Epoch: [168][  190/  211]    Overall Loss 0.021739    Objective Loss 0.021739                                        LR 0.001000    Time 0.616552    
2024-01-15 20:30:51,292 - Epoch: [168][  200/  211]    Overall Loss 0.021508    Objective Loss 0.021508                                        LR 0.001000    Time 0.614266    
2024-01-15 20:30:57,036 - Epoch: [168][  210/  211]    Overall Loss 0.021747    Objective Loss 0.021747    Top1 98.437500    Top5 100.000000    LR 0.001000    Time 0.612364    
2024-01-15 20:30:57,695 - Epoch: [168][  211/  211]    Overall Loss 0.021749    Objective Loss 0.021749    Top1 98.991935    Top5 100.000000    LR 0.001000    Time 0.612580    
2024-01-15 20:30:58,569 - --- validate (epoch=168)-----------
2024-01-15 20:30:58,571 - 6000 samples (256 per mini-batch)
2024-01-15 20:31:05,404 - Epoch: [168][   10/   24]    Loss 0.031371    Top1 99.179688    Top5 100.000000    
2024-01-15 20:31:07,547 - Epoch: [168][   20/   24]    Loss 0.029175    Top1 99.179688    Top5 100.000000    
2024-01-15 20:31:08,296 - Epoch: [168][   24/   24]    Loss 0.029848    Top1 99.166667    Top5 100.000000    
2024-01-15 20:31:09,044 - ==> Top1: 99.167    Top5: 100.000    Loss: 0.030

2024-01-15 20:31:09,046 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 684   2   0   0   0   1   1   0   0]
 [  0   0 583   1   0   0   0   2   0   0]
 [  0   1   2 578   0   1   0   0   1   0]
 [  0   0   0   0 555   0   0   2   1   7]
 [  0   0   0   1   0 514   3   0   0   0]
 [  1   0   0   0   2   0 627   0   0   1]
 [  0   0   2   0   0   0   0 623   0   0]
 [  2   0   0   1   1   0   2   0 578   0]
 [  0   1   0   0   3   0   0   2   3 606]]

2024-01-15 20:31:09,048 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:31:09,048 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:31:09,052 - 

2024-01-15 20:31:09,053 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:31:18,434 - Epoch: [169][   10/  211]    Overall Loss 0.023191    Objective Loss 0.023191                                        LR 0.001000    Time 0.938026    
2024-01-15 20:31:24,107 - Epoch: [169][   20/  211]    Overall Loss 0.022560    Objective Loss 0.022560                                        LR 0.001000    Time 0.752598    
2024-01-15 20:31:30,051 - Epoch: [169][   30/  211]    Overall Loss 0.023577    Objective Loss 0.023577                                        LR 0.001000    Time 0.699822    
2024-01-15 20:31:35,867 - Epoch: [169][   40/  211]    Overall Loss 0.024059    Objective Loss 0.024059                                        LR 0.001000    Time 0.670248    
2024-01-15 20:31:41,548 - Epoch: [169][   50/  211]    Overall Loss 0.022381    Objective Loss 0.022381                                        LR 0.001000    Time 0.649808    
2024-01-15 20:31:47,342 - Epoch: [169][   60/  211]    Overall Loss 0.022808    Objective Loss 0.022808                                        LR 0.001000    Time 0.638055    
2024-01-15 20:31:52,996 - Epoch: [169][   70/  211]    Overall Loss 0.022461    Objective Loss 0.022461                                        LR 0.001000    Time 0.627671    
2024-01-15 20:31:58,655 - Epoch: [169][   80/  211]    Overall Loss 0.022014    Objective Loss 0.022014                                        LR 0.001000    Time 0.619941    
2024-01-15 20:32:04,311 - Epoch: [169][   90/  211]    Overall Loss 0.021648    Objective Loss 0.021648                                        LR 0.001000    Time 0.613883    
2024-01-15 20:32:10,176 - Epoch: [169][  100/  211]    Overall Loss 0.022136    Objective Loss 0.022136                                        LR 0.001000    Time 0.611145    
2024-01-15 20:32:15,828 - Epoch: [169][  110/  211]    Overall Loss 0.021930    Objective Loss 0.021930                                        LR 0.001000    Time 0.606954    
2024-01-15 20:32:21,482 - Epoch: [169][  120/  211]    Overall Loss 0.021742    Objective Loss 0.021742                                        LR 0.001000    Time 0.603490    
2024-01-15 20:32:27,319 - Epoch: [169][  130/  211]    Overall Loss 0.021689    Objective Loss 0.021689                                        LR 0.001000    Time 0.601953    
2024-01-15 20:32:33,341 - Epoch: [169][  140/  211]    Overall Loss 0.021880    Objective Loss 0.021880                                        LR 0.001000    Time 0.601960    
2024-01-15 20:32:39,060 - Epoch: [169][  150/  211]    Overall Loss 0.021850    Objective Loss 0.021850                                        LR 0.001000    Time 0.599951    
2024-01-15 20:32:44,819 - Epoch: [169][  160/  211]    Overall Loss 0.021770    Objective Loss 0.021770                                        LR 0.001000    Time 0.598436    
2024-01-15 20:32:50,582 - Epoch: [169][  170/  211]    Overall Loss 0.021861    Objective Loss 0.021861                                        LR 0.001000    Time 0.597129    
2024-01-15 20:32:56,479 - Epoch: [169][  180/  211]    Overall Loss 0.021890    Objective Loss 0.021890                                        LR 0.001000    Time 0.596712    
2024-01-15 20:33:02,146 - Epoch: [169][  190/  211]    Overall Loss 0.022065    Objective Loss 0.022065                                        LR 0.001000    Time 0.595121    
2024-01-15 20:33:07,805 - Epoch: [169][  200/  211]    Overall Loss 0.022332    Objective Loss 0.022332                                        LR 0.001000    Time 0.593654    
2024-01-15 20:33:13,575 - Epoch: [169][  210/  211]    Overall Loss 0.022156    Objective Loss 0.022156    Top1 99.609375    Top5 100.000000    LR 0.001000    Time 0.592855    
2024-01-15 20:33:14,138 - Epoch: [169][  211/  211]    Overall Loss 0.022141    Objective Loss 0.022141    Top1 99.596774    Top5 100.000000    LR 0.001000    Time 0.592713    
2024-01-15 20:33:14,935 - --- validate (epoch=169)-----------
2024-01-15 20:33:14,936 - 6000 samples (256 per mini-batch)
2024-01-15 20:33:20,909 - Epoch: [169][   10/   24]    Loss 0.027253    Top1 99.296875    Top5 100.000000    
2024-01-15 20:33:23,058 - Epoch: [169][   20/   24]    Loss 0.027547    Top1 99.257812    Top5 99.980469    
2024-01-15 20:33:23,840 - Epoch: [169][   24/   24]    Loss 0.027490    Top1 99.166667    Top5 99.983333    
2024-01-15 20:33:24,629 - ==> Top1: 99.167    Top5: 99.983    Loss: 0.027

2024-01-15 20:33:24,630 - ==> Confusion:
[[603   0   2   0   0   0   0   0   0   0]
 [  0 685   0   1   0   0   0   2   0   0]
 [  0   0 582   2   0   0   1   0   1   0]
 [  0   0   5 573   0   3   0   1   1   0]
 [  0   0   0   0 561   0   0   0   0   4]
 [  0   0   0   1   0 512   3   0   2   0]
 [  2   1   0   0   0   0 628   0   0   0]
 [  0   2   1   0   1   0   0 621   0   0]
 [  1   0   0   2   0   0   1   0 579   1]
 [  0   1   1   1   2   0   0   2   2 606]]

2024-01-15 20:33:24,632 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:33:24,632 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:33:24,636 - 

2024-01-15 20:33:24,638 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:33:33,703 - Epoch: [170][   10/  211]    Overall Loss 0.022652    Objective Loss 0.022652                                        LR 0.000100    Time 0.906404    
2024-01-15 20:33:39,399 - Epoch: [170][   20/  211]    Overall Loss 0.024511    Objective Loss 0.024511                                        LR 0.000100    Time 0.737931    
2024-01-15 20:33:45,180 - Epoch: [170][   30/  211]    Overall Loss 0.023302    Objective Loss 0.023302                                        LR 0.000100    Time 0.684558    
2024-01-15 20:33:50,953 - Epoch: [170][   40/  211]    Overall Loss 0.025261    Objective Loss 0.025261                                        LR 0.000100    Time 0.657714    
2024-01-15 20:33:56,730 - Epoch: [170][   50/  211]    Overall Loss 0.024634    Objective Loss 0.024634                                        LR 0.000100    Time 0.641695    
2024-01-15 20:34:02,410 - Epoch: [170][   60/  211]    Overall Loss 0.023748    Objective Loss 0.023748                                        LR 0.000100    Time 0.629385    
2024-01-15 20:34:08,159 - Epoch: [170][   70/  211]    Overall Loss 0.023388    Objective Loss 0.023388                                        LR 0.000100    Time 0.621597    
2024-01-15 20:34:13,822 - Epoch: [170][   80/  211]    Overall Loss 0.022400    Objective Loss 0.022400                                        LR 0.000100    Time 0.614667    
2024-01-15 20:34:19,627 - Epoch: [170][   90/  211]    Overall Loss 0.021691    Objective Loss 0.021691                                        LR 0.000100    Time 0.610862    
2024-01-15 20:34:25,496 - Epoch: [170][  100/  211]    Overall Loss 0.022269    Objective Loss 0.022269                                        LR 0.000100    Time 0.608451    
2024-01-15 20:34:31,387 - Epoch: [170][  110/  211]    Overall Loss 0.022276    Objective Loss 0.022276                                        LR 0.000100    Time 0.606682    
2024-01-15 20:34:37,159 - Epoch: [170][  120/  211]    Overall Loss 0.022451    Objective Loss 0.022451                                        LR 0.000100    Time 0.604212    
2024-01-15 20:34:42,843 - Epoch: [170][  130/  211]    Overall Loss 0.022214    Objective Loss 0.022214                                        LR 0.000100    Time 0.601455    
2024-01-15 20:34:48,581 - Epoch: [170][  140/  211]    Overall Loss 0.021981    Objective Loss 0.021981                                        LR 0.000100    Time 0.599464    
2024-01-15 20:34:54,270 - Epoch: [170][  150/  211]    Overall Loss 0.022086    Objective Loss 0.022086                                        LR 0.000100    Time 0.597417    
2024-01-15 20:34:59,990 - Epoch: [170][  160/  211]    Overall Loss 0.021909    Objective Loss 0.021909                                        LR 0.000100    Time 0.595822    
2024-01-15 20:35:05,697 - Epoch: [170][  170/  211]    Overall Loss 0.021734    Objective Loss 0.021734                                        LR 0.000100    Time 0.594337    
2024-01-15 20:35:11,355 - Epoch: [170][  180/  211]    Overall Loss 0.021609    Objective Loss 0.021609                                        LR 0.000100    Time 0.592752    
2024-01-15 20:35:17,009 - Epoch: [170][  190/  211]    Overall Loss 0.021732    Objective Loss 0.021732                                        LR 0.000100    Time 0.591308    
2024-01-15 20:35:22,745 - Epoch: [170][  200/  211]    Overall Loss 0.021993    Objective Loss 0.021993                                        LR 0.000100    Time 0.590415    
2024-01-15 20:35:29,068 - Epoch: [170][  210/  211]    Overall Loss 0.022032    Objective Loss 0.022032    Top1 99.218750    Top5 100.000000    LR 0.000100    Time 0.592405    
2024-01-15 20:35:29,643 - Epoch: [170][  211/  211]    Overall Loss 0.021956    Objective Loss 0.021956    Top1 99.596774    Top5 100.000000    LR 0.000100    Time 0.592316    
2024-01-15 20:35:30,297 - --- validate (epoch=170)-----------
2024-01-15 20:35:30,298 - 6000 samples (256 per mini-batch)
2024-01-15 20:35:35,606 - Epoch: [170][   10/   24]    Loss 0.033760    Top1 98.906250    Top5 100.000000    
2024-01-15 20:35:37,724 - Epoch: [170][   20/   24]    Loss 0.025744    Top1 99.277344    Top5 100.000000    
2024-01-15 20:35:38,632 - Epoch: [170][   24/   24]    Loss 0.027601    Top1 99.216667    Top5 100.000000    
2024-01-15 20:35:39,202 - ==> Top1: 99.217    Top5: 100.000    Loss: 0.028

2024-01-15 20:35:39,203 - ==> Confusion:
[[603   0   1   0   0   0   0   0   0   1]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   0 583   1   0   0   0   2   0   0]
 [  0   0   2 577   0   2   0   1   1   0]
 [  0   1   1   0 556   0   0   0   1   6]
 [  0   0   0   1   0 514   3   0   0   0]
 [  0   0   0   0   2   0 628   0   1   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  1   0   0   0   1   0   2   1 579   0]
 [  0   1   0   1   3   1   0   2   2 605]]

2024-01-15 20:35:39,204 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:35:39,204 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:35:39,207 - 

2024-01-15 20:35:39,207 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:35:47,633 - Epoch: [171][   10/  211]    Overall Loss 0.020535    Objective Loss 0.020535                                        LR 0.000100    Time 0.842229    
2024-01-15 20:35:53,442 - Epoch: [171][   20/  211]    Overall Loss 0.022226    Objective Loss 0.022226                                        LR 0.000100    Time 0.711408    
2024-01-15 20:35:59,150 - Epoch: [171][   30/  211]    Overall Loss 0.022080    Objective Loss 0.022080                                        LR 0.000100    Time 0.664478    
2024-01-15 20:36:04,885 - Epoch: [171][   40/  211]    Overall Loss 0.021700    Objective Loss 0.021700                                        LR 0.000100    Time 0.641688    
2024-01-15 20:36:10,630 - Epoch: [171][   50/  211]    Overall Loss 0.021376    Objective Loss 0.021376                                        LR 0.000100    Time 0.628231    
2024-01-15 20:36:16,327 - Epoch: [171][   60/  211]    Overall Loss 0.020907    Objective Loss 0.020907                                        LR 0.000100    Time 0.618467    
2024-01-15 20:36:21,989 - Epoch: [171][   70/  211]    Overall Loss 0.021103    Objective Loss 0.021103                                        LR 0.000100    Time 0.610978    
2024-01-15 20:36:27,750 - Epoch: [171][   80/  211]    Overall Loss 0.021076    Objective Loss 0.021076                                        LR 0.000100    Time 0.606605    
2024-01-15 20:36:33,898 - Epoch: [171][   90/  211]    Overall Loss 0.021369    Objective Loss 0.021369                                        LR 0.000100    Time 0.607495    
2024-01-15 20:36:39,686 - Epoch: [171][  100/  211]    Overall Loss 0.021712    Objective Loss 0.021712                                        LR 0.000100    Time 0.604614    
2024-01-15 20:36:45,357 - Epoch: [171][  110/  211]    Overall Loss 0.021750    Objective Loss 0.021750                                        LR 0.000100    Time 0.601202    
2024-01-15 20:36:51,011 - Epoch: [171][  120/  211]    Overall Loss 0.021552    Objective Loss 0.021552                                        LR 0.000100    Time 0.598208    
2024-01-15 20:36:56,671 - Epoch: [171][  130/  211]    Overall Loss 0.021263    Objective Loss 0.021263                                        LR 0.000100    Time 0.595730    
2024-01-15 20:37:02,325 - Epoch: [171][  140/  211]    Overall Loss 0.021525    Objective Loss 0.021525                                        LR 0.000100    Time 0.593554    
2024-01-15 20:37:08,220 - Epoch: [171][  150/  211]    Overall Loss 0.021661    Objective Loss 0.021661                                        LR 0.000100    Time 0.593278    
2024-01-15 20:37:14,336 - Epoch: [171][  160/  211]    Overall Loss 0.021777    Objective Loss 0.021777                                        LR 0.000100    Time 0.594412    
2024-01-15 20:37:20,205 - Epoch: [171][  170/  211]    Overall Loss 0.021650    Objective Loss 0.021650                                        LR 0.000100    Time 0.593963    
2024-01-15 20:37:26,050 - Epoch: [171][  180/  211]    Overall Loss 0.021557    Objective Loss 0.021557                                        LR 0.000100    Time 0.593431    
2024-01-15 20:37:32,080 - Epoch: [171][  190/  211]    Overall Loss 0.021452    Objective Loss 0.021452                                        LR 0.000100    Time 0.593926    
2024-01-15 20:37:37,898 - Epoch: [171][  200/  211]    Overall Loss 0.021531    Objective Loss 0.021531                                        LR 0.000100    Time 0.593314    
2024-01-15 20:37:43,704 - Epoch: [171][  210/  211]    Overall Loss 0.021446    Objective Loss 0.021446    Top1 98.828125    Top5 100.000000    LR 0.000100    Time 0.592697    
2024-01-15 20:37:44,357 - Epoch: [171][  211/  211]    Overall Loss 0.021422    Objective Loss 0.021422    Top1 99.193548    Top5 100.000000    LR 0.000100    Time 0.592979    
2024-01-15 20:37:45,209 - --- validate (epoch=171)-----------
2024-01-15 20:37:45,211 - 6000 samples (256 per mini-batch)
2024-01-15 20:37:52,520 - Epoch: [171][   10/   24]    Loss 0.027296    Top1 99.335938    Top5 100.000000    
2024-01-15 20:37:54,758 - Epoch: [171][   20/   24]    Loss 0.024940    Top1 99.355469    Top5 100.000000    
2024-01-15 20:37:55,598 - Epoch: [171][   24/   24]    Loss 0.024833    Top1 99.366667    Top5 100.000000    
2024-01-15 20:37:56,367 - ==> Top1: 99.367    Top5: 100.000    Loss: 0.025

2024-01-15 20:37:56,369 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 685   0   1   0   0   1   1   0   0]
 [  0   0 582   0   0   0   0   3   0   1]
 [  0   0   2 578   0   1   0   1   1   0]
 [  0   0   0   0 559   0   1   0   0   5]
 [  0   0   0   1   0 513   2   0   2   0]
 [  2   0   0   0   1   0 628   0   0   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   0   1   0   2   0   0 581   0]
 [  0   1   0   0   1   0   0   2   2 609]]

2024-01-15 20:37:56,371 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:37:56,371 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:37:56,377 - 

2024-01-15 20:37:56,377 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:38:05,612 - Epoch: [172][   10/  211]    Overall Loss 0.022096    Objective Loss 0.022096                                        LR 0.000100    Time 0.923378    
2024-01-15 20:38:11,338 - Epoch: [172][   20/  211]    Overall Loss 0.022241    Objective Loss 0.022241                                        LR 0.000100    Time 0.747951    
2024-01-15 20:38:17,151 - Epoch: [172][   30/  211]    Overall Loss 0.021458    Objective Loss 0.021458                                        LR 0.000100    Time 0.692355    
2024-01-15 20:38:23,139 - Epoch: [172][   40/  211]    Overall Loss 0.022619    Objective Loss 0.022619                                        LR 0.000100    Time 0.668947    
2024-01-15 20:38:29,743 - Epoch: [172][   50/  211]    Overall Loss 0.021673    Objective Loss 0.021673                                        LR 0.000100    Time 0.667172    
2024-01-15 20:38:35,607 - Epoch: [172][   60/  211]    Overall Loss 0.020787    Objective Loss 0.020787                                        LR 0.000100    Time 0.653688    
2024-01-15 20:38:41,337 - Epoch: [172][   70/  211]    Overall Loss 0.020175    Objective Loss 0.020175                                        LR 0.000100    Time 0.642148    
2024-01-15 20:38:47,150 - Epoch: [172][   80/  211]    Overall Loss 0.020311    Objective Loss 0.020311                                        LR 0.000100    Time 0.634525    
2024-01-15 20:38:52,901 - Epoch: [172][   90/  211]    Overall Loss 0.020445    Objective Loss 0.020445                                        LR 0.000100    Time 0.627917    
2024-01-15 20:38:58,561 - Epoch: [172][  100/  211]    Overall Loss 0.020978    Objective Loss 0.020978                                        LR 0.000100    Time 0.621712    
2024-01-15 20:39:04,285 - Epoch: [172][  110/  211]    Overall Loss 0.020671    Objective Loss 0.020671                                        LR 0.000100    Time 0.617219    
2024-01-15 20:39:09,975 - Epoch: [172][  120/  211]    Overall Loss 0.020631    Objective Loss 0.020631                                        LR 0.000100    Time 0.613197    
2024-01-15 20:39:15,718 - Epoch: [172][  130/  211]    Overall Loss 0.020342    Objective Loss 0.020342                                        LR 0.000100    Time 0.610201    
2024-01-15 20:39:22,317 - Epoch: [172][  140/  211]    Overall Loss 0.020223    Objective Loss 0.020223                                        LR 0.000100    Time 0.613722    
2024-01-15 20:39:29,245 - Epoch: [172][  150/  211]    Overall Loss 0.020406    Objective Loss 0.020406                                        LR 0.000100    Time 0.618969    
2024-01-15 20:39:35,193 - Epoch: [172][  160/  211]    Overall Loss 0.020287    Objective Loss 0.020287                                        LR 0.000100    Time 0.617452    
2024-01-15 20:39:41,024 - Epoch: [172][  170/  211]    Overall Loss 0.020705    Objective Loss 0.020705                                        LR 0.000100    Time 0.615424    
2024-01-15 20:39:46,832 - Epoch: [172][  180/  211]    Overall Loss 0.020622    Objective Loss 0.020622                                        LR 0.000100    Time 0.613493    
2024-01-15 20:39:52,528 - Epoch: [172][  190/  211]    Overall Loss 0.020806    Objective Loss 0.020806                                        LR 0.000100    Time 0.611175    
2024-01-15 20:39:58,374 - Epoch: [172][  200/  211]    Overall Loss 0.020724    Objective Loss 0.020724                                        LR 0.000100    Time 0.609842    
2024-01-15 20:40:04,096 - Epoch: [172][  210/  211]    Overall Loss 0.020795    Objective Loss 0.020795    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.608044    
2024-01-15 20:40:04,698 - Epoch: [172][  211/  211]    Overall Loss 0.020784    Objective Loss 0.020784    Top1 99.596774    Top5 100.000000    LR 0.000100    Time 0.608013    
2024-01-15 20:40:06,328 - --- validate (epoch=172)-----------
2024-01-15 20:40:06,330 - 6000 samples (256 per mini-batch)
2024-01-15 20:40:13,440 - Epoch: [172][   10/   24]    Loss 0.030730    Top1 99.218750    Top5 100.000000    
2024-01-15 20:40:15,558 - Epoch: [172][   20/   24]    Loss 0.027438    Top1 99.277344    Top5 100.000000    
2024-01-15 20:40:16,370 - Epoch: [172][   24/   24]    Loss 0.028266    Top1 99.233333    Top5 100.000000    
2024-01-15 20:40:17,166 - ==> Top1: 99.233    Top5: 100.000    Loss: 0.028

2024-01-15 20:40:17,167 - ==> Confusion:
[[602   0   1   0   0   1   1   0   0   0]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   0 582   1   0   0   0   2   1   0]
 [  0   0   0 581   0   0   0   1   1   0]
 [  0   0   0   0 559   0   0   1   1   4]
 [  1   0   0   2   0 512   1   0   2   0]
 [  2   1   0   0   1   1 626   0   0   0]
 [  0   1   1   0   0   0   0 623   0   0]
 [  0   0   0   1   1   1   3   0 577   1]
 [  3   1   0   0   2   0   0   2   1 606]]

2024-01-15 20:40:17,170 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:40:17,170 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:40:17,176 - 

2024-01-15 20:40:17,176 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:40:26,651 - Epoch: [173][   10/  211]    Overall Loss 0.017994    Objective Loss 0.017994                                        LR 0.000100    Time 0.947394    
2024-01-15 20:40:33,360 - Epoch: [173][   20/  211]    Overall Loss 0.019167    Objective Loss 0.019167                                        LR 0.000100    Time 0.809045    
2024-01-15 20:40:39,114 - Epoch: [173][   30/  211]    Overall Loss 0.020056    Objective Loss 0.020056                                        LR 0.000100    Time 0.731108    
2024-01-15 20:40:45,708 - Epoch: [173][   40/  211]    Overall Loss 0.020032    Objective Loss 0.020032                                        LR 0.000100    Time 0.713155    
2024-01-15 20:40:51,630 - Epoch: [173][   50/  211]    Overall Loss 0.021180    Objective Loss 0.021180                                        LR 0.000100    Time 0.688854    
2024-01-15 20:40:57,346 - Epoch: [173][   60/  211]    Overall Loss 0.020644    Objective Loss 0.020644                                        LR 0.000100    Time 0.669299    
2024-01-15 20:41:03,241 - Epoch: [173][   70/  211]    Overall Loss 0.020680    Objective Loss 0.020680                                        LR 0.000100    Time 0.657883    
2024-01-15 20:41:09,107 - Epoch: [173][   80/  211]    Overall Loss 0.021350    Objective Loss 0.021350                                        LR 0.000100    Time 0.648957    
2024-01-15 20:41:14,802 - Epoch: [173][   90/  211]    Overall Loss 0.021319    Objective Loss 0.021319                                        LR 0.000100    Time 0.640110    
2024-01-15 20:41:20,480 - Epoch: [173][  100/  211]    Overall Loss 0.021571    Objective Loss 0.021571                                        LR 0.000100    Time 0.632865    
2024-01-15 20:41:26,206 - Epoch: [173][  110/  211]    Overall Loss 0.021567    Objective Loss 0.021567                                        LR 0.000100    Time 0.627364    
2024-01-15 20:41:32,322 - Epoch: [173][  120/  211]    Overall Loss 0.021483    Objective Loss 0.021483                                        LR 0.000100    Time 0.626039    
2024-01-15 20:41:38,269 - Epoch: [173][  130/  211]    Overall Loss 0.021859    Objective Loss 0.021859                                        LR 0.000100    Time 0.623615    
2024-01-15 20:41:43,971 - Epoch: [173][  140/  211]    Overall Loss 0.022240    Objective Loss 0.022240                                        LR 0.000100    Time 0.619792    
2024-01-15 20:41:49,629 - Epoch: [173][  150/  211]    Overall Loss 0.022307    Objective Loss 0.022307                                        LR 0.000100    Time 0.616189    
2024-01-15 20:41:55,275 - Epoch: [173][  160/  211]    Overall Loss 0.022405    Objective Loss 0.022405                                        LR 0.000100    Time 0.612963    
2024-01-15 20:42:00,935 - Epoch: [173][  170/  211]    Overall Loss 0.022313    Objective Loss 0.022313                                        LR 0.000100    Time 0.610190    
2024-01-15 20:42:06,614 - Epoch: [173][  180/  211]    Overall Loss 0.022174    Objective Loss 0.022174                                        LR 0.000100    Time 0.607837    
2024-01-15 20:42:12,319 - Epoch: [173][  190/  211]    Overall Loss 0.021829    Objective Loss 0.021829                                        LR 0.000100    Time 0.605870    
2024-01-15 20:42:17,994 - Epoch: [173][  200/  211]    Overall Loss 0.021817    Objective Loss 0.021817                                        LR 0.000100    Time 0.603947    
2024-01-15 20:42:24,750 - Epoch: [173][  210/  211]    Overall Loss 0.022034    Objective Loss 0.022034    Top1 99.218750    Top5 100.000000    LR 0.000100    Time 0.607230    
2024-01-15 20:42:25,340 - Epoch: [173][  211/  211]    Overall Loss 0.022002    Objective Loss 0.022002    Top1 99.395161    Top5 100.000000    LR 0.000100    Time 0.607140    
2024-01-15 20:42:26,237 - --- validate (epoch=173)-----------
2024-01-15 20:42:26,239 - 6000 samples (256 per mini-batch)
2024-01-15 20:42:33,525 - Epoch: [173][   10/   24]    Loss 0.024428    Top1 99.335938    Top5 100.000000    
2024-01-15 20:42:35,724 - Epoch: [173][   20/   24]    Loss 0.027115    Top1 99.218750    Top5 100.000000    
2024-01-15 20:42:36,480 - Epoch: [173][   24/   24]    Loss 0.025568    Top1 99.250000    Top5 100.000000    
2024-01-15 20:42:37,102 - ==> Top1: 99.250    Top5: 100.000    Loss: 0.026

2024-01-15 20:42:37,103 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 683   1   1   0   1   0   2   0   0]
 [  0   0 581   0   0   0   0   4   1   0]
 [  0   0   2 578   0   1   0   1   1   0]
 [  0   0   1   0 558   0   0   0   0   6]
 [  0   0   0   1   0 514   3   0   0   0]
 [  1   0   0   0   1   0 628   0   1   0]
 [  0   2   0   1   0   0   0 622   0   0]
 [  1   0   0   2   1   0   1   0 579   0]
 [  0   0   0   0   2   1   0   1   2 609]]

2024-01-15 20:42:37,105 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:42:37,106 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:42:37,110 - 

2024-01-15 20:42:37,110 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:42:45,684 - Epoch: [174][   10/  211]    Overall Loss 0.019511    Objective Loss 0.019511                                        LR 0.000100    Time 0.857288    
2024-01-15 20:42:51,399 - Epoch: [174][   20/  211]    Overall Loss 0.021101    Objective Loss 0.021101                                        LR 0.000100    Time 0.714226    
2024-01-15 20:42:57,080 - Epoch: [174][   30/  211]    Overall Loss 0.022183    Objective Loss 0.022183                                        LR 0.000100    Time 0.665486    
2024-01-15 20:43:02,892 - Epoch: [174][   40/  211]    Overall Loss 0.021989    Objective Loss 0.021989                                        LR 0.000100    Time 0.644389    
2024-01-15 20:43:08,670 - Epoch: [174][   50/  211]    Overall Loss 0.021743    Objective Loss 0.021743                                        LR 0.000100    Time 0.631041    
2024-01-15 20:43:14,356 - Epoch: [174][   60/  211]    Overall Loss 0.021596    Objective Loss 0.021596                                        LR 0.000100    Time 0.620598    
2024-01-15 20:43:20,184 - Epoch: [174][   70/  211]    Overall Loss 0.021664    Objective Loss 0.021664                                        LR 0.000100    Time 0.615177    
2024-01-15 20:43:25,933 - Epoch: [174][   80/  211]    Overall Loss 0.021918    Objective Loss 0.021918                                        LR 0.000100    Time 0.610132    
2024-01-15 20:43:31,969 - Epoch: [174][   90/  211]    Overall Loss 0.022368    Objective Loss 0.022368                                        LR 0.000100    Time 0.609388    
2024-01-15 20:43:37,708 - Epoch: [174][  100/  211]    Overall Loss 0.022246    Objective Loss 0.022246                                        LR 0.000100    Time 0.605827    
2024-01-15 20:43:43,442 - Epoch: [174][  110/  211]    Overall Loss 0.022009    Objective Loss 0.022009                                        LR 0.000100    Time 0.602852    
2024-01-15 20:43:49,155 - Epoch: [174][  120/  211]    Overall Loss 0.022405    Objective Loss 0.022405                                        LR 0.000100    Time 0.600219    
2024-01-15 20:43:54,836 - Epoch: [174][  130/  211]    Overall Loss 0.022654    Objective Loss 0.022654                                        LR 0.000100    Time 0.597737    
2024-01-15 20:44:00,530 - Epoch: [174][  140/  211]    Overall Loss 0.022463    Objective Loss 0.022463                                        LR 0.000100    Time 0.595703    
2024-01-15 20:44:06,256 - Epoch: [174][  150/  211]    Overall Loss 0.022529    Objective Loss 0.022529                                        LR 0.000100    Time 0.594158    
2024-01-15 20:44:11,937 - Epoch: [174][  160/  211]    Overall Loss 0.022336    Objective Loss 0.022336                                        LR 0.000100    Time 0.592523    
2024-01-15 20:44:17,677 - Epoch: [174][  170/  211]    Overall Loss 0.022051    Objective Loss 0.022051                                        LR 0.000100    Time 0.591434    
2024-01-15 20:44:23,502 - Epoch: [174][  180/  211]    Overall Loss 0.021891    Objective Loss 0.021891                                        LR 0.000100    Time 0.590924    
2024-01-15 20:44:29,455 - Epoch: [174][  190/  211]    Overall Loss 0.022027    Objective Loss 0.022027                                        LR 0.000100    Time 0.591152    
2024-01-15 20:44:35,152 - Epoch: [174][  200/  211]    Overall Loss 0.021990    Objective Loss 0.021990                                        LR 0.000100    Time 0.590072    
2024-01-15 20:44:40,850 - Epoch: [174][  210/  211]    Overall Loss 0.021854    Objective Loss 0.021854    Top1 98.828125    Top5 100.000000    LR 0.000100    Time 0.589105    
2024-01-15 20:44:41,465 - Epoch: [174][  211/  211]    Overall Loss 0.021840    Objective Loss 0.021840    Top1 99.193548    Top5 100.000000    LR 0.000100    Time 0.589223    
2024-01-15 20:44:42,081 - --- validate (epoch=174)-----------
2024-01-15 20:44:42,082 - 6000 samples (256 per mini-batch)
2024-01-15 20:44:47,487 - Epoch: [174][   10/   24]    Loss 0.033223    Top1 99.101562    Top5 100.000000    
2024-01-15 20:44:49,661 - Epoch: [174][   20/   24]    Loss 0.030391    Top1 99.140625    Top5 100.000000    
2024-01-15 20:44:50,426 - Epoch: [174][   24/   24]    Loss 0.029656    Top1 99.150000    Top5 100.000000    
2024-01-15 20:44:51,013 - ==> Top1: 99.150    Top5: 100.000    Loss: 0.030

2024-01-15 20:44:51,014 - ==> Confusion:
[[603   0   0   0   0   0   1   0   0   1]
 [  0 685   1   0   0   1   0   1   0   0]
 [  0   0 584   1   0   0   0   1   0   0]
 [  0   0   1 578   0   1   0   2   1   0]
 [  0   0   0   0 560   0   1   0   0   4]
 [  0   1   0   2   0 511   3   0   1   0]
 [  1   1   0   0   1   0 627   0   1   0]
 [  0   3   0   1   0   0   0 621   0   0]
 [  0   0   0   2   2   0   2   0 578   0]
 [  1   0   0   0   6   1   0   2   3 602]]

2024-01-15 20:44:51,017 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:44:51,017 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:44:51,022 - 

2024-01-15 20:44:51,022 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:44:59,425 - Epoch: [175][   10/  211]    Overall Loss 0.021139    Objective Loss 0.021139                                        LR 0.000100    Time 0.840234    
2024-01-15 20:45:05,345 - Epoch: [175][   20/  211]    Overall Loss 0.020309    Objective Loss 0.020309                                        LR 0.000100    Time 0.716016    
2024-01-15 20:45:11,030 - Epoch: [175][   30/  211]    Overall Loss 0.021165    Objective Loss 0.021165                                        LR 0.000100    Time 0.666817    
2024-01-15 20:45:16,739 - Epoch: [175][   40/  211]    Overall Loss 0.022748    Objective Loss 0.022748                                        LR 0.000100    Time 0.642825    
2024-01-15 20:45:22,458 - Epoch: [175][   50/  211]    Overall Loss 0.021806    Objective Loss 0.021806                                        LR 0.000100    Time 0.628619    
2024-01-15 20:45:28,614 - Epoch: [175][   60/  211]    Overall Loss 0.021675    Objective Loss 0.021675                                        LR 0.000100    Time 0.626436    
2024-01-15 20:45:34,454 - Epoch: [175][   70/  211]    Overall Loss 0.021837    Objective Loss 0.021837                                        LR 0.000100    Time 0.620354    
2024-01-15 20:45:40,128 - Epoch: [175][   80/  211]    Overall Loss 0.021509    Objective Loss 0.021509                                        LR 0.000100    Time 0.613722    
2024-01-15 20:45:45,948 - Epoch: [175][   90/  211]    Overall Loss 0.021724    Objective Loss 0.021724                                        LR 0.000100    Time 0.610185    
2024-01-15 20:45:51,651 - Epoch: [175][  100/  211]    Overall Loss 0.021695    Objective Loss 0.021695                                        LR 0.000100    Time 0.606186    
2024-01-15 20:45:57,408 - Epoch: [175][  110/  211]    Overall Loss 0.021900    Objective Loss 0.021900                                        LR 0.000100    Time 0.603407    
2024-01-15 20:46:03,178 - Epoch: [175][  120/  211]    Overall Loss 0.021939    Objective Loss 0.021939                                        LR 0.000100    Time 0.601198    
2024-01-15 20:46:08,922 - Epoch: [175][  130/  211]    Overall Loss 0.021513    Objective Loss 0.021513                                        LR 0.000100    Time 0.599129    
2024-01-15 20:46:14,601 - Epoch: [175][  140/  211]    Overall Loss 0.021274    Objective Loss 0.021274                                        LR 0.000100    Time 0.596891    
2024-01-15 20:46:20,337 - Epoch: [175][  150/  211]    Overall Loss 0.021284    Objective Loss 0.021284                                        LR 0.000100    Time 0.595333    
2024-01-15 20:46:26,046 - Epoch: [175][  160/  211]    Overall Loss 0.021660    Objective Loss 0.021660                                        LR 0.000100    Time 0.593795    
2024-01-15 20:46:32,382 - Epoch: [175][  170/  211]    Overall Loss 0.021826    Objective Loss 0.021826                                        LR 0.000100    Time 0.596134    
2024-01-15 20:46:38,204 - Epoch: [175][  180/  211]    Overall Loss 0.021717    Objective Loss 0.021717                                        LR 0.000100    Time 0.595349    
2024-01-15 20:46:43,920 - Epoch: [175][  190/  211]    Overall Loss 0.021802    Objective Loss 0.021802                                        LR 0.000100    Time 0.594097    
2024-01-15 20:46:50,506 - Epoch: [175][  200/  211]    Overall Loss 0.021852    Objective Loss 0.021852                                        LR 0.000100    Time 0.597315    
2024-01-15 20:46:56,303 - Epoch: [175][  210/  211]    Overall Loss 0.021652    Objective Loss 0.021652    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.596466    
2024-01-15 20:46:56,867 - Epoch: [175][  211/  211]    Overall Loss 0.021766    Objective Loss 0.021766    Top1 98.991935    Top5 100.000000    LR 0.000100    Time 0.596310    
2024-01-15 20:46:57,623 - --- validate (epoch=175)-----------
2024-01-15 20:46:57,623 - 6000 samples (256 per mini-batch)
2024-01-15 20:47:03,696 - Epoch: [175][   10/   24]    Loss 0.034800    Top1 98.945312    Top5 99.960938    
2024-01-15 20:47:05,848 - Epoch: [175][   20/   24]    Loss 0.028730    Top1 99.023438    Top5 99.980469    
2024-01-15 20:47:06,649 - Epoch: [175][   24/   24]    Loss 0.028186    Top1 99.050000    Top5 99.983333    
2024-01-15 20:47:07,210 - ==> Top1: 99.050    Top5: 99.983    Loss: 0.028

2024-01-15 20:47:07,211 - ==> Confusion:
[[601   0   1   0   0   0   1   0   1   1]
 [  0 686   1   0   1   0   0   0   0   0]
 [  0   1 581   0   1   0   0   3   0   0]
 [  1   0   3 575   0   2   0   2   0   0]
 [  0   1   0   0 559   0   0   0   0   5]
 [  0   0   0   2   0 513   2   0   1   0]
 [  0   2   0   0   1   0 627   0   1   0]
 [  0   3   1   0   0   0   0 621   0   0]
 [  1   0   0   0   0   0   2   1 580   0]
 [  3   2   0   0   5   1   0   1   3 600]]

2024-01-15 20:47:07,213 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:47:07,213 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:47:07,220 - 

2024-01-15 20:47:07,220 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:47:15,487 - Epoch: [176][   10/  211]    Overall Loss 0.017316    Objective Loss 0.017316                                        LR 0.000100    Time 0.826580    
2024-01-15 20:47:21,145 - Epoch: [176][   20/  211]    Overall Loss 0.021175    Objective Loss 0.021175                                        LR 0.000100    Time 0.696128    
2024-01-15 20:47:27,479 - Epoch: [176][   30/  211]    Overall Loss 0.021088    Objective Loss 0.021088                                        LR 0.000100    Time 0.675183    
2024-01-15 20:47:33,818 - Epoch: [176][   40/  211]    Overall Loss 0.022035    Objective Loss 0.022035                                        LR 0.000100    Time 0.664815    
2024-01-15 20:47:39,641 - Epoch: [176][   50/  211]    Overall Loss 0.021957    Objective Loss 0.021957                                        LR 0.000100    Time 0.648291    
2024-01-15 20:47:45,497 - Epoch: [176][   60/  211]    Overall Loss 0.022055    Objective Loss 0.022055                                        LR 0.000100    Time 0.637837    
2024-01-15 20:47:52,664 - Epoch: [176][   70/  211]    Overall Loss 0.022574    Objective Loss 0.022574                                        LR 0.000100    Time 0.649077    
2024-01-15 20:48:00,447 - Epoch: [176][   80/  211]    Overall Loss 0.022409    Objective Loss 0.022409                                        LR 0.000100    Time 0.664991    
2024-01-15 20:48:06,527 - Epoch: [176][   90/  211]    Overall Loss 0.021842    Objective Loss 0.021842                                        LR 0.000100    Time 0.658616    
2024-01-15 20:48:12,455 - Epoch: [176][  100/  211]    Overall Loss 0.021654    Objective Loss 0.021654                                        LR 0.000100    Time 0.652019    
2024-01-15 20:48:18,284 - Epoch: [176][  110/  211]    Overall Loss 0.021360    Objective Loss 0.021360                                        LR 0.000100    Time 0.645723    
2024-01-15 20:48:24,321 - Epoch: [176][  120/  211]    Overall Loss 0.021159    Objective Loss 0.021159                                        LR 0.000100    Time 0.642217    
2024-01-15 20:48:30,875 - Epoch: [176][  130/  211]    Overall Loss 0.021856    Objective Loss 0.021856                                        LR 0.000100    Time 0.643218    
2024-01-15 20:48:37,020 - Epoch: [176][  140/  211]    Overall Loss 0.021817    Objective Loss 0.021817                                        LR 0.000100    Time 0.641129    
2024-01-15 20:48:42,936 - Epoch: [176][  150/  211]    Overall Loss 0.021678    Objective Loss 0.021678                                        LR 0.000100    Time 0.637818    
2024-01-15 20:48:48,969 - Epoch: [176][  160/  211]    Overall Loss 0.021313    Objective Loss 0.021313                                        LR 0.000100    Time 0.635654    
2024-01-15 20:48:54,964 - Epoch: [176][  170/  211]    Overall Loss 0.021096    Objective Loss 0.021096                                        LR 0.000100    Time 0.633522    
2024-01-15 20:49:01,078 - Epoch: [176][  180/  211]    Overall Loss 0.020922    Objective Loss 0.020922                                        LR 0.000100    Time 0.632280    
2024-01-15 20:49:07,009 - Epoch: [176][  190/  211]    Overall Loss 0.020686    Objective Loss 0.020686                                        LR 0.000100    Time 0.630211    
2024-01-15 20:49:13,104 - Epoch: [176][  200/  211]    Overall Loss 0.020576    Objective Loss 0.020576                                        LR 0.000100    Time 0.629168    
2024-01-15 20:49:18,901 - Epoch: [176][  210/  211]    Overall Loss 0.020371    Objective Loss 0.020371    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.626808    
2024-01-15 20:49:19,464 - Epoch: [176][  211/  211]    Overall Loss 0.020307    Objective Loss 0.020307    Top1 99.798387    Top5 100.000000    LR 0.000100    Time 0.626499    
2024-01-15 20:49:20,353 - --- validate (epoch=176)-----------
2024-01-15 20:49:20,355 - 6000 samples (256 per mini-batch)
2024-01-15 20:49:27,346 - Epoch: [176][   10/   24]    Loss 0.026943    Top1 99.296875    Top5 100.000000    
2024-01-15 20:49:29,703 - Epoch: [176][   20/   24]    Loss 0.025450    Top1 99.335938    Top5 100.000000    
2024-01-15 20:49:30,559 - Epoch: [176][   24/   24]    Loss 0.024800    Top1 99.366667    Top5 100.000000    
2024-01-15 20:49:31,337 - ==> Top1: 99.367    Top5: 100.000    Loss: 0.025

2024-01-15 20:49:31,338 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   1   0   0   1   0   0   0   0]
 [  0   0 583   0   0   0   0   3   0   0]
 [  0   0   1 579   0   1   0   0   2   0]
 [  0   0   0   0 561   0   0   1   0   3]
 [  0   0   1   1   0 511   3   0   2   0]
 [  0   2   0   0   2   0 627   0   0   0]
 [  0   0   0   0   0   1   0 624   0   0]
 [  1   0   1   1   0   0   1   0 580   0]
 [  0   1   0   0   3   0   0   1   2 608]]

2024-01-15 20:49:31,339 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:49:31,339 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:49:31,344 - 

2024-01-15 20:49:31,344 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:49:40,230 - Epoch: [177][   10/  211]    Overall Loss 0.021677    Objective Loss 0.021677                                        LR 0.000100    Time 0.888475    
2024-01-15 20:49:46,015 - Epoch: [177][   20/  211]    Overall Loss 0.022274    Objective Loss 0.022274                                        LR 0.000100    Time 0.733445    
2024-01-15 20:49:51,752 - Epoch: [177][   30/  211]    Overall Loss 0.021015    Objective Loss 0.021015                                        LR 0.000100    Time 0.680163    
2024-01-15 20:49:57,493 - Epoch: [177][   40/  211]    Overall Loss 0.021561    Objective Loss 0.021561                                        LR 0.000100    Time 0.653604    
2024-01-15 20:50:03,234 - Epoch: [177][   50/  211]    Overall Loss 0.021062    Objective Loss 0.021062                                        LR 0.000100    Time 0.637685    
2024-01-15 20:50:09,024 - Epoch: [177][   60/  211]    Overall Loss 0.020876    Objective Loss 0.020876                                        LR 0.000100    Time 0.627872    
2024-01-15 20:50:14,728 - Epoch: [177][   70/  211]    Overall Loss 0.020870    Objective Loss 0.020870                                        LR 0.000100    Time 0.619648    
2024-01-15 20:50:20,446 - Epoch: [177][   80/  211]    Overall Loss 0.020858    Objective Loss 0.020858                                        LR 0.000100    Time 0.613655    
2024-01-15 20:50:26,206 - Epoch: [177][   90/  211]    Overall Loss 0.020428    Objective Loss 0.020428                                        LR 0.000100    Time 0.609456    
2024-01-15 20:50:32,311 - Epoch: [177][  100/  211]    Overall Loss 0.020394    Objective Loss 0.020394                                        LR 0.000100    Time 0.609550    
2024-01-15 20:50:38,118 - Epoch: [177][  110/  211]    Overall Loss 0.020562    Objective Loss 0.020562                                        LR 0.000100    Time 0.606915    
2024-01-15 20:50:43,961 - Epoch: [177][  120/  211]    Overall Loss 0.020637    Objective Loss 0.020637                                        LR 0.000100    Time 0.605003    
2024-01-15 20:50:49,644 - Epoch: [177][  130/  211]    Overall Loss 0.020581    Objective Loss 0.020581                                        LR 0.000100    Time 0.602174    
2024-01-15 20:50:55,347 - Epoch: [177][  140/  211]    Overall Loss 0.020676    Objective Loss 0.020676                                        LR 0.000100    Time 0.599886    
2024-01-15 20:51:01,844 - Epoch: [177][  150/  211]    Overall Loss 0.021224    Objective Loss 0.021224                                        LR 0.000100    Time 0.603198    
2024-01-15 20:51:07,758 - Epoch: [177][  160/  211]    Overall Loss 0.021828    Objective Loss 0.021828                                        LR 0.000100    Time 0.602451    
2024-01-15 20:51:13,492 - Epoch: [177][  170/  211]    Overall Loss 0.021802    Objective Loss 0.021802                                        LR 0.000100    Time 0.600735    
2024-01-15 20:51:19,260 - Epoch: [177][  180/  211]    Overall Loss 0.021732    Objective Loss 0.021732                                        LR 0.000100    Time 0.599399    
2024-01-15 20:51:24,913 - Epoch: [177][  190/  211]    Overall Loss 0.021662    Objective Loss 0.021662                                        LR 0.000100    Time 0.597602    
2024-01-15 20:51:30,774 - Epoch: [177][  200/  211]    Overall Loss 0.021900    Objective Loss 0.021900                                        LR 0.000100    Time 0.597022    
2024-01-15 20:51:36,440 - Epoch: [177][  210/  211]    Overall Loss 0.021781    Objective Loss 0.021781    Top1 98.828125    Top5 100.000000    LR 0.000100    Time 0.595567    
2024-01-15 20:51:37,135 - Epoch: [177][  211/  211]    Overall Loss 0.021815    Objective Loss 0.021815    Top1 98.790323    Top5 100.000000    LR 0.000100    Time 0.596041    
2024-01-15 20:51:37,931 - --- validate (epoch=177)-----------
2024-01-15 20:51:37,932 - 6000 samples (256 per mini-batch)
2024-01-15 20:51:44,064 - Epoch: [177][   10/   24]    Loss 0.029309    Top1 99.140625    Top5 100.000000    
2024-01-15 20:51:46,197 - Epoch: [177][   20/   24]    Loss 0.025887    Top1 99.179688    Top5 100.000000    
2024-01-15 20:51:46,946 - Epoch: [177][   24/   24]    Loss 0.026063    Top1 99.150000    Top5 100.000000    
2024-01-15 20:51:47,547 - ==> Top1: 99.150    Top5: 100.000    Loss: 0.026

2024-01-15 20:51:47,549 - ==> Confusion:
[[601   0   1   0   0   0   2   0   0   1]
 [  0 686   1   0   0   1   0   0   0   0]
 [  0   0 584   1   0   0   0   0   1   0]
 [  0   0   4 574   0   2   0   2   1   0]
 [  0   0   1   0 558   0   1   0   0   5]
 [  0   0   0   1   0 512   3   0   1   1]
 [  0   1   0   0   1   0 628   0   1   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  1   0   0   0   0   1   1   0 581   0]
 [  0   1   0   0   6   0   0   3   3 602]]

2024-01-15 20:51:47,551 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:51:47,551 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:51:47,556 - 

2024-01-15 20:51:47,557 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:51:55,915 - Epoch: [178][   10/  211]    Overall Loss 0.020181    Objective Loss 0.020181                                        LR 0.000100    Time 0.835765    
2024-01-15 20:52:01,585 - Epoch: [178][   20/  211]    Overall Loss 0.019076    Objective Loss 0.019076                                        LR 0.000100    Time 0.701302    
2024-01-15 20:52:07,268 - Epoch: [178][   30/  211]    Overall Loss 0.020922    Objective Loss 0.020922                                        LR 0.000100    Time 0.656965    
2024-01-15 20:52:12,956 - Epoch: [178][   40/  211]    Overall Loss 0.021076    Objective Loss 0.021076                                        LR 0.000100    Time 0.634880    
2024-01-15 20:52:18,652 - Epoch: [178][   50/  211]    Overall Loss 0.020144    Objective Loss 0.020144                                        LR 0.000100    Time 0.621821    
2024-01-15 20:52:24,494 - Epoch: [178][   60/  211]    Overall Loss 0.020625    Objective Loss 0.020625                                        LR 0.000100    Time 0.615522    
2024-01-15 20:52:30,679 - Epoch: [178][   70/  211]    Overall Loss 0.020130    Objective Loss 0.020130                                        LR 0.000100    Time 0.615914    
2024-01-15 20:52:36,349 - Epoch: [178][   80/  211]    Overall Loss 0.020002    Objective Loss 0.020002                                        LR 0.000100    Time 0.609785    
2024-01-15 20:52:42,078 - Epoch: [178][   90/  211]    Overall Loss 0.020249    Objective Loss 0.020249                                        LR 0.000100    Time 0.605683    
2024-01-15 20:52:47,732 - Epoch: [178][  100/  211]    Overall Loss 0.020394    Objective Loss 0.020394                                        LR 0.000100    Time 0.601643    
2024-01-15 20:52:53,413 - Epoch: [178][  110/  211]    Overall Loss 0.020282    Objective Loss 0.020282                                        LR 0.000100    Time 0.598590    
2024-01-15 20:52:59,200 - Epoch: [178][  120/  211]    Overall Loss 0.019959    Objective Loss 0.019959                                        LR 0.000100    Time 0.596917    
2024-01-15 20:53:05,504 - Epoch: [178][  130/  211]    Overall Loss 0.020575    Objective Loss 0.020575                                        LR 0.000100    Time 0.599486    
2024-01-15 20:53:13,474 - Epoch: [178][  140/  211]    Overall Loss 0.020967    Objective Loss 0.020967                                        LR 0.000100    Time 0.613580    
2024-01-15 20:53:21,418 - Epoch: [178][  150/  211]    Overall Loss 0.020532    Objective Loss 0.020532                                        LR 0.000100    Time 0.625575    
2024-01-15 20:53:29,865 - Epoch: [178][  160/  211]    Overall Loss 0.020895    Objective Loss 0.020895                                        LR 0.000100    Time 0.639260    
2024-01-15 20:53:36,962 - Epoch: [178][  170/  211]    Overall Loss 0.020969    Objective Loss 0.020969                                        LR 0.000100    Time 0.643394    
2024-01-15 20:53:43,796 - Epoch: [178][  180/  211]    Overall Loss 0.021190    Objective Loss 0.021190                                        LR 0.000100    Time 0.645601    
2024-01-15 20:53:50,226 - Epoch: [178][  190/  211]    Overall Loss 0.020851    Objective Loss 0.020851                                        LR 0.000100    Time 0.645455    
2024-01-15 20:53:56,858 - Epoch: [178][  200/  211]    Overall Loss 0.021101    Objective Loss 0.021101                                        LR 0.000100    Time 0.646339    
2024-01-15 20:54:03,875 - Epoch: [178][  210/  211]    Overall Loss 0.021198    Objective Loss 0.021198    Top1 99.218750    Top5 100.000000    LR 0.000100    Time 0.648964    
2024-01-15 20:54:04,645 - Epoch: [178][  211/  211]    Overall Loss 0.021370    Objective Loss 0.021370    Top1 98.991935    Top5 100.000000    LR 0.000100    Time 0.649533    
2024-01-15 20:54:05,746 - --- validate (epoch=178)-----------
2024-01-15 20:54:05,748 - 6000 samples (256 per mini-batch)
2024-01-15 20:54:13,905 - Epoch: [178][   10/   24]    Loss 0.029332    Top1 99.296875    Top5 100.000000    
2024-01-15 20:54:16,362 - Epoch: [178][   20/   24]    Loss 0.025926    Top1 99.218750    Top5 100.000000    
2024-01-15 20:54:17,380 - Epoch: [178][   24/   24]    Loss 0.025387    Top1 99.233333    Top5 100.000000    
2024-01-15 20:54:18,344 - ==> Top1: 99.233    Top5: 100.000    Loss: 0.025

2024-01-15 20:54:18,346 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 686   1   0   1   0   0   0   0   0]
 [  0   0 579   1   0   0   0   6   0   0]
 [  0   0   1 579   0   1   0   1   1   0]
 [  0   0   0   0 560   0   0   0   0   5]
 [  2   0   0   1   0 513   2   0   0   0]
 [  1   1   0   0   1   0 627   0   1   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  0   1   0   0   0   0   0   0 582   1]
 [  0   1   0   0   3   1   0   2   4 604]]

2024-01-15 20:54:18,348 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:54:18,349 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:54:18,354 - 

2024-01-15 20:54:18,354 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:54:28,780 - Epoch: [179][   10/  211]    Overall Loss 0.023137    Objective Loss 0.023137                                        LR 0.000100    Time 1.042496    
2024-01-15 20:54:35,002 - Epoch: [179][   20/  211]    Overall Loss 0.021381    Objective Loss 0.021381                                        LR 0.000100    Time 0.832240    
2024-01-15 20:54:41,590 - Epoch: [179][   30/  211]    Overall Loss 0.021355    Objective Loss 0.021355                                        LR 0.000100    Time 0.774356    
2024-01-15 20:54:48,006 - Epoch: [179][   40/  211]    Overall Loss 0.022477    Objective Loss 0.022477                                        LR 0.000100    Time 0.741112    
2024-01-15 20:54:54,362 - Epoch: [179][   50/  211]    Overall Loss 0.022428    Objective Loss 0.022428                                        LR 0.000100    Time 0.719959    
2024-01-15 20:55:00,835 - Epoch: [179][   60/  211]    Overall Loss 0.023539    Objective Loss 0.023539                                        LR 0.000100    Time 0.707807    
2024-01-15 20:55:07,254 - Epoch: [179][   70/  211]    Overall Loss 0.023007    Objective Loss 0.023007                                        LR 0.000100    Time 0.698360    
2024-01-15 20:55:13,598 - Epoch: [179][   80/  211]    Overall Loss 0.023092    Objective Loss 0.023092                                        LR 0.000100    Time 0.690343    
2024-01-15 20:55:20,055 - Epoch: [179][   90/  211]    Overall Loss 0.023280    Objective Loss 0.023280                                        LR 0.000100    Time 0.685354    
2024-01-15 20:55:27,129 - Epoch: [179][  100/  211]    Overall Loss 0.023576    Objective Loss 0.023576                                        LR 0.000100    Time 0.687540    
2024-01-15 20:55:33,894 - Epoch: [179][  110/  211]    Overall Loss 0.023424    Objective Loss 0.023424                                        LR 0.000100    Time 0.686526    
2024-01-15 20:55:39,664 - Epoch: [179][  120/  211]    Overall Loss 0.023345    Objective Loss 0.023345                                        LR 0.000100    Time 0.677381    
2024-01-15 20:55:45,963 - Epoch: [179][  130/  211]    Overall Loss 0.023260    Objective Loss 0.023260                                        LR 0.000100    Time 0.673721    
2024-01-15 20:55:51,822 - Epoch: [179][  140/  211]    Overall Loss 0.022745    Objective Loss 0.022745                                        LR 0.000100    Time 0.667441    
2024-01-15 20:55:58,727 - Epoch: [179][  150/  211]    Overall Loss 0.022632    Objective Loss 0.022632                                        LR 0.000100    Time 0.668965    
2024-01-15 20:56:05,921 - Epoch: [179][  160/  211]    Overall Loss 0.022481    Objective Loss 0.022481                                        LR 0.000100    Time 0.672112    
2024-01-15 20:56:11,946 - Epoch: [179][  170/  211]    Overall Loss 0.022741    Objective Loss 0.022741                                        LR 0.000100    Time 0.668011    
2024-01-15 20:56:19,063 - Epoch: [179][  180/  211]    Overall Loss 0.023117    Objective Loss 0.023117                                        LR 0.000100    Time 0.670427    
2024-01-15 20:56:26,638 - Epoch: [179][  190/  211]    Overall Loss 0.022936    Objective Loss 0.022936                                        LR 0.000100    Time 0.674998    
2024-01-15 20:56:33,636 - Epoch: [179][  200/  211]    Overall Loss 0.022723    Objective Loss 0.022723                                        LR 0.000100    Time 0.676230    
2024-01-15 20:56:40,327 - Epoch: [179][  210/  211]    Overall Loss 0.022864    Objective Loss 0.022864    Top1 98.828125    Top5 100.000000    LR 0.000100    Time 0.675886    
2024-01-15 20:56:41,246 - Epoch: [179][  211/  211]    Overall Loss 0.022834    Objective Loss 0.022834    Top1 98.991935    Top5 100.000000    LR 0.000100    Time 0.677031    
2024-01-15 20:56:42,574 - --- validate (epoch=179)-----------
2024-01-15 20:56:42,577 - 6000 samples (256 per mini-batch)
2024-01-15 20:56:50,909 - Epoch: [179][   10/   24]    Loss 0.033507    Top1 98.945312    Top5 100.000000    
2024-01-15 20:56:53,362 - Epoch: [179][   20/   24]    Loss 0.026389    Top1 99.199219    Top5 100.000000    
2024-01-15 20:56:54,299 - Epoch: [179][   24/   24]    Loss 0.025843    Top1 99.150000    Top5 100.000000    
2024-01-15 20:56:55,291 - ==> Top1: 99.150    Top5: 100.000    Loss: 0.026

2024-01-15 20:56:55,293 - ==> Confusion:
[[602   0   1   0   0   0   1   0   0   1]
 [  0 684   1   0   0   1   0   2   0   0]
 [  0   0 582   2   0   0   0   0   2   0]
 [  0   0   1 581   0   1   0   0   0   0]
 [  0   1   0   0 554   0   0   2   0   8]
 [  0   0   0   2   0 512   4   0   0   0]
 [  0   1   0   0   2   0 628   0   0   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  0   0   0   3   2   0   2   0 576   1]
 [  0   0   0   1   4   0   0   1   2 607]]

2024-01-15 20:56:55,297 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:56:55,298 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:56:55,309 - 

2024-01-15 20:56:55,310 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:57:08,236 - Epoch: [180][   10/  211]    Overall Loss 0.021796    Objective Loss 0.021796                                        LR 0.000100    Time 1.292398    
2024-01-15 20:57:15,725 - Epoch: [180][   20/  211]    Overall Loss 0.020640    Objective Loss 0.020640                                        LR 0.000100    Time 1.020532    
2024-01-15 20:57:21,563 - Epoch: [180][   30/  211]    Overall Loss 0.022749    Objective Loss 0.022749                                        LR 0.000100    Time 0.874925    
2024-01-15 20:57:27,540 - Epoch: [180][   40/  211]    Overall Loss 0.023486    Objective Loss 0.023486                                        LR 0.000100    Time 0.805591    
2024-01-15 20:57:34,993 - Epoch: [180][   50/  211]    Overall Loss 0.024712    Objective Loss 0.024712                                        LR 0.000100    Time 0.793489    
2024-01-15 20:57:42,069 - Epoch: [180][   60/  211]    Overall Loss 0.023344    Objective Loss 0.023344                                        LR 0.000100    Time 0.779148    
2024-01-15 20:57:49,568 - Epoch: [180][   70/  211]    Overall Loss 0.022628    Objective Loss 0.022628                                        LR 0.000100    Time 0.774945    
2024-01-15 20:57:57,600 - Epoch: [180][   80/  211]    Overall Loss 0.023159    Objective Loss 0.023159                                        LR 0.000100    Time 0.778427    
2024-01-15 20:58:05,225 - Epoch: [180][   90/  211]    Overall Loss 0.023273    Objective Loss 0.023273                                        LR 0.000100    Time 0.776614    
2024-01-15 20:58:11,943 - Epoch: [180][  100/  211]    Overall Loss 0.023136    Objective Loss 0.023136                                        LR 0.000100    Time 0.766112    
2024-01-15 20:58:18,897 - Epoch: [180][  110/  211]    Overall Loss 0.023160    Objective Loss 0.023160                                        LR 0.000100    Time 0.759680    
2024-01-15 20:58:26,730 - Epoch: [180][  120/  211]    Overall Loss 0.022825    Objective Loss 0.022825                                        LR 0.000100    Time 0.761632    
2024-01-15 20:58:34,078 - Epoch: [180][  130/  211]    Overall Loss 0.022832    Objective Loss 0.022832                                        LR 0.000100    Time 0.759537    
2024-01-15 20:58:42,415 - Epoch: [180][  140/  211]    Overall Loss 0.022649    Objective Loss 0.022649                                        LR 0.000100    Time 0.764831    
2024-01-15 20:58:49,773 - Epoch: [180][  150/  211]    Overall Loss 0.022720    Objective Loss 0.022720                                        LR 0.000100    Time 0.762879    
2024-01-15 20:58:57,483 - Epoch: [180][  160/  211]    Overall Loss 0.022910    Objective Loss 0.022910                                        LR 0.000100    Time 0.763382    
2024-01-15 20:59:04,499 - Epoch: [180][  170/  211]    Overall Loss 0.022845    Objective Loss 0.022845                                        LR 0.000100    Time 0.759737    
2024-01-15 20:59:10,750 - Epoch: [180][  180/  211]    Overall Loss 0.022862    Objective Loss 0.022862                                        LR 0.000100    Time 0.752247    
2024-01-15 20:59:17,682 - Epoch: [180][  190/  211]    Overall Loss 0.022817    Objective Loss 0.022817                                        LR 0.000100    Time 0.749133    
2024-01-15 20:59:24,490 - Epoch: [180][  200/  211]    Overall Loss 0.022965    Objective Loss 0.022965                                        LR 0.000100    Time 0.745708    
2024-01-15 20:59:31,618 - Epoch: [180][  210/  211]    Overall Loss 0.022840    Objective Loss 0.022840    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.744130    
2024-01-15 20:59:32,190 - Epoch: [180][  211/  211]    Overall Loss 0.022825    Objective Loss 0.022825    Top1 99.395161    Top5 100.000000    LR 0.000100    Time 0.743314    
2024-01-15 20:59:33,695 - --- validate (epoch=180)-----------
2024-01-15 20:59:33,698 - 6000 samples (256 per mini-batch)
2024-01-15 20:59:41,831 - Epoch: [180][   10/   24]    Loss 0.017756    Top1 99.570312    Top5 100.000000    
2024-01-15 20:59:44,201 - Epoch: [180][   20/   24]    Loss 0.023693    Top1 99.296875    Top5 100.000000    
2024-01-15 20:59:45,095 - Epoch: [180][   24/   24]    Loss 0.022394    Top1 99.366667    Top5 100.000000    
2024-01-15 20:59:45,970 - ==> Top1: 99.367    Top5: 100.000    Loss: 0.022

2024-01-15 20:59:45,973 - ==> Confusion:
[[604   0   1   0   0   0   0   0   0   0]
 [  0 687   0   0   0   0   1   0   0   0]
 [  0   1 582   1   1   0   0   1   0   0]
 [  0   0   3 577   0   2   0   0   1   0]
 [  0   0   0   0 558   0   0   0   1   6]
 [  0   0   0   1   0 513   3   0   1   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  0   0   0   0   1   0   0   1 582   0]
 [  1   1   0   0   2   1   0   2   2 606]]

2024-01-15 20:59:45,978 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 20:59:45,978 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 20:59:45,988 - 

2024-01-15 20:59:45,988 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 20:59:57,510 - Epoch: [181][   10/  211]    Overall Loss 0.021438    Objective Loss 0.021438                                        LR 0.000100    Time 1.152049    
2024-01-15 21:00:04,170 - Epoch: [181][   20/  211]    Overall Loss 0.025154    Objective Loss 0.025154                                        LR 0.000100    Time 0.908928    
2024-01-15 21:00:10,469 - Epoch: [181][   30/  211]    Overall Loss 0.024135    Objective Loss 0.024135                                        LR 0.000100    Time 0.815887    
2024-01-15 21:00:16,876 - Epoch: [181][   40/  211]    Overall Loss 0.023570    Objective Loss 0.023570                                        LR 0.000100    Time 0.772051    
2024-01-15 21:00:23,502 - Epoch: [181][   50/  211]    Overall Loss 0.022832    Objective Loss 0.022832                                        LR 0.000100    Time 0.750127    
2024-01-15 21:00:31,303 - Epoch: [181][   60/  211]    Overall Loss 0.021889    Objective Loss 0.021889                                        LR 0.000100    Time 0.755084    
2024-01-15 21:00:39,444 - Epoch: [181][   70/  211]    Overall Loss 0.021452    Objective Loss 0.021452                                        LR 0.000100    Time 0.763483    
2024-01-15 21:00:45,534 - Epoch: [181][   80/  211]    Overall Loss 0.022112    Objective Loss 0.022112                                        LR 0.000100    Time 0.744025    
2024-01-15 21:00:52,567 - Epoch: [181][   90/  211]    Overall Loss 0.022469    Objective Loss 0.022469                                        LR 0.000100    Time 0.739474    
2024-01-15 21:01:00,874 - Epoch: [181][  100/  211]    Overall Loss 0.022259    Objective Loss 0.022259                                        LR 0.000100    Time 0.748575    
2024-01-15 21:01:07,257 - Epoch: [181][  110/  211]    Overall Loss 0.021742    Objective Loss 0.021742                                        LR 0.000100    Time 0.738532    
2024-01-15 21:01:14,198 - Epoch: [181][  120/  211]    Overall Loss 0.021660    Objective Loss 0.021660                                        LR 0.000100    Time 0.734816    
2024-01-15 21:01:21,770 - Epoch: [181][  130/  211]    Overall Loss 0.021554    Objective Loss 0.021554                                        LR 0.000100    Time 0.736525    
2024-01-15 21:01:29,818 - Epoch: [181][  140/  211]    Overall Loss 0.021695    Objective Loss 0.021695                                        LR 0.000100    Time 0.741385    
2024-01-15 21:01:37,226 - Epoch: [181][  150/  211]    Overall Loss 0.021660    Objective Loss 0.021660                                        LR 0.000100    Time 0.741334    
2024-01-15 21:01:43,484 - Epoch: [181][  160/  211]    Overall Loss 0.021614    Objective Loss 0.021614                                        LR 0.000100    Time 0.734106    
2024-01-15 21:01:50,947 - Epoch: [181][  170/  211]    Overall Loss 0.021645    Objective Loss 0.021645                                        LR 0.000100    Time 0.734808    
2024-01-15 21:01:57,634 - Epoch: [181][  180/  211]    Overall Loss 0.021606    Objective Loss 0.021606                                        LR 0.000100    Time 0.731125    
2024-01-15 21:02:03,943 - Epoch: [181][  190/  211]    Overall Loss 0.021430    Objective Loss 0.021430                                        LR 0.000100    Time 0.725846    
2024-01-15 21:02:11,894 - Epoch: [181][  200/  211]    Overall Loss 0.021599    Objective Loss 0.021599                                        LR 0.000100    Time 0.729298    
2024-01-15 21:02:18,752 - Epoch: [181][  210/  211]    Overall Loss 0.021542    Objective Loss 0.021542    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.727215    
2024-01-15 21:02:19,546 - Epoch: [181][  211/  211]    Overall Loss 0.021571    Objective Loss 0.021571    Top1 99.395161    Top5 100.000000    LR 0.000100    Time 0.727531    
2024-01-15 21:02:20,905 - --- validate (epoch=181)-----------
2024-01-15 21:02:20,907 - 6000 samples (256 per mini-batch)
2024-01-15 21:02:29,502 - Epoch: [181][   10/   24]    Loss 0.025782    Top1 99.375000    Top5 100.000000    
2024-01-15 21:02:31,866 - Epoch: [181][   20/   24]    Loss 0.023239    Top1 99.375000    Top5 100.000000    
2024-01-15 21:02:32,764 - Epoch: [181][   24/   24]    Loss 0.026175    Top1 99.333333    Top5 100.000000    
2024-01-15 21:02:33,534 - ==> Top1: 99.333    Top5: 100.000    Loss: 0.026

2024-01-15 21:02:33,537 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   0 582   1   0   0   0   3   0   0]
 [  0   0   0 580   0   2   0   0   1   0]
 [  0   0   0   0 560   0   1   0   0   4]
 [  0   0   0   1   0 515   2   0   0   0]
 [  0   1   0   0   2   0 628   0   0   0]
 [  0   2   2   0   0   0   0 621   0   0]
 [  0   0   0   0   0   1   1   0 581   1]
 [  0   1   0   0   2   2   0   3   3 604]]

2024-01-15 21:02:33,541 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:02:33,541 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:02:33,550 - 

2024-01-15 21:02:33,551 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:02:45,383 - Epoch: [182][   10/  211]    Overall Loss 0.019672    Objective Loss 0.019672                                        LR 0.000100    Time 1.182595    
2024-01-15 21:02:52,030 - Epoch: [182][   20/  211]    Overall Loss 0.021921    Objective Loss 0.021921                                        LR 0.000100    Time 0.923518    
2024-01-15 21:02:58,591 - Epoch: [182][   30/  211]    Overall Loss 0.019975    Objective Loss 0.019975                                        LR 0.000100    Time 0.834350    
2024-01-15 21:03:05,282 - Epoch: [182][   40/  211]    Overall Loss 0.019905    Objective Loss 0.019905                                        LR 0.000100    Time 0.792981    
2024-01-15 21:03:11,400 - Epoch: [182][   50/  211]    Overall Loss 0.022188    Objective Loss 0.022188                                        LR 0.000100    Time 0.756723    
2024-01-15 21:03:18,113 - Epoch: [182][   60/  211]    Overall Loss 0.021388    Objective Loss 0.021388                                        LR 0.000100    Time 0.742459    
2024-01-15 21:03:25,799 - Epoch: [182][   70/  211]    Overall Loss 0.021155    Objective Loss 0.021155                                        LR 0.000100    Time 0.746174    
2024-01-15 21:03:31,907 - Epoch: [182][   80/  211]    Overall Loss 0.021266    Objective Loss 0.021266                                        LR 0.000100    Time 0.729233    
2024-01-15 21:03:37,689 - Epoch: [182][   90/  211]    Overall Loss 0.021337    Objective Loss 0.021337                                        LR 0.000100    Time 0.712441    
2024-01-15 21:03:44,559 - Epoch: [182][  100/  211]    Overall Loss 0.021293    Objective Loss 0.021293                                        LR 0.000100    Time 0.709880    
2024-01-15 21:03:51,142 - Epoch: [182][  110/  211]    Overall Loss 0.021237    Objective Loss 0.021237                                        LR 0.000100    Time 0.705174    
2024-01-15 21:03:57,829 - Epoch: [182][  120/  211]    Overall Loss 0.020761    Objective Loss 0.020761                                        LR 0.000100    Time 0.702124    
2024-01-15 21:04:04,902 - Epoch: [182][  130/  211]    Overall Loss 0.020535    Objective Loss 0.020535                                        LR 0.000100    Time 0.702500    
2024-01-15 21:04:12,167 - Epoch: [182][  140/  211]    Overall Loss 0.020816    Objective Loss 0.020816                                        LR 0.000100    Time 0.704206    
2024-01-15 21:04:19,436 - Epoch: [182][  150/  211]    Overall Loss 0.020463    Objective Loss 0.020463                                        LR 0.000100    Time 0.705702    
2024-01-15 21:04:26,225 - Epoch: [182][  160/  211]    Overall Loss 0.020627    Objective Loss 0.020627                                        LR 0.000100    Time 0.704020    
2024-01-15 21:04:33,367 - Epoch: [182][  170/  211]    Overall Loss 0.020429    Objective Loss 0.020429                                        LR 0.000100    Time 0.704609    
2024-01-15 21:04:40,069 - Epoch: [182][  180/  211]    Overall Loss 0.020499    Objective Loss 0.020499                                        LR 0.000100    Time 0.702687    
2024-01-15 21:04:46,371 - Epoch: [182][  190/  211]    Overall Loss 0.020718    Objective Loss 0.020718                                        LR 0.000100    Time 0.698863    
2024-01-15 21:04:52,723 - Epoch: [182][  200/  211]    Overall Loss 0.020631    Objective Loss 0.020631                                        LR 0.000100    Time 0.695674    
2024-01-15 21:04:58,516 - Epoch: [182][  210/  211]    Overall Loss 0.020524    Objective Loss 0.020524    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.690124    
2024-01-15 21:04:59,100 - Epoch: [182][  211/  211]    Overall Loss 0.020481    Objective Loss 0.020481    Top1 99.596774    Top5 100.000000    LR 0.000100    Time 0.689619    
2024-01-15 21:05:00,122 - --- validate (epoch=182)-----------
2024-01-15 21:05:00,124 - 6000 samples (256 per mini-batch)
2024-01-15 21:05:06,971 - Epoch: [182][   10/   24]    Loss 0.027927    Top1 99.101562    Top5 99.960938    
2024-01-15 21:05:09,384 - Epoch: [182][   20/   24]    Loss 0.026890    Top1 99.218750    Top5 99.980469    
2024-01-15 21:05:10,168 - Epoch: [182][   24/   24]    Loss 0.025764    Top1 99.266667    Top5 99.983333    
2024-01-15 21:05:10,928 - ==> Top1: 99.267    Top5: 99.983    Loss: 0.026

2024-01-15 21:05:10,930 - ==> Confusion:
[[601   0   1   0   0   0   1   1   0   1]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 582   0   0   0   0   1   3   0]
 [  0   0   2 579   0   1   0   0   1   0]
 [  0   0   0   0 560   0   1   0   0   4]
 [  0   0   0   0   0 515   3   0   0   0]
 [  0   0   0   0   2   0 629   0   0   0]
 [  0   1   1   1   0   0   0 622   0   0]
 [  1   0   0   1   1   0   1   0 578   2]
 [  0   1   0   0   4   2   0   3   2 603]]

2024-01-15 21:05:10,932 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:05:10,932 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:05:10,938 - 

2024-01-15 21:05:10,938 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:05:20,192 - Epoch: [183][   10/  211]    Overall Loss 0.020313    Objective Loss 0.020313                                        LR 0.000100    Time 0.925302    
2024-01-15 21:05:26,025 - Epoch: [183][   20/  211]    Overall Loss 0.021141    Objective Loss 0.021141                                        LR 0.000100    Time 0.754078    
2024-01-15 21:05:32,102 - Epoch: [183][   30/  211]    Overall Loss 0.021245    Objective Loss 0.021245                                        LR 0.000100    Time 0.705222    
2024-01-15 21:05:37,862 - Epoch: [183][   40/  211]    Overall Loss 0.021766    Objective Loss 0.021766                                        LR 0.000100    Time 0.672898    
2024-01-15 21:05:43,572 - Epoch: [183][   50/  211]    Overall Loss 0.021762    Objective Loss 0.021762                                        LR 0.000100    Time 0.652497    
2024-01-15 21:05:49,458 - Epoch: [183][   60/  211]    Overall Loss 0.021961    Objective Loss 0.021961                                        LR 0.000100    Time 0.641826    
2024-01-15 21:05:56,125 - Epoch: [183][   70/  211]    Overall Loss 0.022391    Objective Loss 0.022391                                        LR 0.000100    Time 0.645325    
2024-01-15 21:06:02,578 - Epoch: [183][   80/  211]    Overall Loss 0.022901    Objective Loss 0.022901                                        LR 0.000100    Time 0.645296    
2024-01-15 21:06:09,814 - Epoch: [183][   90/  211]    Overall Loss 0.022554    Objective Loss 0.022554                                        LR 0.000100    Time 0.653943    
2024-01-15 21:06:16,274 - Epoch: [183][  100/  211]    Overall Loss 0.022386    Objective Loss 0.022386                                        LR 0.000100    Time 0.653123    
2024-01-15 21:06:22,712 - Epoch: [183][  110/  211]    Overall Loss 0.022604    Objective Loss 0.022604                                        LR 0.000100    Time 0.652263    
2024-01-15 21:06:29,686 - Epoch: [183][  120/  211]    Overall Loss 0.022297    Objective Loss 0.022297                                        LR 0.000100    Time 0.656008    
2024-01-15 21:06:36,118 - Epoch: [183][  130/  211]    Overall Loss 0.022260    Objective Loss 0.022260                                        LR 0.000100    Time 0.655009    
2024-01-15 21:06:42,505 - Epoch: [183][  140/  211]    Overall Loss 0.021931    Objective Loss 0.021931                                        LR 0.000100    Time 0.653840    
2024-01-15 21:06:49,013 - Epoch: [183][  150/  211]    Overall Loss 0.022243    Objective Loss 0.022243                                        LR 0.000100    Time 0.653627    
2024-01-15 21:06:55,443 - Epoch: [183][  160/  211]    Overall Loss 0.022359    Objective Loss 0.022359                                        LR 0.000100    Time 0.652949    
2024-01-15 21:07:02,306 - Epoch: [183][  170/  211]    Overall Loss 0.021950    Objective Loss 0.021950                                        LR 0.000100    Time 0.654899    
2024-01-15 21:07:08,421 - Epoch: [183][  180/  211]    Overall Loss 0.021812    Objective Loss 0.021812                                        LR 0.000100    Time 0.652474    
2024-01-15 21:07:14,681 - Epoch: [183][  190/  211]    Overall Loss 0.022229    Objective Loss 0.022229                                        LR 0.000100    Time 0.651072    
2024-01-15 21:07:21,276 - Epoch: [183][  200/  211]    Overall Loss 0.022226    Objective Loss 0.022226                                        LR 0.000100    Time 0.651489    
2024-01-15 21:07:27,474 - Epoch: [183][  210/  211]    Overall Loss 0.021941    Objective Loss 0.021941    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.649970    
2024-01-15 21:07:28,486 - Epoch: [183][  211/  211]    Overall Loss 0.022131    Objective Loss 0.022131    Top1 98.991935    Top5 100.000000    LR 0.000100    Time 0.651679    
2024-01-15 21:07:29,748 - --- validate (epoch=183)-----------
2024-01-15 21:07:29,749 - 6000 samples (256 per mini-batch)
2024-01-15 21:07:36,968 - Epoch: [183][   10/   24]    Loss 0.023255    Top1 99.492188    Top5 100.000000    
2024-01-15 21:07:39,155 - Epoch: [183][   20/   24]    Loss 0.025539    Top1 99.257812    Top5 100.000000    
2024-01-15 21:07:40,102 - Epoch: [183][   24/   24]    Loss 0.025674    Top1 99.250000    Top5 100.000000    
2024-01-15 21:07:40,920 - ==> Top1: 99.250    Top5: 100.000    Loss: 0.026

2024-01-15 21:07:40,922 - ==> Confusion:
[[602   0   1   0   0   0   2   0   0   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 584   1   0   0   0   1   0   0]
 [  0   0   0 578   0   2   0   1   2   0]
 [  0   0   0   0 560   0   0   0   0   5]
 [  1   0   0   1   0 512   3   0   1   0]
 [  0   1   0   0   2   0 626   0   2   0]
 [  0   2   0   0   0   0   0 622   0   1]
 [  0   0   0   0   1   1   2   0 580   0]
 [  0   1   0   0   1   1   0   3   4 605]]

2024-01-15 21:07:40,924 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:07:40,924 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:07:40,929 - 

2024-01-15 21:07:40,929 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:07:52,046 - Epoch: [184][   10/  211]    Overall Loss 0.022900    Objective Loss 0.022900                                        LR 0.000100    Time 1.111633    
2024-01-15 21:07:58,602 - Epoch: [184][   20/  211]    Overall Loss 0.025215    Objective Loss 0.025215                                        LR 0.000100    Time 0.883496    
2024-01-15 21:08:05,093 - Epoch: [184][   30/  211]    Overall Loss 0.023667    Objective Loss 0.023667                                        LR 0.000100    Time 0.805257    
2024-01-15 21:08:11,480 - Epoch: [184][   40/  211]    Overall Loss 0.021701    Objective Loss 0.021701                                        LR 0.000100    Time 0.763591    
2024-01-15 21:08:17,771 - Epoch: [184][   50/  211]    Overall Loss 0.021013    Objective Loss 0.021013                                        LR 0.000100    Time 0.736665    
2024-01-15 21:08:24,500 - Epoch: [184][   60/  211]    Overall Loss 0.021078    Objective Loss 0.021078                                        LR 0.000100    Time 0.726013    
2024-01-15 21:08:31,414 - Epoch: [184][   70/  211]    Overall Loss 0.020522    Objective Loss 0.020522                                        LR 0.000100    Time 0.721043    
2024-01-15 21:08:37,468 - Epoch: [184][   80/  211]    Overall Loss 0.020785    Objective Loss 0.020785                                        LR 0.000100    Time 0.706571    
2024-01-15 21:08:43,810 - Epoch: [184][   90/  211]    Overall Loss 0.020900    Objective Loss 0.020900                                        LR 0.000100    Time 0.698505    
2024-01-15 21:08:50,730 - Epoch: [184][  100/  211]    Overall Loss 0.021717    Objective Loss 0.021717                                        LR 0.000100    Time 0.697843    
2024-01-15 21:08:57,221 - Epoch: [184][  110/  211]    Overall Loss 0.021806    Objective Loss 0.021806                                        LR 0.000100    Time 0.693396    
2024-01-15 21:09:03,608 - Epoch: [184][  120/  211]    Overall Loss 0.022022    Objective Loss 0.022022                                        LR 0.000100    Time 0.688823    
2024-01-15 21:09:10,165 - Epoch: [184][  130/  211]    Overall Loss 0.021836    Objective Loss 0.021836                                        LR 0.000100    Time 0.686264    
2024-01-15 21:09:16,847 - Epoch: [184][  140/  211]    Overall Loss 0.021527    Objective Loss 0.021527                                        LR 0.000100    Time 0.684962    
2024-01-15 21:09:23,390 - Epoch: [184][  150/  211]    Overall Loss 0.022080    Objective Loss 0.022080                                        LR 0.000100    Time 0.682898    
2024-01-15 21:09:29,843 - Epoch: [184][  160/  211]    Overall Loss 0.022371    Objective Loss 0.022371                                        LR 0.000100    Time 0.680535    
2024-01-15 21:09:35,906 - Epoch: [184][  170/  211]    Overall Loss 0.022195    Objective Loss 0.022195                                        LR 0.000100    Time 0.676159    
2024-01-15 21:09:42,181 - Epoch: [184][  180/  211]    Overall Loss 0.021866    Objective Loss 0.021866                                        LR 0.000100    Time 0.673446    
2024-01-15 21:09:48,395 - Epoch: [184][  190/  211]    Overall Loss 0.021638    Objective Loss 0.021638                                        LR 0.000100    Time 0.670699    
2024-01-15 21:09:55,016 - Epoch: [184][  200/  211]    Overall Loss 0.021438    Objective Loss 0.021438                                        LR 0.000100    Time 0.670259    
2024-01-15 21:10:01,481 - Epoch: [184][  210/  211]    Overall Loss 0.021277    Objective Loss 0.021277    Top1 100.000000    Top5 100.000000    LR 0.000100    Time 0.669117    
2024-01-15 21:10:02,061 - Epoch: [184][  211/  211]    Overall Loss 0.021219    Objective Loss 0.021219    Top1 100.000000    Top5 100.000000    LR 0.000100    Time 0.668692    
2024-01-15 21:10:02,819 - --- validate (epoch=184)-----------
2024-01-15 21:10:02,820 - 6000 samples (256 per mini-batch)
2024-01-15 21:10:09,513 - Epoch: [184][   10/   24]    Loss 0.026116    Top1 99.218750    Top5 100.000000    
2024-01-15 21:10:11,958 - Epoch: [184][   20/   24]    Loss 0.027697    Top1 99.121094    Top5 100.000000    
2024-01-15 21:10:12,765 - Epoch: [184][   24/   24]    Loss 0.026382    Top1 99.166667    Top5 100.000000    
2024-01-15 21:10:13,503 - ==> Top1: 99.167    Top5: 100.000    Loss: 0.026

2024-01-15 21:10:13,504 - ==> Confusion:
[[601   0   1   0   0   0   2   0   1   0]
 [  0 687   0   0   0   0   0   1   0   0]
 [  0   0 580   2   0   0   0   3   1   0]
 [  0   0   0 580   0   1   0   1   1   0]
 [  0   0   0   0 561   0   0   1   0   3]
 [  1   1   0   1   1 508   4   1   1   0]
 [  1   1   0   0   1   0 628   0   0   0]
 [  0   2   0   1   0   0   0 622   0   0]
 [  1   0   0   1   0   0   2   0 580   0]
 [  1   0   0   0   4   1   0   4   2 603]]

2024-01-15 21:10:13,506 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:10:13,506 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:10:13,511 - 

2024-01-15 21:10:13,511 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:10:23,505 - Epoch: [185][   10/  211]    Overall Loss 0.020961    Objective Loss 0.020961                                        LR 0.000100    Time 0.999334    
2024-01-15 21:10:30,846 - Epoch: [185][   20/  211]    Overall Loss 0.023294    Objective Loss 0.023294                                        LR 0.000100    Time 0.866571    
2024-01-15 21:10:36,965 - Epoch: [185][   30/  211]    Overall Loss 0.024408    Objective Loss 0.024408                                        LR 0.000100    Time 0.781600    
2024-01-15 21:10:42,945 - Epoch: [185][   40/  211]    Overall Loss 0.024660    Objective Loss 0.024660                                        LR 0.000100    Time 0.735661    
2024-01-15 21:10:49,390 - Epoch: [185][   50/  211]    Overall Loss 0.024269    Objective Loss 0.024269                                        LR 0.000100    Time 0.717406    
2024-01-15 21:10:55,524 - Epoch: [185][   60/  211]    Overall Loss 0.023470    Objective Loss 0.023470                                        LR 0.000100    Time 0.700041    
2024-01-15 21:11:01,969 - Epoch: [185][   70/  211]    Overall Loss 0.022954    Objective Loss 0.022954                                        LR 0.000100    Time 0.692069    
2024-01-15 21:11:09,139 - Epoch: [185][   80/  211]    Overall Loss 0.023006    Objective Loss 0.023006                                        LR 0.000100    Time 0.695171    
2024-01-15 21:11:15,214 - Epoch: [185][   90/  211]    Overall Loss 0.023193    Objective Loss 0.023193                                        LR 0.000100    Time 0.685415    
2024-01-15 21:11:22,249 - Epoch: [185][  100/  211]    Overall Loss 0.022846    Objective Loss 0.022846                                        LR 0.000100    Time 0.687210    
2024-01-15 21:11:28,568 - Epoch: [185][  110/  211]    Overall Loss 0.022295    Objective Loss 0.022295                                        LR 0.000100    Time 0.682166    
2024-01-15 21:11:35,177 - Epoch: [185][  120/  211]    Overall Loss 0.022207    Objective Loss 0.022207                                        LR 0.000100    Time 0.680375    
2024-01-15 21:11:41,001 - Epoch: [185][  130/  211]    Overall Loss 0.022077    Objective Loss 0.022077                                        LR 0.000100    Time 0.672828    
2024-01-15 21:11:47,163 - Epoch: [185][  140/  211]    Overall Loss 0.022185    Objective Loss 0.022185                                        LR 0.000100    Time 0.668768    
2024-01-15 21:11:53,271 - Epoch: [185][  150/  211]    Overall Loss 0.022595    Objective Loss 0.022595                                        LR 0.000100    Time 0.664891    
2024-01-15 21:11:59,219 - Epoch: [185][  160/  211]    Overall Loss 0.022627    Objective Loss 0.022627                                        LR 0.000100    Time 0.660499    
2024-01-15 21:12:05,034 - Epoch: [185][  170/  211]    Overall Loss 0.022805    Objective Loss 0.022805                                        LR 0.000100    Time 0.655848    
2024-01-15 21:12:12,610 - Epoch: [185][  180/  211]    Overall Loss 0.022579    Objective Loss 0.022579                                        LR 0.000100    Time 0.661492    
2024-01-15 21:12:19,713 - Epoch: [185][  190/  211]    Overall Loss 0.022456    Objective Loss 0.022456                                        LR 0.000100    Time 0.664050    
2024-01-15 21:12:27,817 - Epoch: [185][  200/  211]    Overall Loss 0.022255    Objective Loss 0.022255                                        LR 0.000100    Time 0.671359    
2024-01-15 21:12:34,592 - Epoch: [185][  210/  211]    Overall Loss 0.022155    Objective Loss 0.022155    Top1 99.218750    Top5 100.000000    LR 0.000100    Time 0.671643    
2024-01-15 21:12:35,313 - Epoch: [185][  211/  211]    Overall Loss 0.022149    Objective Loss 0.022149    Top1 99.193548    Top5 100.000000    LR 0.000100    Time 0.671869    
2024-01-15 21:12:36,815 - --- validate (epoch=185)-----------
2024-01-15 21:12:36,817 - 6000 samples (256 per mini-batch)
2024-01-15 21:12:44,558 - Epoch: [185][   10/   24]    Loss 0.031748    Top1 99.023438    Top5 100.000000    
2024-01-15 21:12:46,789 - Epoch: [185][   20/   24]    Loss 0.027477    Top1 99.140625    Top5 100.000000    
2024-01-15 21:12:47,727 - Epoch: [185][   24/   24]    Loss 0.029091    Top1 99.100000    Top5 100.000000    
2024-01-15 21:12:48,556 - ==> Top1: 99.100    Top5: 100.000    Loss: 0.029

2024-01-15 21:12:48,558 - ==> Confusion:
[[605   0   0   0   0   0   0   0   0   0]
 [  0 684   1   1   0   1   0   1   0   0]
 [  0   0 584   0   0   0   1   1   0   0]
 [  0   1   2 578   0   1   0   1   0   0]
 [  0   1   0   0 555   0   1   0   0   8]
 [  0   0   0   2   0 514   2   0   0   0]
 [  0   2   0   0   1   0 626   0   2   0]
 [  0   3   2   0   1   0   0 619   0   0]
 [  0   0   0   0   1   0   2   1 580   0]
 [  0   2   0   0   5   1   1   2   3 601]]

2024-01-15 21:12:48,563 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:12:48,563 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:12:48,569 - 

2024-01-15 21:12:48,569 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:12:58,289 - Epoch: [186][   10/  211]    Overall Loss 0.023364    Objective Loss 0.023364                                        LR 0.000100    Time 0.971850    
2024-01-15 21:13:05,809 - Epoch: [186][   20/  211]    Overall Loss 0.023140    Objective Loss 0.023140                                        LR 0.000100    Time 0.861811    
2024-01-15 21:13:12,111 - Epoch: [186][   30/  211]    Overall Loss 0.024559    Objective Loss 0.024559                                        LR 0.000100    Time 0.784497    
2024-01-15 21:13:18,225 - Epoch: [186][   40/  211]    Overall Loss 0.025071    Objective Loss 0.025071                                        LR 0.000100    Time 0.741177    
2024-01-15 21:13:24,693 - Epoch: [186][   50/  211]    Overall Loss 0.024060    Objective Loss 0.024060                                        LR 0.000100    Time 0.722282    
2024-01-15 21:13:31,555 - Epoch: [186][   60/  211]    Overall Loss 0.023607    Objective Loss 0.023607                                        LR 0.000100    Time 0.716232    
2024-01-15 21:13:37,886 - Epoch: [186][   70/  211]    Overall Loss 0.023851    Objective Loss 0.023851                                        LR 0.000100    Time 0.704343    
2024-01-15 21:13:44,768 - Epoch: [186][   80/  211]    Overall Loss 0.024054    Objective Loss 0.024054                                        LR 0.000100    Time 0.702294    
2024-01-15 21:13:51,511 - Epoch: [186][   90/  211]    Overall Loss 0.024372    Objective Loss 0.024372                                        LR 0.000100    Time 0.699167    
2024-01-15 21:13:58,022 - Epoch: [186][  100/  211]    Overall Loss 0.024134    Objective Loss 0.024134                                        LR 0.000100    Time 0.694349    
2024-01-15 21:14:04,176 - Epoch: [186][  110/  211]    Overall Loss 0.023766    Objective Loss 0.023766                                        LR 0.000100    Time 0.687159    
2024-01-15 21:14:10,621 - Epoch: [186][  120/  211]    Overall Loss 0.023474    Objective Loss 0.023474                                        LR 0.000100    Time 0.683596    
2024-01-15 21:14:16,874 - Epoch: [186][  130/  211]    Overall Loss 0.022921    Objective Loss 0.022921                                        LR 0.000100    Time 0.679095    
2024-01-15 21:14:22,796 - Epoch: [186][  140/  211]    Overall Loss 0.022330    Objective Loss 0.022330                                        LR 0.000100    Time 0.672873    
2024-01-15 21:14:29,660 - Epoch: [186][  150/  211]    Overall Loss 0.022241    Objective Loss 0.022241                                        LR 0.000100    Time 0.673759    
2024-01-15 21:14:36,125 - Epoch: [186][  160/  211]    Overall Loss 0.022232    Objective Loss 0.022232                                        LR 0.000100    Time 0.672017    
2024-01-15 21:14:42,507 - Epoch: [186][  170/  211]    Overall Loss 0.022346    Objective Loss 0.022346                                        LR 0.000100    Time 0.670018    
2024-01-15 21:14:49,170 - Epoch: [186][  180/  211]    Overall Loss 0.022225    Objective Loss 0.022225                                        LR 0.000100    Time 0.669800    
2024-01-15 21:14:56,128 - Epoch: [186][  190/  211]    Overall Loss 0.021913    Objective Loss 0.021913                                        LR 0.000100    Time 0.671161    
2024-01-15 21:15:02,825 - Epoch: [186][  200/  211]    Overall Loss 0.022235    Objective Loss 0.022235                                        LR 0.000100    Time 0.671079    
2024-01-15 21:15:09,491 - Epoch: [186][  210/  211]    Overall Loss 0.021825    Objective Loss 0.021825    Top1 100.000000    Top5 100.000000    LR 0.000100    Time 0.670854    
2024-01-15 21:15:10,213 - Epoch: [186][  211/  211]    Overall Loss 0.021760    Objective Loss 0.021760    Top1 100.000000    Top5 100.000000    LR 0.000100    Time 0.671093    
2024-01-15 21:15:11,186 - --- validate (epoch=186)-----------
2024-01-15 21:15:11,188 - 6000 samples (256 per mini-batch)
2024-01-15 21:15:18,829 - Epoch: [186][   10/   24]    Loss 0.025556    Top1 99.179688    Top5 100.000000    
2024-01-15 21:15:21,135 - Epoch: [186][   20/   24]    Loss 0.024190    Top1 99.296875    Top5 100.000000    
2024-01-15 21:15:21,919 - Epoch: [186][   24/   24]    Loss 0.023806    Top1 99.333333    Top5 100.000000    
2024-01-15 21:15:22,635 - ==> Top1: 99.333    Top5: 100.000    Loss: 0.024

2024-01-15 21:15:22,636 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   0   0   1   0   1   0   0   0]
 [  0   0 584   1   0   0   0   1   0   0]
 [  0   0   0 581   0   1   0   0   1   0]
 [  0   0   0   0 561   0   0   0   0   4]
 [  0   1   0   1   1 510   3   0   1   1]
 [  0   1   0   0   2   0 626   0   2   0]
 [  0   1   0   1   0   0   0 623   0   0]
 [  0   0   0   1   0   1   2   0 579   1]
 [  0   0   0   0   2   2   0   2   2 607]]

2024-01-15 21:15:22,638 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:15:22,639 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:15:22,643 - 

2024-01-15 21:15:22,643 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:15:32,815 - Epoch: [187][   10/  211]    Overall Loss 0.028235    Objective Loss 0.028235                                        LR 0.000100    Time 1.017057    
2024-01-15 21:15:39,316 - Epoch: [187][   20/  211]    Overall Loss 0.023671    Objective Loss 0.023671                                        LR 0.000100    Time 0.833458    
2024-01-15 21:15:46,046 - Epoch: [187][   30/  211]    Overall Loss 0.024006    Objective Loss 0.024006                                        LR 0.000100    Time 0.779933    
2024-01-15 21:15:52,275 - Epoch: [187][   40/  211]    Overall Loss 0.023278    Objective Loss 0.023278                                        LR 0.000100    Time 0.740614    
2024-01-15 21:15:58,771 - Epoch: [187][   50/  211]    Overall Loss 0.022080    Objective Loss 0.022080                                        LR 0.000100    Time 0.722380    
2024-01-15 21:16:05,925 - Epoch: [187][   60/  211]    Overall Loss 0.023318    Objective Loss 0.023318                                        LR 0.000100    Time 0.721177    
2024-01-15 21:16:11,902 - Epoch: [187][   70/  211]    Overall Loss 0.022791    Objective Loss 0.022791                                        LR 0.000100    Time 0.703511    
2024-01-15 21:16:18,292 - Epoch: [187][   80/  211]    Overall Loss 0.022983    Objective Loss 0.022983                                        LR 0.000100    Time 0.695436    
2024-01-15 21:16:24,825 - Epoch: [187][   90/  211]    Overall Loss 0.023497    Objective Loss 0.023497                                        LR 0.000100    Time 0.690710    
2024-01-15 21:16:31,574 - Epoch: [187][  100/  211]    Overall Loss 0.023407    Objective Loss 0.023407                                        LR 0.000100    Time 0.689084    
2024-01-15 21:16:38,395 - Epoch: [187][  110/  211]    Overall Loss 0.023565    Objective Loss 0.023565                                        LR 0.000100    Time 0.688434    
2024-01-15 21:16:45,031 - Epoch: [187][  120/  211]    Overall Loss 0.023532    Objective Loss 0.023532                                        LR 0.000100    Time 0.686358    
2024-01-15 21:16:51,400 - Epoch: [187][  130/  211]    Overall Loss 0.022923    Objective Loss 0.022923                                        LR 0.000100    Time 0.682542    
2024-01-15 21:16:57,755 - Epoch: [187][  140/  211]    Overall Loss 0.022723    Objective Loss 0.022723                                        LR 0.000100    Time 0.679165    
2024-01-15 21:17:04,239 - Epoch: [187][  150/  211]    Overall Loss 0.022531    Objective Loss 0.022531                                        LR 0.000100    Time 0.677097    
2024-01-15 21:17:10,443 - Epoch: [187][  160/  211]    Overall Loss 0.022437    Objective Loss 0.022437                                        LR 0.000100    Time 0.673537    
2024-01-15 21:17:16,938 - Epoch: [187][  170/  211]    Overall Loss 0.022260    Objective Loss 0.022260                                        LR 0.000100    Time 0.672111    
2024-01-15 21:17:23,243 - Epoch: [187][  180/  211]    Overall Loss 0.021926    Objective Loss 0.021926                                        LR 0.000100    Time 0.669791    
2024-01-15 21:17:29,354 - Epoch: [187][  190/  211]    Overall Loss 0.022168    Objective Loss 0.022168                                        LR 0.000100    Time 0.666688    
2024-01-15 21:17:35,426 - Epoch: [187][  200/  211]    Overall Loss 0.021995    Objective Loss 0.021995                                        LR 0.000100    Time 0.663709    
2024-01-15 21:17:41,589 - Epoch: [187][  210/  211]    Overall Loss 0.022133    Objective Loss 0.022133    Top1 99.218750    Top5 100.000000    LR 0.000100    Time 0.661446    
2024-01-15 21:17:42,237 - Epoch: [187][  211/  211]    Overall Loss 0.022129    Objective Loss 0.022129    Top1 99.193548    Top5 100.000000    LR 0.000100    Time 0.661378    
2024-01-15 21:17:43,130 - --- validate (epoch=187)-----------
2024-01-15 21:17:43,132 - 6000 samples (256 per mini-batch)
2024-01-15 21:17:50,351 - Epoch: [187][   10/   24]    Loss 0.027656    Top1 99.179688    Top5 100.000000    
2024-01-15 21:17:53,011 - Epoch: [187][   20/   24]    Loss 0.028823    Top1 99.121094    Top5 100.000000    
2024-01-15 21:17:53,815 - Epoch: [187][   24/   24]    Loss 0.027707    Top1 99.166667    Top5 100.000000    
2024-01-15 21:17:54,613 - ==> Top1: 99.167    Top5: 100.000    Loss: 0.028

2024-01-15 21:17:54,615 - ==> Confusion:
[[604   0   0   0   0   0   0   0   0   1]
 [  0 686   0   0   0   1   0   1   0   0]
 [  0   0 582   0   0   1   0   2   1   0]
 [  0   1   3 576   0   1   0   1   1   0]
 [  0   0   0   0 559   0   0   0   0   6]
 [  0   2   0   1   0 510   5   0   0   0]
 [  0   0   0   0   1   0 629   0   1   0]
 [  0   2   1   0   0   0   0 622   0   0]
 [  1   0   1   1   1   0   1   0 579   0]
 [  1   1   0   1   4   1   0   2   2 603]]

2024-01-15 21:17:54,617 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:17:54,618 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:17:54,623 - 

2024-01-15 21:17:54,624 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:18:05,422 - Epoch: [188][   10/  211]    Overall Loss 0.015785    Objective Loss 0.015785                                        LR 0.000100    Time 1.079684    
2024-01-15 21:18:11,783 - Epoch: [188][   20/  211]    Overall Loss 0.017315    Objective Loss 0.017315                                        LR 0.000100    Time 0.857845    
2024-01-15 21:18:17,727 - Epoch: [188][   30/  211]    Overall Loss 0.017992    Objective Loss 0.017992                                        LR 0.000100    Time 0.769980    
2024-01-15 21:18:24,076 - Epoch: [188][   40/  211]    Overall Loss 0.017588    Objective Loss 0.017588                                        LR 0.000100    Time 0.736177    
2024-01-15 21:18:30,677 - Epoch: [188][   50/  211]    Overall Loss 0.017926    Objective Loss 0.017926                                        LR 0.000100    Time 0.720948    
2024-01-15 21:18:36,548 - Epoch: [188][   60/  211]    Overall Loss 0.019422    Objective Loss 0.019422                                        LR 0.000100    Time 0.698616    
2024-01-15 21:18:42,519 - Epoch: [188][   70/  211]    Overall Loss 0.019462    Objective Loss 0.019462                                        LR 0.000100    Time 0.684093    
2024-01-15 21:18:48,510 - Epoch: [188][   80/  211]    Overall Loss 0.019693    Objective Loss 0.019693                                        LR 0.000100    Time 0.673453    
2024-01-15 21:18:54,257 - Epoch: [188][   90/  211]    Overall Loss 0.019786    Objective Loss 0.019786                                        LR 0.000100    Time 0.662465    
2024-01-15 21:18:59,962 - Epoch: [188][  100/  211]    Overall Loss 0.020124    Objective Loss 0.020124                                        LR 0.000100    Time 0.653257    
2024-01-15 21:19:05,641 - Epoch: [188][  110/  211]    Overall Loss 0.019995    Objective Loss 0.019995                                        LR 0.000100    Time 0.645486    
2024-01-15 21:19:11,619 - Epoch: [188][  120/  211]    Overall Loss 0.020375    Objective Loss 0.020375                                        LR 0.000100    Time 0.641501    
2024-01-15 21:19:17,351 - Epoch: [188][  130/  211]    Overall Loss 0.020510    Objective Loss 0.020510                                        LR 0.000100    Time 0.636234    
2024-01-15 21:19:23,052 - Epoch: [188][  140/  211]    Overall Loss 0.020814    Objective Loss 0.020814                                        LR 0.000100    Time 0.631511    
2024-01-15 21:19:29,338 - Epoch: [188][  150/  211]    Overall Loss 0.021236    Objective Loss 0.021236                                        LR 0.000100    Time 0.631300    
2024-01-15 21:19:35,939 - Epoch: [188][  160/  211]    Overall Loss 0.021100    Objective Loss 0.021100                                        LR 0.000100    Time 0.633092    
2024-01-15 21:19:43,506 - Epoch: [188][  170/  211]    Overall Loss 0.021635    Objective Loss 0.021635                                        LR 0.000100    Time 0.640353    
2024-01-15 21:19:49,842 - Epoch: [188][  180/  211]    Overall Loss 0.021874    Objective Loss 0.021874                                        LR 0.000100    Time 0.639971    
2024-01-15 21:19:56,348 - Epoch: [188][  190/  211]    Overall Loss 0.021912    Objective Loss 0.021912                                        LR 0.000100    Time 0.640525    
2024-01-15 21:20:02,911 - Epoch: [188][  200/  211]    Overall Loss 0.021781    Objective Loss 0.021781                                        LR 0.000100    Time 0.641305    
2024-01-15 21:20:08,885 - Epoch: [188][  210/  211]    Overall Loss 0.021767    Objective Loss 0.021767    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.639208    
2024-01-15 21:20:09,541 - Epoch: [188][  211/  211]    Overall Loss 0.021752    Objective Loss 0.021752    Top1 99.395161    Top5 100.000000    LR 0.000100    Time 0.639283    
2024-01-15 21:20:10,496 - --- validate (epoch=188)-----------
2024-01-15 21:20:10,499 - 6000 samples (256 per mini-batch)
2024-01-15 21:20:17,911 - Epoch: [188][   10/   24]    Loss 0.027474    Top1 98.945312    Top5 100.000000    
2024-01-15 21:20:20,279 - Epoch: [188][   20/   24]    Loss 0.025222    Top1 99.218750    Top5 100.000000    
2024-01-15 21:20:21,127 - Epoch: [188][   24/   24]    Loss 0.027039    Top1 99.183333    Top5 100.000000    
2024-01-15 21:20:21,982 - ==> Top1: 99.183    Top5: 100.000    Loss: 0.027

2024-01-15 21:20:21,985 - ==> Confusion:
[[603   0   1   0   0   0   0   0   0   1]
 [  0 685   1   0   0   1   0   1   0   0]
 [  0   0 579   3   1   0   0   2   1   0]
 [  0   0   0 581   0   1   0   1   0   0]
 [  0   0   0   0 557   1   1   1   0   5]
 [  0   0   0   2   0 513   2   0   1   0]
 [  0   1   0   0   1   0 628   0   1   0]
 [  0   2   0   1   1   0   0 621   0   0]
 [  0   0   0   1   0   0   3   0 579   1]
 [  0   1   0   0   5   0   0   2   2 605]]

2024-01-15 21:20:21,989 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:20:21,989 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:20:21,996 - 

2024-01-15 21:20:21,996 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:20:32,456 - Epoch: [189][   10/  211]    Overall Loss 0.026486    Objective Loss 0.026486                                        LR 0.000100    Time 1.045828    
2024-01-15 21:20:38,918 - Epoch: [189][   20/  211]    Overall Loss 0.024237    Objective Loss 0.024237                                        LR 0.000100    Time 0.845948    
2024-01-15 21:20:45,325 - Epoch: [189][   30/  211]    Overall Loss 0.023696    Objective Loss 0.023696                                        LR 0.000100    Time 0.777428    
2024-01-15 21:20:51,504 - Epoch: [189][   40/  211]    Overall Loss 0.023334    Objective Loss 0.023334                                        LR 0.000100    Time 0.737434    
2024-01-15 21:20:58,187 - Epoch: [189][   50/  211]    Overall Loss 0.023011    Objective Loss 0.023011                                        LR 0.000100    Time 0.723567    
2024-01-15 21:21:04,654 - Epoch: [189][   60/  211]    Overall Loss 0.022571    Objective Loss 0.022571                                        LR 0.000100    Time 0.710716    
2024-01-15 21:21:11,244 - Epoch: [189][   70/  211]    Overall Loss 0.021850    Objective Loss 0.021850                                        LR 0.000100    Time 0.703297    
2024-01-15 21:21:17,287 - Epoch: [189][   80/  211]    Overall Loss 0.022275    Objective Loss 0.022275                                        LR 0.000100    Time 0.690904    
2024-01-15 21:21:24,135 - Epoch: [189][   90/  211]    Overall Loss 0.021981    Objective Loss 0.021981                                        LR 0.000100    Time 0.690214    
2024-01-15 21:21:30,355 - Epoch: [189][  100/  211]    Overall Loss 0.022573    Objective Loss 0.022573                                        LR 0.000100    Time 0.683372    
2024-01-15 21:21:37,232 - Epoch: [189][  110/  211]    Overall Loss 0.022331    Objective Loss 0.022331                                        LR 0.000100    Time 0.683748    
2024-01-15 21:21:43,819 - Epoch: [189][  120/  211]    Overall Loss 0.022265    Objective Loss 0.022265                                        LR 0.000100    Time 0.681639    
2024-01-15 21:21:50,163 - Epoch: [189][  130/  211]    Overall Loss 0.022219    Objective Loss 0.022219                                        LR 0.000100    Time 0.677989    
2024-01-15 21:21:56,520 - Epoch: [189][  140/  211]    Overall Loss 0.022103    Objective Loss 0.022103                                        LR 0.000100    Time 0.674960    
2024-01-15 21:22:02,914 - Epoch: [189][  150/  211]    Overall Loss 0.022384    Objective Loss 0.022384                                        LR 0.000100    Time 0.672578    
2024-01-15 21:22:09,372 - Epoch: [189][  160/  211]    Overall Loss 0.022168    Objective Loss 0.022168                                        LR 0.000100    Time 0.670892    
2024-01-15 21:22:16,219 - Epoch: [189][  170/  211]    Overall Loss 0.021945    Objective Loss 0.021945                                        LR 0.000100    Time 0.671696    
2024-01-15 21:22:22,281 - Epoch: [189][  180/  211]    Overall Loss 0.021481    Objective Loss 0.021481                                        LR 0.000100    Time 0.668051    
2024-01-15 21:22:29,174 - Epoch: [189][  190/  211]    Overall Loss 0.021433    Objective Loss 0.021433                                        LR 0.000100    Time 0.669160    
2024-01-15 21:22:35,595 - Epoch: [189][  200/  211]    Overall Loss 0.021366    Objective Loss 0.021366                                        LR 0.000100    Time 0.667799    
2024-01-15 21:22:41,935 - Epoch: [189][  210/  211]    Overall Loss 0.021299    Objective Loss 0.021299    Top1 99.218750    Top5 100.000000    LR 0.000100    Time 0.666181    
2024-01-15 21:22:42,533 - Epoch: [189][  211/  211]    Overall Loss 0.021440    Objective Loss 0.021440    Top1 98.588710    Top5 100.000000    LR 0.000100    Time 0.665857    
2024-01-15 21:22:43,728 - --- validate (epoch=189)-----------
2024-01-15 21:22:43,730 - 6000 samples (256 per mini-batch)
2024-01-15 21:22:51,070 - Epoch: [189][   10/   24]    Loss 0.025137    Top1 99.218750    Top5 100.000000    
2024-01-15 21:22:53,436 - Epoch: [189][   20/   24]    Loss 0.025942    Top1 99.218750    Top5 100.000000    
2024-01-15 21:22:54,256 - Epoch: [189][   24/   24]    Loss 0.026799    Top1 99.183333    Top5 100.000000    
2024-01-15 21:22:54,930 - ==> Top1: 99.183    Top5: 100.000    Loss: 0.027

2024-01-15 21:22:54,931 - ==> Confusion:
[[603   0   0   0   0   0   2   0   0   0]
 [  0 686   1   0   0   1   0   0   0   0]
 [  0   0 583   2   0   0   0   0   1   0]
 [  0   0   1 579   0   1   0   1   1   0]
 [  0   1   0   0 556   0   0   1   1   6]
 [  1   0   0   1   0 512   2   0   2   0]
 [  1   1   0   0   2   0 626   0   1   0]
 [  1   1   1   0   0   0   0 622   0   0]
 [  0   0   1   0   0   1   1   1 580   0]
 [  0   1   0   0   4   1   1   2   2 604]]

2024-01-15 21:22:54,934 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:22:54,934 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:22:54,939 - 

2024-01-15 21:22:54,940 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:23:04,324 - Epoch: [190][   10/  211]    Overall Loss 0.020151    Objective Loss 0.020151                                        LR 0.000100    Time 0.938337    
2024-01-15 21:23:10,560 - Epoch: [190][   20/  211]    Overall Loss 0.023308    Objective Loss 0.023308                                        LR 0.000100    Time 0.780892    
2024-01-15 21:23:17,038 - Epoch: [190][   30/  211]    Overall Loss 0.022679    Objective Loss 0.022679                                        LR 0.000100    Time 0.736470    
2024-01-15 21:23:23,552 - Epoch: [190][   40/  211]    Overall Loss 0.022120    Objective Loss 0.022120                                        LR 0.000100    Time 0.715155    
2024-01-15 21:23:29,667 - Epoch: [190][   50/  211]    Overall Loss 0.021908    Objective Loss 0.021908                                        LR 0.000100    Time 0.694396    
2024-01-15 21:23:35,746 - Epoch: [190][   60/  211]    Overall Loss 0.021683    Objective Loss 0.021683                                        LR 0.000100    Time 0.679957    
2024-01-15 21:23:41,721 - Epoch: [190][   70/  211]    Overall Loss 0.022077    Objective Loss 0.022077                                        LR 0.000100    Time 0.668162    
2024-01-15 21:23:48,142 - Epoch: [190][   80/  211]    Overall Loss 0.021599    Objective Loss 0.021599                                        LR 0.000100    Time 0.664876    
2024-01-15 21:23:54,909 - Epoch: [190][   90/  211]    Overall Loss 0.022169    Objective Loss 0.022169                                        LR 0.000100    Time 0.666174    
2024-01-15 21:24:01,280 - Epoch: [190][  100/  211]    Overall Loss 0.022119    Objective Loss 0.022119                                        LR 0.000100    Time 0.663262    
2024-01-15 21:24:07,537 - Epoch: [190][  110/  211]    Overall Loss 0.022542    Objective Loss 0.022542                                        LR 0.000100    Time 0.659824    
2024-01-15 21:24:14,164 - Epoch: [190][  120/  211]    Overall Loss 0.022042    Objective Loss 0.022042                                        LR 0.000100    Time 0.660055    
2024-01-15 21:24:20,073 - Epoch: [190][  130/  211]    Overall Loss 0.022472    Objective Loss 0.022472                                        LR 0.000100    Time 0.654727    
2024-01-15 21:24:27,230 - Epoch: [190][  140/  211]    Overall Loss 0.022752    Objective Loss 0.022752                                        LR 0.000100    Time 0.659063    
2024-01-15 21:24:33,910 - Epoch: [190][  150/  211]    Overall Loss 0.022829    Objective Loss 0.022829                                        LR 0.000100    Time 0.659652    
2024-01-15 21:24:40,199 - Epoch: [190][  160/  211]    Overall Loss 0.022634    Objective Loss 0.022634                                        LR 0.000100    Time 0.657725    
2024-01-15 21:24:47,105 - Epoch: [190][  170/  211]    Overall Loss 0.022644    Objective Loss 0.022644                                        LR 0.000100    Time 0.659645    
2024-01-15 21:24:53,489 - Epoch: [190][  180/  211]    Overall Loss 0.022308    Objective Loss 0.022308                                        LR 0.000100    Time 0.658456    
2024-01-15 21:25:00,566 - Epoch: [190][  190/  211]    Overall Loss 0.022077    Objective Loss 0.022077                                        LR 0.000100    Time 0.661037    
2024-01-15 21:25:06,869 - Epoch: [190][  200/  211]    Overall Loss 0.021946    Objective Loss 0.021946                                        LR 0.000100    Time 0.659497    
2024-01-15 21:25:13,299 - Epoch: [190][  210/  211]    Overall Loss 0.022230    Objective Loss 0.022230    Top1 98.828125    Top5 100.000000    LR 0.000100    Time 0.658702    
2024-01-15 21:25:14,137 - Epoch: [190][  211/  211]    Overall Loss 0.022212    Objective Loss 0.022212    Top1 99.193548    Top5 100.000000    LR 0.000100    Time 0.659546    
2024-01-15 21:25:14,903 - --- validate (epoch=190)-----------
2024-01-15 21:25:14,904 - 6000 samples (256 per mini-batch)
2024-01-15 21:25:20,521 - Epoch: [190][   10/   24]    Loss 0.030460    Top1 99.218750    Top5 100.000000    
2024-01-15 21:25:22,716 - Epoch: [190][   20/   24]    Loss 0.030412    Top1 99.062500    Top5 100.000000    
2024-01-15 21:25:23,474 - Epoch: [190][   24/   24]    Loss 0.028980    Top1 99.116667    Top5 100.000000    
2024-01-15 21:25:24,035 - ==> Top1: 99.117    Top5: 100.000    Loss: 0.029

2024-01-15 21:25:24,036 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 582   0   0   0   0   3   1   0]
 [  0   0   1 577   0   2   0   1   2   0]
 [  0   1   0   0 557   0   0   1   0   6]
 [  0   0   0   1   0 511   5   0   1   0]
 [  1   2   0   0   1   0 627   0   0   0]
 [  0   2   0   0   0   0   0 623   0   0]
 [  0   0   0   2   1   1   3   0 577   0]
 [  0   1   0   0   3   1   0   3   3 604]]

2024-01-15 21:25:24,039 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:25:24,039 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:25:24,043 - 

2024-01-15 21:25:24,044 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:25:33,705 - Epoch: [191][   10/  211]    Overall Loss 0.029108    Objective Loss 0.029108                                        LR 0.000100    Time 0.965964    
2024-01-15 21:25:40,073 - Epoch: [191][   20/  211]    Overall Loss 0.027613    Objective Loss 0.027613                                        LR 0.000100    Time 0.801185    
2024-01-15 21:25:46,864 - Epoch: [191][   30/  211]    Overall Loss 0.026466    Objective Loss 0.026466                                        LR 0.000100    Time 0.760455    
2024-01-15 21:25:53,157 - Epoch: [191][   40/  211]    Overall Loss 0.024653    Objective Loss 0.024653                                        LR 0.000100    Time 0.727633    
2024-01-15 21:25:59,179 - Epoch: [191][   50/  211]    Overall Loss 0.024101    Objective Loss 0.024101                                        LR 0.000100    Time 0.702528    
2024-01-15 21:26:05,745 - Epoch: [191][   60/  211]    Overall Loss 0.023506    Objective Loss 0.023506                                        LR 0.000100    Time 0.694839    
2024-01-15 21:26:11,699 - Epoch: [191][   70/  211]    Overall Loss 0.022709    Objective Loss 0.022709                                        LR 0.000100    Time 0.680615    
2024-01-15 21:26:17,931 - Epoch: [191][   80/  211]    Overall Loss 0.022973    Objective Loss 0.022973                                        LR 0.000100    Time 0.673418    
2024-01-15 21:26:24,294 - Epoch: [191][   90/  211]    Overall Loss 0.023362    Objective Loss 0.023362                                        LR 0.000100    Time 0.669286    
2024-01-15 21:26:30,975 - Epoch: [191][  100/  211]    Overall Loss 0.022964    Objective Loss 0.022964                                        LR 0.000100    Time 0.669138    
2024-01-15 21:26:37,466 - Epoch: [191][  110/  211]    Overall Loss 0.022148    Objective Loss 0.022148                                        LR 0.000100    Time 0.667309    
2024-01-15 21:26:44,174 - Epoch: [191][  120/  211]    Overall Loss 0.021633    Objective Loss 0.021633                                        LR 0.000100    Time 0.667581    
2024-01-15 21:26:50,530 - Epoch: [191][  130/  211]    Overall Loss 0.021960    Objective Loss 0.021960                                        LR 0.000100    Time 0.665114    
2024-01-15 21:26:56,473 - Epoch: [191][  140/  211]    Overall Loss 0.022240    Objective Loss 0.022240                                        LR 0.000100    Time 0.660024    
2024-01-15 21:27:03,052 - Epoch: [191][  150/  211]    Overall Loss 0.022462    Objective Loss 0.022462                                        LR 0.000100    Time 0.659870    
2024-01-15 21:27:09,478 - Epoch: [191][  160/  211]    Overall Loss 0.022517    Objective Loss 0.022517                                        LR 0.000100    Time 0.658741    
2024-01-15 21:27:15,511 - Epoch: [191][  170/  211]    Overall Loss 0.022458    Objective Loss 0.022458                                        LR 0.000100    Time 0.655471    
2024-01-15 21:27:21,163 - Epoch: [191][  180/  211]    Overall Loss 0.022306    Objective Loss 0.022306                                        LR 0.000100    Time 0.650454    
2024-01-15 21:27:27,076 - Epoch: [191][  190/  211]    Overall Loss 0.022267    Objective Loss 0.022267                                        LR 0.000100    Time 0.647333    
2024-01-15 21:27:34,635 - Epoch: [191][  200/  211]    Overall Loss 0.022281    Objective Loss 0.022281                                        LR 0.000100    Time 0.652754    
2024-01-15 21:27:40,538 - Epoch: [191][  210/  211]    Overall Loss 0.022501    Objective Loss 0.022501    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.649774    
2024-01-15 21:27:41,168 - Epoch: [191][  211/  211]    Overall Loss 0.022444    Objective Loss 0.022444    Top1 99.798387    Top5 100.000000    LR 0.000100    Time 0.649679    
2024-01-15 21:27:42,108 - --- validate (epoch=191)-----------
2024-01-15 21:27:42,110 - 6000 samples (256 per mini-batch)
2024-01-15 21:27:49,424 - Epoch: [191][   10/   24]    Loss 0.028904    Top1 99.179688    Top5 99.960938    
2024-01-15 21:27:51,644 - Epoch: [191][   20/   24]    Loss 0.026085    Top1 99.316406    Top5 99.980469    
2024-01-15 21:27:52,576 - Epoch: [191][   24/   24]    Loss 0.024616    Top1 99.366667    Top5 99.983333    
2024-01-15 21:27:53,435 - ==> Top1: 99.367    Top5: 99.983    Loss: 0.025

2024-01-15 21:27:53,436 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 687   1   0   0   0   0   0   0   0]
 [  0   0 582   1   0   0   1   1   1   0]
 [  0   0   2 579   0   1   0   0   1   0]
 [  0   1   0   0 561   0   0   0   0   3]
 [  0   0   0   2   0 513   3   0   0   0]
 [  0   0   0   0   1   0 630   0   0   0]
 [  1   2   1   1   0   0   0 620   0   0]
 [  0   0   0   1   1   1   1   0 580   0]
 [  0   2   0   0   2   0   0   3   2 606]]

2024-01-15 21:27:53,439 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:27:53,439 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:27:53,444 - 

2024-01-15 21:27:53,444 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:28:03,367 - Epoch: [192][   10/  211]    Overall Loss 0.023890    Objective Loss 0.023890                                        LR 0.000100    Time 0.992223    
2024-01-15 21:28:09,024 - Epoch: [192][   20/  211]    Overall Loss 0.022343    Objective Loss 0.022343                                        LR 0.000100    Time 0.778898    
2024-01-15 21:28:14,727 - Epoch: [192][   30/  211]    Overall Loss 0.021338    Objective Loss 0.021338                                        LR 0.000100    Time 0.709370    
2024-01-15 21:28:20,366 - Epoch: [192][   40/  211]    Overall Loss 0.021489    Objective Loss 0.021489                                        LR 0.000100    Time 0.672968    
2024-01-15 21:28:26,106 - Epoch: [192][   50/  211]    Overall Loss 0.022074    Objective Loss 0.022074                                        LR 0.000100    Time 0.653154    
2024-01-15 21:28:32,415 - Epoch: [192][   60/  211]    Overall Loss 0.021374    Objective Loss 0.021374                                        LR 0.000100    Time 0.649422    
2024-01-15 21:28:38,213 - Epoch: [192][   70/  211]    Overall Loss 0.022786    Objective Loss 0.022786                                        LR 0.000100    Time 0.639455    
2024-01-15 21:28:44,611 - Epoch: [192][   80/  211]    Overall Loss 0.022470    Objective Loss 0.022470                                        LR 0.000100    Time 0.639469    
2024-01-15 21:28:50,923 - Epoch: [192][   90/  211]    Overall Loss 0.021903    Objective Loss 0.021903                                        LR 0.000100    Time 0.638541    
2024-01-15 21:28:57,169 - Epoch: [192][  100/  211]    Overall Loss 0.022222    Objective Loss 0.022222                                        LR 0.000100    Time 0.637136    
2024-01-15 21:29:03,316 - Epoch: [192][  110/  211]    Overall Loss 0.022334    Objective Loss 0.022334                                        LR 0.000100    Time 0.635085    
2024-01-15 21:29:09,413 - Epoch: [192][  120/  211]    Overall Loss 0.022284    Objective Loss 0.022284                                        LR 0.000100    Time 0.632953    
2024-01-15 21:29:15,704 - Epoch: [192][  130/  211]    Overall Loss 0.021927    Objective Loss 0.021927                                        LR 0.000100    Time 0.632649    
2024-01-15 21:29:22,220 - Epoch: [192][  140/  211]    Overall Loss 0.021930    Objective Loss 0.021930                                        LR 0.000100    Time 0.633993    
2024-01-15 21:29:29,185 - Epoch: [192][  150/  211]    Overall Loss 0.022158    Objective Loss 0.022158                                        LR 0.000100    Time 0.638145    
2024-01-15 21:29:35,518 - Epoch: [192][  160/  211]    Overall Loss 0.021824    Objective Loss 0.021824                                        LR 0.000100    Time 0.637834    
2024-01-15 21:29:41,661 - Epoch: [192][  170/  211]    Overall Loss 0.021917    Objective Loss 0.021917                                        LR 0.000100    Time 0.636441    
2024-01-15 21:29:47,469 - Epoch: [192][  180/  211]    Overall Loss 0.022180    Objective Loss 0.022180                                        LR 0.000100    Time 0.633339    
2024-01-15 21:29:53,594 - Epoch: [192][  190/  211]    Overall Loss 0.022027    Objective Loss 0.022027                                        LR 0.000100    Time 0.632240    
2024-01-15 21:29:59,640 - Epoch: [192][  200/  211]    Overall Loss 0.022212    Objective Loss 0.022212                                        LR 0.000100    Time 0.630851    
2024-01-15 21:30:06,080 - Epoch: [192][  210/  211]    Overall Loss 0.022417    Objective Loss 0.022417    Top1 98.828125    Top5 100.000000    LR 0.000100    Time 0.631469    
2024-01-15 21:30:06,754 - Epoch: [192][  211/  211]    Overall Loss 0.022393    Objective Loss 0.022393    Top1 99.193548    Top5 100.000000    LR 0.000100    Time 0.631667    
2024-01-15 21:30:07,639 - --- validate (epoch=192)-----------
2024-01-15 21:30:07,640 - 6000 samples (256 per mini-batch)
2024-01-15 21:30:15,250 - Epoch: [192][   10/   24]    Loss 0.025432    Top1 99.179688    Top5 100.000000    
2024-01-15 21:30:17,816 - Epoch: [192][   20/   24]    Loss 0.023088    Top1 99.296875    Top5 100.000000    
2024-01-15 21:30:18,605 - Epoch: [192][   24/   24]    Loss 0.022813    Top1 99.316667    Top5 100.000000    
2024-01-15 21:30:19,368 - ==> Top1: 99.317    Top5: 100.000    Loss: 0.023

2024-01-15 21:30:19,369 - ==> Confusion:
[[603   0   0   0   0   0   0   0   1   1]
 [  0 684   1   0   1   0   1   1   0   0]
 [  0   0 585   1   0   0   0   0   0   0]
 [  0   0   4 578   0   0   0   0   1   0]
 [  0   0   0   0 558   0   1   0   0   6]
 [  0   0   0   1   0 515   2   0   0   0]
 [  0   1   0   0   1   0 629   0   0   0]
 [  0   0   0   0   0   0   0 625   0   0]
 [  0   0   1   1   2   1   2   0 576   1]
 [  0   1   0   0   2   1   0   2   3 606]]

2024-01-15 21:30:19,372 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:30:19,372 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:30:19,377 - 

2024-01-15 21:30:19,378 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:30:29,499 - Epoch: [193][   10/  211]    Overall Loss 0.015296    Objective Loss 0.015296                                        LR 0.000100    Time 1.012021    
2024-01-15 21:30:35,916 - Epoch: [193][   20/  211]    Overall Loss 0.017713    Objective Loss 0.017713                                        LR 0.000100    Time 0.826792    
2024-01-15 21:30:41,980 - Epoch: [193][   30/  211]    Overall Loss 0.019302    Objective Loss 0.019302                                        LR 0.000100    Time 0.753281    
2024-01-15 21:30:47,968 - Epoch: [193][   40/  211]    Overall Loss 0.019815    Objective Loss 0.019815                                        LR 0.000100    Time 0.714628    
2024-01-15 21:30:54,068 - Epoch: [193][   50/  211]    Overall Loss 0.020263    Objective Loss 0.020263                                        LR 0.000100    Time 0.693688    
2024-01-15 21:30:59,910 - Epoch: [193][   60/  211]    Overall Loss 0.020761    Objective Loss 0.020761                                        LR 0.000100    Time 0.675409    
2024-01-15 21:31:06,356 - Epoch: [193][   70/  211]    Overall Loss 0.020701    Objective Loss 0.020701                                        LR 0.000100    Time 0.671003    
2024-01-15 21:31:13,288 - Epoch: [193][   80/  211]    Overall Loss 0.020595    Objective Loss 0.020595                                        LR 0.000100    Time 0.673751    
2024-01-15 21:31:19,811 - Epoch: [193][   90/  211]    Overall Loss 0.020873    Objective Loss 0.020873                                        LR 0.000100    Time 0.671351    
2024-01-15 21:31:26,058 - Epoch: [193][  100/  211]    Overall Loss 0.020746    Objective Loss 0.020746                                        LR 0.000100    Time 0.666660    
2024-01-15 21:31:32,585 - Epoch: [193][  110/  211]    Overall Loss 0.020986    Objective Loss 0.020986                                        LR 0.000100    Time 0.665342    
2024-01-15 21:31:39,414 - Epoch: [193][  120/  211]    Overall Loss 0.021153    Objective Loss 0.021153                                        LR 0.000100    Time 0.666783    
2024-01-15 21:31:45,591 - Epoch: [193][  130/  211]    Overall Loss 0.021508    Objective Loss 0.021508                                        LR 0.000100    Time 0.662996    
2024-01-15 21:31:51,800 - Epoch: [193][  140/  211]    Overall Loss 0.021293    Objective Loss 0.021293                                        LR 0.000100    Time 0.659976    
2024-01-15 21:31:58,650 - Epoch: [193][  150/  211]    Overall Loss 0.021388    Objective Loss 0.021388                                        LR 0.000100    Time 0.661640    
2024-01-15 21:32:06,263 - Epoch: [193][  160/  211]    Overall Loss 0.021583    Objective Loss 0.021583                                        LR 0.000100    Time 0.667852    
2024-01-15 21:32:12,707 - Epoch: [193][  170/  211]    Overall Loss 0.022137    Objective Loss 0.022137                                        LR 0.000100    Time 0.666461    
2024-01-15 21:32:18,690 - Epoch: [193][  180/  211]    Overall Loss 0.021907    Objective Loss 0.021907                                        LR 0.000100    Time 0.662669    
2024-01-15 21:32:24,996 - Epoch: [193][  190/  211]    Overall Loss 0.022099    Objective Loss 0.022099                                        LR 0.000100    Time 0.660974    
2024-01-15 21:32:31,435 - Epoch: [193][  200/  211]    Overall Loss 0.022068    Objective Loss 0.022068                                        LR 0.000100    Time 0.660107    
2024-01-15 21:32:37,787 - Epoch: [193][  210/  211]    Overall Loss 0.021859    Objective Loss 0.021859    Top1 98.828125    Top5 100.000000    LR 0.000100    Time 0.658912    
2024-01-15 21:32:38,471 - Epoch: [193][  211/  211]    Overall Loss 0.021819    Objective Loss 0.021819    Top1 99.193548    Top5 100.000000    LR 0.000100    Time 0.659026    
2024-01-15 21:32:39,624 - --- validate (epoch=193)-----------
2024-01-15 21:32:39,625 - 6000 samples (256 per mini-batch)
2024-01-15 21:32:46,671 - Epoch: [193][   10/   24]    Loss 0.024603    Top1 99.218750    Top5 100.000000    
2024-01-15 21:32:48,779 - Epoch: [193][   20/   24]    Loss 0.026898    Top1 99.257812    Top5 99.980469    
2024-01-15 21:32:49,522 - Epoch: [193][   24/   24]    Loss 0.027964    Top1 99.200000    Top5 99.983333    
2024-01-15 21:32:50,364 - ==> Top1: 99.200    Top5: 99.983    Loss: 0.028

2024-01-15 21:32:50,365 - ==> Confusion:
[[601   0   0   0   0   0   3   0   0   1]
 [  0 686   0   0   0   0   0   2   0   0]
 [  0   0 583   1   0   0   0   2   0   0]
 [  0   0   1 578   0   1   0   1   2   0]
 [  0   0   0   0 560   0   0   0   0   5]
 [  0   0   0   1   0 510   5   1   1   0]
 [  1   1   0   0   1   0 627   0   1   0]
 [  0   2   0   1   0   1   0 621   0   0]
 [  0   0   1   0   2   1   2   0 577   1]
 [  1   0   0   0   1   0   0   2   2 609]]

2024-01-15 21:32:50,368 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:32:50,368 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:32:50,372 - 

2024-01-15 21:32:50,372 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:33:00,320 - Epoch: [194][   10/  211]    Overall Loss 0.020872    Objective Loss 0.020872                                        LR 0.000100    Time 0.994776    
2024-01-15 21:33:06,001 - Epoch: [194][   20/  211]    Overall Loss 0.020455    Objective Loss 0.020455                                        LR 0.000100    Time 0.781340    
2024-01-15 21:33:11,649 - Epoch: [194][   30/  211]    Overall Loss 0.020567    Objective Loss 0.020567                                        LR 0.000100    Time 0.709145    
2024-01-15 21:33:17,289 - Epoch: [194][   40/  211]    Overall Loss 0.020195    Objective Loss 0.020195                                        LR 0.000100    Time 0.672851    
2024-01-15 21:33:23,329 - Epoch: [194][   50/  211]    Overall Loss 0.021457    Objective Loss 0.021457                                        LR 0.000100    Time 0.659065    
2024-01-15 21:33:29,479 - Epoch: [194][   60/  211]    Overall Loss 0.021783    Objective Loss 0.021783                                        LR 0.000100    Time 0.651689    
2024-01-15 21:33:35,602 - Epoch: [194][   70/  211]    Overall Loss 0.021698    Objective Loss 0.021698                                        LR 0.000100    Time 0.646047    
2024-01-15 21:33:41,811 - Epoch: [194][   80/  211]    Overall Loss 0.021417    Objective Loss 0.021417                                        LR 0.000100    Time 0.642845    
2024-01-15 21:33:47,977 - Epoch: [194][   90/  211]    Overall Loss 0.021739    Objective Loss 0.021739                                        LR 0.000100    Time 0.639917    
2024-01-15 21:33:53,760 - Epoch: [194][  100/  211]    Overall Loss 0.021638    Objective Loss 0.021638                                        LR 0.000100    Time 0.633744    
2024-01-15 21:33:59,590 - Epoch: [194][  110/  211]    Overall Loss 0.021523    Objective Loss 0.021523                                        LR 0.000100    Time 0.629118    
2024-01-15 21:34:05,474 - Epoch: [194][  120/  211]    Overall Loss 0.021484    Objective Loss 0.021484                                        LR 0.000100    Time 0.625711    
2024-01-15 21:34:12,713 - Epoch: [194][  130/  211]    Overall Loss 0.021056    Objective Loss 0.021056                                        LR 0.000100    Time 0.633259    
2024-01-15 21:34:19,650 - Epoch: [194][  140/  211]    Overall Loss 0.021068    Objective Loss 0.021068                                        LR 0.000100    Time 0.637564    
2024-01-15 21:34:26,697 - Epoch: [194][  150/  211]    Overall Loss 0.021626    Objective Loss 0.021626                                        LR 0.000100    Time 0.642030    
2024-01-15 21:34:34,396 - Epoch: [194][  160/  211]    Overall Loss 0.021663    Objective Loss 0.021663                                        LR 0.000100    Time 0.650007    
2024-01-15 21:34:41,459 - Epoch: [194][  170/  211]    Overall Loss 0.021533    Objective Loss 0.021533                                        LR 0.000100    Time 0.653304    
2024-01-15 21:34:48,893 - Epoch: [194][  180/  211]    Overall Loss 0.021238    Objective Loss 0.021238                                        LR 0.000100    Time 0.658301    
2024-01-15 21:34:56,403 - Epoch: [194][  190/  211]    Overall Loss 0.021381    Objective Loss 0.021381                                        LR 0.000100    Time 0.663168    
2024-01-15 21:35:04,763 - Epoch: [194][  200/  211]    Overall Loss 0.021439    Objective Loss 0.021439                                        LR 0.000100    Time 0.671788    
2024-01-15 21:35:11,373 - Epoch: [194][  210/  211]    Overall Loss 0.021522    Objective Loss 0.021522    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.671254    
2024-01-15 21:35:12,000 - Epoch: [194][  211/  211]    Overall Loss 0.021620    Objective Loss 0.021620    Top1 99.193548    Top5 100.000000    LR 0.000100    Time 0.671041    
2024-01-15 21:35:13,196 - --- validate (epoch=194)-----------
2024-01-15 21:35:13,198 - 6000 samples (256 per mini-batch)
2024-01-15 21:35:21,315 - Epoch: [194][   10/   24]    Loss 0.034067    Top1 99.023438    Top5 100.000000    
2024-01-15 21:35:23,817 - Epoch: [194][   20/   24]    Loss 0.028771    Top1 99.179688    Top5 100.000000    
2024-01-15 21:35:24,748 - Epoch: [194][   24/   24]    Loss 0.028581    Top1 99.133333    Top5 99.983333    
2024-01-15 21:35:25,471 - ==> Top1: 99.133    Top5: 99.983    Loss: 0.029

2024-01-15 21:35:25,473 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 687   0   0   1   0   0   0   0   0]
 [  0   0 579   0   0   1   0   3   2   1]
 [  0   0   1 579   0   1   0   1   1   0]
 [  0   1   0   0 556   0   0   3   0   5]
 [  0   2   0   1   0 512   2   0   1   0]
 [  0   2   0   0   0   0 627   0   2   0]
 [  0   2   0   2   0   0   0 621   0   0]
 [  1   0   0   0   1   0   1   1 580   0]
 [  1   1   0   0   4   1   0   2   2 604]]

2024-01-15 21:35:25,475 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:35:25,475 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:35:25,480 - 

2024-01-15 21:35:25,481 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:35:36,981 - Epoch: [195][   10/  211]    Overall Loss 0.020606    Objective Loss 0.020606                                        LR 0.000100    Time 1.149915    
2024-01-15 21:35:43,485 - Epoch: [195][   20/  211]    Overall Loss 0.022176    Objective Loss 0.022176                                        LR 0.000100    Time 0.900084    
2024-01-15 21:35:50,796 - Epoch: [195][   30/  211]    Overall Loss 0.025944    Objective Loss 0.025944                                        LR 0.000100    Time 0.843719    
2024-01-15 21:35:57,326 - Epoch: [195][   40/  211]    Overall Loss 0.024363    Objective Loss 0.024363                                        LR 0.000100    Time 0.795978    
2024-01-15 21:36:03,552 - Epoch: [195][   50/  211]    Overall Loss 0.022903    Objective Loss 0.022903                                        LR 0.000100    Time 0.761285    
2024-01-15 21:36:09,580 - Epoch: [195][   60/  211]    Overall Loss 0.022117    Objective Loss 0.022117                                        LR 0.000100    Time 0.734835    
2024-01-15 21:36:15,569 - Epoch: [195][   70/  211]    Overall Loss 0.021767    Objective Loss 0.021767                                        LR 0.000100    Time 0.715380    
2024-01-15 21:36:21,350 - Epoch: [195][   80/  211]    Overall Loss 0.021258    Objective Loss 0.021258                                        LR 0.000100    Time 0.698204    
2024-01-15 21:36:27,460 - Epoch: [195][   90/  211]    Overall Loss 0.021344    Objective Loss 0.021344                                        LR 0.000100    Time 0.688498    
2024-01-15 21:36:33,817 - Epoch: [195][  100/  211]    Overall Loss 0.021579    Objective Loss 0.021579                                        LR 0.000100    Time 0.683201    
2024-01-15 21:36:39,548 - Epoch: [195][  110/  211]    Overall Loss 0.022012    Objective Loss 0.022012                                        LR 0.000100    Time 0.673185    
2024-01-15 21:36:45,652 - Epoch: [195][  120/  211]    Overall Loss 0.022027    Objective Loss 0.022027                                        LR 0.000100    Time 0.667942    
2024-01-15 21:36:51,462 - Epoch: [195][  130/  211]    Overall Loss 0.022076    Objective Loss 0.022076                                        LR 0.000100    Time 0.661243    
2024-01-15 21:36:57,415 - Epoch: [195][  140/  211]    Overall Loss 0.021627    Objective Loss 0.021627                                        LR 0.000100    Time 0.656522    
2024-01-15 21:37:03,386 - Epoch: [195][  150/  211]    Overall Loss 0.021179    Objective Loss 0.021179                                        LR 0.000100    Time 0.652556    
2024-01-15 21:37:09,127 - Epoch: [195][  160/  211]    Overall Loss 0.021184    Objective Loss 0.021184                                        LR 0.000100    Time 0.647643    
2024-01-15 21:37:16,024 - Epoch: [195][  170/  211]    Overall Loss 0.020974    Objective Loss 0.020974                                        LR 0.000100    Time 0.650100    
2024-01-15 21:37:22,814 - Epoch: [195][  180/  211]    Overall Loss 0.020928    Objective Loss 0.020928                                        LR 0.000100    Time 0.651688    
2024-01-15 21:37:29,970 - Epoch: [195][  190/  211]    Overall Loss 0.020957    Objective Loss 0.020957                                        LR 0.000100    Time 0.655045    
2024-01-15 21:37:36,919 - Epoch: [195][  200/  211]    Overall Loss 0.021092    Objective Loss 0.021092                                        LR 0.000100    Time 0.657029    
2024-01-15 21:37:42,663 - Epoch: [195][  210/  211]    Overall Loss 0.020804    Objective Loss 0.020804    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.653087    
2024-01-15 21:37:43,237 - Epoch: [195][  211/  211]    Overall Loss 0.020869    Objective Loss 0.020869    Top1 99.395161    Top5 100.000000    LR 0.000100    Time 0.652709    
2024-01-15 21:37:44,200 - --- validate (epoch=195)-----------
2024-01-15 21:37:44,201 - 6000 samples (256 per mini-batch)
2024-01-15 21:37:51,363 - Epoch: [195][   10/   24]    Loss 0.023220    Top1 99.414062    Top5 100.000000    
2024-01-15 21:37:53,489 - Epoch: [195][   20/   24]    Loss 0.024789    Top1 99.414062    Top5 100.000000    
2024-01-15 21:37:54,240 - Epoch: [195][   24/   24]    Loss 0.026644    Top1 99.333333    Top5 100.000000    
2024-01-15 21:37:55,011 - ==> Top1: 99.333    Top5: 100.000    Loss: 0.027

2024-01-15 21:37:55,012 - ==> Confusion:
[[604   0   1   0   0   0   0   0   0   0]
 [  0 685   1   0   0   0   0   2   0   0]
 [  0   0 583   0   0   0   0   2   0   1]
 [  0   0   1 578   0   1   0   2   1   0]
 [  0   0   0   0 560   0   0   1   0   4]
 [  1   0   0   1   0 514   2   0   0   0]
 [  1   1   0   0   1   0 628   0   0   0]
 [  0   1   0   0   0   0   0 624   0   0]
 [  0   0   1   2   0   3   0   0 578   0]
 [  1   1   0   0   2   0   0   3   2 606]]

2024-01-15 21:37:55,015 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:37:55,015 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:37:55,019 - 

2024-01-15 21:37:55,019 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:38:04,202 - Epoch: [196][   10/  211]    Overall Loss 0.028803    Objective Loss 0.028803                                        LR 0.000100    Time 0.918182    
2024-01-15 21:38:09,933 - Epoch: [196][   20/  211]    Overall Loss 0.023704    Objective Loss 0.023704                                        LR 0.000100    Time 0.745588    
2024-01-15 21:38:15,661 - Epoch: [196][   30/  211]    Overall Loss 0.022148    Objective Loss 0.022148                                        LR 0.000100    Time 0.687943    
2024-01-15 21:38:22,025 - Epoch: [196][   40/  211]    Overall Loss 0.023778    Objective Loss 0.023778                                        LR 0.000100    Time 0.675035    
2024-01-15 21:38:28,415 - Epoch: [196][   50/  211]    Overall Loss 0.022601    Objective Loss 0.022601                                        LR 0.000100    Time 0.667799    
2024-01-15 21:38:34,428 - Epoch: [196][   60/  211]    Overall Loss 0.022350    Objective Loss 0.022350                                        LR 0.000100    Time 0.656690    
2024-01-15 21:38:40,161 - Epoch: [196][   70/  211]    Overall Loss 0.022056    Objective Loss 0.022056                                        LR 0.000100    Time 0.644767    
2024-01-15 21:38:47,036 - Epoch: [196][   80/  211]    Overall Loss 0.022148    Objective Loss 0.022148                                        LR 0.000100    Time 0.650082    
2024-01-15 21:38:53,087 - Epoch: [196][   90/  211]    Overall Loss 0.022163    Objective Loss 0.022163                                        LR 0.000100    Time 0.645057    
2024-01-15 21:38:59,011 - Epoch: [196][  100/  211]    Overall Loss 0.021751    Objective Loss 0.021751                                        LR 0.000100    Time 0.639783    
2024-01-15 21:39:04,863 - Epoch: [196][  110/  211]    Overall Loss 0.021928    Objective Loss 0.021928                                        LR 0.000100    Time 0.634806    
2024-01-15 21:39:11,306 - Epoch: [196][  120/  211]    Overall Loss 0.022685    Objective Loss 0.022685                                        LR 0.000100    Time 0.635582    
2024-01-15 21:39:17,450 - Epoch: [196][  130/  211]    Overall Loss 0.022697    Objective Loss 0.022697                                        LR 0.000100    Time 0.633920    
2024-01-15 21:39:23,679 - Epoch: [196][  140/  211]    Overall Loss 0.022481    Objective Loss 0.022481                                        LR 0.000100    Time 0.633128    
2024-01-15 21:39:29,976 - Epoch: [196][  150/  211]    Overall Loss 0.022452    Objective Loss 0.022452                                        LR 0.000100    Time 0.632887    
2024-01-15 21:39:36,102 - Epoch: [196][  160/  211]    Overall Loss 0.022436    Objective Loss 0.022436                                        LR 0.000100    Time 0.631609    
2024-01-15 21:39:41,951 - Epoch: [196][  170/  211]    Overall Loss 0.022545    Objective Loss 0.022545                                        LR 0.000100    Time 0.628855    
2024-01-15 21:39:48,564 - Epoch: [196][  180/  211]    Overall Loss 0.022226    Objective Loss 0.022226                                        LR 0.000100    Time 0.630647    
2024-01-15 21:39:55,864 - Epoch: [196][  190/  211]    Overall Loss 0.022269    Objective Loss 0.022269                                        LR 0.000100    Time 0.635862    
2024-01-15 21:40:02,655 - Epoch: [196][  200/  211]    Overall Loss 0.022077    Objective Loss 0.022077                                        LR 0.000100    Time 0.638020    
2024-01-15 21:40:08,839 - Epoch: [196][  210/  211]    Overall Loss 0.021972    Objective Loss 0.021972    Top1 100.000000    Top5 100.000000    LR 0.000100    Time 0.637081    
2024-01-15 21:40:09,418 - Epoch: [196][  211/  211]    Overall Loss 0.022015    Objective Loss 0.022015    Top1 99.395161    Top5 100.000000    LR 0.000100    Time 0.636801    
2024-01-15 21:40:10,329 - --- validate (epoch=196)-----------
2024-01-15 21:40:10,331 - 6000 samples (256 per mini-batch)
2024-01-15 21:40:17,628 - Epoch: [196][   10/   24]    Loss 0.029248    Top1 99.062500    Top5 100.000000    
2024-01-15 21:40:19,936 - Epoch: [196][   20/   24]    Loss 0.028459    Top1 99.199219    Top5 100.000000    
2024-01-15 21:40:20,753 - Epoch: [196][   24/   24]    Loss 0.026655    Top1 99.250000    Top5 99.983333    
2024-01-15 21:40:21,485 - ==> Top1: 99.250    Top5: 99.983    Loss: 0.027

2024-01-15 21:40:21,486 - ==> Confusion:
[[601   0   1   0   0   1   1   0   0   1]
 [  0 685   0   0   1   1   1   0   0   0]
 [  0   0 585   0   0   0   0   1   0   0]
 [  0   0   2 578   0   2   0   0   1   0]
 [  0   0   0   0 557   0   0   1   0   7]
 [  0   1   0   2   0 514   1   0   0   0]
 [  1   0   0   0   1   1 628   0   0   0]
 [  0   1   0   0   1   0   0 623   0   0]
 [  1   0   0   1   0   2   1   0 578   1]
 [  0   1   0   0   3   2   0   1   2 606]]

2024-01-15 21:40:21,488 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:40:21,488 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:40:21,492 - 

2024-01-15 21:40:21,492 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:40:31,521 - Epoch: [197][   10/  211]    Overall Loss 0.020538    Objective Loss 0.020538                                        LR 0.000100    Time 1.002794    
2024-01-15 21:40:37,680 - Epoch: [197][   20/  211]    Overall Loss 0.024870    Objective Loss 0.024870                                        LR 0.000100    Time 0.809251    
2024-01-15 21:40:43,968 - Epoch: [197][   30/  211]    Overall Loss 0.024865    Objective Loss 0.024865                                        LR 0.000100    Time 0.749092    
2024-01-15 21:40:50,019 - Epoch: [197][   40/  211]    Overall Loss 0.024285    Objective Loss 0.024285                                        LR 0.000100    Time 0.713060    
2024-01-15 21:40:56,643 - Epoch: [197][   50/  211]    Overall Loss 0.023176    Objective Loss 0.023176                                        LR 0.000100    Time 0.702827    
2024-01-15 21:41:02,549 - Epoch: [197][   60/  211]    Overall Loss 0.024359    Objective Loss 0.024359                                        LR 0.000100    Time 0.684093    
2024-01-15 21:41:09,333 - Epoch: [197][   70/  211]    Overall Loss 0.022961    Objective Loss 0.022961                                        LR 0.000100    Time 0.683264    
2024-01-15 21:41:15,316 - Epoch: [197][   80/  211]    Overall Loss 0.022572    Objective Loss 0.022572                                        LR 0.000100    Time 0.672628    
2024-01-15 21:41:21,373 - Epoch: [197][   90/  211]    Overall Loss 0.022603    Objective Loss 0.022603                                        LR 0.000100    Time 0.665183    
2024-01-15 21:41:27,263 - Epoch: [197][  100/  211]    Overall Loss 0.022192    Objective Loss 0.022192                                        LR 0.000100    Time 0.657551    
2024-01-15 21:41:33,594 - Epoch: [197][  110/  211]    Overall Loss 0.022257    Objective Loss 0.022257                                        LR 0.000100    Time 0.655314    
2024-01-15 21:41:39,619 - Epoch: [197][  120/  211]    Overall Loss 0.022183    Objective Loss 0.022183                                        LR 0.000100    Time 0.650903    
2024-01-15 21:41:45,829 - Epoch: [197][  130/  211]    Overall Loss 0.021589    Objective Loss 0.021589                                        LR 0.000100    Time 0.648580    
2024-01-15 21:41:51,726 - Epoch: [197][  140/  211]    Overall Loss 0.021323    Objective Loss 0.021323                                        LR 0.000100    Time 0.644362    
2024-01-15 21:41:57,544 - Epoch: [197][  150/  211]    Overall Loss 0.021274    Objective Loss 0.021274                                        LR 0.000100    Time 0.640177    
2024-01-15 21:42:03,475 - Epoch: [197][  160/  211]    Overall Loss 0.021537    Objective Loss 0.021537                                        LR 0.000100    Time 0.637230    
2024-01-15 21:42:09,184 - Epoch: [197][  170/  211]    Overall Loss 0.021493    Objective Loss 0.021493                                        LR 0.000100    Time 0.633322    
2024-01-15 21:42:15,089 - Epoch: [197][  180/  211]    Overall Loss 0.021624    Objective Loss 0.021624                                        LR 0.000100    Time 0.630936    
2024-01-15 21:42:20,939 - Epoch: [197][  190/  211]    Overall Loss 0.021787    Objective Loss 0.021787                                        LR 0.000100    Time 0.628511    
2024-01-15 21:42:26,952 - Epoch: [197][  200/  211]    Overall Loss 0.022167    Objective Loss 0.022167                                        LR 0.000100    Time 0.627143    
2024-01-15 21:42:33,435 - Epoch: [197][  210/  211]    Overall Loss 0.022182    Objective Loss 0.022182    Top1 98.046875    Top5 100.000000    LR 0.000100    Time 0.628143    
2024-01-15 21:42:34,148 - Epoch: [197][  211/  211]    Overall Loss 0.022147    Objective Loss 0.022147    Top1 98.588710    Top5 100.000000    LR 0.000100    Time 0.628540    
2024-01-15 21:42:35,444 - --- validate (epoch=197)-----------
2024-01-15 21:42:35,446 - 6000 samples (256 per mini-batch)
2024-01-15 21:42:42,559 - Epoch: [197][   10/   24]    Loss 0.022547    Top1 99.335938    Top5 100.000000    
2024-01-15 21:42:44,753 - Epoch: [197][   20/   24]    Loss 0.024340    Top1 99.316406    Top5 100.000000    
2024-01-15 21:42:45,539 - Epoch: [197][   24/   24]    Loss 0.024037    Top1 99.300000    Top5 100.000000    
2024-01-15 21:42:46,182 - ==> Top1: 99.300    Top5: 100.000    Loss: 0.024

2024-01-15 21:42:46,183 - ==> Confusion:
[[602   0   1   0   0   0   1   0   1   0]
 [  0 686   1   0   0   0   0   1   0   0]
 [  0   0 580   1   0   0   0   1   3   1]
 [  0   0   1 579   0   2   0   0   1   0]
 [  0   1   0   0 560   0   0   0   1   3]
 [  1   0   0   1   0 512   3   0   1   0]
 [  0   0   0   0   0   0 630   0   1   0]
 [  0   2   0   1   0   0   0 621   1   0]
 [  0   0   0   1   1   1   1   2 577   1]
 [  0   0   0   0   2   0   0   1   1 611]]

2024-01-15 21:42:46,186 - ==> Best [Top1: 99.383   Top5: 99.983   Sparsity:0.00   Params: 71148 on epoch: 167]
2024-01-15 21:42:46,186 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:42:46,191 - 

2024-01-15 21:42:46,191 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:42:54,906 - Epoch: [198][   10/  211]    Overall Loss 0.021308    Objective Loss 0.021308                                        LR 0.000100    Time 0.871433    
2024-01-15 21:43:00,715 - Epoch: [198][   20/  211]    Overall Loss 0.024114    Objective Loss 0.024114                                        LR 0.000100    Time 0.726097    
2024-01-15 21:43:06,671 - Epoch: [198][   30/  211]    Overall Loss 0.023416    Objective Loss 0.023416                                        LR 0.000100    Time 0.682547    
2024-01-15 21:43:12,536 - Epoch: [198][   40/  211]    Overall Loss 0.023655    Objective Loss 0.023655                                        LR 0.000100    Time 0.658520    
2024-01-15 21:43:18,746 - Epoch: [198][   50/  211]    Overall Loss 0.024160    Objective Loss 0.024160                                        LR 0.000100    Time 0.650991    
2024-01-15 21:43:24,752 - Epoch: [198][   60/  211]    Overall Loss 0.023416    Objective Loss 0.023416                                        LR 0.000100    Time 0.642566    
2024-01-15 21:43:30,922 - Epoch: [198][   70/  211]    Overall Loss 0.022497    Objective Loss 0.022497                                        LR 0.000100    Time 0.638895    
2024-01-15 21:43:36,996 - Epoch: [198][   80/  211]    Overall Loss 0.022271    Objective Loss 0.022271                                        LR 0.000100    Time 0.634907    
2024-01-15 21:43:42,906 - Epoch: [198][   90/  211]    Overall Loss 0.021822    Objective Loss 0.021822                                        LR 0.000100    Time 0.629983    
2024-01-15 21:43:49,066 - Epoch: [198][  100/  211]    Overall Loss 0.021584    Objective Loss 0.021584                                        LR 0.000100    Time 0.628573    
2024-01-15 21:43:54,980 - Epoch: [198][  110/  211]    Overall Loss 0.021450    Objective Loss 0.021450                                        LR 0.000100    Time 0.625181    
2024-01-15 21:44:00,836 - Epoch: [198][  120/  211]    Overall Loss 0.021534    Objective Loss 0.021534                                        LR 0.000100    Time 0.621868    
2024-01-15 21:44:06,649 - Epoch: [198][  130/  211]    Overall Loss 0.021729    Objective Loss 0.021729                                        LR 0.000100    Time 0.618737    
2024-01-15 21:44:12,923 - Epoch: [198][  140/  211]    Overall Loss 0.021566    Objective Loss 0.021566                                        LR 0.000100    Time 0.619342    
2024-01-15 21:44:19,772 - Epoch: [198][  150/  211]    Overall Loss 0.021381    Objective Loss 0.021381                                        LR 0.000100    Time 0.623705    
2024-01-15 21:44:25,531 - Epoch: [198][  160/  211]    Overall Loss 0.021330    Objective Loss 0.021330                                        LR 0.000100    Time 0.620703    
2024-01-15 21:44:31,582 - Epoch: [198][  170/  211]    Overall Loss 0.021369    Objective Loss 0.021369                                        LR 0.000100    Time 0.619775    
2024-01-15 21:44:37,290 - Epoch: [198][  180/  211]    Overall Loss 0.021515    Objective Loss 0.021515                                        LR 0.000100    Time 0.617050    
2024-01-15 21:44:43,144 - Epoch: [198][  190/  211]    Overall Loss 0.021742    Objective Loss 0.021742                                        LR 0.000100    Time 0.615378    
2024-01-15 21:44:49,007 - Epoch: [198][  200/  211]    Overall Loss 0.021889    Objective Loss 0.021889                                        LR 0.000100    Time 0.613917    
2024-01-15 21:44:54,756 - Epoch: [198][  210/  211]    Overall Loss 0.021581    Objective Loss 0.021581    Top1 99.609375    Top5 100.000000    LR 0.000100    Time 0.612054    
2024-01-15 21:44:55,340 - Epoch: [198][  211/  211]    Overall Loss 0.021549    Objective Loss 0.021549    Top1 99.596774    Top5 100.000000    LR 0.000100    Time 0.611918    
2024-01-15 21:44:56,170 - --- validate (epoch=198)-----------
2024-01-15 21:44:56,172 - 6000 samples (256 per mini-batch)
2024-01-15 21:45:03,150 - Epoch: [198][   10/   24]    Loss 0.015917    Top1 99.609375    Top5 100.000000    
2024-01-15 21:45:05,337 - Epoch: [198][   20/   24]    Loss 0.023792    Top1 99.414062    Top5 100.000000    
2024-01-15 21:45:06,086 - Epoch: [198][   24/   24]    Loss 0.024877    Top1 99.383333    Top5 100.000000    
2024-01-15 21:45:06,856 - ==> Top1: 99.383    Top5: 100.000    Loss: 0.025

2024-01-15 21:45:06,857 - ==> Confusion:
[[604   0   0   0   0   0   1   0   0   0]
 [  0 685   0   0   2   0   0   1   0   0]
 [  0   0 583   0   0   0   0   3   0   0]
 [  0   0   2 579   0   1   0   1   0   0]
 [  0   0   0   0 558   0   0   2   0   5]
 [  0   0   0   0   0 516   2   0   0   0]
 [  0   0   0   0   1   0 629   0   1   0]
 [  0   2   0   1   0   0   0 622   0   0]
 [  0   0   0   1   0   0   2   0 581   0]
 [  0   1   0   1   2   1   0   2   2 606]]

2024-01-15 21:45:06,859 - ==> Best [Top1: 99.383   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 198]
2024-01-15 21:45:06,860 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:45:06,870 - 

2024-01-15 21:45:06,870 - Training epoch: 54000 samples (256 per mini-batch)
2024-01-15 21:45:15,839 - Epoch: [199][   10/  211]    Overall Loss 0.025817    Objective Loss 0.025817                                        LR 0.000100    Time 0.896753    
2024-01-15 21:45:21,866 - Epoch: [199][   20/  211]    Overall Loss 0.027147    Objective Loss 0.027147                                        LR 0.000100    Time 0.749677    
2024-01-15 21:45:27,795 - Epoch: [199][   30/  211]    Overall Loss 0.026493    Objective Loss 0.026493                                        LR 0.000100    Time 0.697363    
2024-01-15 21:45:34,226 - Epoch: [199][   40/  211]    Overall Loss 0.026661    Objective Loss 0.026661                                        LR 0.000100    Time 0.683779    
2024-01-15 21:45:40,074 - Epoch: [199][   50/  211]    Overall Loss 0.026386    Objective Loss 0.026386                                        LR 0.000100    Time 0.663946    
2024-01-15 21:45:45,860 - Epoch: [199][   60/  211]    Overall Loss 0.025510    Objective Loss 0.025510                                        LR 0.000100    Time 0.649712    
2024-01-15 21:45:51,948 - Epoch: [199][   70/  211]    Overall Loss 0.024666    Objective Loss 0.024666                                        LR 0.000100    Time 0.643854    
2024-01-15 21:45:57,973 - Epoch: [199][   80/  211]    Overall Loss 0.024655    Objective Loss 0.024655                                        LR 0.000100    Time 0.638647    
2024-01-15 21:46:04,059 - Epoch: [199][   90/  211]    Overall Loss 0.024242    Objective Loss 0.024242                                        LR 0.000100    Time 0.635289    
2024-01-15 21:46:09,905 - Epoch: [199][  100/  211]    Overall Loss 0.024232    Objective Loss 0.024232                                        LR 0.000100    Time 0.630200    
2024-01-15 21:46:15,561 - Epoch: [199][  110/  211]    Overall Loss 0.023828    Objective Loss 0.023828                                        LR 0.000100    Time 0.624321    
2024-01-15 21:46:21,364 - Epoch: [199][  120/  211]    Overall Loss 0.023502    Objective Loss 0.023502                                        LR 0.000100    Time 0.620650    
2024-01-15 21:46:27,142 - Epoch: [199][  130/  211]    Overall Loss 0.023188    Objective Loss 0.023188                                        LR 0.000100    Time 0.617344    
2024-01-15 21:46:33,647 - Epoch: [199][  140/  211]    Overall Loss 0.023256    Objective Loss 0.023256                                        LR 0.000100    Time 0.619701    
2024-01-15 21:46:39,410 - Epoch: [199][  150/  211]    Overall Loss 0.023627    Objective Loss 0.023627                                        LR 0.000100    Time 0.616793    
2024-01-15 21:46:45,159 - Epoch: [199][  160/  211]    Overall Loss 0.023319    Objective Loss 0.023319                                        LR 0.000100    Time 0.614165    
2024-01-15 21:46:51,308 - Epoch: [199][  170/  211]    Overall Loss 0.023257    Objective Loss 0.023257                                        LR 0.000100    Time 0.614204    
2024-01-15 21:47:00,058 - Epoch: [199][  180/  211]    Overall Loss 0.023120    Objective Loss 0.023120                                        LR 0.000100    Time 0.628680    
2024-01-15 21:47:06,011 - Epoch: [199][  190/  211]    Overall Loss 0.022941    Objective Loss 0.022941                                        LR 0.000100    Time 0.626915    
2024-01-15 21:47:11,698 - Epoch: [199][  200/  211]    Overall Loss 0.022769    Objective Loss 0.022769                                        LR 0.000100    Time 0.624000    
2024-01-15 21:47:17,398 - Epoch: [199][  210/  211]    Overall Loss 0.022714    Objective Loss 0.022714    Top1 99.218750    Top5 100.000000    LR 0.000100    Time 0.621429    
2024-01-15 21:47:17,967 - Epoch: [199][  211/  211]    Overall Loss 0.022650    Objective Loss 0.022650    Top1 99.596774    Top5 100.000000    LR 0.000100    Time 0.621177    
2024-01-15 21:47:18,901 - --- validate (epoch=199)-----------
2024-01-15 21:47:18,903 - 6000 samples (256 per mini-batch)
2024-01-15 21:47:26,092 - Epoch: [199][   10/   24]    Loss 0.020019    Top1 99.492188    Top5 100.000000    
2024-01-15 21:47:28,551 - Epoch: [199][   20/   24]    Loss 0.025545    Top1 99.296875    Top5 100.000000    
2024-01-15 21:47:29,350 - Epoch: [199][   24/   24]    Loss 0.024763    Top1 99.283333    Top5 100.000000    
2024-01-15 21:47:30,221 - ==> Top1: 99.283    Top5: 100.000    Loss: 0.025

2024-01-15 21:47:30,223 - ==> Confusion:
[[603   0   1   0   0   0   1   0   0   0]
 [  0 688   0   0   0   0   0   0   0   0]
 [  0   0 585   0   0   0   0   1   0   0]
 [  0   0   0 579   0   2   0   1   1   0]
 [  0   1   1   0 557   0   0   1   0   5]
 [  1   0   0   1   0 513   2   0   0   1]
 [  0   2   0   0   1   1 625   0   2   0]
 [  0   3   0   1   0   0   0 621   0   0]
 [  0   0   1   1   1   0   0   0 581   0]
 [  0   1   0   0   3   1   0   3   2 605]]

2024-01-15 21:47:30,225 - ==> Best [Top1: 99.383   Top5: 100.000   Sparsity:0.00   Params: 71148 on epoch: 198]
2024-01-15 21:47:30,226 - Saving checkpoint to: logs/2024.01.15-113640/qat_checkpoint.pth.tar
2024-01-15 21:47:30,231 - --- test ---------------------
2024-01-15 21:47:30,232 - 10000 samples (256 per mini-batch)
2024-01-15 21:47:35,789 - Test: [   10/   40]    Loss 0.015656    Top1 99.570312    Top5 100.000000    
2024-01-15 21:47:37,980 - Test: [   20/   40]    Loss 0.015639    Top1 99.453125    Top5 100.000000    
2024-01-15 21:47:40,116 - Test: [   30/   40]    Loss 0.013842    Top1 99.505208    Top5 100.000000    
2024-01-15 21:47:42,076 - Test: [   40/   40]    Loss 0.012355    Top1 99.550000    Top5 100.000000    
2024-01-15 21:47:42,670 - ==> Top1: 99.550    Top5: 100.000    Loss: 0.012

2024-01-15 21:47:42,671 - ==> Confusion:
[[ 977    0    1    0    0    0    0    1    0    1]
 [   0 1133    0    1    0    0    0    1    0    0]
 [   1    0 1027    1    0    0    0    3    0    0]
 [   0    1    0 1005    0    2    0    1    1    0]
 [   0    0    0    0  979    0    1    0    0    2]
 [   1    0    0    2    0  887    2    0    0    0]
 [   2    3    0    0    1    1  949    0    2    0]
 [   0    2    2    0    0    0    0 1024    0    0]
 [   0    0    1    0    0    1    0    0  972    0]
 [   1    0    0    0    5    0    0    1    0 1002]]

2024-01-15 21:47:42,681 - 
2024-01-15 21:47:42,681 - Log file for this run: /Users/francescocenciarelli/Desktop/Cambridge/PMLS/coursework/ai8x-training/logs/2024.01.15-113640/2024.01.15-113640.log
