/*******************************************************************************
 * Copyright (C) 2019-2023 Maxim Integrated Products, Inc., All rights Reserved.
 *
 * This software is protected by copyright laws of the United States and
 * of foreign countries. This material may also be protected by patent laws
 * and technology transfer regulations of the United States and of foreign
 * countries. This software is furnished under a license agreement and/or a
 * nondisclosure agreement and may only be used or reproduced in accordance
 * with the terms of those agreements. Dissemination of this information to
 * any party or parties not specified in the license agreement and/or
 * nondisclosure agreement is expressly prohibited.
 *
 * The above copyright notice and this permission notice shall be included
 * in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
 * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL MAXIM INTEGRATED BE LIABLE FOR ANY CLAIM, DAMAGES
 * OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 *
 * Except as contained in this notice, the name of Maxim Integrated
 * Products, Inc. shall not be used except as stated in the Maxim Integrated
 * Products, Inc. Branding Policy.
 *
 * The mere transfer of this software does not imply any licenses
 * of trade secrets, proprietary technology, copyrights, patents,
 * trademarks, maskwork rights, or any other form of intellectual
 * property whatsoever. Maxim Integrated Products, Inc. retains all
 * ownership rights.
 *******************************************************************************/

// mnist
// This file was @generated by ai8xize.py --test-dir sdk/Examples/MAX78000/CNN --prefix mnist --checkpoint-file trained/ai85-mnist-qat8-q.pth.tar --config-file networks/mnist-chw-ai85.yaml --softmax --device MAX78000 --timer 0 --display-checkpoint --verbose

#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#include "mxc.h"
#include "cnn.h"
#include "sampledata.h"
#include "sampleoutput.h"
#include "weights.h"
#include "math.h"
#include "backpropagation.h"
#include "training_samples.h"
#include "training_labels.h"
#include "testing_samples.h"
#include "testing_labels.h"

volatile uint32_t timer;

uint8_t weights[10][192] = {0};

int8_t biases[10] = {0};

static int prediction[CNN_NUM_OUTPUTS][CNN_NUM_OUTPUTS_FROZEN_LAYER] = {0};

float learning_rate = 0.5;

int true_output[CNN_NUM_OUTPUTS] = {1, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static int cost[10] = {0};

int deltaW = 0;
static int dW[CNN_NUM_OUTPUTS][CNN_NUM_OUTPUTS_FROZEN_LAYER] = {0};
static int32_t ml_data[CNN_NUM_OUTPUTS];
static int32_t ml_data_frozen[CNN_NUM_OUTPUTS_LAYER_0];
static int8_t output_L0[CNN_NUM_OUTPUTS_FROZEN_LAYER] = {0};

static q15_t ml_softmax[CNN_NUM_OUTPUTS];

volatile uint32_t cnn_time; // Stopwatch
volatile uint32_t timestamp;
int input_test;
static uint32_t *training_input;
int input_t = 0;

void fail(void)
{
	printf("\n*** FAIL ***\n\n");
	while (1)
		;
}

// 1-channel 28x28 data input (784 bytes / 196 32-bit words):
// CHW 28x28, channel 0
static const uint32_t input_0[] = SAMPLE_INPUT_0;

void load_input(void)
{
	// This function loads the sample data input -- replace with actual data

	memcpy32((uint32_t *)0x50400000, input_0, 196);
}

float *calculate_output_error(q15_t output_batch[], int target[], int dim_vec)
{
	float *output_error = (float *)malloc(dim_vec * sizeof(float));
	if (output_error == NULL)
	{
		perror("Memory allocation failed");
		exit(EXIT_FAILURE);
	}

	for (int i = 0; i < dim_vec; i++)
	{

		float output_float = (float)output_batch[i] / 32768.0f; // Convert q15 to float

		// printf("%.2f ", output_float);
		output_error[i] = output_float - target[i]; // Error calculation
	}
	// printf("\n\n");
	return output_error;
}

void load_training_input(void)
{
	if (input_t == 10)
		input_t = 0;

	training_input = (uint32_t *)samples_training[input_t];
	memcpy32((uint32_t *)0x50400000, training_input, 1024);
	input_t += 1;
}

void load_testing_input(void)
{
	if (input_test == 10)
		input_test = 0;

	training_input = (uint32_t *)samples_testing[input_test];
	memcpy32((uint32_t *)0x50400000, training_input, 1024);
}

void print_inference_result(void)
{
	int digs, tens;

	printf("Classification results:\n");
	for (int i = 0; i < CNN_NUM_OUTPUTS; i++)
	{
		digs = (1000 * ml_softmax[i] + 0x4000) >> 15;
		tens = digs % 10;
		digs = digs / 10;
		printf("[%7d] -> Class %d: %d.%d%%\n", ml_data[i], i, digs, tens);
	}
}

void print_p_out(q15_t *p_out, uint16_t dim_vec)
{
	for (int i = 0; i < dim_vec; i++)
	{
		float f_out = p_out[i] / 32768.0f; // Convert q15 to float
		printf("p_out[%d] = %f  ", i, f_out);
	}
}

// Expected output of layer 4 for mnist given the sample input (known-answer test)
// Delete this function for production code
static const uint32_t sample_output[] = SAMPLE_OUTPUT;
int check_output(void)
{
	int i;
	uint32_t mask, len;
	volatile uint32_t *addr;
	const uint32_t *ptr = sample_output;

	while ((addr = (volatile uint32_t *)*ptr++) != 0)
	{
		mask = *ptr++;
		len = *ptr++;
		for (i = 0; i < len; i++)
			if ((*addr++ & mask) != *ptr++)
			{
				printf("Data mismatch (%d/%d) at address 0x%08x: Expected 0x%08x, read 0x%08x.\n",
					   i + 1, len, addr - 1, *(ptr - 1), *(addr - 1) & mask);
				return CNN_FAIL;
			}
	}

	return CNN_OK;
}

// Classification layer:
static int32_t ml_data[CNN_NUM_OUTPUTS];
static q15_t ml_softmax[CNN_NUM_OUTPUTS];

void softmax_layer(void)
{
	cnn_unload((uint32_t *)ml_data);
	softmax_q17p14_q15((const q31_t *)ml_data, CNN_NUM_OUTPUTS, ml_softmax);
}

void backward_pass(uint8_t input_sample[10][192], float output_error[10], float grad_weights[10][192], float grad_biases[10])
{
	for (int i = 0; i < 10; i++)
	{
		grad_biases[i] = 0;
		for (int j = 0; j < 192; j++)
		{
			grad_weights[i][j] = 0;
		}
	}
	// Compute gradients for the single sample
	for (int i = 0; i < 10; i++)
	{
		grad_biases[i] += output_error[i];
		for (int j = 0; j < 192; j++)
		{
			float input = 0;
			for (int col = 0; col < 10; col++)
			{
				input += mod2(input_sample[col][j]);
			}
			grad_weights[i][j] += output_error[i] * input;
		}
		// printf("%.2f  ", output_error[i]);
	}
}

void update_weights(uint8_t weights[10][192], int8_t biases[10],
					float grad_weights[10][192], float grad_biases[10],
					float learning_rate)
{
	for (int i = 0; i < 10; i++)
	{
		int8_t bias_d = biases[i];
		bias_d -= (int)(learning_rate * grad_biases[i]);
		if (mod2(bias_d) < -128)
			bias_d = -128;
		if (mod2(bias_d) > 127)
			bias_d = 127;
		biases[i] = (int8_t)bias_d;

		for (int j = 0; j < 192; j++)
		{
			uint8_t weight = weights[i][j];
			if (i == 0)
			{
				// printf("Weight is %d ", mod2(weight));
				// printf("Weight is being changed by %.3f ", (learning_rate * grad_weights[i][j]));
			}

			weight -= (int)(learning_rate * grad_weights[i][j]);
			// if (i==0)
			//  printf("Weight is now %d ,", mod2(weight));

			if (mod2(weight) < -128)
				weight = -128;
			if (mod2(weight) > 127)
				weight = 127;
			weights[i][j] = (uint8_t)weight;
			// if (i== 0)
			//  printf("Just checking here %d \n\n", mod2(weights[i][j]));
		}
	}
}

int main(void)
{
	int i;
	int digs, tens;

	MXC_ICC_Enable(MXC_ICC0); // Enable cache

	// Switch to 100 MHz clock
	MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
	SystemCoreClockUpdate();

	printf("Waiting...\n");

	// DO NOT DELETE THIS LINE:
	MXC_Delay(SEC(2)); // Let debugger interrupt if needed

	// Enable peripheral, enable CNN interrupt, turn on CNN clock
	// CNN clock: APB (50 MHz) div 1
	cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_PCLK, MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1);

	printf("Inference layer by layer on MAX78000");

	int layer_count = 0;
	for (int j = 0; j < 10; j++)
	{
		printf("\n\n Starting next trial \n\n");

		cnn_init();
		cnn_load_weights();
		cnn_load_bias();

		for (layer_count = 0; layer_count < LAYER_NUM; layer_count = get_next_OS_layers(layer_count))
		{
			cnn_set_layer_count(layer_count);
			cnn_config_layer(layer_count);

			if (layer_count == 0)
			{
				load_testing_input();
			}
			cnn_start();

			while (cnn_time == 0)
			{
				__WFI();
			}

			if (layer_count == 0)
			{
				cnn_unload_frozen_layer((uint32_t *)ml_data_frozen);
				output_layer_3(ml_data_frozen, output_L0);

				get_weights(weights);
				int predict[10] = {0};
				for (int i = 0; i < 10; ++i)
				{
					// printf("Row %d: ", i);
					for (int m = 0; m < 192; ++m)
					{
						// printf("%d ", mod2(weights[m][i]));
						predict[i] += (mod2(weights[i][m]) * output_L0[m]);
						// printf("%d, ", mod2(weights[i][m]));
						// printf("%d, ", output_L0[m]);
						//  printf("==== %d", predict[i]);
						// printf("\n\n");
					}
					// printf("%d", predict[i]);
					// printf("\n");
				}
			}
			cnn_stop_SMs();
		}

		softmax_layer();

		print_p_out(ml_softmax, CNN_NUM_OUTPUTS);

		input_test++;
	}

	float grad_weights[10][192];
	float grad_biases[10];

	for (int epoch = 0; epoch < 10; epoch++)
	{
		printf("Epoch %d \n\n ", epoch);

		MXC_TMR_SW_Start(MXC_TMR1);

		for (int image_index = 0; image_index < 10; image_index++)
		{
			cnn_init();
			cnn_load_weights();
			cnn_load_bias();

			int layer_count = 0;

			for (layer_count = 0; layer_count < LAYER_NUM; layer_count = get_next_OS_layers(layer_count))
			{
				cnn_set_layer_count(layer_count);
				cnn_config_layer(layer_count);

				if (layer_count == 0)
				{
					load_training_input();
				}

				cnn_start();
				while (cnn_time == 0)
				{
					__WFI();
				}

				if (layer_count == 0)
				{
					cnn_unload_frozen_layer((uint32_t *)ml_data_frozen);
					output_layer_3(ml_data_frozen, output_L0);

					get_weights(weights);
					int predict[10] = {0};

					for (int i = 0; i < 10; ++i)
					{
						for (int m = 0; m < 192; ++m)
						{
							predict[i] += (mod2(weights[i][m]) * output_L0[m]);
						}
					}
					cnn_stop_SMs();
				}
			}

			softmax_layer();

			float *output_error = calculate_output_error(ml_softmax, labels_training[input_t], 10);
			// connect loss function to this
			/*
	 printf("Output error: \n");
	 for (int l = 0; l < 10; l++)
					 {
						 printf("%.3f ", output_error[l] );
					 }
					 printf("\n\n"); */

			backward_pass(weights, output_error, grad_weights, grad_biases);

			// printf("Grad of Weights: \n");
			// for (int col = 0; col < 10; col++)
			//{
			// for (int row = 0; row < 10; row++)
			//{
			// printf("%.3f  ", grad_weights[col][row]);
			//}
			//}

			update_weights(weights, biases, grad_weights, grad_biases, learning_rate);

			set_weights(weights);
			// set_bias(biases);
		}

		timer = MXC_TMR_SW_Stop(MXC_TMR1);
		printf("Epoch finished in %u seconds\n\n\n", timer / 1000000);
	}

	input_test = 0;
	layer_count = 0;
	for (int j = 0; j < 10; j++)
	{
		printf("\n\n Starting next trial \n\n");

		cnn_init();
		cnn_load_weights();
		cnn_load_bias();

		for (layer_count = 0; layer_count < LAYER_NUM; layer_count = get_next_OS_layers(layer_count))
		{
			cnn_set_layer_count(layer_count);
			cnn_config_layer(layer_count);

			if (layer_count == 0)
			{
				load_testing_input();
			}
			cnn_start();

			while (cnn_time == 0)
			{
				__WFI();
			}

			if (layer_count == 0)
			{
				cnn_unload_frozen_layer((uint32_t *)ml_data_frozen);
				output_layer_3(ml_data_frozen, output_L0);
			}

			cnn_stop_SMs();
		}

		softmax_layer();

		print_p_out(ml_softmax, CNN_NUM_OUTPUTS);
		input_test++;
	}

	/*
		// Starting the training loop



			for (int j = 0; j < 1; j++)
			{
				cnn_init();
				cnn_load_weights();
				cnn_load_bias();


			for (int epoch = 0; epoch < 1; epoch++)
			{

				cnn_init();
				cnn_load_weights();
				cnn_load_bias();


				for (int batch_index = 0 ; batch_index < 1; batch_index++)
				{
					// CHANGE THE LOAD BOATCH
					//load_batch(input_batch, target_batch, batch_index, batch_size);


				   int layer_count = 0;

					// populate output batch from the output of the conv4
				   for (layer_count = 0; layer_count < LAYER_NUM; layer_count = get_next_OS_layers(layer_count))
				   {
					   cnn_set_layer_count(layer_count);
					   cnn_config_layer(layer_count);

					   if (layer_count == 0)
					   {
						   load_training_input();
					   }

					   cnn_start();
					   while (cnn_time == 0)
					   {
						   __WFI();
					   }

					   if (layer_count == 0)
					   {
						   cnn_unload_frozen_layer((uint32_t *)ml_data_frozen);
						   output_layer_3(ml_data_frozen, output_L0);

						   get_weights(weights);
						   int predict[10] = {0};

						   for (int i = 0; i < 10; ++i) {
							   // printf("Row %d: ", i);

							   for (int m = 0; m < 192; ++m) {
								   // printf("%d ", mod2(weights[m][i]));
								   predict[i] += (mod2(weights[i][m]) * output_L0[m]);

								   //printf("%d, ", mod2(weights[i][m]));
								   //printf("%d, ", output_L0[m]);
								   //printf("==== %d", predict[i]);
									  //printf("\n\n");
									  //printf("%d", predict[i]);
									  //printf("\n");
								  }
						   }
						   cnn_stop_SMs();
						  }
					   }

				   softmax_layer();




				   float* output_error = calculate_output_error(ml_softmax, labels_training[1], 10);
					// connect loss function to this
					  /*
				   printf("Output error: \n");
				   for (int l = 0; l < 10; l++)
				   {
					   printf("%.3f ", output_error[l] );
				   }
				   printf("\n\n");
				   */

	/*

				  backward_pass(weights, output_error, grad_weights, grad_biases);

				 printf("Grad of Weights: \n");
				  for (int col = 0; col < 10; col++)
				  {
					  for (int row = 0; row < 10; row++)
					  {
						  printf("%.3f  ", grad_weights[col][row]);
					  }
				  }


				  update_weights(weights, biases, grad_weights, grad_biases, learning_rate);

				}
			}

  #ifdef CNN_INFERENCE_TIMER
	printf("Approximate inference time: %u us\n\n", cnn_time);
  #endif

	/*
	for (int f = 0; f < CNN_NUM_OUTPUTS; f++) {
			for (int place = 0; place < CNN_NUM_OUTPUTS_FROZEN_LAYER; place++) {
				predict[f] += (mod2(weights[place][f]) * output_L0[place]);
				prediction[f][place] = (mod2(weights[place][f]) * mod2(output_L0[place]));

				printf("%d, ", mod2(weights[place][f]));
				printf("%d, ", output_L0[place]);
				printf("==== %d", predict[f]);
				printf("\n\n");

			}
			printf("%d", predict[f]);
			printf("\n\n");
		}
  */

	/*
	}


	printf("\n*** CNN Inference Test mnist ***\n");

	cnn_init(); // Bring state machine into consistent state
	cnn_load_weights(); // Load kernels
	cnn_load_bias();
	cnn_configure(); // Configure state machine
	load_input(); // Load data input
	cnn_start(); // Start CNN processing

	while (cnn_time == 0)
	  MXC_LP_EnterSleepMode(); // Wait for CNN

	if (check_output() != CNN_OK) fail();
	softmax_layer();

	printf("\n*** PASS ***\n\n");

  #ifdef CNN_INFERENCE_TIMER
	printf("Approximate inference time: %u us\n\n", cnn_time);
  #endif

	cnn_disable(); // Shut down CNN clock, disable peripheral

	print_p_out(ml_softmax, CNN_NUM_OUTPUTS);


	printf("Classification results:\n");
	for (i = 0; i < CNN_NUM_OUTPUTS; i++) {
	  digs = (1000 * ml_softmax[i] + 0x4000) >> 15;
	  tens = digs % 10;
	  digs = digs / 10;
	  printf("[%7d] -> Class %d: %d.%d%%\n", ml_data[i], i, digs, tens);

	}

	*/

	return 0;
}

/*
  SUMMARY OF OPS
  Hardware: 10,883,968 ops (10,751,808 macc; 128,576 comp; 3,584 add; 0 mul; 0 bitwise)
	Layer 0: 470,400 ops (423,360 macc; 47,040 comp; 0 add; 0 mul; 0 bitwise)
	Layer 1: 8,356,800 ops (8,294,400 macc; 62,400 comp; 0 add; 0 mul; 0 bitwise)
	Layer 2: 1,954,304 ops (1,935,360 macc; 18,944 comp; 0 add; 0 mul; 0 bitwise)
	Layer 3: 100,544 ops (96,768 macc; 192 comp; 3,584 add; 0 mul; 0 bitwise)
	Layer 4: 1,920 ops (1,920 macc; 0 comp; 0 add; 0 mul; 0 bitwise)

  RESOURCE USAGE
  Weight memory: 71,148 bytes out of 442,368 bytes total (16.1%)
  Bias memory:   10 bytes out of 2,048 bytes total (0.5%)
*/
